[["index.html", "Appunti di Costruzione e validazione di strumenti di misura dell’efficacia dell’intervento psicologico in neuropsicologia – B020881 (B213) Benvenuti", " Appunti di Costruzione e validazione di strumenti di misura dell’efficacia dell’intervento psicologico in neuropsicologia – B020881 (B213) Corrado Caudek 2023-02-11 Benvenuti Benvenuti nella versione online di Costruzione e validazione di strumenti di misura dell’efficacia dell’intervento psicologico in neuropsicologia. Questo sito web contiene il materiale didattico dell’insegnamento B020881 (B213) rivolto agli studenti del secondo anno del Corso di Laurea Magistrale in Psicologia Clinica e della Salute e Neuropsicologia (curriculum: assessment e intervento psicologici in neuropsicologia - E21), A.A. 2021-2022. L’insegnamento si propone di fornire agli studenti un’introduzione all’assessment psicologico, ovvero un insieme di conoscenze/competenze che si pongono all’intersezione tra psicometria, statistica e informatica. Nello specifico, l’insegnamento si focalizzerà sull’analisi fattoriale confermativa (confermatory factor analysis, CFA) e sull’analisi fattoriale esplorativa, (explorative factor analysis, EFA), cioè sugli strumenti che vengono usati durante il processo di sviluppo dei test psicometrici, ovvero che vengono usati per esaminare la struttura latente di una scala psicologica (ad esempio un questionario). In questo contesto, la CFA viene utilizzata per verificare il numero di dimensioni sottostanti gli indicatori (fattori) e l’intensità delle relazioni item-fattore (saturazioni fattoriali). La CFA consente anche di capire di come dovrebbe essere svolto lo scoring di un test. Quando la struttura latente è multifattoriale (cioè, a due o più fattori), il numero di fattori è indicativo del numero di sottoscale e di come esse dovrebbero essere codificate. La CFA è un importante strumento analitico anche per altri aspetti della valutazione psicometrica. Può essere utilizzata per stimare l’affidabilità di scala dei test psicometrici in modo da evitare i problemi della teoria classica dei test (ad es. alpha di Cronbach). Dati i recenti progressi nell’analisi dei dati categoriali, ora la CFA offre un quadro analitico comparabile a quello offerto dalla teoria di risposta agli item (IRT). In effetti, secondo Brown (2015), la CFA offre una maggiore flessibilità analitica rispetto al modello IRT tradizionale. Un costrutto è un concetto teorico che può essere operazionalizzato nei termini di un fattore. In psicologia clinica, psichiatria e neuropsicologia, ad esempio, i disturbi mentali sono costrutti manifestati da vari insiemi di sintomi che sono riportati dal paziente o osservati da altri. La CFA è uno strumento analitico indispensabile per la validazione dei costrutti psicologici. I risultati della CFA possono fornire prove convincenti della validità convergente e discriminante dei costrutti teorici. La validità convergente è indicata dall’evidenza che diversi indicatori di costrutti teoricamente simili o sovrapposti sono fortemente correlati. La validità discriminante è indicata dai risultati che mostrano che gli indicatori di costrutti teoricamente distinti sono altamente incorrelati. Un punto di forza fondamentale degli approcci CFA per la costruzione e la validazione di uno strumento psicometrico è che le risultanti stime di validità convergente e discriminante sono corrette per l’errore di misurazione. Pertanto, la CFA fornisce un quadro analitico migliore rispetto ai metodi tradizionali che non tengono conto dell’errore di misurazione (ad esempio, gli approcci ordinari ai minimi quadrati come la correlazione/regressione multipla, i quali presuppongono che le variabili nell’analisi siano prive di errori di misurazione). Spesso, parte della covariazione delle misure osservate è dovuta a fonti diverse dai fattori latenti di interesse. Questa covariazione aggiuntiva spesso riflette la varianza del metodo utilizzato per la misurazione. Gli effetti del metodo possono verificarsi anche all’interno di un’unica modalità di valutazione. Ad esempio, effetti del metodo sono solitamente presenti nei questionari che contengono una combinazione di elementi formulati positivamente e negativamente. Sfortunatamente, l’EFA non è in grado di stimare gli effetti del metodo. In effetti, l’uso di EFA quando esistono effetti del metodo può produrre risultati fuorvianti, ovvero suggerire la presenza di fattori aggiuntivi che corrispondono invece ad artefatti della misurazione. Nella CFA, invece, gli effetti del metodo possono essere specificati come parte della teoria dell’errore del modello di misurazione. Un altro punto di forza della CFA è la sua capacità di affrontare il problema della generalizzabilità del modello di misurazione tra gruppi di individui o nel tempo. La valutazione dell’invarianza della misura è un aspetto importante dello sviluppo del test. Se un test è destinato a essere somministrato in una popolazione eterogenea, si dovrebbe stabilire che le sue proprietà di misurazione sono equivalenti in sottogruppi della popolazione (es. sesso, razza). Si dice che un test è distorto quando alcuni dei suoi elementi non misurano il costrutto sottostante in modo comparabile tra gruppi di rispondenti. Il test fornisce una stima distorta se, ad esempio, per un dato livello di vera intelligenza, gli uomini tendono a ottenere un punteggio di QI più alto rispetto alle donne. Il problema della generalizzabilità della validità del costrutto tra i gruppi può essere affrontato nella CFA esaminando gruppi multipli mediante modelli MIMIC (indicatori multipli, cause multiple). Inotre, è possibile chiedersi se il modello di misurazione sia equivalente tra i gruppi. Le soluzioni CFA a gruppi multipli vengono anche utilizzate per esaminare l’invarianza della misurazione longitudinale. Questo è un aspetto molto importante dell’analisi delle variabili latenti dei progetti di misure ripetute. In assenza di tale valutazione, non è possibile determinare se il cambiamento temporale in un costrutto sia dovuto a un vero cambiamento dei rispondenti o a cambiamenti nel modo di rispondere alla scala nel tempo. L’analisi a gruppi multipli può essere applicata a qualsiasi tipo di modello CFA. Ad esempio, queste procedure possono essere incorporate nell’analisi dei dati multitratto-multimetodo per esaminare la generalizzabilità della validità del costrutto tra gruppi. In questo insegnamento la discussione delle teciche della CFA sarà preceduta da un’introduzione relativa alla EFA e la teoria classica dei test. La EFA, infatti, può essere concepita il metodo che viene utilizzato nei primi passi dello sviluppo di una scala psicometria, mentre la teoria classica dei test rappresenta la cornice teorica di partenza, di cui la CFA e i modelli di equazioni strutturali costituiscono uno sviluppo. L’insegnamento pone una grande enfasi non solo sulla comprensione dei concetti teorici necessari per la costruzione e la validazione di uno strumento di misura in psicologia, ma anche sulla capacità di applicare tali concetti in situazioni concrete. Di conseguenza, la discussione dei concetti sarà sempre accompagnata da applicazioni pratiche. Tali applicazioni richiedono l’uso di un software. In questo insegnamento useremo \\(\\textsf{R}\\) (R Core Team 2021) quale linguaggio di programmazione probabilistica e, tra gli altri, il pacchetto lavaan che consente di svolgere le analisi statistiche della CFA e della EFA (Beaujean 2014). La teoria classica dei test verrà descritta con riferimento al classico testo di Lord and Novick (1968). Questa dispensa, inoltre, segue da vicino la trattazione della CFA fornita nei testi di McDonald (2013) e di Brown (2015). Trattando di argomenti avanzati, questo insegnamento presuppone la conoscenza di base dei concetti fondamentali della teoria delle probabilità; presuppone inoltre il possesso delle conoscenze di base necessarie per procedere all’utilizzo di \\(\\textsf{R}\\). Informazioni su tali argomenti sono forniti nella dispensa di Psicometria (A.A. 2021-2022). Corrado Caudek Marzo 2023 References "],["license.html", "License", " License The online version of this book is licensed under the Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License. The code is public domain, licensed under Creative Commons CC0 1.0 Universal (CC0 1.0). "],["lanalisi-di-regressione.html", "Capitolo 1 L’analisi di regressione", " Capitolo 1 L’analisi di regressione La conoscenza dell’analisi di regressione è necessaria per capire la teoria classica dei test, l’analisi fattoriale e i modelli di equazioni strutturali. Sebbene le tecniche dell’analisi di regressione analizzino solo le variabili osservate, i principi della regressione costituiscono la base delle tecniche più avanzate che includono anche le variabili latenti. "],["regressione-bivariata.html", "1.1 Regressione bivariata", " 1.1 Regressione bivariata Il modello di regressione bivariata descrive l’associazione tra il valore atteso di \\(Y \\mid x_i\\) e \\(x\\) nei termini di una relazione lineare: \\[ \\mathbb{E}(Y \\mid x_i) = \\alpha + \\beta x_i, \\] dove i valori \\(x_i\\) sono considerati fissi per disegno. Nel modello “classico”, si assume che le distribuzioni \\(Y \\mid x_i\\) siano Normali con deviazione standard \\(\\sigma_\\varepsilon\\). Il significato dei coefficienti di regressione è semplice: \\(\\alpha\\) è il valore atteso di \\(Y\\) quando \\(X = 0\\); \\(\\beta\\) è l’incremento atteso nel valore atteso di \\(Y\\) quando \\(X\\) aumenta di un’unità. Il modello statistico della regressione bivariata è rappresentato nella figura seguente. Per fare un esempio pratico, consideriamo i dati dell’antropologo Sahlins, il quale si è chiesto se esiste un’associazione tra l’ampiezza del clan (consumers) e l’area occupata da quel clan (acres) in una popolazione di cacciatori-raccoglitori. I dati sono i seguenti: data(Sahlins) head(Sahlins) #&gt; consumers acres #&gt; 1 1.00 1.71 #&gt; 2 1.08 1.52 #&gt; 3 1.15 1.29 #&gt; 4 1.15 3.09 #&gt; 5 1.20 2.21 #&gt; 6 1.30 2.26 Sahlins %&gt;% ggplot(aes(x = consumers, y = acres)) + geom_point() + geom_smooth(method = lm, se = FALSE) fm &lt;- lm(acres ~ consumers, data = Sahlins) fm$coef #&gt; (Intercept) consumers #&gt; 1.3756445 0.5163201 Dalla figura notiamo che, se consumers aumenta di un’unità (da 1.2 a 2.2), allora la retta di regressione (ovvero, il valore atteso di \\(Y\\)) aumenta di circa 0.5 punti – esattamente, aumenta di 0.5163 punti, come indicato dalla stima del coefficiente \\(\\beta\\). L’interpretazione del coefficiente \\(\\alpha\\) è più problematica, perché non ha senso pensare ad un clan di ampiezza 0. Per affrontare questo problema, centriamo il predittore. 1.1.1 Regressori centrati Esprimiamo la variabile consumers nei termini degli scarti dalla media: Sahlins &lt;- Sahlins %&gt;% mutate( xc = consumers - mean(consumers) ) Svolgiamo nuovamente l’analisi di regressione con il nuovo predittore: fm1 &lt;- lm(acres ~ xc, data = Sahlins) fm1$coef #&gt; (Intercept) xc #&gt; 2.1620000 0.5163201 Sahlins %&gt;% ggplot(aes(x = xc, y = acres)) + geom_point() + geom_smooth(method = lm, se = FALSE) La stima di \\(\\beta\\) è rimasta invariata ma ora possiamo attribuire un significato alla stima di \\(\\alpha\\): questo coefficiente indica il valore atteso della \\(Y\\) quando \\(X\\) assume il suo valore medio. 1.1.2 Minimi quadrati La stima dei coefficienti del modello di regressione può essere effettuata in modi diversi: massima verosimiglianza o metodi bayesiani. Se ci limitiamo qui alla massima verosimiglianza possiamo semplificare il problema assumento che le distribuzioni condizionate \\(Y \\mid x\\) siano Normali. In tali circostanze, la stima dei coefficienti del modello di regressione può essere trovata con il metodo dei minimi quadrati. In pratica, questo significa trovare i coefficienti \\(a\\) e \\(b\\) che minimizzano \\[ SS_{\\text{res}} = \\sum(y_i - \\hat{y}_i)^2, \\] con \\(\\hat{y}_i = a + b x_i\\). Per fornire un’idea di come questo viene fatto, usiamo una simulazione. Per semplicità, supponiamo di conoscere \\(a = 1.3756445\\) e di volere stimare \\(b\\). x &lt;- Sahlins$consumers y &lt;- Sahlins$acres a &lt;- 1.3756445 nrep &lt;- 1e3 b &lt;- seq(0, 1, length.out = nrep) ssres &lt;- rep(NA, nrep) for (i in 1:nrep) { yhat &lt;- a + b[i] * x ssres[i] &lt;- sum((y - yhat)^2) } Un grafico di \\(SS_{\\text{res}}\\) in funzione di \\(b\\) mostra che il valore \\(b\\) che minimizza \\(SS_{\\text{res}}\\) corrisponde, appunto, a 0.5163. tibble(b, ssres) %&gt;% ggplot(aes(x = b, y = ssres)) + geom_line() 1.1.3 Relazione tra \\(b\\) e \\(r\\) Un altro modo per interpretare \\(b\\) è quello di considerare la relazione tra la pendenza della retta di regressione e il coefficiente di correlazione: \\[ b_X = r_{XY} \\frac{S_X}{S_Y} \\] L’equazione precedente rende chiaro che, se i dati sono standardizzati, \\(b = r\\). Verifichiamo: Sahlins %&gt;% dplyr::select(acres, consumers) %&gt;% cor() #&gt; acres consumers #&gt; acres 1.0000000 0.3756561 #&gt; consumers 0.3756561 1.0000000 fm2 &lt;- lm(scale(acres) ~ scale(consumers), data = Sahlins) fm2$coef #&gt; (Intercept) scale(consumers) #&gt; 9.917106e-17 3.756561e-01 1.1.4 Attenuazione Il fenomeno dell’attenuazione si verifica quando \\(X\\) viene misurato con una componente di errore. Esaminiamo la seguente simulazione. set.seed(1234) n &lt;- 100 x &lt;- rnorm(n, 10, 1.5) y &lt;- 1.5 * x + rnorm(n, 0, 2) tibble(x, y) %&gt;% ggplot(aes(x, y)) + geom_point() sim_dat &lt;- tibble(x, y) fm &lt;- lm(y ~ x, sim_dat) fm$coef #&gt; (Intercept) x #&gt; 0.4221074 1.4652201 Questi sono i coefficienti di regressione quando \\(X\\) è misurata senza errori. sim_dat &lt;- sim_dat %&gt;% mutate( x1 = x + rnorm(n, 0, 2) ) fm1 &lt;- lm(y ~ x1, sim_dat) fm1$coef #&gt; (Intercept) x1 #&gt; 8.3872176 0.6295924 Aggiungendo una componente d’errore su \\(X\\), la grandezza del coefficiente \\(b\\) diminuisce. 1.1.5 Coefficiente di determinazione Tecnicamente, il coefficiente di determinazione è dato da: \\[ R^2 = \\frac{\\sum(\\hat{y} - \\bar{y})^2}{\\sum(y_i - \\bar{y})^2} \\] Al denominatore abbiamo la devianza totale, ovvero una misura della dispersione di \\(y_i\\) rispetto alla media \\(\\bar{y}\\). Al numeratore abbiamo una misura della dispersione del valore atteso della \\(Y\\) rispetto alla sua media. Il rapporto, dunque, ci dice qual è la quota della variabilità totale di \\(Y\\) che può essere predetta in base al modello lineare. Per i dati di Sahlins abbiamo: mod &lt;- lm(acres ~ consumers, data = Sahlins) a &lt;- mod$coef[1] b &lt;- mod$coef[2] yhat &lt;- a + b * Sahlins$consumers ss_tot &lt;- sum((Sahlins$acres - mean(Sahlins$acres))^2) ss_reg &lt;- sum((yhat - mean(Sahlins$acres))^2) r2 &lt;- ss_reg / ss_tot r2 #&gt; [1] 0.1411175 Verifichiamo: summary(mod) #&gt; #&gt; Call: #&gt; lm(formula = acres ~ consumers, data = Sahlins) #&gt; #&gt; Residuals: #&gt; Min 1Q Median 3Q Max #&gt; -0.8763 -0.1873 -0.0211 0.2135 1.1206 #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error t value Pr(&gt;|t|) #&gt; (Intercept) 1.3756 0.4684 2.937 0.00881 ** #&gt; consumers 0.5163 0.3002 1.720 0.10263 #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; #&gt; Residual standard error: 0.4543 on 18 degrees of freedom #&gt; Multiple R-squared: 0.1411, Adjusted R-squared: 0.0934 #&gt; F-statistic: 2.957 on 1 and 18 DF, p-value: 0.1026 Da cui deriva che \\(R^2\\) è uguale al quadrato del coefficiente di correlazione: cor(Sahlins$acres, Sahlins$consumers)^2 #&gt; [1] 0.1411175 1.1.6 Errore standard della regressione L’errore standard della regressione è una stima della dispersione di \\(y \\mid x_i\\) nella popolazione. Non è altro che la deviazione standard dei residui \\[ e = y_i - \\hat{y}_i \\] che, al denominatore, riporta \\(n-2\\). La ragione è che, per calcolare \\(\\hat{y}\\), vengono “perduti” due gradi di libertà – il calcolo di \\(\\hat{y}\\) è basato sulla stima di due coefficienti: \\(a\\) e \\(b\\). e &lt;- yhat - Sahlins$acres (sum(e^2) / (length(Sahlins$acres) - 2)) %&gt;% sqrt() #&gt; [1] 0.4543179 Il valore trovato corrisponde a quello riportato nell’output di lm(). "],["regressione-multipla.html", "1.2 Regressione multipla", " 1.2 Regressione multipla Nella regressione multipla vengono utilizzati \\(k &gt; 1\\) predittori: \\[ y_i = \\alpha + \\sum_{j=1}^k \\beta_j x_i + \\varepsilon_i. \\] L’interpretazione geometrica è simile a quella del modello bivariato. Nel caso di due predittori, il valore atteso della \\(y\\) può essere rappresentato da un piano; nel caso di \\(k &gt; 2\\) predittori, da un iper-piano. Nel caso di \\(k=2\\), tale piano è posto in uno spazio di dimensioni \\(x_1\\), \\(x_2\\) (che possiamo immaginare definire un piano orizzontale) e \\(y\\) (ortogonale a tale piano). La superficie piana che rappresenta \\(\\mathbb{E}(y)\\) è inclinata in maniera tale che l’angolo tra il piano e l’asse \\(x_1\\) corrisponde a \\(\\beta_1\\) e l’angolo tra il piano e l’asse \\(x_2\\) corrisponde a \\(\\beta_2\\). 1.2.1 Significato dei coefficienti parziali di regressione Ai coefficienti parziali del modello di regressione multipla possiamo assegnare la seguente interpretazione: Il coefficiente parziale di regressione \\(\\beta_j\\) rappresenta l’incremento atteso della \\(y\\) se \\(x_j\\) viene incrementata di un’unità, tenendo costante il valore delle altre variabili indipendenti. Un modo per interpretare la locuzione “al netto dell’effetto delle altre variabili indipendenti” è quello di esaminare la relazione tra la \\(y\\) parzializzata e la \\(x_j\\) parzializzata. In questo contesto, parzializzare significa decomporre una variabile di due componenti: una componente che è linearmente predicibile da una o più altre variabili e una componente che è linearmente incorrelata con tali varibili “terze”. Se eseguiamo questa “depurazione” dell’effetto delle variabili “terze” sia sulla \\(y\\) sia su \\(x_j\\), possiamo poi esaminare la relazione bivariata che intercorre tra la componente della \\(y\\) linearmente indipendente dalle variabili “terze” e la componente della \\(x_j\\) linearmente indipendente dalle variabili “terze”. Il coefficiente di regressione bivariato così ottenuto sarà identico al coefficiente parziale di regressione nel modello di regressione multipla. Questa procedura ci consente di assegnare un’interpretazione “intuitiva” al coefficiente parziale di regressione \\(\\beta_j\\). Esaminiamo un caso concreto. d &lt;- rio::import( here::here(&quot;data&quot;, &quot;kidiq.dta&quot;) ) glimpse(d) #&gt; Rows: 434 #&gt; Columns: 5 #&gt; $ kid_score &lt;dbl&gt; 65, 98, 85, 83, 115, 98, 69, 106, 102, 95, 91, 58, 84, 78, 1… #&gt; $ mom_hs &lt;dbl&gt; 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, … #&gt; $ mom_iq &lt;dbl&gt; 121.11753, 89.36188, 115.44316, 99.44964, 92.74571, 107.9018… #&gt; $ mom_work &lt;dbl&gt; 4, 4, 4, 3, 4, 1, 4, 3, 1, 1, 1, 4, 4, 4, 2, 1, 3, 3, 4, 3, … #&gt; $ mom_age &lt;dbl&gt; 27, 25, 27, 25, 27, 18, 20, 23, 24, 19, 23, 24, 27, 26, 24, … fm &lt;- lm( kid_score ~ mom_iq + mom_work + mom_age + mom_hs, data = d ) fm$coef #&gt; (Intercept) mom_iq mom_work mom_age mom_hs #&gt; 20.8226117 0.5620814 0.1337287 0.2198599 5.5611781 Eseguiamo la parzializzazione di \\(y\\) in funzione delle variabili mom_work, mom_age e mom_hs: fm_y &lt;- lm(kid_score ~ mom_work + mom_age + mom_hs, data = d) Lo stesso per mom_iq: fm_x &lt;- lm(mom_iq ~ mom_work + mom_age + mom_hs, data = d) Esaminiamo ora la regressione bivariata tra le componenti parzializzate della \\(y\\) e di \\(x_j\\): mod &lt;- lm(fm_y$residuals ~ fm_x$residuals) mod$coef #&gt; (Intercept) fm_x$residuals #&gt; -1.651851e-15 5.620814e-01 Si vede come il coefficiente di regressione bivariato risulta identico al corrispondente coefficiente parziale di regressione. 1.2.2 Relazioni causali Un altro modo per interpretare i coefficienti parziali di regressione è nell’ambito dei quelli che vengono chiamati i path diagrams. I diagrammi di percorso, che tratteremo in seguito e qui solo anticipiamo, descrivono le relazioni “causali” tra variabili: le variabili a monte del diagramma di percorso rappresentano le “cause” esogene e le variabili a valle indicano gli effetti, ovvero le variabili endogene. I coefficienti di percorso vengono rappresentati graficamente come frecce orientate e corrispondono all’effetto diretto sulla variabile verso cui punta la freccia della variabile a monte della freccia. In tale rappresentazione grafica, i coefficienti di percorso non sono altro che i coefficienti parziali di regressione del modello di regressione multipla. In questo contesto, indicano l’effetto diretto atteso sulla variabile endogena in conseguenza dell’incremento di un’unità della variabile esogena, lasciano immutate tutte le altre relazioni strutturali del modello. Usiamo la funzione sem() del pacchetto lavaan per definire il modello rappresentato nel successivo diagramma di percorso: model &lt;- &quot; kid_score ~ mom_hs + mom_iq + mom_work + mom_age &quot; Adattiamo il modello ai dati fit &lt;- sem(model, data = d) Il diagramma di percorso si ottiene con le seguenti istruzioni: semPaths( fit, &quot;est&quot;, posCol = c(&quot;black&quot;), edge.label.cex = 0.9, sizeMan = 7, what = &quot;path&quot; ) Come indicato nel diagramma, l’effetto diretto di mom_iq su kid_score è identico al corrispondente coefficiente parziale di regressione. Il problema di capire se sia appropriato utilizzare un modello di regressione per descrivere le relazioni causali tra le variabili è affrontato nel prossimo paragrafo in riferimento all’errore di specificazione. 1.2.3 Errore di specificazione Spiritosamente chiamato “heartbreak of L.O.V.E.” [Left-Out Variable Error; Mauro (1990)], l’errore di specificazione è una caratteristica fondamentale dei modelli di regressione che deve sempre essere tenuta a mente quando interpretiamo i risultati di questa tecnica di analisi statistica. L’errore di specificazione si verifica quando escludiamo dal modello di regressione una variabile che ha due caratteristiche: è associata con altre variabili inserite nel modello, ha un effetto diretto sulla \\(y\\). Come conseguenza dell’errore di specificazione, l’intensità e il segno dei coefficienti parziali di regressione risultano sistematicamente distorti. Consideriamo un esempio con dati simulati nei quali immaginiamo che la prestazione sia positivamente associata alla motivazione e negativamente associata all’ansia. Immaginiamo inoltre che vi sia una correlazione positiva tra ansia a motivazione. Ci chiediamo cosa succede al coefficiente parziale della variabile “motivazione” se la variabile “ansia” viene esclusa dal modello di regressione. set.seed(123) n &lt;- 400 anxiety &lt;- rnorm(n, 10, 1.5) motivation &lt;- 4.0 * anxiety + rnorm(n, 0, 3.5) cor(anxiety, motivation) #&gt; [1] 0.8617706 Creo la variabile performance come una combinazione lineare di motivazione e ansia nella quale la motivazione ha un effetto piccolo, ma positivo, sulla prestazione, e l’ansia ha un grande effetto negativo sulla prestazione: performance &lt;- 0.5 * motivation - 5.0 * anxiety + rnorm(n, 0, 3) Salvo i dati in un DataFrame: sim_dat2 &lt;- tibble(performance, motivation, anxiety) Eseguo l’analisi di regressione specificando in maniera corretta il modello, ovvero usando come predittori sia l’ansia che la depressione: fm1 &lt;- lm(performance ~ motivation + anxiety, sim_dat2) Le stime dei coefficienti parziali di regressione recuperano correttamente l’intensità e il segno dei coefficienti utilizzati nel modello generatore dei dati: coef(fm1) #&gt; (Intercept) motivation anxiety #&gt; 1.3711965 0.4953886 -5.1052176 Eseguo ora l’analisi di regressione ignorando il predittore anxiety che ha le due caratteristiche di essere associato a motivation e di avere un effetto diretto sulla prestazione: fm2 &lt;- lm(performance ~ motivation, sim_dat2) summary(fm2) #&gt; #&gt; Call: #&gt; lm(formula = performance ~ motivation, data = sim_dat2) #&gt; #&gt; Residuals: #&gt; Min 1Q Median 3Q Max #&gt; -13.501 -3.409 0.005 3.311 12.616 #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error t value Pr(&gt;|t|) #&gt; (Intercept) -12.39720 1.44591 -8.574 2.24e-16 *** #&gt; motivation -0.43717 0.03553 -12.305 &lt; 2e-16 *** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; #&gt; Residual standard error: 4.866 on 398 degrees of freedom #&gt; Multiple R-squared: 0.2756, Adjusted R-squared: 0.2738 #&gt; F-statistic: 151.4 on 1 and 398 DF, p-value: &lt; 2.2e-16 Si noti che, al di là della “significatività statistica” (si vedano le considerazioni fornite nel paragrafo sulla stepwise regression), il risultato prodotto dal modello di regressione è totalmente sbagliato: come conseguenza dell’errore di specificazione, il segno del coefficiente parziale di regressione della variabile “motivazione” è negativo, anche se nel modello generatore dei dati tale coefficiente aveva il segno opposto. Quindi, se interpretiamo il coefficiente parziale ottenuto in termini casuali, siamo portati a concludere che la motivazione fa diminuire la prestazione. Ma in realtà è vero l’opposto. È facile vedere perché si verifica l’errore di specificazione. Supponiamo che il vero modello sia \\[ y = \\alpha + \\beta_1 X_1 + \\beta_2 X_2 + \\varepsilon \\] il quale verrebbe stimato da \\[ y = a + b_1 X_1 + b_2 X_2 + e. \\] Supponiamo però che il ricercatore creda invece che \\[ y = \\alpha^\\prime + \\beta_1^\\prime X_1 + \\varepsilon^\\prime \\] e quindi stimi \\[ y = a^\\prime + b_1^\\prime X_1 + e^\\prime \\] omettendo \\(X_2\\) dal modello. Per capire che relazione intercorre tra \\(b_1^\\prime\\) e \\(b_1\\), iniziamo a scrivere la formula per \\(b_1^\\prime\\): \\[\\begin{equation} b_1^\\prime = \\frac{\\mbox{Cov}(X_1, Y)}{\\mbox{Var}(X_1)}. \\end{equation}\\] Sviluppando, otteniamo \\[\\begin{equation} \\begin{aligned} b_1^\\prime &amp;= \\frac{\\mbox{Cov}(X_1, a + b_1 X_1 + b_2 X_2 + e)}{\\mbox{Var}(X_1)}\\notag\\\\ &amp;= \\frac{\\mbox{Cov}(X_1, a)+b_1 \\mbox{Cov}(X_1, X_1) + b_2 \\mbox{Cov}(X_1, X_2) + \\mbox{Cov}(X_1, e)}{\\mbox{Var}(X_1)}\\notag\\\\ &amp;= \\frac{0 + b_1 \\mbox{Var}(X_1) + b_2 \\mbox{Cov}(X_1, X_2) + 0}{\\mbox{Var}(X_1)}\\notag\\\\ &amp;= b_1 + b_2 \\frac{\\mbox{Cov}(X_1, X_2)}{\\mbox{Var}(X_1)}. \\end{aligned} \\end{equation}\\] Quindi, se erroneamente omettiamo \\(X_2\\) dal modello, abbiamo che \\[\\begin{equation} \\mathbb{E}(b_1^\\prime) = \\beta_1 + \\beta_2 \\frac{\\sigma_{12}}{\\sigma_1^2}. \\tag{1.1} \\end{equation}\\] Verifichiamo tale conclusione per i dati dell’esempio che stiamo discutendo. Nel caso presente, \\(X_1\\) è motivation e \\(X_2\\) è anxiety. Applicando la (1.1) otteniamo lo stesso valore per il coefficiente di regressione associato a motivation che era stato ottenuto adattando ai dati il modello performance ~ motivation: fm1$coef[2] + fm1$coef[3] * cov(sim_dat2$motivation, sim_dat2$anxiety) / var(sim_dat2$motivation) #&gt; motivation #&gt; -0.4371675 Possiamo dunque concludere che \\(b_1^\\prime\\) è uno stimatore distorto di \\(\\beta_1\\). Si noti che questa distorsione non scompare all’aumentare della numerosità campionaria, il che (in termini statistici) significa che un tale stimatore è inconsistente. Quello che succede in pratica è che alla variabile \\(X_1\\) vengono attribuiti gli effetti delle variabili che sono state omesse dal modello. Si noti che una tale distorsione sistematica di \\(b_1^\\prime\\) può essere evitata solo se si verificano due condizioni: \\(\\beta_2 = 0\\). Questo è ovvio, dato che, se \\(\\beta_2 = 0\\), ciò significa che il modello non è specificato in modo errato, cioè \\(X_2\\) non appartiene al modello perché non ha un effetto diretto sulla \\(Y\\). \\(\\sigma_{12} = 0\\). Cioè, se \\(X_1\\) e \\(X_2\\) sono incorrelate, allora l’omissione di una delle due variabili non comporta stime distorte dell’effetto dell’altra. 1.2.4 Soppressione Le conseguenze dell’errore di specificazione sono chiamate “soppressione” (suppression). In generale, si ha soppressione quando (1) il valore assoluto del peso beta di un predittore è maggiore di quello della sua correlazione bivariata con il criterio o (2) i due hanno segni opposti. L’esempio descritto sopra è un caso di soppressione negativa, dove il predittore ha correlazioni bivariate positive con il criterio, ma si riceve un peso beta negativo nell’analisi di regressione multipla. Un secondo tipo di soppressione è la soppressione classica, in cui un predittore non è correlato al criterio ma riceve un peso beta diverso da zero. C’è anche la soppressione reciproca che può verificarsi quando due variabili sono correlate positivamente con il criterio ma negativamente tra loro. 1.2.5 Stepwise regression Un’implicazione della soppressione è che i predittori non dovrebbero essere selezionati in base ai valori delle correlazioni bivariate con il criterio. Queste associazioni, dette di ordine zero, non controllano gli effetti degli altri predittori, quindi i loro valori possono essere fuorvianti rispetto ai coefficienti di regressione parziale per le stesse variabili. Per lo stesso motivo, il fatto che le correlazioni bivariate con il criterio siano statisticamente significative o meno è irrilevante per quanto riguarda la selezione dei predittori. Sebbene le procedure informatiche di regressione rendano facile i processi di selezione dei predittori in base a tali criteri, tali procedure sono da evitare. Il rischio è che anche piccole, ma non rilevate, non-linearità o effetti indiretti tra i predittori possano seriamente distocere i coefficienti di regressione parziale. È meglio selezionare giudiziosamente il minor numero di predittori sulla base di ragioni teoriche o dei risultati di ricerche precedenti. In altri termini, le procedure di stepwise regression non dovrebbero mai essere usate. Una volta che sono stati selezionati, i predittori possono essere inseriti nell’equazione di regressione in due modi diversi: tutti i predittori possono essere inseriti nel modello contemporaneamente; i predittori possono essere inseriti nel modello sequenzialmente, mediante una serie di passaggi. L’ordine di ingresso può essere determinato in base a standard: teorici (razionali) o empirici (statistici). Lo standard razionale corrisponde alla regressione gerarchica, in cui si comunica al computer un ordine fisso per inserire i predittori. Ad esempio, a volte le variabili demografiche vengono inserite nel primo passaggio, quindi nel secondo passaggio viene inserita una variabile psicologica di interesse. Questo ordine non solo controlla le variabili demografiche ma permette anche di valutare il potere predittivo della variabile psicologica, al di là di quello delle semplici variabili demografiche. Quest’ultimo può essere stimato come l’aumento della correlazione multipla al quadrato, o \\(\\Delta R^2\\), da quella della fase 1 con solo predittori demografici a quella della fase 2 con tutti i predittori nell’equazione di regressione. Un esempio di standard statistico è la regressione stepwise, in cui il computer seleziona l’inserimento dei predittori in base esclusivamente alla significatività statistica; cioè, viene chiesto: quale predittore, se inserito nell’equazione, avrebbe il valore_\\(p\\) più piccolo per il test del suo coefficiente di regressione parziale? Dopo la selezione, i predittori in una fase successiva possono essere rimossi dall’equazione di regressione in base ai loro valori-\\(p\\) (ad esempio, se \\(p \\geq\\) .05). Il processo stepwise si interrompe quando, aggiungendo più predittori, \\(\\Delta R^2\\) non migliora. Varianti della regressione stepwise includono forward inclusion, in cui i predittori selezionati non vengono successivamente rimossi dal modello, e backward elimination, che inizia con tutti i predittori nel modello per poi rimuoverne alcuni in passi successivi. Per le ragioni descritte nel paragrafo sull’errore di specificazione, i metodi basati sulle procedure di stepwise regression non dovrebbero mai essere usati. Infatti, i problemi relativi a tale procedura sono così gravi che varie riviste non accettano studi che fanno uso di una tale tecnica statistica. I risultati ottenuti con tali metodi, infatti, sono quasi certamente non replicabili in campioni diversi. Una considerazione finale riguarda l’idea di rimuovere i predittori “non significativi” dal modello di regressione. Questa è una cattiva idea. Il ricercatore non deve sentirsi in dovere di trascurare quei predittore che non risultano “statisticamente significativi”. In campioni piccoli, la potenza dei test di significatività è bassa e la rimozione di un predittore non significativo può alterare sostanzialmente la soluzione. Se c’è una buona ragione per includere un predittore, allora è meglio lasciarlo nel modello, fino a prova contraria. In termini generali, qualsiasi considerazione basata sulla “significatività statistia” è fuorviante. References "],["ch:teoria_classica.html", "Capitolo 2 Fondamenti teorici ", " Capitolo 2 Fondamenti teorici "],["valutazione-psicometrica-come-ragionamento-inferenziale.html", "2.1 Valutazione psicometrica come ragionamento inferenziale", " 2.1 Valutazione psicometrica come ragionamento inferenziale In apparenza, i test psicometrici sono solo dei test. Somministriamo un test, otteniamo un punteggio ed è naturale pensare che sia tutto lì. Nonostante le apparenze, la valutazione psicologica e neuropsicologica non consiste soltanto nell’assegnare di punteggi: si tratta di ragionare su ciò che osserviamo di quello che le persone dicono, fanno o producono, in maniera tale da giungere a delle concezioni più ampie di tali persone a proposito di aspetti che non abbiamo – e spesso non possiamo – osservare. Più specificamente, possiamo considerare la valutazione psicologica e neuropsicologica come un esempio di ragionamento che fa uso di modelli probabilistici per giungere a delle spiegazioni, previsioni o conclusioni. I dati osservati diventano un’evidenza quando sono ritenuti rilevanti per l’inferenza desiderata attraverso l’instaurazione di relazioni tra i dati e l’obiettivo dell’inferenza. Spesso utilizziamo dati provenienti da più fonti. Queste possono essere di tipo simile (ad esempio, item di test aventi lo stesso formato) o di tipo molto diverso (ad esempio, il curriculum di un richiedente oltre al colloquio, la storia medica della famiglia di un paziente, \\(\\dots\\)). Le evidenze possono essere contraddittorie (ad esempio, uno studente riesce a svolgere un compito difficile ma fallisce in un uno facile) e quasi sempre non sono del tutto conclusive. Queste caratteristiche hanno due implicazioni. In primo luogo, è difficile capire cosa le evidenze implicano. I processi inferenziali sono sempre complessi. In secondo luogo, a causa della natura non conclusiva delle evidenze disponibili, non siamo mai del tutto certi delle nostre inferenze. Per affrontare tale incertezza, la teoria psicometria ci fornisce gli strumenti che ci possono aiutare nel processo inferenziale, dai dati disponibili alle decisioni che prendiamo. Un secolo fa, la relazione tra prestazioni osservate, da un lato, e l’abilità inosservabile del rispondente, dall’altro, iniziò a essere formalizzata nei termini dell’errore di misurazione. Gulliksen (1961) ha descritto “il problema centrale della teoria dei test” come “la relazione tra l’abilità dell’individuo e il suo punteggio osservato sul test” (p. 101). Tale caratterizzazione è valida ancora oggi, con una definizione opportunamente ampia di “abilità” e di “punteggio sul test” che sia in grado di comprendere le diverse forme di assessment psicologico e neuropsicologico. Comprendere e essere in grado di rappresentare la relazione tra le prestazioni osservate e la capacità soggiacente è dunque fondamentale per le forme di ragionamento che vengono impiegate nella valutazione psicologica e neuropsicologica. Come risultato dell’errore di misurazione, i ragionamenti che compiamo nella valutazione psicologica e neuropsicologica costituiscono un esempio di ragionamento in condizioni di incertezza. A causa della natura imperfetta della misurazione e dell’incompletezza dell’informazione disponibile, le nostre inferenze sono incerte e possono essere sempre invalidate o riviste. Ragionare da ciò che è parziale (ciò che vediamo uno paziente dire, fare o produrre) a ciò che è generale (la “vera” abilità del paziente) è necessariamente incerto, e le nostre inferenze o conclusioni sono sempre prone ad errori. Quali strumenti devono essere impiegati per affrontare la nostra incertezza sulla relazione che intercorre tra prestazioni osservate e abilità soggiacenti? Secondo Lewis, molti dei progressi nella teoria psicometrica sono resi possibili “trattando lo studio della relazione tra le risposte agli item di un test e il tratto ipotizzato di un individuo come problema di inferenza statistica” (Lewis 1986). Una connessione diretta tra errore di misura e approccio probabilistico è stata anche proposta da Samejima: “There may be an enormous number of factors eliciting a student’s specific overt reactions to a stimulus, and, therefore, it is suitable, even necessary, to handle the situation in terms of the probabilistic relationship between the two” (Samejima 1983). Questo punto di vista è diventato quello dominante nella psicometria moderna e sottolinea l’utilità di utilizzare il linguaggio e gli strumenti della teoria della probabilità per comunicare il carattere parziale dei dati di cui dispone lo psicologo e l’incertezza delle inferenze che ne derivano. I reattivi psicologici possono essere costruiti e la validati mediante vari approcci probabilistici: la Teoria Classica dei test (classical test theory, in breve CTT) e la teoria di risposta all’item (item response theory, in breve IRT) sono quelli più noti. Recentemente, il problema della valutazione psicologica è stato anche formulato in un’ottica bayesiana. In questo insegnamento esamineremo la CTT e i suoi sviluppi più recenti. References "],["la-teoria-classica.html", "2.2 La Teoria Classica", " 2.2 La Teoria Classica La CTT nasce alla fine dell’Ottocento (Alfred Binet e altri, 1894) allo scopo di studiare l’attendibilità e la validità dei risultati dei questionari utilizzati per valutare le caratteristiche psico-sociali, non direttamente osservabili, delle persone esaminate. L’impiego su vasta scala e lo sviluppo della CTT ha inizio negli anni Trenta, anche se il modello formale su cui tale teoria si basa viene proposta da Spearman all’inizio del Novecento (Spearman 1904). La tecnica dell’analisi fattoriale esplorativa (Exploratory Factor Analysis, EFA), verrà poi affinata da Thurstone (1947) alla fine della seconda guerra mondiale. Tra la fine degli anni ’60 e gli inizi degli anni ’70, Jöreskog (1969) sviluppa l’analisi fattoriale confermativa (Confirmatory Factor Analysis, CFA). Negli anni ’70, l’analisi fattoriale viene integrata con la path analysis nel lavoro di Jöreskog (1978) che dà origine ai modelli di equazioni strutturali (Structural Equation Modeling, SEM). Iniziamo qui ad esaminare queste tecniche psicometriche prendendo in esame, per prima, la teoria classica dei test. Seguiremo la trattazione proposta da Lord and Novick (1968). L’equazione fondamentale alla quale si riconduce la teoria classica dei test è quella che ipotizza una relazione lineare e additiva tra il punteggio osservato di un test (\\(X\\)), la misura della variabile latente (\\(T\\)) e la componente casuale dell’errore (\\(E\\)). L’aspetto cruciale nella CTT riguarda la varianza dell’errore. Minore è la varianza dell’errore, più accuratamente il punteggio reale viene riflesso dai nostri punteggi osservati. In un mondo perfetto, tutti i valori di errore sarebbero uguali a 0. Cioè, ogni partecipante otterrebbe il punteggio esatto. Questo però non è possibile. Pertanto, abbiamo una certa varianza negli errori. La corrispondente deviazione standard di tali errori ha il un nome: si chiama errore standard di misurazione, indicato da \\(\\sigma_E\\). Uno dei principali obiettivi della CTT è quello di ottenere una stima di \\(\\sigma_E\\) in modo da potere valutare la qualità di una scala psicometrica. References "],["le-due-componenti-del-punteggio-osservato.html", "2.3 Le due componenti del punteggio osservato", " 2.3 Le due componenti del punteggio osservato CTT si occupa delle relazioni tra \\(X\\), \\(T\\) ed \\(E\\). La CTT si basa su un modello relativamente semplice in cui il punteggio osservato, nel quale il punteggio vero (cioè l’abilità inosservabile del rispondente) e l’errore aleatorio di misurazione sono legati da una relazione lineare. Indicati con \\(T_{\\nu j}\\) (true score) l’abilità latente da misurare dell’individuo \\(\\nu\\) nella prova \\(j\\), con \\(X_{\\nu j}\\) la variabile osservata (observed score) per l’individuo \\(\\nu\\) nella prova \\(j\\) e con \\(E_{\\nu j}\\) l’errore aleatorio di misurazione, il modello è \\[\\begin{equation} X_{\\nu j} = T_{\\nu} + E_{\\nu j}. \\tag{2.1} \\end{equation}\\] Dunque, in base alla (2.1) il punteggio osservato \\(X_{\\nu j}\\) differisce da quello vero \\(T_{\\nu j}\\) a causa di una componente di errore casuale la quale viene assunta essere \\(E_{\\nu j} \\sim \\mathcal{N}(0, \\sigma_E)\\). Uno degli obiettivi centrali della CTT è quello di quantificare l’entità di tale errore (ovvero, di stimare \\(\\sigma_E\\)). Vedremo come questa quantificazione verrà fornita in due forme: l’attendibilità del test e la stima dell’errore standard della misurazione. L’attendibilità (o affidabilità) rappresenta l’accuratezza con cui un test può misurare il punteggio vero (Coaley, 2014) e corrisponde al rapporto tra la varianza dei punteggi veri e la varianza dei punteggi osservati: se l’attendibilità è grande, \\(\\sigma_E\\) è piccolo – \\(X\\) ha un piccolo errore di misurazione e sarà vicino a \\(T\\). se l’attendibilità è piccola, \\(\\sigma_E\\) è grande – \\(X\\) presenta un grande errore di misurazione e si discosterà molto da \\(T\\). La stima dell’errore standard della misurazione è appunto una stima della deviazione standard della variabile casuale \\(E\\) (ovvero \\(\\sigma_E\\)) che corrompe i punteggi veri. 2.3.1 Il punteggio vero La (2.1) ci dice che il punteggio osservato è dato dalla somma di due componenti: una componente sistematica (il punteggio vero) e una componente casuale (l’errore di misurazione). Ma che cos’è il punteggio vero? CTT attribuisce diverse interpretazioni al punteggio vero. La CTT considera un reattivo psicologico come una selezione casuale di item da un universo/popolazione di item attinenti al costrutto da misurare (Nunnally 1994; Kline 2013). Se il reattivo psicologico viene concepito in questo modo, il punteggio vero diventa il punteggio che un rispondente otterrebbe se fosse misurato su tutto l’universo degli item proprio del costrutto in esame. L’errore di misurazione riflette dunque il grado in cui gli item che costituiscono il test non riescono a rappresentare l’intero universo degli item attinenti al costrutto. In maniera equivalente, il punteggio vero può essere concepito come il punteggio non “distorto” da componenti estranee al costrutto, ovvero da effetti di apprendimento, fatica, memoria, motivazione, eccetera. Essendo concepita come del tutto casuale (ovvero, priva di qualunque natura sistematica), la componente casuale non introduce alcun bias nella tendenza centrale della misurazione (la media di \\(E\\) viene assunta essere uguale a 0). In termini puramente statistici, il punteggio vero è un punteggio inosservabile che corrisponde al valore atteso di infinite realizzazioni del punteggio ottenuto: \\[ T = \\mathbb{E}(X) \\equiv \\mu_X \\equiv \\mu_{T}. \\] Combinando la seconda e la terza definizione presentate sopra, Lord and Novick (1968) concepiscono il punteggio vero come la media dei punteggi che un soggetto otterrebbe se il test venisse somministrato ripetutamente nelle stesse condizioni, in assenza di effetti di apprendimento e/o fatica. 2.3.2 Somministrazioni ripetute Nella formulazione del modello della CTT si possono distinguere due tipi di esperimenti aleatori: uno che considera l’unità di osservazione (l’individuo) come campionaria, l’altro che considera il punteggio, per un determinato individuo, come una variabile casuale. Un importante risultato è dato dall’unione dei due esperimenti casuali, ovvero dalla dimostrazione che i risultati della CTT, la quale è stata sviluppata ipotizzando ipotetiche somministrazioni ripetute del test allo stesso individuo sotto le medesime condizioni, si generalizzano al caso di una singola somministrazione del test ad un campione di individui (Allen and Yen 2001). In base a questo risultato, se consideriamo la somministrazione del test ad una popolazione di individui, allora diventa più facile assegnare un contenuto empirico alle quantità della CTT: \\(\\sigma^2_X\\) è la varianza del punteggio osservato nella popolazione, \\(\\sigma^2_T\\) è la varianza dei punteggio vero nella popolazione, \\(\\sigma^2_E\\) è la varianza della componente d’errore nella popolazione. 2.3.3 Le assunzioni sul punteggio ottenuto La CTT assume che la media del punteggio osservato \\(X\\) sia uguale alla media del punteggio vero, \\[ \\mu_X \\equiv \\mu_{T}, \\tag{2.2} \\] in altri termini, assume che il punteggio osservato fornisca una stima statisticamente corretta dell’abilità latente (punteggio vero). In pratica, il punteggio osservato non sarà mai uguale all’abilità latente, ma corrisponde solo ad uno dei possibili punteggi che il soggetto può ottenere, subordinatamente alla sua abilità latente. L’errore della misura è la differenza tra il punteggio osservato e il punteggio vero: \\[E \\equiv X - T.\\] In base all’assunzione secondo cui il valore atteso dei punteggi è uguale alla media del valore vero, segue che \\[ \\mathbb{E}(E) = \\mathbb{E}(X - T) = \\mathbb{E}(X) - \\mathbb{E}(T) = \\mu_{T} - \\mu_{T} = 0, \\] ovvero, il valore atteso degli errori è uguale a zero. References "],["lerrore-standard-della-misurazione-sigma_e.html", "2.4 L’errore standard della misurazione \\(\\sigma_E\\)", " 2.4 L’errore standard della misurazione \\(\\sigma_E\\) La radice quadrata della varianza degli errori di misurazione, ovvero la deviazione standard degli errori, \\(\\sigma_E\\), è la quantità fondamentale della CTT ed è chiamata errore standard della misurazione. La stima dell’errore standard della misurazione costituisce uno degli obiettivi più importanti della CTT. Ricordiamo che la deviazione standard è simile (ma non identica) alla media del valore assoluto degli scarti dei valori di una distribuzione dalla media. Possiamo dunque utilizzare questa proprietà per descrivere il modo in cui la CTT interpreta \\(\\sigma_E\\). In altre parole, l’errore standard della misurazione \\(\\sigma_E\\) ci dice qual è, approssimativamente, la variazione attesa del punteggio osservato, se il test venisse somministrato ripetute volte al rispondente sotto le stesse condizioni (in assenza di effetti di apprendimento o di fatica). "],["assiomi-della-teoria-classica.html", "2.5 Assiomi della Teoria Classica", " 2.5 Assiomi della Teoria Classica La CTT assume che gli errori siano delle variabili casuali incorrelate tra loro \\[ \\rho(E_i, E_k \\mid T) = 0, \\qquad\\text{con}\\; i \\neq k, \\] e incorrelate con il punteggio vero, \\[ \\rho(E, T) = 0, \\] le quali seguono una distribuzione gaussiana con media zero e deviazione standard pari a \\(\\sigma_E\\): \\[ E \\sim \\mathcal{N}(0, \\sigma_E). \\] La quantità \\(\\sigma_E\\) è appunto chiamata errore standard della misurazione. Sulla base di tali assunzioni la CTT deriva la formula dell’attendibilità di un test. Si noti che le assunzioni della CTT hanno una corrispondenza puntuale con le assunzioni su cui si basa il modello di regressione lineare. "],["lattendibilità-del-test.html", "2.6 L’attendibilità del test", " 2.6 L’attendibilità del test In questo paragrafo vedremo come il coefficiente di attendibilità (altri termini che vengono usati sono: affidabilità, costanza, credibilità) fornisce una stima della quota della varianza del punteggio osservato che può essere attribuita all’abilità latente (“punteggio vero”, cioè privo di errore di misurazione). In generale, un coefficiente di attendibilità maggiore di 0.80 viene ritenuto soddisfacente perché indica che l’80% o più della varianza dei punteggi ottenuti è causata da ciò che il test intende misurare, anziché dall’errore di misurazione. Per definire l’attendibilità, la CTT si serve di due quantità: la varianza del punteggio osservato, la correlazione tra punteggio osservato e punteggio vero. Vediamo come queste quantità possano essere ottenute sulla base delle assunzioni del modello statistico che sta alla base della CTT. 2.6.1 La varianza del punteggio osservato La varianza del punteggio osservato \\(X\\) è uguale alla somma della varianza del punteggio vero e della varianza dell’errore di misurazione. Dimostrazione. La varianza del punteggio osservato è uguale a \\[ \\sigma^2_X = \\mathbb{V}(T+E) = \\sigma_T^2 + \\sigma_E^2 + 2 \\sigma_{TE}. \\tag{2.3} \\] Dato che \\(\\sigma_{TE}=\\rho_{TE}\\sigma_T \\sigma_E=0\\), in quanto \\(\\rho_{TE}=0\\), ne segue che \\[ \\sigma^2_X = \\sigma_T^2 + \\sigma_E^2. \\tag{2.4} \\] 2.6.2 La covarianza tra punteggio osservato e punteggio vero La covarianza tra punteggio osservato \\(X\\) e punteggio vero \\(T\\) è uguale alla varianza del punteggio vero. Dimostrazione. La covarianza tra punteggio osservato e punteggio vero è uguale a \\[ \\begin{aligned} \\sigma_{X T} &amp;= \\mathbb{E}(XT) - \\mathbb{E}(X)\\mathbb{E}(T)\\notag\\\\ &amp;= \\mathbb{E}[(T+E)T] - \\mathbb{E}(T+E)\\mathbb{E}(T)\\notag\\\\ &amp;= \\mathbb{E}(T^2) + \\underbrace{\\mathbb{E}(ET)}_{=0} - [\\mathbb{E}(T)]^2 - \\underbrace{\\mathbb{E}(E)}_{=0} \\mathbb{E}(T)\\notag\\\\ &amp;=\\mathbb{E}(T^2) - [\\mathbb{E}(T)]^2\\notag \\\\ &amp;= \\sigma_T^2. \\end{aligned} \\] 2.6.3 Correlazione tra punteggio osservato e punteggio vero La correlazione tra punteggio osservato \\(X\\) e punteggio vero \\(T\\) è uguale al rapporto tra la covarianza tra \\(X\\) e \\(T\\) divisa per il prodotto delle due deviazioni standard: \\[ \\rho_{XT} = \\frac{\\sigma_{XT}}{\\sigma_X \\sigma_T} = \\frac{\\sigma^2_{T}}{\\sigma_X \\sigma_T} = \\frac{\\sigma_{T}}{\\sigma_X}. \\tag{2.5} \\] 2.6.4 Definizione e significato dell’attendibilità Sulla base della (2.5) giungiamo alla definizione dell’attendibilità. La CTT definisce attendibilità di un test (o di un item) come il quadrato della correlazione tra punteggio osservato \\(X\\) e punteggio vero \\(T\\), ovvero come il rapporto tra la varianza del punteggio vero e la varianza del punteggio osservato: \\[\\begin{equation} \\rho_{XT}^2 = \\frac{\\sigma_{T}^2}{\\sigma_X^2}. \\tag{2.6} \\end{equation}\\] Questa è la quantità fondamentale della CTT e misura il grado di variazione del punteggio vero rispetto alla variazione del punteggio osservato. Dato che \\(\\sigma^2_X = \\sigma_T^2 + \\sigma_E^2\\), in base alla (2.6) possiamo scrivere \\[ \\begin{equation} \\rho_{XT}^2 = \\frac{\\sigma_{T}^2}{\\sigma_X^2} =\\frac{\\sigma_{X}^2 - \\sigma^2_E}{\\sigma_X^2} = 1-\\frac{\\sigma_{E}^2}{\\sigma_X^2}. \\tag{2.7} \\end{equation} \\] Questo significa che il coefficiente di attendibilità assume valore \\(1\\) se la varianza degli errori \\(\\sigma_{E}^2\\) è nulla e assume valore \\(0\\) se la varianza degli errori è uguale alla varianza del punteggio osservato. Il coefficiente di attendibilità è dunque un numero puro contenuto nell’intervallo compreso tra \\(0\\) e \\(1\\). "],["attendibilità-e-modello-di-regressione-lineare.html", "2.7 Attendibilità e modello di regressione lineare", " 2.7 Attendibilità e modello di regressione lineare Il modello di regressione lineare sta alla base della CTT. Infatti si può dire che tutte le proprietà della CTT che abbiamo discusso in precedenza non sono altro che le caratteristiche di un modello di regressione lineare nel quale i punteggi osservati \\(X\\) sono la variabile dipendente, i punteggi veri \\(T\\) sono la variabile indipendente. Se rappresentiamo la CTT in questo modo, il coefficiente di attendibilità \\(\\rho_{XT}^2 = \\frac{\\sigma_{T}^2}{\\sigma_X^2}\\) non diventa altro che la quota di varianza del punteggio osservato \\(X\\) che viene spiegata dal punteggio vero \\(T\\) in base ad un modello lineare con pendenza unitaria e intercetta nulla: \\[ X = 0 + 1 \\cdot T + E. \\] Nei termini di una tale rappresentazione, il coefficiente di attendibilità è uguale al coefficiente di determinazione del modello di regressione. 2.7.1 Simulazione Per dare un contenuto concreto alle affermazioni precedenti, consideriamo la seguente simulazione svolta in \\(\\textsf{R}\\). In tale simulazione il punteggio vero \\(T\\) e l’errore \\(E\\) sono creati in modo tale da soddisfare i vincoli della CTT: \\(T\\) e \\(E\\) sono variabili casuali gaussiane tra loro incorrelate. Nella simulazione generiamo 100 coppie di valori \\(X\\) e \\(T\\) con i seguenti parametri: \\(T \\sim \\mathcal{N}(\\mu_T = 12, \\sigma^2_T = 6)\\), \\(E \\sim \\mathcal{N}(\\mu_E = 0, \\sigma^2_T = 3)\\): set.seed(123) library(&quot;MASS&quot;) n &lt;- 100 Sigma &lt;- matrix(c(6, 0, 0, 3), byrow = TRUE, ncol = 2) Sigma #&gt; [,1] [,2] #&gt; [1,] 6 0 #&gt; [2,] 0 3 mu &lt;- c(12, 0) mu #&gt; [1] 12 0 Y &lt;- mvrnorm(n, mu, Sigma, empirical = TRUE) T &lt;- Y[, 1] E &lt;- Y[, 2] Le istruzioni precedenti (empirical = TRUE) creano un campione di valori nei quali le medie e la matrice di covarianze assumono esattamente i valori richiesti. Possiamo dunque immaginare tale insieme di dati come la “popolazione”. Secondo la CTT, il punteggio osservato è \\(X = T + E\\). Simuliamo dunque il punteggio osservato \\(X\\) come: X &lt;- T + E Le prime 6 osservazioni così ottenute sono: head(cbind(T, E, X)) #&gt; T E X #&gt; [1,] 11.148054 -1.5708292 9.577225 #&gt; [2,] 13.137936 -0.3334731 12.804463 #&gt; [3,] 10.391355 2.5457324 12.937087 #&gt; [4,] 11.452152 -0.1955005 11.256652 #&gt; [5,] 9.978233 -0.4919698 9.486263 #&gt; [6,] 10.729882 2.9609180 13.690800 Un diagramma di dispersione è fornito nella figura seguente: tibble(X, T) %&gt;% ggplot(aes(X, T)) + geom_point() FIGURA 2.1: Simulazione della relazione tra punteggio osservato e punteggio vero per 100 individui in base alle assunzioni della CTT. Secondo la CTT, il valore atteso di \\(T\\) è uguale al valore atteso di \\(X\\). Verifichiamo questa assunzione nei nostri dati: mean(T) #&gt; [1] 12 mean(X) #&gt; [1] 12 L’errore deve avere media zero, varianza \\(\\sigma_E^2\\) e deve essere incorrelato con \\(T\\): mean(E) #&gt; [1] 4.061421e-18 var(E) #&gt; [1] 3 cor(T, E) #&gt; [1] -1.947179e-16 Ricordiamo che la radice quadrata della varianza degli errori è l’errore standard della misurazione, \\(\\sigma_E\\). La quantità \\(\\sqrt{\\sigma_E^2}\\) fornisce una misura della dispersione del punteggio osservato attorno al valore vero, nella condizione ipotetica di ripetute somministrazioni del test: sqrt(3) #&gt; [1] 1.732051 Dato che \\(T\\) e \\(E\\) sono incorrelati, ne segue che la varianza del punteggio osservato \\(X\\) è uguale alla somma della varianza del punteggio vero \\(T\\) e della varianza degli errori \\(E\\): var(X) #&gt; [1] 9 var(T) + var(E) #&gt; [1] 9 La varianza del punteggio vero \\(T\\) è uguale alla covarianza tra il punteggio vero \\(T\\) e il punteggio osservato \\(X\\): var(T) #&gt; [1] 6 cov(T, X) #&gt; [1] 6 La correlazione tra punteggio osservato e punteggio vero è uguale al rapporto tra la deviazione standard del punteggio vero e la deviazione standard del punteggio osservato: cor(X, T) #&gt; [1] 0.8164966 sd(T) / sd(X) #&gt; [1] 0.8164966 Per la CTT, l’attendibilità è uguale al quadrato del coefficiente di correlazione tra il punteggio vero \\(T\\) e il punteggio osservato \\(X\\), ovvero: cor(X, T)^2 #&gt; [1] 0.6666667 La motivazione di questa simulazione è quella di mettere in relazione il coefficiente di attendibilità, calcolato con la formula della CTT (come abbiamo fatto sopra), con il modello di regressione lineare. Analizziamo dunque i dati della simulazione mediante il seguente modello di regressione lineare: \\[ X = a + b T + E. \\] Usando \\(\\textsf{R}\\) otteniamo: fm &lt;- lm(X ~ T) summary(fm) #&gt; #&gt; Call: #&gt; lm(formula = X ~ T) #&gt; #&gt; Residuals: #&gt; Min 1Q Median 3Q Max #&gt; -4.1967 -1.1013 0.0524 1.1551 4.2393 #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error t value Pr(&gt;|t|) #&gt; (Intercept) 8.527e-15 8.746e-01 0 1 #&gt; T 1.000e+00 7.143e-02 14 &lt;2e-16 *** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; #&gt; Residual standard error: 1.741 on 98 degrees of freedom #&gt; Multiple R-squared: 0.6667, Adjusted R-squared: 0.6633 #&gt; F-statistic: 196 on 1 and 98 DF, p-value: &lt; 2.2e-16 Si noti che la retta di regressione ha intercetta 0 e pendenza 1. Questo è coerente con l’assunzione \\(\\mathbb{E}(X) = \\mathbb{E}(T)\\). Ma il risultato più importante di questa simulazione è che il coefficiente di determinazione (\\(R^2\\) = 0.67) del modello di regressione \\(X = 0 + 1 \\times T + E\\) è identico al coefficiente di attendibilità che si può calcolare con la formula \\(\\rho_{XT}^2 = \\frac{\\sigma_{T}^2}{\\sigma_X^2}\\): var(T) / var(X) #&gt; [1] 0.6666667 Ciò ci consente di interpretare il coefficiente di attendibilità nel modo seguente: l’attendibilità di un test non è altro che la quota di varianza del punteggio osservato \\(X\\) che viene spiegata dalla regressione di \\(X\\) sul punteggio vero \\(T\\) in un modello di regressione lineare dove \\(\\alpha\\) = 0 e \\(\\beta\\) = 1. "],["misurazioni-parallele-e-affidabilità.html", "2.8 Misurazioni parallele e affidabilità", " 2.8 Misurazioni parallele e affidabilità L’equazione \\(\\rho_{XT}^2 = \\frac{\\sigma_{T}^2}{\\sigma_X^2}\\) definisce il coefficiente di attendibilità ma non ci fornisce gli strumenti per calcolarlo in pratica, dato che la varianza del punteggio vero \\(\\sigma_{T}^2\\) è una quantità incognita. Il metodo utilizzato dalla CTT per ottenere una stima empirica dell’attendibilità è quello delle forme parallele del test: se è possibile elaborare versioni alternative dello stesso test che risultino equivalenti tra loro in termini di contenuto, modalità di risposta e caratteristiche statistiche, allora diventa anche possibile stimare il coefficiente di attendibilità. Secondo la CTT, due test \\(X=T+E\\) e \\(X^\\prime=T^\\prime+E^\\prime\\) si dicono misurazioni parallele della stessa abilità latente se \\(T = T^\\prime\\), \\(\\mathbb{V}(E) = \\mathbb{V}(E^\\prime)\\). Da tali assunzioni segue che \\(\\mathbb{E}(X) = \\mathbb{E}(X^\\prime)\\). Dimostrazione. Dato che \\(\\mathbb{E}(X) = T\\) e che \\(\\mathbb{E}(X^\\prime) = T\\), è immediato vedere che \\(\\mathbb{E}(X) =\\mathbb{E}(X^\\prime)\\) in quanto \\(\\mathbb{E}(E) = \\mathbb{E}(E^\\prime) = 0\\). In maniera corrispondente, anche le varianze dei punteggi osservati di due misurazioni parallele devono essere uguali, \\(\\mathbb{V}(X) = \\mathbb{V}(X^\\prime)\\). Dimostrazione. Per \\(X\\) abbiamo che \\(\\mathbb{V}(X) = \\mathbb{V}(T + E) = \\mathbb{V}(T) + \\mathbb{V}(E)\\); per \\(X^\\prime\\) abbiamo che \\(\\mathbb{V}(X^\\prime) = \\mathbb{V}(T^\\prime + E^\\prime) = \\mathbb{V}(T^\\prime) + \\mathbb{V}(E^\\prime)\\). Dato che \\(\\mathbb{V}(E) = \\mathbb{V}(E^\\prime)\\) e che \\(T = T^\\prime\\), ne segue che \\(\\mathbb{V}(X) = \\mathbb{V}(X^\\prime)\\). Per costruzione, inoltre, gli errori \\(E\\) e \\(E^\\prime\\) devono essere incorrelati con \\(T\\) e tra loro. 2.8.1 La correlazione tra due forme parallele del test Dimostriamo ora che, in base alle assunzioni della CTT, la correlazione tra due forme parallele del test è uguale al rapporto tra la varianza del punteggio vero e la varianza del punteggio osservato. Dimostrazione. Assumendo, senza perdita di generalità, che \\(\\mathbb{E}(X)=\\E(X&#39;)=\\mathbb{E}(T)=0\\), possiamo scrivere \\[\\begin{equation} \\begin{aligned} \\rho_{X X^\\prime} &amp;= \\frac{\\sigma(X, X^\\prime)}{\\sigma(X) \\sigma(X^\\prime)}\\notag\\\\ &amp;= \\frac{\\mathbb{E}(XX^\\prime)}{\\sigma(X) \\sigma(X^\\prime)}\\notag\\\\ &amp;=\\frac{\\mathbb{E}[(T+E)(T+E^\\prime)]}{\\sigma(X) \\sigma(X^\\prime)}\\notag\\\\ &amp;=\\frac{\\mathbb{E}(T^2)+\\mathbb{E}(TE^\\prime)+\\mathbb{E}(TE)+ \\mathbb{E}(EE^\\prime)}{\\sigma(X) \\sigma(X^\\prime)}.\\notag \\end{aligned} \\end{equation}\\] Ma \\(\\mathbb{E}(TE) = \\mathbb{E}(TE^\\prime) = \\mathbb{E}(EE^\\prime)=0\\). Inoltre, \\(\\sigma(X) =\\sigma(X^\\prime)= \\sigma_X\\). Dunque, \\[\\begin{equation} \\rho_{X X^\\prime} =\\frac{\\mathbb{E}(T^2)}{\\sigma_X \\sigma_X} = \\frac{\\sigma^2_T}{\\sigma^2_X}. \\tag{2.8} \\end{equation}\\] Si noti come la (2.8) e l’equazione che definisce il coefficiente di attendibilità, ovvero \\(\\rho_{XT}^2 = \\frac{\\sigma_{T}^2}{\\sigma_X^2}\\), riportano tutte e due la stessa quantità a destra dell’uguale. Otteniamo così un importante risultato: il coefficiente di attendibilità, ovvero il quadrato del coefficiente di correlazione tra il punteggio osservato e il punteggio vero, è uguale alla correlazione tra il valore osservato di due misurazioni parallele: \\[\\begin{equation} \\rho^2_{XT} = \\rho_{XX^\\prime}. \\tag{2.9} \\end{equation}\\] Tale risultato è importante perché consente di esprimere la quantità inosservabile \\(\\rho^2_{XT}\\) nei termini della quantità \\(\\rho_{XX^\\prime}\\) che può essere calcolata sulla base dei punteggi osservati di due forme parallele del test. Quindi, la stima di \\(\\rho^2_{XT}\\) si riduce alla stima di \\(\\rho^2_{XX^\\prime}\\). Per questa ragione, la (2.9) è forse la formula più importante della CTT. 2.8.2 La correlazione tra punteggio osservato e punteggio vero Consideriamo ora la correlazione tra punteggio osservato e punteggio vero. La (2.9) si può scrivere come \\[ \\rho_{XT} = \\sqrt{\\rho_{XX^\\prime}}. \\] In altri termini: la radice quadrata del coefficiente di attendibilità è uguale alla correlazione tra il punteggio osservato e il punteggio vero. 2.8.3 I fattori che influenzano l’attendibilità Considerando le tre equazioni \\[ \\rho^2_{XT} = \\rho_{XX&#39;},\\quad \\rho_{XT}^2 = \\frac{\\sigma_{T}^2}{\\sigma_X^2}, \\quad \\rho_{XT}^2 = 1-\\frac{\\sigma_{E}^2}{\\sigma_X^2}, \\] possiamo dire che ci sono tre modi equivalenti per concludere che l’attendibilità di un test è alta. L’attendibilità di un test è alta se è alta la correlazione tra le forme parallele del test, se è grande la varianza del punteggio vero relativamente alla varianza del punteggio osservato, se è piccola la varianza dell’errore di misura relativamente alla varianza del punteggio osservato. Tali considerazioni hanno importanti implicazioni per le scelte che devono guidare la costruzione di un test. Si consideri, in particolare, l’equazione \\(\\rho^2_{XT} = \\rho_{XX&#39;}\\). Se interpretiamo \\(\\rho_{XX&#39;}\\) come la correlazione tra due item, allora tale equazione ci fornisce un criterio per la scelta degli item da includere in un test: devono essere inclusi nel test gli item che correlano maggiormente tra loro. In questo modo, infatti, l’attendibilità del test aumenterà perché gli item inclusi nel test sono maggiormente correlati con il punteggio vero. "],["metodi-alternativi-per-la-stima-del-coefficiente-di-attendibilità.html", "2.9 Metodi alternativi per la stima del coefficiente di attendibilità", " 2.9 Metodi alternativi per la stima del coefficiente di attendibilità Come si stima in pratica l’affidabilità? Un modo grossolano (e molto impreciso) consiste nel somministrare allo stesso gruppo di individui lo stesso test in due differenti momenti e di calcolare il coefficiente di correlazione dei punteggi totali (test-retest reliability). McDonald (2013) afferma che tale procedura può essere giustificata in due modi diversi. La prima giustificazione è basata sull’assunzione che il valore vero non varia tra le due somministrazioni del test. Se le cose stanno in questo modo, gli errori saranno indipendenti e la correlazione tra il punteggio osservato nelle due somministrazioni ci fornirà una stima di \\(\\rho_{XX^\\prime}\\). Il problema è che non disponiamo di nessuno strumento per distinguere questa situazione ideale dal caso in cui viene violata l’assunzione dell’invarianza del punteggio vero. Una seconda giustificazione del metodo test-retest ci porta a definire il punteggio vero di retest come la componente del punteggio osservato che non varia tra le due somministrazioni. Il tal senso, il coefficiente di attendibilità viene concepito come un coefficiente di stabilità temporale. In generale, maggiore è l’intervallo temporale tra le due somministrazioni, minore sarà il valore del coefficiente di stabilità temporale. Uno dei problemi del metodo test-retest è che due somministrazioni successive di un test ci forniscono soltanto un sottoinsieme delle possibili informazioni che verrebbero raccolte da uno studio longitudinale che copre un periodo temporale maggiore. Se tale studio longitudinale venisse eseguito, potremmo trovare la funzione che descrive la variazione del punteggio osservato in funzione del tempo. In generale, tale funzione non può essere descritta da un singolo parametro. Resta aperta la domanda di quale sia relazione tra questa funzione e il coefficiente di attendibilità. Se sono disponibili due forme parallele dello stesso test, l’affidabilità può essere calcolata mediante il coefficiente di correlazione dei punteggi totali dei due test (parallel-forms reliability), valendo l’uguaglianza \\(\\rho_{XX^\\prime} = \\rho^2_{XT}\\). Anche questo metodo, come il metodo del test-retest, non è esente da errori. Il metodo di stima più diffuso è quello dell’attendibilità come consistenza interna (internal consistency reliability), originariamente ricavato da Kuder and Richardson (1937) per item dicotomici e poi generalizzato da Cronbach (1951) per item a risposte ordinali. L’idea su cui si basa consiste nel fatto che ogni singolo item del test, se confrontato con tutti gli altri, può essere usato per stimare l’affidabilità del test. L’analisi degli item valuta dunque la misura in cui gli item del test sono espressione dello stesso costrutto. References "],["lincertezza-della-misura.html", "Capitolo 3 L’incertezza della misura", " Capitolo 3 L’incertezza della misura Lord e Novick (1968) fanno notare come l’errore \\(E = X - T\\) sia la variabile aleatoria di primario interesse per la CTT, in quanto lo scopo è stimare il punteggio vero di ciascun rispondente e confrontare le stime ottenute nel caso di rispondenti diversi. La grandezza dell’errore che si commette utilizzando il punteggio osservato quale misura del punteggio vero può essere quantificata mediante la deviazione standard di \\(E\\), ovvero mediante ciò che viene chiamato l’errore standard della misurazione, \\(\\sigma_E\\) (Standard Error of Measurement, SEM). Ma come è possibile stimare \\(\\sigma_E\\)? "],["la-stima-dellerrore-standard-della-misurazione.html", "3.1 La stima dell’errore standard della misurazione", " 3.1 La stima dell’errore standard della misurazione L’errore standard della misurazione quantifica il grado di incertezza presente nei punteggi di un test. Può essere dimostrato che una stima dell’errore standard della misurazione (\\(\\sigma_E\\)) è data da: \\[ \\sigma_E = \\sigma_X \\sqrt{1 -\\rho_{XX^\\prime}}, \\tag{3.1} \\] dove \\(\\sigma_X\\) è la deviazione standard dei punteggi ottenuti in un campione di rispondenti e \\(\\rho_{XX^\\prime}\\) è il coefficiente di attendibilità. Per stimare \\(\\sigma_E\\) è dunque necessario sottrarre da uno l’attendibilità del test, prendere la radice quadrata della differenza e moltiplicare la radice quadrata per la deviazione standard dei punteggi del test. Si noti che l’errore standard della misurazione \\(\\sigma_E\\) è direttamente associato all’attendibilità del test: l’errore standard della misurazione diminuisce al crescere dell’attendibilità del test. Se l’attendibilità del test è uguale a 0 \\(\\sigma_E\\) diventa uguale alla deviazione standard del punteggio osservato del test. Se l’attendibilità del test è uguale a 1 \\(\\sigma_E\\) diventa uguale a zero: se il test è perfettamente affidabile non ci sono errori e \\(\\sigma_E\\) è uguale a zero. 3.1.1 Interpretazione McDonald afferma che il termine \\(E\\) segue una propensity distribution, ovvero rappresenta le fluttuazioni casuali nel tempo di un rispondente, che corrispondono a fluttuazioni di umore, motivazione, ecc. L’errore standard della misura fornisce una stima della deviazione standard di tali punteggi, ovvero una stima della deviazione standard dei punteggi che un un singolo individuo otterrebbe nel caso di ipotetiche infinite somministrazioni di un test (o di forme parallele di un test) sotto le stesse identiche condizioni, se il punteggio vero rimane costante. La CTT assume i punteggi ottenuti da un individuo, nel caso di ipotetiche infinite somministrazioni di un test nelle stesse identiche condizioni, abbiano una distribuzione normale centrata sul valore vero. L’errore standard della misurazione è la stima della deviazione standard di una tale distribuzione di punteggi ipotetici. Maggiore è l’errore standard della misurazione, maggiore è l’errore che si compie usando il test per valutare l’abilità latente del rispondente. Il coefficiente di attendibilità, la varianza dell’errore e l’errore standard della misurazione sono tutti indicatori diretti o indiretti della precisione del test. Tuttavia, questi indici forniscono informazioni diverse sul grado di precisione del test: l’errore standard della misurazione ci consente di fare inferenze sulla precisione del punteggio osservato di un singolo rispondente, ma non è possibile assegnare tale interpretazione al coefficiente di attendibilità; l’errore standard della misurazione è espresso nella stessa unità di misura del punteggio osservato, mentre la varianza di \\(E\\) è espressa nei termini del quadrato del punteggio osservato; l’attendibilità corrisponde ad un rapporto tra varianze e dunque è un numero puro (privo di unità di misura). Supponiamo che un test di intelligenza produca un punteggio medio pari a 100 con una deviazione standard di 15. Supponiamo inoltre che il test abbia una attendibilità pari a 0.73. Si calcoli l’errore standard della misurazione. Applicando la formula dell’errore standard della misurazione, otteniamo \\[\\begin{equation} \\begin{aligned} \\sigma_E &amp;= \\sigma_X \\sqrt{1 -\\rho_{XX^\\prime}} \\notag\\\\ &amp;= 15 \\sqrt{1 - 0.73} \\notag\\\\ &amp;= 7.79.\\notag \\end{aligned} \\end{equation}\\] Il valore di 7.79 significa che, se immaginiamo di somministrare molte volte il test ad un rispondente, sotto le stesse identiche condizioni, ci aspettiamo che i valori ottenuti differiscano tra loro, in media, di circa 8 punti tra le successive somministrazioni del test. Inoltre, se immaginiamo di somministrare molte volte il test ad un rispondente, sotto le stesse identiche condizioni, ci aspettiamo che il 95% dei punteggi così ottenuti sia compreso nell’intervallo \\[ \\text{punteggio vero del rispondente} \\pm 1.96 \\cdot \\text{errore standard della misurazione}. \\] Questa è una proprietà della distribuzione gaussiana. Per il caso presente, questo intervallo è uguale a \\(2 \\cdot 1.96 \\cdot 7.79 = 30.54\\) punti. In altre parole, ci possiamo aspettare che, nel caso di somministrazioni ripetute del test sotto le stesse identiche condizioni, i punteggi del QI di un singolo rispondente varino tra loro all’interno di un intervallo di 30 punti. Ciò significa che, se il test avesse un’attendibilità pari a 0.73, e se la deviazione standard dei punteggi del test nella popolazione fosse pari a 15, la somministrazione di un tale test ad un singolo individuo sarebbe di scarsa utilità, a causa dell’enorme errore di misurazione. Per fare un confronto con i dati di questo esempio, la Full Scale IQ (FSIQ) della WAIS-IV (Wechsler 2008) ha un’attendibilità split-half pari a 0.98, con errore standard di misurazione pari a 2.16. Continuando con l’esempio precedente, per gli ipotetici dati riportati sopra, poniamoci ora la seguente domanda: qual è la probabilità che un rispondente ottenga un punteggio minore o uguale a 116 nel test, se il suo punteggio vero è uguale a 120? Il problema si risolve rendendosi conto che i punteggi del rispondente si distribuiscono normalmente attorno al punteggio vero di 120, con una deviazione standard uguale a 7.79. Dobbiamo dunque trovare l’area sottesa alla normale \\(\\mathcal{N}(120, 7.79)\\) nell’intervallo \\([-\\infty, 116]\\). Utilizzando , la soluzione si trova nel modo seguente: pnorm(116, 120, 7.79) #&gt; [1] 0.3038082 Se la variabile aleatorie corrispondente al punteggio osservato segue una distribuzione \\(\\mathcal{N}(120, 7.79)\\), la probabilità che il rispondente ottenga un punteggio minore o uguale a 116 è dunque uguale a 0.30. Poniamoci ora la seguente domanda: quale intervallo di valori centrato sul punteggio vero contiene, con una probabilità di 0.95, i punteggi che il rispondente otterrebbe in ipotetiche somministrazioni ripetute del test sotto le stesse identiche condizioni? Dobbiamo trovare i quantili della distribuzione \\(\\mathcal{N}(120, 7.79)\\) a cui sono associate le probabilità di 0.025 e 0.975. La soluzione è dunque data da: qnorm(c(.025, .975), 120, 7.79) #&gt; [1] 104.7319 135.2681 L’intervallo cercato è dunque \\([104.7, 135.3]\\). 3.1.2 Simulazione Ritorniamo ora alla simulazione precedente nella quale abbiamo messo in relazione il modello della CTT con il modello di regressione lineare. In base a tale simulazione, poniamoci lo scopo di chiarire il significato dell’errore standard della misurazione. Impostiamo la simulazione come abbiamo fatto in precedenza. Chiamiamo \\(X\\) il valore osservato in un test. Per la CTT, il punteggio osservato \\(X\\) è costituito da due componenti, la componente vera \\(T\\) e la componente d’errore \\(E\\). Si suppone che gli errori siano gaussiani e incorrelati con la componente vera. Immaginiamo di somministrare 200 volte il test ad un individuo sotto le stesse identiche condizioni. library(&quot;MASS&quot;) library(&quot;arm&quot;) set.seed(123) n &lt;- 200 Sigma &lt;- matrix( c( 11, 0, 0, 4 ), byrow = TRUE, ncol = 2 ) mu &lt;- c(100, 0) Y &lt;- mvrnorm(n, mu, Sigma, empirical = TRUE) T &lt;- Y[, 1] E &lt;- Y[, 2] Verifichiamo l’incorrelazione tra \\(T\\) ed \\(E\\): cor(T, E) #&gt; [1] -1.069186e-16 I valori ottenuti sono la somma del valore vero e della componente d’errore: X &lt;- T + E Per questi dati, il coefficiente di attendibilità è uguale a: rxx &lt;- cor(X, T)^2 rxx #&gt; [1] 0.7333333 Possiamo ora calcolare l’errore standard della misurazione utilizzando la (3.1): sd(X) * sqrt(1 - rxx) #&gt; [1] 2 Si noti che tale valore non è altro che la deviazione standard degli errori della misurazione: sd(E) #&gt; [1] 2 Ovvero, nei termini del modello di regressione \\(X = 0 + 1 \\cdot T + E\\), l’errore standard della misurazione corrisponde all’errore standard della regressione: fm &lt;- lm(formula = X ~ T) summary(fm) #&gt; #&gt; Call: #&gt; lm(formula = X ~ T) #&gt; #&gt; Residuals: #&gt; Min 1Q Median 3Q Max #&gt; -4.4315 -1.4041 -0.1474 1.2191 7.2121 #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error t value Pr(&gt;|t|) #&gt; (Intercept) -1.929e-13 4.288e+00 0.00 1 #&gt; T 1.000e+00 4.285e-02 23.34 &lt;2e-16 *** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; #&gt; Residual standard error: 2.005 on 198 degrees of freedom #&gt; Multiple R-squared: 0.7333, Adjusted R-squared: 0.732 #&gt; F-statistic: 544.5 on 1 and 198 DF, p-value: &lt; 2.2e-16 Si noti che, nell’output di \\(\\textsf{R}\\) fornito sopra, l’errore standard della regressione, ovvero residual sd, corrisponde a 2.01 anziché a 2.0. Ciò si verifica in quanto \\(\\textsf{R}\\) ha calcolato una stima della deviazione standard dei residui nella popolazione utilizzando, al denominatore, \\(n - 2\\). Nel nostro caso è invece necessario dividere per \\(n\\) in quanto i dati della simulazione sono quelli della popolazione, non di un campione. References "],["dimostrazione.html", "3.2 Dimostrazione", " 3.2 Dimostrazione Poniamoci ora il problema di derivare la formula dell’errore standard della misurazione. Per derivare la formula \\(\\sigma_E = \\sigma_X \\sqrt{1 -\\rho_{XX^\\prime}}\\) sono necessari due passi: prima dobbiamo trovare la varianza del punteggio vero; poi dobbiamo esprimere il punteggio osservato come la somma della varianza del punteggio vero e la varianza dell’errore. Dimostrazione. In base alla definizione del coefficiente di attendibilità \\(\\rho_{XX^\\prime} = \\frac{\\sigma^2_T}{\\sigma^2_X}\\) possiamo scrivere \\(\\sigma^2_T = \\rho_{XX^\\prime} \\sigma^2_X\\), dove \\(X\\) e \\(X^\\prime\\) sono due forme parallele di un test. Ricordiamo che misurazioni parallele hanno le seguenti proprietà: \\(\\mathbb{E}(X) = \\mathbb{E}(X^\\prime)\\) e \\(\\mathbb{V}(X) = \\mathbb{V}(X^\\prime)\\). Dato che \\(\\sigma_{X}=\\sigma_{X^\\prime}\\), l’equazione precedente diventa \\(\\sigma^2_T = \\rho_{XX^\\prime} \\sigma_X\\sigma_{X^\\prime}.\\) Utilizzando la definizione della covarianza tra \\(X\\) e \\(X^\\prime\\), ovvero, \\(\\sigma_{XX^\\prime}=\\rho_{XX^\\prime}\\sigma_X\\sigma_{X^\\prime}\\), possiamo concludere che la varianza del punteggio vero è uguale alla covarianza tra due misurazioni parallele: \\[ \\sigma^2_T = \\sigma_{XX^\\prime}. \\] Essendo l’attendibilità del test il rapporto tra la varianza del punteggio vero e la varianza del punteggio osservato, ed essendo che la varianza del punteggio vero uguale alla covarianza tra due misurazioni parallele, possiamo concludere che l’attendibilità aumenta all’aumentare della covarianza media tra gli item del test. Si noti come questo importante risultato della CTT dipenda dall’ipotesi di omogeneità delle varianze degli item del test. Calcoliamo ora la varianza di \\(E\\). La varianza del punteggio osservato è uguale a \\(\\sigma^2_X = \\sigma^2_T + \\sigma^2_E.\\) Sulla base della definizione di attendibilità \\(\\sigma^2_T = \\rho_{XX^\\prime} \\sigma^2_X\\), la varianza del punteggio osservato si può scrivere come \\(\\sigma^2_X =\\rho_{XX^\\prime} \\sigma^2_X + \\sigma^2_E\\), da cui \\[\\begin{equation} \\begin{aligned} \\sigma^2_E &amp;= \\sigma^2_X - \\sigma^2_X\\rho_{XX^\\prime}\\notag\\\\ &amp;= \\sigma^2_X (1 -\\rho_{XX^\\prime}). \\end{aligned} \\end{equation}\\] La varianza degli errori della misurazione \\(\\sigma^2_E = \\sigma^2_X (1 -\\rho_{XX^\\prime})\\) è dunque uguale al prodotto di due fattori: il primo fattore è la varianza del punteggio osservato; il secondo fattore è uguale a uno meno la correlazione tra due forme parallele del test. Possiamo così calcolare una quantità incognita, \\(\\sigma^2_E\\), nei termini di due quantità osservabili, \\(\\sigma^2_X\\) e \\(\\rho_{XX^\\prime}\\). "],["intervallo-di-confidenza-per-il-punteggio-vero-e-sigma_e.html", "3.3 Intervallo di confidenza per il punteggio vero e \\(\\sigma_E\\)", " 3.3 Intervallo di confidenza per il punteggio vero e \\(\\sigma_E\\) Uno degli usi che vengono fatti dell’errore standard della misurazione è quello di costruire, con essi, gli intervalli di confidenza per il punteggio vero. Tale uso, però, non è corretto (Charter 1996). Gli intervalli di confidenza costruiti usando l’errore standard della misurazione vengono talvolta incorrettamente interpretati in modo tale da suggerire che l’intervallo di confidenza al \\((1 - \\alpha)\\%\\) identifica una gamma di valori, centrata sul valore osservato, entro il quale cadono i punteggi veri del test nel \\((1 - \\alpha)\\%\\) di ipotetiche somministrazioni ripetute del test. Ma le cose non stanno così. In realtà, come abbiamo detto sopra, l’errore standard della misurazione è la deviazione standard, calcolata rispetto al valore vero, di ipotetiche misurazioni ripetute dello stesso test. Si può ribadire questo concetto nel modo seguente: “In spite of Dudek (1979)’s reminder that the SEM should not be used to construct confidence intervals, many test manuals, computer-scoring programs, and texts in psychology and education continue to do so. Because authors of many textbooks and manuals make these errors, it is understandable that those who learned from and look to these sources for guidance also make these errors. In summary, the SEM should not be used to construct confidence intervals for test scores” (p. 1141). Sembra piuttosto chiaro. References "],["la-stima-del-punteggio-vero.html", "Capitolo 4 La stima del punteggio vero", " Capitolo 4 La stima del punteggio vero Uno degli scopi principali della valutazione psicologica è quello di stimare il punteggio vero del rispondente. Il punteggio osservato \\(X\\) differisce dal punteggio vero \\(T\\) a causa della presenza dell’errore della misurazione: \\(X = T + E\\). Poniamoci ora il problema di utilizzare i concetti della Teoria Classica per stimare il punteggio vero di un rispondente utilizzando il suo punteggio osservato e l’attendibilità del test. Questa stima è utile soprattutto quando è necessario costruire un intervallo di confidenza per il punteggio vero. Per costruire l’intervallo di confidenza del punteggio vero dobbiamo utilizzare due quantità: una stima del punteggio vero, l’errore standard della stima (ovvero, una stima della deviazione standard della distribuzione delle stime del punteggio vero che si otterrebbe se il test venisse somministrato infinite volte sotto le stesse condizioni). Iniziamo con il problema della stima del punteggio vero. "],["il-paradosso-di-kelley.html", "4.1 Il paradosso di Kelley", " 4.1 Il paradosso di Kelley Nella sua monografia del 1954, “Clinical versus statistical prediction: A theoretical analysis and a review of the evidence”, Paul Meehl suscitò un grande scalpore con una convincente dimostrazione del fatto che metodi meccanici di combinazione dei dati, come ad esempio la regressione multipla, sono in grado di fornire delle predizioni migliori di quanto sia in grado di fare la diagnosi clinica eseguita da esperti. L’enorme quantità di letteratura che è stata prodotta in seguito a tale contributo ha fornito forti e univoche evidenze a sostegno di questa osservazione. È interessante notare che Robyn Dawes (2005) ha pubblicato un articolo su Journal of Clinical Psychology (61, 1245–1255) dal titolo seguente: “The ethical implications of Paul Meehl’s Work on comparing clinical versus actuarial prediction methods”. L’argomento principale sostenuto da Dawes è che, date le evidenze molto convincenti che sono disponibili, non è etico usare il giudizio clinico in preferenza all’uso di modelli statistici di previsione. Citiamo dall’abstract: Whenever statistical prediction rules […] are available for making a relevant prediction, they should be used in preference to intuition. […] Providing service that assumes that clinicians “can do better” simply based on self-confidence or plausibility in the absence of evidence that they can actually do so is simply unethical. Sulla base di quanto detto sopra, e in riferimento ai nostri scopi presenti, si pone dunque il problema di capire come sia possibile utilizzare il modello di regressione per ottenere una stima del punteggio vero di un rispondente. A questo proposito si deve notare che è necessario tenere in considerazione il fatto che le nostre variabili indipendenti sono corrotte dall’errore di misurazione, mentre il modello di regressione tradizionale presuppone che le variabili indipendenti siano misurate senza errori. Le considerazioni seguenti sono state proposte da Kelly negli anni ’20. Come dimostrato in seguito, la formula di Kelley si basa sull’equivalenza algebrica secondo la quale l’attendibilità è uguale al quadrato del coefficiente di correlazione tra i punteggi osservati e i punteggi veri. In base alla formula di Kelley, il punteggio vero di un rispondente può essere stimato nel modo seguente mediante il modello di regressione: \\[ \\hat{T} = \\mu_x + \\rho (X - \\mu_x), \\tag{4.1} \\] laddove \\(X\\) è il punteggio osservato, \\(\\mu_x\\) è la media dei punteggi ottenuti da tutti i rispondenti di un campione e \\(\\rho\\) è l’attendibilità del test. Quando l’attendibilità è perfetta (\\(\\rho = 1\\)), il punteggio vero è uguale al punteggio osservato. Quando l’attendibilità è zero (tutta la varianza è dovuta all’errore della misurazione), allora la stima migliore del punteggio vero è data dalla media del campione. Quando \\(0 &lt; \\rho &lt; 1\\), la stima del punteggio vero corrisponde ad un valore che si discosta dal punteggio osservato nella direzione della media del campione. La stima del punteggio vero, dunque, esibisce la proprietà della regressione verso la media del punteggio osservato, in funzione dell’attendibilità del test[^1]. La (4.1) può essere interpretata dicendo che, per stimare il punteggio vero di un rispondente, partiamo dalla media della distribuzione della popolazione dei rispondenti e ci spostiamo nella direzione del punteggio osservato di un rispondente. Tuttavia, non raggiungiamo il valore del punteggio osservato: la quantità di cui ci spostiamo è proporzionale all’attendibilità. In altre parole, a seconda della dimensione di \\(\\rho\\), la stima del punteggio vero di un individuo è dovuta, in parte, a dove si trova l’individuo in relazione al gruppo di appartenenza: la stima del punteggio vero dell’individuo si sposterà verso l’alto se l’individuo è collocato sotto la media del gruppo di appartenenza e si sposterà verso il basso se l’individuo è collocato al di sopra della media del gruppo di appartenenza. Questa equazione è stata chiamata il paradosso di Kelley. È importante sottolineare che l’interpretazione precedente rivela che la formula di Kelley contraddice la nozione intuitiva secondo cui il punteggio osservato può essere utilizzato quale stima del punteggio vero (cioè, \\(\\hat{T} = X\\)). Tale ragionamento ingenuo sarebbe corretto se l’attendibilità del test fosse perfetta (\\(\\rho = 1\\)). All’altra estremità dello spettro, quando \\(\\rho = 0\\), la formula di Kelley ci suggerisce \\(\\mu_x\\) quale stima del punteggio vero, il che è equivale a dire che il punteggio osservato deve essere ignorato – infatti se la varianza di \\(X\\) è solamente dovuta all’errore di misurazione, allora il test è del tutto inutile quale strumento inferenziale per differenziare le abilità dei rispondenti. Fortunatamente, in pratica è molto improbabile che \\(\\rho = 0\\). Se \\(\\rho\\) cade tra gli estremi di 0 e 1, allora il punteggio vero stimato sarà compreso tra il punteggio osservato e \\(\\mu_x\\). Per capire cosa esso catturi, possiamo citare Kelley(1947), che osservò: This is an interesting equation in that it expresses the estimate of true ability as the weighted sum of two separate estimates, – one based upon the individual’s observed score, \\(X_1\\) (\\(X\\) nella notazione corrente) and the other based upon the mean of the group to which he belongs, \\(M_1\\) (\\(\\mu_x\\) nella notazione corrente). If the test is highly reliable, much weight is given to the test score and little to the group mean, and vice versa. Dimostrazione. Come si arriva all’equazione di Kelley? Abbiamo visto in precedenza come l’equazione che mette in relazione il punteggio osservato con il punteggio vero non è altro che un modello di regressione con intercetta nulla e pendenza unitaria: \\(X = 0 + 1 \\cdot T + E\\). In questo caso, però, il problema è diverso, in quanto noi vogliamo predire il punteggio vero sulla base del punteggio osservato per mezzo di un modello di regressione (Nunnally, 1978). Avendo quale scopo quello di “predire” il punteggio vero \\(T\\) sulla base del punteggio osservato \\(X\\), il modello di regressione diventa \\[ T = \\alpha + \\beta X + \\varepsilon. \\] Se esprimiamo le variabili come deviazioni dalla media, \\(x = X - \\bar{X}\\) e \\(\\tau = T - \\mathbb{E}(T)\\), allora l’intercetta diventa uguale a zero e il modello diventa \\(\\tau = \\beta x + \\varepsilon\\), ovvero \\(\\hat{\\tau} = \\beta x.\\) Il problema è quello di calcolare il coefficiente \\(\\beta\\). Nel modello \\(\\hat{\\tau} = \\beta x\\), la pendenza della retta di regressione è uguale a \\(\\beta = \\frac{\\sigma_{\\tau x}}{\\sigma^2_x}\\). Possiamo dunque scrivere il modello di regressione nel modo seguente: \\[\\begin{equation} \\hat{\\tau} = \\frac{\\sigma_{\\tau x}}{\\sigma^2_x} x. \\tag{4.2} \\end{equation}\\] La correlazione tra \\(x\\) (o \\(X\\)) e \\(\\tau\\) (o \\(T\\)) è uguale a \\(\\rho_{\\tau x} = \\frac{\\sigma_{\\tau x}}{\\sigma_x \\sigma_{\\tau}}\\). Dunque \\(\\sigma_{\\tau x} = \\rho_{\\tau x}\\sigma_x \\sigma_{\\tau}\\) e l’equazione precedente diventa \\[ \\begin{equation} \\begin{aligned} \\hat{\\tau} &amp;= \\frac{\\sigma_{TX}}{\\sigma^2_X} X \\notag\\\\ &amp;= \\frac{\\rho_{\\tau x}\\sigma_x \\sigma_{\\tau}}{\\sigma^2_x} x \\notag\\\\ &amp;= \\rho_{\\tau x}\\frac{\\sigma_{\\tau}}{\\sigma_x} x. \\notag \\end{aligned} \\end{equation} \\] In base alla definizione di attendibilità, la varianza del punteggio vero è \\(\\sigma^2_{\\tau} = \\sigma^2_x \\rho_{xx^\\prime}\\). Dunque, la deviazione standard del punteggio vero diventa \\(\\sigma_{\\tau} = \\sigma_x \\sqrt{\\rho_{xx^\\prime}}\\). Sostituendo questo risultato nell’equazione precedente otteniamo \\[ \\begin{equation} \\begin{aligned} \\hat{\\tau} &amp;= \\rho_{\\tau x}\\frac{\\sigma_x \\sqrt{\\rho_{xx^\\prime}}}{\\sigma_x} x \\notag\\\\ &amp;= \\rho_{\\tau x} \\sqrt{\\rho_{xx^\\prime}} x. \\notag \\end{aligned} \\end{equation} \\] In precedenza abbiamo visto che \\(\\rho^2_{\\tau x} = \\rho_{xx^\\prime}\\), dunque \\[ \\begin{equation} \\begin{aligned} \\hat{\\tau} &amp;= \\rho_{\\tau x} \\sqrt{\\rho_{xx^\\prime}} x \\notag\\\\ &amp;= \\sqrt{\\rho_{xx^\\prime}} \\sqrt{\\rho_{xx^\\prime}} x \\notag\\\\ &amp;= \\rho_{xx^\\prime} x.\\notag \\end{aligned} \\end{equation} \\] In conclusione, una stima del punteggio vero si ottiene moltiplicando il punteggio osservato, espresso come deviazione dalla media, per il coefficiente di attendibilità. Riscriviamo ora la formula appena ottenuta nei termini del punteggio grezzo \\(X\\) (non in termini di deviazioni dalla media. Per fare ciò, sommiamo \\(\\bar{X}\\) così da ottenere \\[ \\hat{T} = \\rho_{XX^\\prime} (X - \\bar{X}) + \\bar{X}, \\] laddove \\(\\hat{T}^\\prime\\) è la stima del punteggio vero grezzo. Sviluppando otteniamo \\[ \\begin{equation} \\begin{aligned} \\hat{T} &amp;= \\rho_{XX^\\prime} (X - \\bar{X}) + \\bar{X}\\notag\\\\ &amp;= X\\rho_{XX^\\prime} - \\bar{X} \\rho_{XX^\\prime} + \\bar{X}\\notag\\\\ &amp;= \\bar{X} (1 - \\rho_{XX^\\prime}) + X\\rho_{XX^\\prime}\\notag\\\\ &amp;= \\bar{X} - \\bar{X}\\rho_{XX&#39;} + X\\rho_{XX^\\prime}\\notag\\\\ &amp;= \\bar{X} + \\rho_{XX&#39;} (X - \\bar{X}).\\notag \\end{aligned} \\end{equation} \\] Per i dati campionari, la formula diventa: \\[ \\hat{T} = \\bar{X} + r_{XX^\\prime} (X - \\bar{X}), \\] dove \\(X\\) è il punteggio (grezzo) osservato, \\(\\bar{X}\\) è la media dei punteggi osservati di un campione di rispondenti e \\(r_{XX^\\prime}\\) è il coefficiente di attendibilità. Esercizio 4.1 Posto un coefficiente di attendibilità pari a 0.80 e una media del test pari a \\(\\bar{X} = 100\\), si trovi una stima del punteggio vero per un rispondente con un punteggio osservato uguale a \\(X\\) = 115. La stima del punteggio vero \\(\\hat{T}\\) è uguale a \\[ \\begin{equation} \\begin{aligned} \\hat{T} &amp;= \\bar{X} + r_{XX^\\prime} (X - \\bar{X})\\notag\\\\ &amp;= 100 + 0.80 \\cdot (115 - 100) = 112. \\end{aligned} \\end{equation} \\] "],["lerrore-standard-della-stima.html", "4.2 L’errore standard della stima", " 4.2 L’errore standard della stima Oltre a ottenere una stima del punteggio vero da un punteggio osservato, il modello di regressione di Kelley ci fornisce anche l’errore standard della stima. È chiaro che la stima del punteggio vero è difficile da interpretare se non è accompagnata da una qualche indicazione sulla precisione della stima. Tale informazione viene appunto fornita dall’errore standard della stima. Se il test potesse essere somministrato ad un rispondente più volte sotto le identiche condizioni, sarebbe possibile ottenere in ciascuna somministrazione una stima del valore vero \\(\\hat{T}\\). A causa dell’errore della misurazione, il punteggio osservato non può che variare in ciascuna ipotetica somministrazioni del test e, di conseguenza, in ciascuna ipotetica somministrazione varierà anche la stima di \\(\\hat{T}\\). La deviazione standard di tali (ipotetiche) stime di \\(\\hat{T}\\) è chiamata errore standard della stima. L’errore standard della stima, \\(\\sigma_{\\hat{T}}\\), si calcola con la formula seguente: \\[ \\begin{equation} \\sigma_{\\hat{T}} = \\sigma_X \\sqrt{\\rho_{XX^\\prime} (1 -\\rho_{XX^\\prime})}. \\tag{4.3} \\end{equation} \\] Dimostrazione. Per ricavare la \\tag{4.4} si definisce \\(\\varepsilon\\) l’errore che si commette quando si stima il punteggio vero \\(\\hat{T}\\) con il punteggio osservato \\(T\\) (si veda Lord e Novick, 1968): \\[ \\varepsilon = T - \\hat{T}. \\] Si presti attenzione alla notazione: \\(E = X - T\\) indica l’errore della misurazione, ovvero la differenza tra il punteggio osservato e il punteggio vero. Invece \\(\\varepsilon = T - \\hat{T}\\) indica la differenza tra il punteggio vero e la stima del punteggio vero. Avendo che \\(\\hat{T} = \\bar{X} + \\rho_{XX^\\prime} (X - \\bar{X})\\), la varianza di \\(\\varepsilon = T - \\hat{T}\\) si può scrivere come \\[ \\begin{equation} \\begin{aligned} \\mathbb{V}(\\varepsilon) &amp;= \\mathbb{V}(T - \\hat{T})\\notag\\\\ &amp;= \\mathbb{V}(T - \\bar{X} - \\rho_{XX^\\prime} X + \\rho_{XX^\\prime}\\bar{X}). \\end{aligned} \\end{equation} \\] Dato che la varianza di una variabile aleatoria non cambia sommando a tale variabile una costante, dobbiamo semplicemente calcolare \\[ \\begin{equation} \\mathbb{V}(\\varepsilon) = \\mathbb{V}(T - \\rho_{XX^\\prime}X).\\notag \\end{equation} \\] Dobbiamo trovare la varianza della somma di due variabili aleatorie, una delle quali moltiplicata per una costante. Dunque: \\[ \\mathbb{V}(\\varepsilon) = \\mathbb{V}(T) + \\rho_{XX^\\prime}^2 \\mathbb{V}(X) - 2 \\rho_{XX^\\prime} \\mbox{Cov}(X,T), \\] ovvero, semplificando la notazione, \\[ \\begin{equation} \\sigma^2_{\\varepsilon} = \\sigma^2_T + \\rho_{XX^\\prime}^2 \\sigma^2_X - 2 \\rho_{XX^\\prime} \\sigma_{XT}.\\notag \\end{equation} \\] La quantità \\(\\rho_{XX^\\prime}\\) è il coefficiente di attendibilità. Quindi \\[ \\begin{equation} \\sigma^2_{\\varepsilon} = \\sigma^2_T + \\left(\\frac{\\sigma_T^2}{\\sigma_X^2}\\right)^2 \\sigma^2_X - 2 \\frac{\\sigma_T^2}{\\sigma_X^2} \\sigma_{XT}.\\notag \\end{equation} \\] Semplificando otteniamo \\[ \\begin{equation} \\begin{aligned} \\sigma^2_{\\varepsilon} &amp;= \\sigma^2_T + \\frac{\\sigma_T^4}{\\sigma_X^4} \\sigma^2_X - 2 \\frac{\\sigma_T^2}{\\sigma_X^2} \\sigma_{XT}\\notag\\\\ &amp;= \\sigma^2_T + \\sigma^2_T\\frac{\\sigma_T^2}{\\sigma_X^2} - \\sigma_T^2 2 \\frac{\\sigma_{XT}}{\\sigma_X^2} \\notag\\\\ &amp;= \\sigma^2_T \\left(1 + \\frac{\\sigma_T^2}{\\sigma_X^2} - 2 \\frac{\\sigma_{XT}}{\\sigma_X^2}\\right).\\notag \\end{aligned} \\end{equation} \\] Dato che \\(\\sigma_{XT}=\\sigma^2_T\\), l’equazione precedente diventa uguale a \\[ \\begin{equation} \\begin{aligned} \\sigma^2_{\\varepsilon} &amp;= \\sigma^2_T \\left(1 +\\frac{\\sigma_T^2}{\\sigma_X^2} - 2 \\frac{\\sigma_{T}^2}{\\sigma_X^2}\\right)\\notag\\\\ &amp;= \\sigma^2_T \\left(1 - \\frac{\\sigma_{T}^2}{\\sigma_X^2}\\right). \\end{aligned} \\end{equation} \\] L’errore standard della stima è dunque uguale a \\[ \\begin{equation} \\begin{aligned} \\sigma_{\\varepsilon} &amp;=\\sigma_T \\sqrt{1-\\frac{\\sigma^2_T}{\\sigma^2_X}}\\notag\\\\ &amp;=\\sigma_T \\sqrt{\\frac{\\sigma^2_X - \\sigma^2_T}{\\sigma^2_X}}\\notag\\\\ &amp;=\\frac{\\sigma_T}{\\sigma_X} \\sqrt{\\sigma^2_X - \\sigma^2_T}. \\end{aligned} \\end{equation} \\] Dato che \\(\\sigma^2_X=\\sigma^2_T+\\sigma^2_E\\), abbiamo \\[ \\begin{equation} \\begin{aligned} \\sigma_{\\varepsilon} &amp;= \\frac{\\sigma_T}{\\sigma_X} \\sqrt{\\sigma^2_E }\\notag\\\\ &amp;= \\frac{\\sigma_T}{\\sigma_X} \\sigma_E \\notag\\\\ &amp;= \\sqrt{\\rho_{XX^\\prime}} \\sigma_E. \\notag \\end{aligned} \\end{equation} \\] Ricordando che l’errore standard della misurazione è \\(\\sigma_E = \\sigma_X \\sqrt{1 - \\rho_{XX^\\prime}}\\), possiamo scrivere \\[ \\begin{equation} \\begin{aligned} \\sigma_{\\varepsilon} &amp;= \\sqrt{\\rho_{XX^\\prime}} \\sigma_E \\notag\\\\ &amp;= \\sqrt{\\rho_{XX^\\prime}} \\sigma_X \\sqrt{1-\\rho_{XX^\\prime}} \\notag\\\\ &amp;= \\sigma_X \\sqrt{\\rho_{XX^\\prime} (1 - \\rho_{XX^\\prime})}.\\notag \\end{aligned} \\end{equation} \\] Per dati campionari, l’errore standard della stima si calcola nel modo seguente: \\[ s_{\\hat{T}} = s_X \\sqrt{r_{XX^\\prime} (1-r_{XX^\\prime})}, \\] dove \\(s_X\\) è deviazione standard del campione e \\(r_{XX^\\prime}\\) è il coefficiente di attendibilità. "],["intervallo-di-confidenza-per-il-punteggio-vero.html", "4.3 Intervallo di confidenza per il punteggio vero", " 4.3 Intervallo di confidenza per il punteggio vero L’errore standard della stima \\(\\sigma_{\\hat{T}}\\) viene usato per calcolare l’intervallo di confidenza per il punteggio vero[^2]: \\[ \\hat{T} \\pm z \\sigma_{\\hat{T}}, \\] laddove \\(\\hat{T}\\) è la stima del punteggio vero e \\(z\\) è il quantile della normale standardizzata al livello di probabilità desiderato. Se il campione è piccolo (minore di 30) è opportuno usare \\(t\\) anziché \\(z\\). Si osservi che l’intervallo \\(\\hat{T} \\pm z \\sigma_{\\hat{T}}\\) è centrato sulla stima puntuale del valore vero e ha una ampiezza che dipende sia dal livello di copertura desiderato (da cui dipende il quantile \\(z_{\\frac{\\alpha}{2}}\\)), sia dal grado di precisione dello stimatore misurato dall’errore standard della stima, \\(\\sigma_{\\hat{T}} = \\sigma_X \\sqrt{\\rho_{XX^\\prime} (1 -\\rho_{XX^\\prime})}\\). L’errore standard della stima diventa tanto più grande quanto minore è l’attendibilità \\(\\rho_{XX^\\prime}\\) del test. L’intervallo di confidenza ricorda allo psicologo quanto sia imprecisa la misura che utilizza: tanto più grande è l’intervallo di confidenza, tanto maggiore è l’incertezza dell’interpretazione. L’intervallo di confidenza è lo strumento che consente allo psicologo di giungere ad una conclusione sapendo qual è la probabilità che tale conclusione sia sbagliata. Se la decisione è basata su un intervallo di confidenza al 95%, la probabilità di sbagliare è 0.05. Se lo psicologo vuole che la probabilità d’errore sia più piccola, può costruire un intervallo di confidenza utilizzando un valore \\(\\alpha\\) minore. La diminuzione di \\(\\alpha\\), però, produce un aumento dell’ampiezza dell’intervallo di confidenza. Valori accettabili per \\(\\alpha\\) sono 0.1 e 0.05. Esercizio 4.2 Charter (1996) discute l’effetto della variazione dell’attendibilità del test sull’ampiezza dell’intervallo di confidenza per il punteggio vero. Nell’esempio considera i punteggi del QI (\\(\\mu\\) = 100, \\(\\sigma\\) = 15) immaginando di variare il coefficiente di attendibilità del test tramite il quale il QI viene misurato. I valori esaminati sono 0.55, 0.65, 0.75, 0.85 e 0.95. Consideriamo, ad esempio, il caso di un punteggio osservato pari a QI = 120 e poniamo che \\(\\rho_{xx^\\prime}\\) = 0.65. In tali circostanze, la stima del punteggio vero è pari a \\[ \\begin{equation} \\begin{aligned} \\hat{T} &amp;= \\bar{X} + r_{XX^\\prime} (X - \\bar{X}) \\notag\\\\ &amp;= 100 + 0.65 (120 - 100)\\notag\\\\ &amp;= 113.\\notag \\end{aligned} \\end{equation} \\] L’errore standard della stima è uguale a \\[ \\begin{equation} \\begin{aligned} \\sigma_{\\hat{T}} &amp;= \\sigma_{X} \\sqrt{r_{XX^\\prime} (1 - r_{XX^\\prime})} \\notag\\\\ &amp;= 15 \\sqrt{0.65 (1 - 0.65)}\\notag\\\\ &amp;= 7.15.\\notag \\end{aligned} \\end{equation} \\] L’intervallo di confidenza al 95% per la stima del punteggio vero diventa pertanto uguale a \\[ 113 \\pm 1.96 \\cdot 7.15 = [98.98, 127.02]. \\] "],["cut-off.html", "4.4 Cut-off", " 4.4 Cut-off Uno degli usi possibili degli intervalli di confidenza per il punteggio vero è quello di confrontare i limiti dell’intervallo di confidenza con un cut-off. Sono possibili tre alternative: il limite inferiore dell’intervallo di confidenza è maggiore del cut-off, il limite superiore dell’intervallo è minore del cut-off, oppure il valore del cut-off è contenuto all’interno dell’intervallo. Nel primo caso, lo psicologo afferma, con un grado di certezza \\(1 -\\alpha\\), che il valore vero del rispondente è superiore al cut-off. Nel secondo caso, lo psicologo afferma, con un grado di certezza \\(1 -\\alpha\\), che il valore vero del rispondente è inferiore al cut-off. Nel terzo caso lo psicologo non può concludere né che il valore vero sia inferiore né che sia superiore al cut-off. Esercizio 4.3 Si considerino i punteggi del QI, per cui \\(\\bar{X}\\) = 100 e \\(s_X\\) = 15. Sia l’attendibilità del test \\(\\rho_{XX^\\prime}\\) = 0.95. Supponiamo che il rispondente abbia un QI = 130. Poniamo che il cut-off per ammettere il rispondente ad un corso avanzato sia 120. Ci sono tre alternative: il valore vero del rispondente è sicuramente maggiore di 120; il valore vero del rispondente è sicuramente inferiore di 120; le evidenze disponibili ci lasciano in dubbio se il punteggio vero sia maggiore o minore di 120. Svolgiamo i calcoli per trovare l’intervallo di confidenza al livello di certezza del 95%: xm &lt;- 100 sx &lt;- 15 rho &lt;- .95 x &lt;- 130 t.hat &lt;- xm + rho * (x - xm) t.hat #&gt; [1] 128.5 se.t &lt;- sx * sqrt(rho * (1 - rho)) se.t #&gt; [1] 3.269174 t.hat + c(1, -1) * qnorm(.025, 0, 1) * se.t #&gt; [1] 122.0925 134.9075 Dato che il limite inferiore dell’intervallo di confidenza è maggiore del cut-off, lo psicologo conclude che il punteggio vero del rispondente è maggiore di 120. Quindi, raccomanda che il rispondente sia ammesso al corso avanzato. Continuiamo con l’esempio precedente, ma supponiamo che l’attendibilità del test abbia un valore simile a quello che solitamente si ottiene empiricamente, ovvero 0.80. xm &lt;- 100 sx &lt;- 15 rho &lt;- .8 x &lt;- 130 t.hat &lt;- xm + rho * (x - xm) t.hat #&gt; [1] 124 se.t &lt;- sx * sqrt(rho * (1 - rho)) se.t #&gt; [1] 6 t.hat + c(1, -1) * qnorm(.025, 0, 1) * se.t #&gt; [1] 112.2402 135.7598 In questo secondo esempio, l’intervallo di confidenza al 95% è \\([112.24, 135.76]\\) e contiene il valore del cut-off. Dunque, la decisione dello psicologo è che non vi sono evidenze sufficienti che il vero valore del rispondente sia superiore al cut-off. Si noti come la diminuzione dell’attendibilità del test porta all’aumento delle dimensioni dell’intervallo di confidenza. "],["procedure-alternative.html", "4.5 Procedure alternative", " 4.5 Procedure alternative Non vi è un unico modo per costruire gli intervalli di confidenza per il punteggio vero. Charter e Feldt (1991) descrivono altri quattro approcci possibili, oltre a quello discusso qui, per costruire gli intervalli di confidenza per il punteggio vero. L’approccio che abbiamo descritto è accettato da tutti gli autori; le procedure alternative descritte da Charter e Feldt (1991), non sono invece accettate come valide da tutti gli autori. La più comune delle procedure alternative descritte da Charter e Feldt (1991), che rappresenta l’approccio tradizionale a questo problema, centra l’intervallo di confidenza sul punteggio osservato di un rispondente e utilizza l’errore standard della misurazione per calcolare i limiti dell’intervallo di confidenza: \\[ X_j \\pm z_{\\frac{\\alpha}{2}} \\sigma_E, \\] dove \\(\\sigma_E = \\sigma_X \\sqrt{1 -\\rho_{XX^\\prime}}\\). Tale procedura è però stata criticata da diversi autori (es., Dudek, 1979). "],["utilizzo-e-costruzione-di-test-psicometrici.html", "Capitolo 5 Utilizzo e costruzione di test psicometrici", " Capitolo 5 Utilizzo e costruzione di test psicometrici La maggior parte degli psicologi che utilizzano i test non costruiscono dei test ad hoc ma utilizzano i test già validati e interpretano i punteggi attenuti sulla base delle norme fornite nel manuale del test. Nella selezione del test che è più appropriato per il problema che lo psicologo deve affrontare, si devono considerare domande quali: Qual è il valore minimo di attendibilità che è richiesto? Ovvero, a che livello di precisione dobbiamo essere in grado di differenziare tra i rispondenti? Che tipo di validità è importante? Quali sono le caratteristiche della popolazione che il gruppo normativo deve rappresentare? Qual è il livello di istruzione necessario per completare il test? Qual è il tempo disponibile per la somministrazione del test e per lo scoring dei risultati? Quali sono i costi necessari per la somministrazione del test e per lo scoring dei risultati? Avendo dato una risposta a tali domande, la selezione del test solitamente si riduce ad una scelta tra poche alternative. Per giungere ad una decisione tra tali alternative è importante consultare la letteratura specialistica che discute le proprietà psicometriche dei test e la loro validità. Ciascuno psicologo ha l’obbligo di dimostrare che il test che usa per un certo scopo costituisca lo strumento migliore, tra quelli disponibili, per giungere ad una decisione razionale e obiettiva relativamente al problema che si trova ad affrontare (si veda il Codice Deontologico). Se nessuno dei test disponibili si dimostra appropriato per misurare un determinato tratto psicologico, si procede alla costruzione di un nuovo reattivo. La costruzione di un test richiede sia conoscenze specialistiche di tipo psicometrico, sia una conoscenza specialistica del fenomeno considerato. Le fasi di costruzione dei test comprendono la definizione delle aree di contenuto che andranno misurate dal test; la generazione degli item per ciascuna area in un numero di circa tre volte superiore a quello che ci si aspetta farà parte della versione finale del test; la somministrazione degli item ad un campione sufficientemente numeroso (centinaia di rispondenti selezionati in modo tale che il campione sia rappresentativo della popolazione di interesse); l’analisi degli item che ci consente di selezionare gli item migliori; infine, la somministrazione della versione revisionata del test ad un nuovo campione per stabilire se la versione finale del test sia soddisfacente dal punto di vista psicometrico. In caso affermativo, il campione esaminato fornisce le norme del test e questa fase va sotto il nome di standardizzazione del test. "],["caratteristiche-dellanalisi-fattoriale.html", "5.1 Caratteristiche dell’analisi fattoriale", " 5.1 Caratteristiche dell’analisi fattoriale La teoria psicometria è l’unico strumento che abbiamo a disposizione per creare strumenti di misurazione validi e attendibili per l’assessment psicologico e neuropsicologico. La psicometria comprende due diversi approcci metodologici per la costruzione dei reattivi psicologici: la teoria classica dei test e la teoria di risposta all’item (item response theory). Esamineremo qui gli aspetti di base della teoria classica dei test e ci focalizzeremo, in particolare, sull’analisi fattoriale. Se vogliamo costruire un test psicometrico per la valutazione di un particolare deficit psicologico o neuropsicologico, prima di iniziare lo studio, dobbiamo fornire una risposta ad una serie di domande. Per esempio, come dobbiamo selezionare gli item? Gli item scelti coprono tutto il dominio del fenomeno considerato? Quanti item dobbiamo usare? A quanti soggetti dobbiamo somministrare lo strumento? Quali analisi statistiche dobbiamo svolgere sui dati raccolti? L’analisi fattoriale è uno strumento statistico che può essere utilizzato per trovare una risposta a queste domande. Chiariamo subito che l’analisi fattoriale è una tecnica statistica complessa che richiede l’uso di un software. Per gli scopi di questo insegnamento useremo il pacchetto lavaan del linguaggio statistico . L’analisi fattoriale può essere pensata come una tecnica statistica per la ricerca di variabili latenti a partire da alcune variabili osservate. La distinzione tra variabili latenti e variabili osservate si basa sulla osservabilità, ossia sulla possibilità di rilevazione empirica. Le prime sono variabili non direttamente osservabili in quanto rappresentano concetti molto generali o complessi, mentre le seconde sono facilmente rilevabili. In ogni caso, entrambe possono essere operazionalizzate, per cui anche nel caso delle variabili latenti c’è una sostanziale differenza con i concetti. Ma che cos’è una variabile latente o fattore? Un fattore può essere descritto come una combinazione lineare di variabili manifeste tra loro associate le quali rappresentano una specifica dimensione di un costrutto psicologico, la quale si distingue da altre dimensioni dello stesso costrutto o dalle dimensioni di costrutti diversi (Tabachnick &amp; Fidell, 2001). Per esempio, la Wechsler Adult Intelligence Scale – Fourth Edition (WAIS-IV) dà una valutazione complessiva delle capacità cognitive di adolescenti e adulti e distingue tra quattro dimensioni dell’intelligenza: comprensione verbale, ragionamento visuo-percettivo, memoria di lavoro e velocità di elaborazione. L’analisi fattoriale viene usata per lo sviluppo e la validazione di un test psicometrico e per stabilire la validità di costrutto di uno strumento per una specifica popolazione. Una volta che la struttura interna di un costrutto è stata chiarita, l’analisi fattoriale può essere usata per identificare le variabili esterne (per esempio, il genere o il livello di istruzione) che sono associate alle varie dimensioni del costrutto di interesse (Nunnally &amp; Bernstein, 1994). 5.1.1 L’analisi fattoriale esplorativa e confermativa Nei suoi primi modelli matematici, l’analisi fattoriale era una tecnica di analisi esplorativa appunto perché permetteva di “esplorare” le relazioni nascoste fra un gran numero di variabili. In tempi più recenti, la tecnica delle equazioni strutturali ha permesso di sviluppare una tecnica di analisi fattoriale di tipo confermativo, che cioè permette di verificare se effettivamente i fattori ipotizzati servono a spiegare le variabili misurate. In tempi ancora più recenti è stato notato che i vincoli posti dai modelli SEM sono, alle volte, troppo restrittivi per cui le tecniche dell’analisi fattoriale esplorativa vengono integrate con i modelli di equazioni strutturali in maniera tale da produrre un nuovo approccio alla definizione delle variabili latenti, ovvero quelli che si chiamano modelli ESEM (Exploratory Structural Equation Modeling). 5.1.2 Assunzioni dell’analisi fattoriale L’assunzione di base dell’analisi fattoriale esplorativa è che, dato un insieme di variabili osservate, esista un insieme più piccolo di fattori latenti i quali siano in grado di spiegare i legami, le interrelazioni e le dipendenze tra le variabili statistiche osservate. Dato che l’analisi fattoriale si propone di spiegare una matrice di correlazioni, molte delle assunzioni che stanno alla base del calcolo delle correlazioni si applicano anche all’analisi fattoriale: campioni di grande numerosità, il fatto che le variabili considerate abbiano una distribuzione di probabilità continua, la linearità nella relazione tra le variabili. In generale, queste assunzioni si riducono al requisito della normalità multivariata, ovvero il requisito per il quale tutte le variabili considerate e tutte le combinazioni lineari tra tali variabili sono distribuite normalmente. Molto spesso, però, l’assunzione di normalità multivariata è violata a causa del fatto che, anziché essere delle variabili continue, gli item sono spesso variabili (discrete) che derivano da risposte a questionari fornite utilizzando scale di tipo Likert. Vedremo come questo problema può essere superato utilizzando le correlazioni policoriche. 5.1.3 Sviluppo storico dell’analisi fattoriale L’analisi fattoriale è un metodo di analisi multivariata che, dal punto di vista storico, risulta fortemente interconnessa con i modelli psicometrici. Alcuni concetti basilari per i successivi sviluppi dell’analisi fattoriale si possono trovare in Galton (1888, 1889) con il concetto di fonte comune (common source) e in Pearson (1901) con l’introduzione delle componenti principali come metodo di riduzione dei dati. Si deve però a Spearman (1904) l’elaborazione del primo modello di analisi fattoriale secondo il quale le risposte fornite ad un insieme di test di abilità sono riconducibili ad un unico fattore generale di intelligenza. L’analisi fattoriale è stata sviluppata da diversi gruppi di psicologi inglesi e americani che, tra l’inizio del ’900 e il 1930, svilupparono una serie di tecniche statistiche per affrontare problemi quali quello di determinare le dimensioni dell’intelligenza (Garnett, 1919; Pearson, 1901; Spearman, 1904, 1923, 1927, 1929; Thurstone, 1935, 1937a, 1937b; Wilson, 1928). In Inghilterra, Spearman e i suoi colleghi (Burt, 1939, 1941; Garnett, 1919; Ledermann, 1937, 1938; Spearman, 1904, 1922, 1923, 1927, 1928, 1929, 1930a, 1930b; Thomson, 1934, 1936, 1938) svilupparono il concetto della teoria dei due fattori dell’intelligenza umana secondo cui esiste un fattore generale, g, che esprime l’intelligenza generale, è ereditario e compare in maggiore o minor misura in tutti i test, e esistono inoltre tanti fattori specifici, s, che rappresentano l’acquisizione specifica attraverso l’apprendimento e l’esperienza, e sono presenti in modo differenziato in ogni singolo test. Dato che i fattori specifici sono incorrelati tra loro, il fattore g spiega la maggior parte delle correlazioni tra i punteggi delle abilità mentali (Nunnally &amp; Bernstein, 1994). Anche se successive ricerche non confermarono totalmente l’ipotesi di Spearman dell’esistenza di un fattore g, e particolarmente vennero alla luce dei fattori di gruppo, che potevano spiegare le correlazioni esistenti tra test simili (Garnett, 1919; Spearman, 1927), la maggior parte dello sviluppo iniziale dell’analisi fattoriale fu dedicata alla ricerca di un singolo fattore per l’intelligenza. Spearman analizzò molti insiemi di dati nel tentativo di trovare conferma al modello uni-fattoriale: alcuni di questi, tuttavia, non risultarono compatibili con il modello dei due fattori. La generalizzazione del modello fattoriale al caso in cui sono presenti più fattori comuni si deve a Thurstone (1938, 1947). Nel modello di Thurstone non viene fatto più riferimento ad un fattore generale che influenza tutte le variabili osservate: si ipotizza invece la presenza di una molteplicità di fattori comuni i quali determinano le variabili osservate. I contributi di Thurstone riguardano alcuni degli aspetti fondamentali dell’analisi fattoriale esplorativa, quali il concetto di struttura semplice e i fattori obliqui. Thurstone e collaboratori applicarono la teoria dei fattori multipli a vari problemi psicometrici (Thurstone, 1931, 1940, 1947, 1948, 1954) diventando ben presto il riferimento più importante per lo sviluppo delle procedure dell’analisi fattoriale. La centralità della scuola statunitense continuò fino alla fine degli anni ’60, quando un numero di importanti psicometristi europei contribuirono a spostare il focus dell’assessment psicologico dall’approccio esplorativo a quello confermativo (Jöreskog, 1967, 1969, 1970; Jöreskog &amp; Goldberger, 1972; Sörbom, 1974). I contributi statistici di Jöreskog e Sörbom hanno contribuito a sviluppare quelli che oggi chiamiamo i modelli di equazioni strutturali (Structural Equation Models, SEM), i quali costituiscono una delle tecniche più utilizzate per l’analisi dei dati nelle discipline psicologiche e sociali. Un’ulteriore linea di ricerca venne sviluppata nel campo della biometria, ad opera di Sewall Wright (1934). In un tale approccio vengono utilizzati modelli di equazioni simultanee, che includono però solo variabili osservabili, per analizzare particolari schemi di rappresentazione dei nessi di influenza tra le variabili noti come analisi dei percorsi (path analysis). A partire dalla metà degli anni cinquanta, con la diffusione dei centri calcolo, l’analisi fattoriale è diventata uno dei metodi di analisi dei dati più largamente utilizzati in psicologia e, in particolare, nelle ricerche volte alla costruzione dei reattivi psicologici. Le tradizioni di ricerca dei modelli di equazioni simultanee con variabili osservate, da una parte, e dei modelli di equazioni strutturali con variabili osservate e latenti, dall’altra, sono rimaste sostanzialmente indipendenti fino agli anni ’60 dello scorso secolo, quando metodologi delle scienze sociali, come Blalock (1961, 1963), Boudon (1965) e Duncan (1966) hanno cominciato a sottolineare i vantaggi derivanti dalla possibilità di combinare la semplicità di rappresentare nessi di influenza tra le variabili tramite i diagrammi tipici della path analysis, con il rigore derivante dalla specificazione delle equazioni simultanee, in modo tale da includere sia variabili osservate sia variabili latenti. La disponibilità di programmi per computer che permettono di tradurre in un linguaggio non matematico le complesse operazioni matematiche connesse alla risoluzione simultanea di sistemi di equazioni lineari con variabili latenti ha poi facilitato enormemente la diffusione delle tecniche dell’analisi fattoriale confermativa. A partire dalla fine degli anni sessanta, soprattutto grazie a Karl Jöreskog, il modello di analisi fattoriale si è ulteriormente raffinato e sviluppato verso un approccio confermativo orientato prevalentemente all’esame di ipotesi teoriche. Sebbene l’analisi fattoriale confermativa (CFA) possa essere vista come una motivazione per la creazione di modelli di misurazione parsimoniosi, tali modelli spesso includono un certo livello di errore di misurazione sistematico che deriva dal fatto che gli item sono raramente indicatori puri dei corrispondenti costrutti, e quindi ci si può aspettare un certo grado di associazione rilevante per il costrutto anche tra item e costrutti non target, ma concettualmente associati (Morin et al., 2016). Quando tali associazioni restano inespresse nel modello, a causa dei vincoli restrittivi dell’approccio CFA (cioè, del fatto che gli item possono essere indicatori di un unico fattore), allora i risultati dell’analisi possono risultare sistematicamente distorti. In particolare, si può osservare una sovrastima delle associazioni tra i fattori. Inoltre, i vincoli eccessivamente restrittivi dei modelli CFA possono anche minare la bontà di adattamento dei modelli e la validità discriminante dei fattori (Marsh et al., 2010, 2014). I contemporanei modelli ESEM si pongono l’obiettivo di affrontare questo tipo di problemi. 5.1.4 Fasi dell’analisi fattoriale Indipendentemente dal software statistico che viene utilizzato e dal livello di esperienza del ricercatore, lo sviluppo di un test psicometrico inizia con l’analisi fattoriale esplorativa. In essa si possono distinguere otto stadi successivi: la specificazione del problema, la scelta degli item, la verifica dell’adeguatezza della matrice di correlazione, l’estrazione iniziale dei fattori, la rotazione dei fattori, l’ulteriore selezione degli item, l’interpretazione dei risultati, la costruzione di un report della ricerca, la validazione dei risultati. Queste diverse fasi della costruzione e validazione di un reattivo psicologivo verranno discusse nel seguito di queste dispense. "],["il-modello-unifattoriale.html", "Capitolo 6 Il modello unifattoriale", " Capitolo 6 Il modello unifattoriale In questo Capitolo verranno presentate le basi teoriche dell’analisi fattoriale, ovvero di quel modello statistico che offre la possibilità di ricostruire le correlazioni osservate tra le variabili manifeste considerando le saturazioni delle variabili in uno o più fattori generali. Nell’analisi fattoriale \\(p\\) variabili manifeste (item) vengono concepite come condizionalmente indipendenti date \\(m\\) variabili latenti chiamate fattori. L’analisi fattoriale si pone lo scopo di interpretare i fattori come dei costrutti teorici inosservabili. Infatti, il desiderio di spiegare mediante il concetto di intelligenza le correlazioni osservate tra le prestazioni di un gruppo di individui in una serie di compiti è stato la forza trainante nello sviluppo originale dell’analisi fattoriale. L’analisi fattoriale consente di identificare i costrutti di cui gli item sono espressione e di stabilire in che misura ciascun item rappresenta il costrutto. Il modello unifattoriale ipotizza \\(m = 1\\); il modello multifattoriale ipotizza \\(m &gt; 1\\). Lo scopo di questo capitolo è quello di introdurre il modello fattoriale che assume l’esistenza di un unico fattore comune latente. "],["modello-monofattoriale.html", "6.1 Modello monofattoriale", " 6.1 Modello monofattoriale Con \\(p\\) variabili manifeste \\(y_i\\), il caso più semplice è quello di un solo fattore comune: \\[\\begin{equation} y_i = \\mu_i + \\lambda_{i} \\xi + 1 \\cdot \\varepsilon_i \\qquad i=1, \\dots, p, \\tag{6.1} \\end{equation}\\] dove \\(\\xi\\) rappresenta il fattore comune a tutte le \\(y_i\\), \\(\\varepsilon_i\\) sono i fattori specifici o unici di ogni variabile osservata e \\(\\lambda_i\\) sono le saturazioni (o pesi) fattoriali le quali stabiliscono il peso del fattore latente su ciascuna variabile osservata. Si noti che il modello di analisi fattoriale è solo apparentemente simile al modello di regressione. Infatti, sia il fattore comune \\(\\xi\\) sia i fattori specifici \\(\\varepsilon_i\\) sono inosservabili: tutto ciò che giace a destra dell’uguaglianza è dunque incognito. L’analisi di regressione e l’analisi fattoriale si differenziano non solo per tale aspetto, ma anche per il fatto di avere obiettivi diversi. L’analisi di regressione ha l’obiettivo di individuare le variabili esplicative, direttamente osservabili, che sono in grado di spiegare la maggior parte della varianza della variabile dipendente. Il problema dell’analisi unifattoriale, invece, è quello di identificare la variabile esplicativa inosservabile che è in grado di spiegare la maggior parte della covarianza tra le variabili osservate. Nel caso di cinque variabili osservate e un solo fattore comune, ad esempio, il modellofattoriale (6.1) può essere rappresentato graficamente nel modo seguente. Si suole assumere per comodità che \\(\\mu=0\\), il che corrisponde a considerare le variabili \\(y_i\\) come ottenute dagli scarti dalle medie \\(\\mu_i\\), per \\(i = 1, \\dots, p\\): \\[\\begin{equation} y_i -\\mu_i = \\lambda_i \\xi + 1 \\cdot \\varepsilon_i. \\tag{6.2} \\end{equation}\\] Si assume che il fattore comune abbia media zero, \\(\\mathbb{E}(\\xi)=0\\), e varianza unitaria, \\(\\mathbb{V}(\\xi)=1\\), i fattori specifici abbiano media zero, \\(\\mathbb{E}(\\varepsilon_j)=0\\), varianza \\(\\mathbb{V}(\\varepsilon_i)=\\psi_{i}\\) e siano incorrelati tra loro, \\(\\mathbb{E}(\\varepsilon_i \\varepsilon_k)=0\\), e con il fattore comune, \\(\\mathbb{E}(\\varepsilon_i \\xi)=0\\). In questo modello, poiché i fattori specifici sono tra loro incorrelati, l’interdipendenza tra le variabili è completamente spiegata dal fattore comune. Dalle ipotesi precedenti è possibile ricavare: la covarianza tra \\(y_i\\) e il fattore comune, la varianza della \\(i\\)-esima variabile osservabile \\(y_i\\), la covarianza tra due variabili \\(y_i\\) e \\(y_k\\). Questo sarà l’obiettivo della discussione presente in questo capitolo. "],["correlazione-parziale.html", "6.2 Correlazione parziale", " 6.2 Correlazione parziale Prima di discutere il modello statistico dell’analisi fattoriale, chiariamo il concetto di correlazione parziale. La nascita dell’analisi fattoriale viene di solito attribuita a Charles Spearman. Nel 1904, Sperman pubblicò un articolo dal titolo “General Intelligence, objectively determined and measured” dove propose la Teoria dei Due Fattori. Nel suo articolo del 1904, Spearman dimostrò come, mediante il metodo dell’annullamento della tetrade (tetrad differences), sia possibile identificare un fattore inosservabile a partire da una matrice di correlazioni. L’annullamento della tetrade rappresenta un’applicazione della teoria della correlazione parziale. Il problema è quello di stabilire se, controllando un insieme di variabili inosservabili \\(\\xi_j\\), dette fattori, le correlazioni tra le variabili osservabili \\(Y_i\\), al netto degli effetti lineari delle \\(\\xi_j\\), diventino statisticamente nulle. Consideriamo un esempio nel quale sono presenti solo tre variabili: \\(Y_1\\), \\(Y_2\\) e \\(F\\). In generale, la correlazione \\(r_{1,2}\\) tra due variabili \\(Y_1\\) e \\(Y_2\\) può risultare dalla loro associazione con una terza variabile \\(F\\). Per calcolare la correlazione parziale tra \\(Y_1\\) e \\(Y_2\\) al netto dell’effetto lineare di \\(F\\) è necessario trovare le componenti di \\(Y_1\\) e di \\(Y_2\\) che sono linearmente indipendenti da \\(F\\). Vediamo come si può ottenere questo risultato. La componente di \\(Y_1\\) linearmente indipendente da \\(F\\) è data dai residui \\(E_1\\) del modello \\[ Y_1 = b_{01} + b_{11}F + E_1. \\] La componente di \\(Y_2\\) linearmente indipendente da \\(F\\) è data dai residui \\(E_2\\) del modello \\[ Y_2 = b_{02} + b_{12}F + E_2. \\] La correlazione parziale \\(r_{1,2 \\mid F}\\) è la correlazione di Pearson tra \\(E_1\\) e \\(E_2\\), ovvero la correlazione tra le componenti di \\(Y_1\\) e \\(Y_2\\) linearmente indipendenti da \\(F\\). La correlazione parziale tra \\(Y_1\\) e \\(Y_2\\) al netto dell’effetto di \\(F\\) può essere calcolata direttamente dalle correlazioni semplici tra le tre variabili \\(Y_1\\), \\(Y_2\\) e \\(F\\) mediante la seguente formula: \\[\\begin{equation} r_{1,2 \\mid F} = \\frac{r_{12} - r_{1F}r_{2F}}{\\sqrt{(1-r_{1F}^2)(1-r_{2F}^2)}} \\tag{6.3} \\end{equation}\\] Facciamo un esempio numerico. Sia \\(f\\) una variabile su cui misuriamo \\(n\\) valori set.seed(123) n &lt;- 1000 f &lt;- rnorm(n, 24, 12) Siano \\(y_1\\) e \\(y_2\\) funzioni lineari di \\(f\\), a cui viene aggiunta una componente d’errore gaussiano: y1 &lt;- 10 + 7 * f + rnorm(n, 0, 50) y2 &lt;- 3 + 2 * f + rnorm(n, 0, 50) La correlazione tra \\(y_1\\) e \\(y_2\\) (\\(r_{12}= 0.355\\)) deriva dal fatto che \\(\\hat{y}_1\\) e \\(\\hat{y}_2\\) sono entrambe funzioni lineari di \\(f\\): Y &lt;- cbind(y1, y2, f) R &lt;- cor(Y) round(R, 3) #&gt; y1 y2 f #&gt; y1 1.000 0.380 0.867 #&gt; y2 0.380 1.000 0.423 #&gt; f 0.867 0.423 1.000 Eseguiamo le regressioni di \\(y_1\\) su \\(f\\) e di \\(y_2\\) su \\(F\\): fm1 &lt;- lm(y1 ~ f) fm2 &lt;- lm(y2 ~ f) Nella regressione, ciascuna osservazione \\(y_{i1}\\) viene scomposta in due componenti linearmente indipendenti, i valori adattati \\(\\hat{y}_{i}\\) e i residui, \\(e_{i}\\): \\(y_i = \\hat{y}_i + e_1\\). Nel caso di \\(y_1\\) abbiamo round(head(cbind(y1, y1.hat = fm1$fit, e = fm1$res, fm1$fit + fm1$res)), 3) #&gt; y1 y1.hat e #&gt; 1 81.130 130.505 -49.375 81.130 #&gt; 2 106.667 159.704 -53.037 106.667 #&gt; 3 308.032 317.846 -9.813 308.032 #&gt; 4 177.314 186.285 -8.971 177.314 #&gt; 5 61.393 191.482 -130.089 61.393 #&gt; 6 374.094 331.668 42.426 374.094 Lo stesso può dirsi di \\(y_2\\). La correlazione parziale \\(r_{12 \\mid f}\\) tra \\(y_1\\) e \\(y_2\\) dato \\(f\\) è uguale alla correlazione di Pearson tra i residui \\(e_1\\) e \\(e_2\\) calcolati mediante i due modelli di regressione descritti sopra: cor(fm1$res, fm2$res) #&gt; [1] 0.02828618 La correlazione parziale tra \\(y_1\\) e \\(y_2\\) al netto di \\(f\\) è .02829. Per i dati esaminati sopra, dunque, la correlazione parziale tra le variabili \\(y_1\\) e \\(y_2\\) diventa uguale a zero se la variabile \\(f\\) viene controllata (ovvero, se escludiamo da \\(y_1\\) e da \\(y_2\\) l’effetto lineare di \\(f\\)). Il fatto che la correlazione parziale sia zero significa che la correlazione che abbiamo osservato tra \\(y_1\\) e \\(y_2\\) (\\(r = 0.355\\)) non dipendeva dall’effetto che una variabile \\(y\\) esercitava sull’altra, ma bensì dal fatto che c’era una terza variabile, \\(f\\), che influenzava sia \\(y_1\\) sia \\(y_2\\). In altre parole, le variabili \\(y_1\\) e \\(y_2\\) sono condizionalmente indipendenti dato \\(f\\). Ciò significa, come abbiamo visto sopra, che la componente di \\(y_1\\) linearmente indipendente da \\(f\\) è incorrelata con la componente di \\(y_2\\) linearmente indipendente da \\(f\\). La correlazione che abbiamo calcolato tra i residui di due modelli di regressione non è altro che la correlazione che viene calcolata applicando la (6.3). Infatti, inserendo nella (6.3) i valori delle correlazioni esaminate otteniamo (R[1, 2] - R[1, 3] * R[2, 3]) / sqrt((1 - R[1, 3]^2) * (1 - R[2, 3]^2)) %&gt;% round(3) #&gt; [1] 0.02827513 In conclusione, possiamo dunque attribuire alla (6.3) la seguente interpretazione: la correlazione parziale tra le variabili \\(y_1\\) e \\(y_2\\) dato \\(f\\) non è altro che la correlazione tra le componenti di \\(y_1\\) e \\(y_2\\) da cui l’effetto lineare di \\(f\\) è stato rimosso. "],["principio-base-dellanalisi-fattoriale.html", "6.3 Principio base dell’analisi fattoriale", " 6.3 Principio base dell’analisi fattoriale Attualmente, l’inferenza statistica nell’analisi fattoriale spesso si svolge mediante il calcolo di stime della massima verosimiglianza ottenute mediante procedure iterative come l’algoritmo EM (Rubin &amp; Thayer, 1982). All’inizio dell’analisi fattoriale, tuttavia, la procedura di estrazione dei fattori faceva leva sulle relazioni invarianti che il modello fattoriale impone agli elementi della matrice di covarianza delle variabili osservate. Il più conosciuto tra tali invarianti è la tetrade che si presenta nei modelli ad un fattore. La tetrade è una combinazione di quattro correlazioni. Se l’associazione osservata tra le variabili dipende effettivamente dal fatto che le variabili in questione sono state causalmente generate da un fattore comune inosservabile, allora è possibile generare una combinazione delle correlazioni tra le variabili che porta all’annullamento della tetrade. In altre parole, l’analisi fattoriale si chiede se esiste un insieme esiguo di \\(m&lt;p\\) variabili inosservabili che rendono significativamente nulle tutte le correlazioni parziali tra le \\(p\\) variabili osservate al netto dei fattori comuni. Se il metodo della correlazione parziale consente di identificare \\(m\\) variabili latenti, allora lo psicologo conclude che tali fattori corrispondono agli \\(m\\) costrutti che intende misurare. Per chiarire il metodo dell’annullamento della tetrade consideriamo la matrice di correlazioni riportata nella Tabella @ref(tab:corr_parziale). Nella tabella, la correlazione parziale tra ciascuna coppia di variabili \\(y_i\\), \\(y_j\\) (con \\(i \\neq j\\)) dato \\(\\xi\\) è sempre uguale a zero. Ad esempio, la correlazione parziale tra \\(y_3\\) e \\(y_5\\) dato \\(\\xi\\) è: \\[\\begin{equation} \\begin{aligned} r_{35 \\mid \\xi} &amp;= \\frac{r_{35} - r_{3\\xi}r_{5\\xi}} {\\sqrt{(1-r_{3\\xi}^2)(1-r_{5\\xi}^2)}} \\notag \\\\[12pt] &amp;= \\frac{0.35 - 0.7 \\times 0.5} {\\sqrt{(1-0.7^2)(1-0.5^2)}} = 0. \\notag \\end{aligned} \\end{equation}\\] Lo stesso risultato si trova per qualunque altra coppia di variabili \\(y_i\\) e \\(y_j\\), ovvero \\(r_{ij \\mid \\xi} = 0\\). Matrice di correlazioni nella quale tutte le correlazioni parziali tra le variabili \\(Y\\) al netto dell’effetto di \\(\\xi\\) sono nulle. \\(\\xi\\) \\(y_1\\) \\(y_2\\) \\(y_3\\) \\(y_4\\) \\(y_5\\) \\(\\xi\\) 1.00 \\(y_1\\) 0.90 1.00 \\(y_2\\) 0.80 0.72 1.00 \\(y_3\\) 0.70 0.63 0.56 1.00 \\(y_4\\) 0.60 0.54 0.48 0.42 1.00 \\(y_5\\) 0.50 0.45 0.40 0.35 0.30 1.00 Possiamo dunque dire che, per la matrice di correlazioni della Tabella precedente, esiste un’unica variabile \\(\\xi\\) la quale, quando viene controllata, spiega tutte le \\[ p(p-1)/2 = 5(5-1)/2=10 \\] correlazioni tra le variabili \\(y\\). Questo risultato non è sorprendente, in quanto la matrice di correlazioni della Tabella esaminata è stata costruita in modo tale da possedere tale proprietà. Ma supponiamo di essere in una situazione diversa, ovvero di avere osservato soltanto le variabili \\(y_i\\) e di non conoscere \\(\\xi\\). In tali circostanze ci possiamo porre la seguente domanda: “esiste una variabile inosservabile \\(\\xi\\) la quale, se venisse controllata, renderebbe uguali a zero tutte le correlazioni parziali tra le variabili \\(y\\)?” Se una tale variabile inosservabile esiste, ed è in grado di spiegare tutte le correlazioni tra le variabili osservate \\(y\\), allora essa viene chiamata fattore. Definizione 6.1 Un fattore è una variabile inosservabile in grado di rendere significativamente nulle tutte le correlazioni parziali tra le variabili manifeste. 6.3.1 Vincoli sulle correlazioni Come si può stabilire se esiste una variabile inosservabile in grado di rendere nulle tutte le correlazioni parziali tra le variabili osservate? Riscriviamo la (6.3) per specificare la correlazione parziale tra le variabili \\(y_i\\) e \\(y_j\\) dato \\(\\xi\\): \\[ r_{ij \\mid \\xi} = \\frac{r_{ij} - r_{i\\xi}r_{j\\xi}} {\\sqrt{(1-r_{i\\xi}^2)(1-r_{j\\xi}^2)}} \\] Affinché \\(r_{ij \\mid \\xi}\\) sia uguale a zero è necessario che \\[ r_{ij} - r_{i\\xi}r_{j\\xi}=0 \\] ovvero \\[ r_{ij} = r_{i\\xi}r_{j\\xi}. \\] In altri termini, se esiste un fattore non osservato \\(\\xi\\) in grado di rendere uguali a zero tutte le correlazioni parziali \\(r_{ih \\mid \\xi}\\), allora la correlazione tra ciascuna coppia di variabili \\(y\\) deve essere uguale al prodotto delle correlazioni tra ciascuna \\(y\\) e il fattore latente \\(\\xi\\). Questo è il principio base dell’analisi fattoriale. 6.3.2 Teoria dei Due Fattori Per fare un esempio concreto relativo al metodo dell’annullamento della tetrade, esaminiamo la matrice di correlazioni originariamente analizzata da Spearman. Spearman (1904) raccolse alcune misure di capacità intellettuale su un piccolo numero di studenti di una scuola superiore. Nello specifico, esaminò i voti di tali studenti nelle seguenti materie: studio dei classici (\\(c\\)), letteratura inglese (\\(e\\)) e abilità matematiche (\\(m\\)). Considerò anche la prestazione in un compito di discriminazione dell’altezza di suoni (pitch discrimination) (\\(p\\)), ovvero un’abilità diversa da quelle richieste nei test scolastici. Secondo la Teoria dei Due Fattori, le prestazioni relative ad un determinato compito intellettuale possiedono una componente comune (detta fattore “g”) con le prestazioni in un qualunque altro compito intellettuale e una componente specifica a quel determinato compito. Il modello dell’intelligenza di Spearman prevede dunque due fattori, uno generale e uno specifico (detto fattore “s”). Il fattore “g” costituisce la componente invariante dell’abilità intellettiva, mente il fattore “s” è una componente che varia da condizione a condizione. Come è possibile stabilire se esiste una variabile latente in grado di spiegare le correlazioni tra le variabili osservate da Spearman? Lo strumento proposto da Spearman per rispondere a questa domanda è l’annullamento della tetrade. L’annullamento della tetrade utilizza i vincoli sulle correlazioni che derivano dalla definizione di correlazione parziale. In precedenza abbiamo visto che la correlazione parziale tra le variabili \\(y\\) indicizzate da \\(i\\) e \\(j\\), al netto dell’effetto di \\(\\xi\\), è nulla se \\[ r_{ij} = r_{i\\xi}r_{j\\xi}. \\] Nel caso dei dati di Spearman, dunque, le correlazioni parziali sono nulle se la correlazione tra “studi classici” e “letteratura inglese” è uguale al prodotto della correlazione tra “studi classici” e il fattore \\(\\xi\\) e della correlazione tra “letteratura inglese” e il fattore \\(\\xi\\). Inoltre, la correlazione tra “studi classici” e “abilità matematica” deve essere uguale al prodotto della correlazione tra “studi classici” e il fattore \\(\\xi\\) e della correlazione tra “abilità matematica” e il fattore \\(\\xi\\); e così via. Le correlazioni tra le variabili manifeste e il fattore latente sono dette saturazioni fattoriali e vengono denotate con la lettera \\(\\lambda\\). Se il modello di Spearman è corretto, avremo che \\[ r_{ec}=\\lambda_e \\times \\lambda_{c}, \\] dove \\(r_{ec}\\) è la correlazione tra “letteratura inglese” (e) e “studi classici” (c), \\(\\lambda_e\\) è la correlazione tra “letteratura inglese” e \\(\\xi\\), e \\(\\lambda_{c}\\) è la correlazione tra “studi classici” e \\(\\xi\\). Allo stesso modo, la correlazione tra “studi classici” e “matematica” (m) dovrà essere uguale a \\[ \\lambda_c \\times \\lambda_m, \\] eccetera. 6.3.3 Annullamento della tetrade Date le correlazioni tra tre coppie di variabili manifeste, il metodo dell’annullamento della tetrade rende possibile stimare i valori delle saturazioni fattoriali \\(\\lambda\\). Ad esempio, per le variabili \\(c\\), \\(m\\) ed \\(e\\), possiamo scrivere le seguenti tre equazioni in tre incognite: \\[\\begin{equation} \\begin{aligned} r_{cm} &amp;= \\lambda_c \\times \\lambda_m, \\notag \\\\ r_{em} &amp;= \\lambda_e \\times \\lambda_m, \\\\ r_{ce} &amp;= \\lambda_c \\times \\lambda_e. \\notag \\end{aligned} \\end{equation}\\] Risolvendo il precedente sistema di equazioni lineari, il coefficiente di saturazione \\(\\lambda_m\\) della variabile \\(y_m\\) nel fattore comune \\(\\xi\\), ad esempio, può essere calcolato a partire dalle correlazioni tra le variabili manifeste \\(c\\), \\(m\\), ed \\(e\\) nel modo seguente: \\[\\begin{equation} \\lambda_m = \\sqrt{ \\frac{r_{cm} r_{em}}{r_{ce}}}. \\tag{6.4} \\end{equation}\\] Lo stesso vale per le altre due saturazioni \\(\\lambda_c\\) e \\(\\lambda_e\\). Nel suo articolo del 1904, Spearman osservò le seguenti correlazioni tra le variabili \\(Y_c\\), \\(Y_e\\), \\(Y_m\\) e \\(Y_p\\): \\[ \\begin{array}{ccccc} \\hline &amp; Y_C &amp; Y_E &amp; Y_M &amp; Y_P \\\\ \\hline Y_C &amp; 1.00 &amp; 0.78 &amp; 0.70 &amp; 0.66 \\\\ Y_E &amp; &amp; 1.00 &amp; 0.64 &amp; 0.54 \\\\ Y_M &amp; &amp; &amp; 1.00 &amp; 0.45 \\\\ Y_P &amp; &amp; &amp; &amp; 1.00 \\\\ \\hline \\end{array} \\] Utilizzando la (6.4), mediante le correlazioni \\(r_{cm}\\), \\(r_{em}\\), e \\(r_{ce}\\) fornite dalla tabella precedente, la saturazione \\(\\lambda_m\\) diventa uguale a: \\[ \\hat{\\lambda}_m = \\sqrt{ \\frac{r_{cm} r_{em}}{r_{ce}} } = \\sqrt{ \\frac{0.70 \\times 0.64}{0.78} } = 0.76. \\] È importante notare che il metodo dell’annullamento della tetrade produce risultati falsificabili. Infatti, ci sono modi diversi per calcolare la stessa saturazione fattoriale. Se il modello fattoriale è corretto si deve ottenere lo stesso risultato in tutti i casi. Nel caso presente, la saturazione fattoriale \\(\\lambda_m\\) può essere calcolata in altri due modi: \\[\\begin{equation} \\begin{aligned} \\hat{\\lambda}_m &amp;= \\sqrt{ \\frac{r_{cm} r_{mp}}{r_{cp}} } = \\sqrt{ \\frac{0.78 \\times 0.45}{0.66} } = 0.69, \\notag \\\\ \\hat{\\lambda}_m &amp;= \\sqrt{ \\frac{r_{em} r_{mp}}{r_{ep}} } = \\sqrt{ \\frac{0.64 \\times 0.45}{0.54} } = 0.73. \\notag\\end{aligned} \\end{equation}\\] I tre valori che sono stati ottenuti sono molto simili. Qual è allora la stima migliore di \\(\\lambda_m\\)? 6.3.4 Metodo del centroide La soluzione più semplice è quella di fare la media di questi tre valori (\\(\\bar{\\lambda}_m = 0.73\\)). Un metodo migliore (meno vulnerabile ai valori anomali) è dato dal rapporto tra la somma dei numeratori e dei denominatori: \\[ \\hat{\\lambda}_m = \\sqrt{ \\frac{0.70 \\times 0.64 + 0.78 \\times 0.45 + 0.64 \\times 0.45}{0.78+0.66+0.54} } = 0.73 \\] In questo caso, i due metodi danno lo stesso risultato. Le altre tre saturazioni fattoriali trovate mediante il metodo del centroide sono: \\[ \\hat{\\lambda}_c = 0.97, \\quad \\hat{\\lambda}_e = 0.84, \\quad \\hat{\\lambda}_p = 0.65. \\] In conclusione, \\[ \\boldsymbol{\\hat{\\Lambda}}^\\prime= (\\hat{\\lambda}_c, \\hat{\\lambda}_e, \\hat{\\lambda}_m, \\hat{\\lambda}_p) = (0.97, 0.84, 0.73, 0.65). \\] 6.3.5 Introduzione a lavaan Analizziamo ora nuovamente gli stessi dati usando un metodo di stima moderno (massima verosimiglianza), mediante le funzioni del pacchetto lavaan. La matrice completa dei dati di Spearman è messa a disposizione da Kan, Maas, and Levine (2019). Iniziamo a caricare i pacchetti necessari: library(&quot;lavaan&quot;) library(&quot;semPlot&quot;) library(&quot;knitr&quot;) library(&quot;kableExtra&quot;) library(&quot;tidyr&quot;) library(&quot;corrplot&quot;) Specifichiamo il nome delle variabili manifeste varnames &lt;- c( &quot;Classics&quot;, &quot;French&quot;, &quot;English&quot;, &quot;Math&quot;, &quot;Pitch&quot;, &quot;Music&quot; ) e il loro numero ny &lt;- length(varnames) Leggiamo la matrice di correlazione: spearman_cor_mat &lt;- matrix( c( 1.00, .83, .78, .70, .66, .63, .83, 1.00, .67, .67, .65, .57, .78, .67, 1.00, .64, .54, .51, .70, .67, .64, 1.00, .45, .51, .66, .65, .54, .45, 1.00, .40, .63, .57, .51, .51, .40, 1.00 ), ny, ny, byrow = TRUE, dimnames = list(varnames, varnames) ) Specifichiamo l’ampiezza campionaria: n &lt;- 33 Esaminiamo la sintassi usata da lavaan a livello degli item: # Regression y ~ f1 + f2 + x1 + x2 f1 ~ f2 + f3 f2 ~ f3 + x1 + x2 # Latent variables f1 &lt;- ~ y1 + y2 + y3 f2 &lt;- ~ y4 + y5 + y6 f3 &lt;- ~ y7 + y8 + y9 + y10 # Variances and covariances y1 ~ ~y1 y1 ~ ~y2 f1 ~ ~f2 # Intercepts y1 ~ 1 f1 ~ 1 Definiamo il modello unifattoriale in lavaan. L’operatore =~ si può leggere dicendo che la variabile latente a sinistra dell’operatore viene identificata dalle variabili manifeste elencate a destra dell’operatore e separate dal segno +: spearman_mod &lt;- &quot; g =~ Classics + French + English + Math + Pitch + Music &quot; Adattiamo il modello ai dati con la funzione cfa(): fit1 &lt;- lavaan::cfa( spearman_mod, sample.cov = spearman_cor_mat, sample.nobs = n, std.lv = TRUE ) L’argomento std.lv = TRUE specifica che imponiamo una varianza pari a 1 a tutte le variabili latenti comuni (nel caso presente, solo una). Ciò consente di stimare le saturazioni fattoriali. Possiamo esaminare la soluzione ottenuta con la seguente istruzione: summary( fit1, fit.measures = TRUE, standardized = TRUE ) #&gt; lavaan 0.6.14 ended normally after 23 iterations #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of model parameters 12 #&gt; #&gt; Number of observations 33 #&gt; #&gt; Model Test User Model: #&gt; #&gt; Test statistic 2.913 #&gt; Degrees of freedom 9 #&gt; P-value (Chi-square) 0.968 #&gt; #&gt; Model Test Baseline Model: #&gt; #&gt; Test statistic 133.625 #&gt; Degrees of freedom 15 #&gt; P-value 0.000 #&gt; #&gt; User Model versus Baseline Model: #&gt; #&gt; Comparative Fit Index (CFI) 1.000 #&gt; Tucker-Lewis Index (TLI) 1.086 #&gt; #&gt; Loglikelihood and Information Criteria: #&gt; #&gt; Loglikelihood user model (H0) -212.547 #&gt; Loglikelihood unrestricted model (H1) -211.091 #&gt; #&gt; Akaike (AIC) 449.094 #&gt; Bayesian (BIC) 467.052 #&gt; Sample-size adjusted Bayesian (SABIC) 429.622 #&gt; #&gt; Root Mean Square Error of Approximation: #&gt; #&gt; RMSEA 0.000 #&gt; 90 Percent confidence interval - lower 0.000 #&gt; 90 Percent confidence interval - upper 0.000 #&gt; P-value H_0: RMSEA &lt;= 0.050 0.976 #&gt; P-value H_0: RMSEA &gt;= 0.080 0.016 #&gt; #&gt; Standardized Root Mean Square Residual: #&gt; #&gt; SRMR 0.025 #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Standard #&gt; Information Expected #&gt; Information saturated (h1) model Structured #&gt; #&gt; Latent Variables: #&gt; Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all #&gt; g =~ #&gt; Classics 0.942 0.129 7.314 0.000 0.942 0.956 #&gt; French 0.857 0.137 6.239 0.000 0.857 0.871 #&gt; English 0.795 0.143 5.545 0.000 0.795 0.807 #&gt; Math 0.732 0.149 4.923 0.000 0.732 0.743 #&gt; Pitch 0.678 0.153 4.438 0.000 0.678 0.689 #&gt; Music 0.643 0.155 4.142 0.000 0.643 0.653 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all #&gt; .Classics 0.083 0.051 1.629 0.103 0.083 0.086 #&gt; .French 0.234 0.072 3.244 0.001 0.234 0.242 #&gt; .English 0.338 0.094 3.610 0.000 0.338 0.349 #&gt; .Math 0.434 0.115 3.773 0.000 0.434 0.447 #&gt; .Pitch 0.510 0.132 3.855 0.000 0.510 0.526 #&gt; .Music 0.556 0.143 3.893 0.000 0.556 0.573 #&gt; g 1.000 1.000 1.000 È possibile semplificare l’output dalla funzione summary() in maniera tale da stampare solo la tabella completa delle stime dei parametri e degli errori standard, ecc. kable(coef(fit1), booktabs = TRUE, format = &quot;markdown&quot;) x g=~Classics 0.94152885 g=~French 0.85748943 g=~English 0.79479800 g=~Math 0.73208069 g=~Pitch 0.67826478 g=~Music 0.64324900 Classics~~Classics 0.08322018 French~~French 0.23440834 English~~English 0.33799292 Math~~Math 0.43375436 Pitch~~Pitch 0.50965401 Music~~Music 0.55592713 Anziché stampare direttamente la tabella dei parametri, è meglio riformattarla con kable quando utilizziamo RMarkdown. Senza usare kable, l’output diventa: parameterEstimates(fit1, standardized = TRUE) #&gt; lhs op rhs est se z pvalue ci.lower ci.upper std.lv #&gt; 1 g =~ Classics 0.942 0.129 7.314 0.000 0.689 1.194 0.942 #&gt; 2 g =~ French 0.857 0.137 6.239 0.000 0.588 1.127 0.857 #&gt; 3 g =~ English 0.795 0.143 5.545 0.000 0.514 1.076 0.795 #&gt; 4 g =~ Math 0.732 0.149 4.923 0.000 0.441 1.024 0.732 #&gt; 5 g =~ Pitch 0.678 0.153 4.438 0.000 0.379 0.978 0.678 #&gt; 6 g =~ Music 0.643 0.155 4.142 0.000 0.339 0.948 0.643 #&gt; 7 Classics ~~ Classics 0.083 0.051 1.629 0.103 -0.017 0.183 0.083 #&gt; 8 French ~~ French 0.234 0.072 3.244 0.001 0.093 0.376 0.234 #&gt; 9 English ~~ English 0.338 0.094 3.610 0.000 0.154 0.522 0.338 #&gt; 10 Math ~~ Math 0.434 0.115 3.773 0.000 0.208 0.659 0.434 #&gt; 11 Pitch ~~ Pitch 0.510 0.132 3.855 0.000 0.251 0.769 0.510 #&gt; 12 Music ~~ Music 0.556 0.143 3.893 0.000 0.276 0.836 0.556 #&gt; 13 g ~~ g 1.000 0.000 NA NA 1.000 1.000 1.000 #&gt; std.all std.nox #&gt; 1 0.956 0.956 #&gt; 2 0.871 0.871 #&gt; 3 0.807 0.807 #&gt; 4 0.743 0.743 #&gt; 5 0.689 0.689 #&gt; 6 0.653 0.653 #&gt; 7 0.086 0.086 #&gt; 8 0.242 0.242 #&gt; 9 0.349 0.349 #&gt; 10 0.447 0.447 #&gt; 11 0.526 0.526 #&gt; 12 0.573 0.573 #&gt; 13 1.000 1.000 Se invece usiamo kable, con gli opportuni parametri, otteniamo: parameterEstimates(fit1, standardized = TRUE) %&gt;% dplyr::filter(op == &quot;=~&quot;) %&gt;% dplyr::select( &quot;Latent Factor&quot; = lhs, Indicator = rhs, B = est, SE = se, Z = z, &quot;p-value&quot; = pvalue, Beta = std.all ) %&gt;% knitr::kable( digits = 3, booktabs = TRUE, format = &quot;markdown&quot;, caption = &quot;Factor Loadings&quot; ) TABELLA 6.1: Factor Loadings Latent Factor Indicator B SE Z p-value Beta g Classics 0.942 0.129 7.314 0 0.956 g French 0.857 0.137 6.239 0 0.871 g English 0.795 0.143 5.545 0 0.807 g Math 0.732 0.149 4.923 0 0.743 g Pitch 0.678 0.153 4.438 0 0.689 g Music 0.643 0.155 4.142 0 0.653 Esaminiamo la matrice delle correlazioni residue: cor_table &lt;- residuals(fit1, type = &quot;cor&quot;)$cov knitr::kable( cor_table, digits = 3, format = &quot;markdown&quot;, booktabs = TRUE ) Classics French English Math Pitch Music Classics 0.000 -0.003 0.008 -0.011 0.001 0.005 French -0.003 0.000 -0.033 0.023 0.050 0.001 English 0.008 -0.033 0.000 0.040 -0.016 -0.017 Math -0.011 0.023 0.040 0.000 -0.062 0.024 Pitch 0.001 0.050 -0.016 -0.062 0.000 -0.050 Music 0.005 0.001 -0.017 0.024 -0.050 0.000 Creiamo un qq-plot dei residui: res1 &lt;- residuals(fit1, type = &quot;cor&quot;)$cov res1[upper.tri(res1, diag = TRUE)] &lt;- NA v1 &lt;- as.vector(res1) v2 &lt;- v1[!is.na(v1)] tibble(v2) %&gt;% ggplot(aes(sample = v2)) + stat_qq() + stat_qq_line() Il pacchetto semPlot consente di disegnare diagrammi di percorso per vari modelli SEM. La funzione semPaths prende in input un oggetto creato da lavaan e disegna il diagramma, con diverse opzioni disponibili. Il diagramma qui prodotto controlla le dimensioni dei caratteri/etichette, la visualizzazione dei residui e il colore dei percorsi/coefficienti. Sono disponibili queste e molte altre opzioni di controllo. semPaths( fit1, residuals = FALSE, sizeMan = 7, &quot;std&quot;, posCol = c(&quot;black&quot;), edge.label.cex = 1.2, layout = &quot;circle2&quot; ) In una versione alternativa del diagramma di percorso aggiungiamo anche le specificità: semPaths( fit1, &quot;std&quot;, posCol = c(&quot;black&quot;), edge.label.cex = 1.2, sizeMan = 7 ) Il calcolo delle saturazioni fattoriali con il metodo del centroide aveva prodotto il risultato: \\(\\boldsymbol{\\hat{\\Lambda}}&#39;= (0.97, 0.84, 0.73, 0.65)\\). Si noti la somiglianza con i valori ottenuti mediante il metodo di massima verosimiglianza. References "],["conclusioni.html", "Conclusioni", " Conclusioni Nel presente capitolo abbiamo introdotto il metodo dell’annullamento della tetrade che consente di stimare le saturazioni di un modello monofattoriale. Abbiamo anche visto che il metodo dell’annullamento della tetrade non è altro che un’applicazione della correlazione parziale. Possiamo dire che un tema cruciale nella costruzione dei test psicologici è quello di stabilire il numero di fattori/tratti che sono soggiacenti all’insieme degli indicatori che vengono considerati. La teoria classica dei test richiede che il test sia monofattoriale, ovvero che gli indicatori considerati siano l’espressione di un unico tratto latente. La violazione della monodimensionalità rende problematica l’applicazione dei principi della teoria classica dei test ai punteggi di un test che non possiede tale proprietà. L’esame della dimensionalità di un gruppo di indicatori rappresenta dunque una fase cruciale nel processo di costruzione di un test e, solitamente, questo esame è affrontato mediante l’analisi fattoriale. In questo capitolo abbiamo presentato le proprietà di base del modello unifattoriale. "],["il-modello-statistico-dellanalisi-fattoriale.html", "Capitolo 7 Il modello statistico dell’analisi fattoriale ", " Capitolo 7 Il modello statistico dell’analisi fattoriale "],["modello-monofattoriale-1.html", "7.1 Modello monofattoriale", " 7.1 Modello monofattoriale Il punto di partenza dell’analisi fattoriale esplorativa è rappresentato da una marice di dimensioni \\(p \\times p\\) (dove \\(p\\) è il numero di variabili osservate) che contiene i coefficienti di correlazione (o di covarianza) tra le variabili. Il punto di arrivo è rappresentato da una matrice di dimensioni \\(p \\times k\\) (dove \\(k\\)) è il numero di fattori comuni che contiene i coefficienti (le saturazioni) che esprimono la relazione tra i fattori e le variabili osservate. Considereremo ora il modello matematico dell’analisi fattoriale esplorativa, con un solo fattore comune, che rappresenta il caso più semplice. Con \\(p\\) variabili manifeste \\(Y_i\\), il modello ad un fattore comune può essere espresso algebricamente nel modo seguente: \\[ Y_i = \\mu_i + \\lambda_{i} \\xi + \\delta_i \\qquad i=1, \\dots, p \\] dove \\(\\xi\\) rappresenta il fattore latente, chiamato anche fattore comune, poiché è comune a tutte le \\(Y_i\\), i \\(\\delta_i\\) sono invece specifici di ogni variabile osservata e per tale ragione vengono chiamati fattori specifici o unici, e infine i \\(\\lambda_i\\) sono detti saturazioni (o pesi) fattoriali poiché consentono di valutare il peso del fattore latente su ciascuna variabile osservata. Si suole assumere per comodità che \\(\\mu=0\\), il che corrisponde a considerare le variabili \\(Y_i\\) come ottenute dagli scarti dalle medie \\(\\mu_i\\) per \\(i = 1, \\dots, p\\): \\[ Y_i -\\mu_i = \\lambda_i \\xi + \\delta_i. \\] Si assume che il fattore comune abbia media zero, \\(\\mathbb{E}(\\xi)=0\\), e varianza unitaria, \\(\\mathbb{V}(\\xi)=1\\), che i fattori specifici abbiano media zero, \\(\\mathbb{E}(\\delta_j)=0\\), e varianza \\(\\mathbb{V}(\\delta_j)=\\psi_{i}\\), che i fattori specifici siano incorrelati tra loro, \\(\\mathbb{E}(\\delta_i \\delta_k)=0\\), e che i fattori specifici siano incorrelati con il fattore comune, \\(\\mathbb{E}(\\delta_i \\xi)=0\\). In questo modello, poiché i fattori specifici sono tra loro incorrelati, l’interdipendenza tra le variabili manifeste è completamente spiegata dal fattore comune. Dalle ipotesi precedenti è possibile ricavare la covarianza tra \\(Y_i\\) e il fattore comune, la varianza della \\(i\\)-esima variabile manifesta \\(Y_i\\) e la covarianza tra due variabili manifeste \\(Y_i\\) e \\(Y_k\\). "],["covarianza-tra-un-indicatore-e-il-fattore-comune.html", "7.2 Covarianza tra un indicatore e il fattore comune", " 7.2 Covarianza tra un indicatore e il fattore comune Dal modello monofattoriale è possibile determinare l’espressione della covarianza teorica tra una variabile manifesta \\(Y_i\\) e il fattore comune \\(\\xi\\): \\[ \\mbox{Cov}(Y_i,\\xi)=\\mathbb{E}(Y_i \\xi)-\\mathbb{E}(Y_i)\\mathbb{E}(\\xi). \\] Dato che \\(\\mathbb{E}(\\xi)=0\\), possiamo scrivere \\[\\begin{equation} \\begin{aligned} \\mbox{Cov}(Y_i,\\xi) &amp;= \\mathbb{E}(Y_i \\xi)=\\mathbb{E}[(\\lambda_i \\xi + \\delta_i) \\xi]\\notag\\\\ &amp;=\\mathbb{E}(\\lambda_i \\xi^2 + \\delta_i \\xi)\\notag\\\\ &amp;=\\lambda_i\\underbrace{\\mathbb{E}(\\xi^2)}_{\\mathbb{V}(\\xi)=1} + \\underbrace{\\mathbb{E}(\\delta_i \\xi)}_{\\mbox{Cov}(\\delta_i, \\xi)=0}\\notag\\\\ &amp;= \\lambda_i.\\notag \\end{aligned} \\end{equation}\\] Nel modello a un solo fattore, dunque, la saturazione \\(\\lambda_j\\) rappresenta la covarianza la variabile manifesta \\(Y_i\\) e il fattore comune \\(\\xi\\) e indica l’importanza del fattore nel determinare il punteggio osservato. Se le variabili \\(Y_i\\) sono standardizzate, la saturazione fattoriale \\(\\lambda_i\\) corrisponde alla correlazione tra \\(Y_i\\) e \\(\\xi\\). "],["espressione-fattoriale-della-varianza.html", "7.3 Espressione fattoriale della varianza", " 7.3 Espressione fattoriale della varianza Nell’ipotesi che le variabili \\(Y_i\\) abbiano media nulla, la varianza di \\(Y_i\\) \\[\\begin{equation} \\mathbb{V}(Y_i) = \\mathbb{E}(Y_i^2) -[\\mathbb{E}(Y_i)]^2 = \\mathbb{E}(Y_i^2)\\notag \\end{equation}\\] è data da \\[\\begin{equation} \\begin{aligned} \\mathbb{V}(Y_i) &amp;= \\mathbb{E}[(\\lambda_i \\xi + \\delta_i)^2 ]\\notag\\\\ &amp;=\\lambda_i^2 \\underbrace{\\mathbb{E}(\\xi^2) }_{\\mathbb{V}(\\xi)=1} + \\underbrace{\\mathbb{E}(\\delta_i^2) }_{\\mathbb{V}(\\delta_i)=\\psi_{i}} + 2\\lambda_i \\underbrace{\\mathbb{E}(\\xi \\delta_i) }_{\\mbox{Cov}(\\xi, \\delta_{i})=0}\\notag\\\\ &amp;=\\lambda^2_i + \\psi_{i}. \\end{aligned} \\end{equation}\\] La quantità \\(\\lambda^2_i\\) è denominata comunalità della \\(i\\)-esima variabile manifesta e corrisponde alla quota della varianza della \\(Y_i\\) spiegata dal fattore comune. Di conseguenza \\(\\psi_{i}\\) è la parte residua della varianza di \\(Y_i\\) non spiegata dal fattore comune ed è denominata unicità di \\(Y_i\\). Nel caso di variabili standardizzate, l’unicità diventa uguale a \\[ \\psi_{i}=1-\\lambda^2_i. \\] In definitiva, la varianza totale di una variabile osservata può essere divisa in una quota che ciascuna variabile condivide con le altre variabili ed è spiegata dal fattore comune (questa quota è chiamata comunalità ed è uguale uguale al quadrato della saturazione della variabile osservata nel fattore comune, ovvero \\(h^2_i = \\lambda_i^2\\)), e in una quota che è spiegata dal fattore specifico (questa parte è chiamata unicità ed è uguale a \\(u_i = \\psi_{i}\\)). Esercizio 7.1 Riprendiamo l’analisi della matrice di correlazioni di Spearman. Nell’output prodotto dalla funzione factanal() viene riportata la quantità denominata SS loadings. Tale quantità indica la porzione della varianza totale delle 4 variabili manifeste che viene spiegata dal fattore comune. Ciascuna variabile standardizzata contribuisce con un’unità di varianza; nel caso presente, dunque la varianza totale è uguale a 4. Si ricordi che, nella statistica multivariata, per varianza totale si intende la somma delle varianze delle variabili manifeste (nel linguaggio dell’algebra matriciale questa quantità corrisponde alla traccia della matrice di covarianze). La quota della varianza totale spiegata dal modello, invece, è data dalla somma delle comunalità delle quattro variabili, ovvero dalla somma delle saturazioni fattoriali innalzate al quadrato. Spearman &lt;- matrix( c( 1.0, .78, .70, .66, .78, 1.0, .64, .54, .70, .64, 1.0, .45, .66, .54, .45, 1.0 ), byrow = TRUE, ncol = 4 ) rownames(Spearman) &lt;- c(&quot;C&quot;, &quot;E&quot;, &quot;M&quot;, &quot;P&quot;) colnames(Spearman) &lt;- c(&quot;C&quot;, &quot;E&quot;, &quot;M&quot;, &quot;P&quot;) Spearman #&gt; C E M P #&gt; C 1.00 0.78 0.70 0.66 #&gt; E 0.78 1.00 0.64 0.54 #&gt; M 0.70 0.64 1.00 0.45 #&gt; P 0.66 0.54 0.45 1.00 Eseguiamo l’analisi fattoriale: fm &lt;- factanal(covmat = Spearman, factors = 1) fm #&gt; #&gt; Call: #&gt; factanal(factors = 1, covmat = Spearman) #&gt; #&gt; Uniquenesses: #&gt; C E M P #&gt; 0.086 0.329 0.460 0.539 #&gt; #&gt; Loadings: #&gt; Factor1 #&gt; C 0.956 #&gt; E 0.819 #&gt; M 0.735 #&gt; P 0.679 #&gt; #&gt; Factor1 #&gt; SS loadings 2.587 #&gt; Proportion Var 0.647 #&gt; #&gt; The degrees of freedom for the model is 2 and the fit was 0.023 Le saturazioni fattoriali sono: L &lt;- c(fm$load[1], fm$load[2], fm$load[3], fm$load[4]) L #&gt; [1] 0.9562592 0.8193902 0.7350316 0.6790212 Facendo il prodotto interno otteniamo: t(L) %*% L #&gt; [,1] #&gt; [1,] 2.587173 In termini proporzionali, la quota della varianza totale delle variabile manifeste che viene spiegata dal modello ad un fattore comune è dunque uguale a \\(2.587 / 4 = 0.647\\). Questa quantità è indicata nell’output con la denominazione Proportion Var. Si dice unicità (uniqueness) la quota della varianza della variabile considerata che non viene spiegata dalla soluzione fattoriale: round(fm$uniqueness, 3) #&gt; C E M P #&gt; 0.086 0.329 0.460 0.539 La comunalità (ovvero, la quota di varianza di ciascuna variabile manifesta che viene spiegata dal fattore comune) può essere trovata come: round(1 - fm$uniqueness, 3) #&gt; C E M P #&gt; 0.914 0.671 0.540 0.461 oppure con L^2 #&gt; [1] 0.9144316 0.6714003 0.5402714 0.4610697 "],["covarianza-tra-due-variabili-manifeste.html", "7.4 Covarianza tra due variabili manifeste", " 7.4 Covarianza tra due variabili manifeste Nell’ipotesi che le variabili \\(Y_i\\) abbiano media nulla, la covarianza tra \\(Y_i\\) e \\(Y_k\\) \\[ \\mbox{Cov}(Y_i, Y_k)=\\mathbb{E}(Y_i Y_k) - \\mathbb{E}(Y_i)\\mathbb{E}(Y_k)=\\mathbb{E}(Y_i Y_k) \\] è uguale al prodotto delle corrispondenti saturazioni fattoriali. \\[\\begin{equation} \\begin{aligned} \\mbox{Cov}(Y_i, Y_k) &amp;= \\mathbb{E}(Y_i Y_k) \\notag\\\\ &amp; =\\mathbb{E}[(\\lambda_i \\xi + \\delta_i)(\\lambda_k \\xi + \\delta_k)]\\notag\\\\ &amp;=\\mathbb{E}(\\lambda_i\\lambda_k\\xi^2 + \\lambda_i \\xi \\delta_k + \\lambda_k \\delta_i \\xi + \\delta_i \\delta_k)\\notag\\\\ &amp;=\\lambda_i\\lambda_k\\underbrace{\\mathbb{E}(\\xi^2)}_{\\mathbb{V}(\\xi)=1}+\\lambda_i\\underbrace{\\mathbb{E}(\\xi \\delta_k)}_{\\mbox{Cov}(\\xi, \\delta_k) =0}+\\notag\\\\ \\;&amp;+\\lambda_k\\underbrace{\\mathbb{E}(\\delta_i \\xi)}_{\\mbox{Cov}(\\delta_i, \\xi) =0} +\\underbrace{\\mathbb{E}(\\delta_i \\delta_k)}_{\\mbox{Cov}(\\delta_i, \\delta_k)=0}\\notag\\\\ &amp;=\\lambda_i\\lambda_k \\end{aligned} \\end{equation}\\] "],["correlazioni-osservate-e-correlazioni-riprodotte-dal-modello.html", "7.5 Correlazioni osservate e correlazioni riprodotte dal modello", " 7.5 Correlazioni osservate e correlazioni riprodotte dal modello In generale possiamo affermare che il modello monofattoriale è adeguato se si verifica che \\(\\mbox{Cov}(Y_i, Y_k \\mid \\xi) = 0\\) (\\(i, k = 1, \\dots,p; \\; i\\neq k\\)), ossia se il fattore comune spiega tutta la covarianza tra le variabili osservate. La matrice di correlazioni riprodotte dal modello è chiamata \\(\\boldsymbol{\\Sigma}\\) e può essere espressa come: \\[ \\boldsymbol{\\Sigma} = \\boldsymbol{\\Lambda} \\boldsymbol{\\Lambda}^\\prime + \\boldsymbol{\\Psi} \\] In altri termini, il modello monofattoriale è adeguato se è nulla la differenza tra la matrice di correlazioni osservate e la matrice di correlazioni riprodotte dal modello. Per i dati di Spearman, le correlazioni riprodotte dal modello ad un fattore sono round(L %*% t(L) + diag(fm$uniq), 3) #&gt; [,1] [,2] [,3] [,4] #&gt; [1,] 1.000 0.784 0.703 0.649 #&gt; [2,] 0.784 1.000 0.602 0.556 #&gt; [3,] 0.703 0.602 1.000 0.499 #&gt; [4,] 0.649 0.556 0.499 1.000 La matrice delle differenze tra le correlazioni campionarie e quelle riprodotte è round(Spearman - (L %*% t(L) + diag(fm$uniq)), 3) #&gt; C E M P #&gt; C 0.000 -0.004 -0.003 0.011 #&gt; E -0.004 0.000 0.038 -0.016 #&gt; M -0.003 0.038 0.000 -0.049 #&gt; P 0.011 -0.016 -0.049 0.000 Lo scarto maggiore tra le correlazioni campionarie e quelle riprodotte è uguale a 0.049. Si può dunque concludere che il modello monofattoriale spiega in maniera ragionevole i dati di Spearman. "],["bontà-di-adattamento-del-modello-ai-dati.html", "7.6 Bontà di adattamento del modello ai dati", " 7.6 Bontà di adattamento del modello ai dati La verifica della bontà di adattamento del modello ai dati si determina mediante un test statistico che valuta la differenza tra la matrice di correlazioni (o di covarianze) osservata e la matrice di correlazioni (o covarianze) predetta dal modello fattoriale. L’ipotesi nulla che viene valutata è che la matrice delle correlazioni residue sia dovuta semplicemente agli errori di campionamento, ovvero che la matrice di correlazioni predetta dal modello \\(\\boldsymbol{\\Sigma}(\\theta)\\) sia uguale alla matrice di correlazioni \\(\\boldsymbol{\\Sigma}\\) nella popolazione. La statistica test \\(v\\) è una funzione della differenza tra la matrice riprodotta \\(\\boldsymbol{S}(\\theta)\\) e quella osservata \\(\\boldsymbol{S}\\) \\[ v = f\\left[\\boldsymbol{S}(\\theta) - \\boldsymbol{S}\\right] \\] e si distribuisce come una \\(\\chi^2\\) con \\(\\nu\\) gradi di libertà \\[ \\nu = p(p+1)/ 2 - q, \\] dove \\(p\\) è il numero di variabili manifeste e \\(q\\) è il numero di parametri stimati dal modello fattoriale (ovvero, \\(\\lambda\\) e \\(\\psi\\)). La statistica \\(v\\) assume valore 0 se i parametri del modello riproducono esattamente la matrice di correlazioni tra le variabili nella popolazione. Tanto maggiore è la statistica \\(v\\) tanto maggiore è la discrepanza tra le correlazioni osservate e quelle predette dal modello fattoriale. Un risultato statisticamente significativo (es., \\(p\\) &lt; .05) – il quale suggerisce che una tale differenza non è uguale a zero – rivela dunque una discrepanza tra il modello e i dati. Il test del modello fattoriale mediante la statistica \\(\\chi^2\\) segue dunque una logica diversa da quella utilizzata nei normali test di ipotesi statistiche: un risultato statisticamente significativo indica una mancanza di adattamento del modello ai dati. L’applicazione del test \\(\\chi^2\\) per valutare la bontà di adattamento del modello ai dati richiede che ciascuna variabile manifesta sia distribuita normalmente – più precisamente, richiede che le variabili manifeste siano un campione casuale che deriva da una normale multivariata. Questo requisito non è facile da rispettare in pratica. Tuttavia, il limite principale della statistica \\(\\chi^2\\) è che essa dipende fortemente dalle dimensioni del campione: al crescere delle dimensioni campionarie è più facile ottenere un risultato statisticamente significativo (ovvero, concludere che vi è un cattivo adattamento del modello ai dati). Per questa ragione, la bontà di adattamento del modello ai dati viene valutata da molteplici indici, non soltanto dalla statistica \\(\\chi^2\\). Più comune è calcolare il rapporto \\(\\chi^2 / \\nu\\) e usare tale rapporto per valutare la bontà dell’adattamento. Valori minori di 3 o 4 suggeriscono che il modello ben si adatta ai dati. "],["lerrore-standard-della-misurazione-e-il-modello-fattoriale.html", "7.7 L’errore standard della misurazione e il modello fattoriale", " 7.7 L’errore standard della misurazione e il modello fattoriale Per concludere, prendiamo nuovamente in esame la nozione dell’errore standard della misurazione, uno dei concetti centrali della CTT, e vediamo come tale concetto possa essere “ripensato” in riferimento al modello statistico dell’analisi fattoriale. Iniziamo con una dimostrazione. Dimostrazione. Secondo la CTT, il punteggio \\(X\\) ottenuto dalla somministrazione del test è uguale a \\(X = T + E\\), dove \\(E\\) è una variabile aleatorie indipendente da \\(T\\). Se consideriamo il rispondente \\(i\\)-esimo, il modello diventa \\(X_i = T_i + E_i\\), dove \\(T_i\\) è il valore vero ed \\(E_i\\) è una variabile aleatoria con media 0. Riscriviamo ora questa equazione nei termini di un modello monofattoriale con \\(p\\) variabili manifeste (item). Per ciascun item avremo: \\[\\begin{equation} \\begin{aligned} Y_{1i} &amp;= \\lambda_1 \\xi_i + \\delta_{1i} \\notag\\\\ Y_{2i} &amp;= \\lambda_2 \\xi_i + \\delta_{2i} \\notag\\\\ \\dots\\notag\\\\ Y_{pi} &amp;= \\lambda_p \\xi_i + \\delta_{pi} \\notag \\end{aligned} \\end{equation}\\] Il punteggio totale \\(X_i\\) per il rispondente \\(i\\)-esimo è dato dalla somma dei punteggi osservati in ciascun item, ovvero \\[\\begin{equation} \\begin{aligned} X_i &amp;= \\sum_{j=1}^p Y_{ji} = \\sum_{j=1}^p \\lambda_j \\xi_i + \\sum_{j=1}^p \\delta_{ji}\\notag\\\\[12pt] &amp;= \\left( \\sum_{j=1}^p \\lambda_j \\right) \\xi_i + \\sum_{j=1}^p \\delta_{ji} \\notag\\\\[12pt] &amp;= T_i + E_i\\notag \\end{aligned} \\end{equation}\\] Secondo la CTT, la varianza del punteggio osservato \\(X_i\\) si scompone in due componenti: \\(\\sigma^2_{X_i} = \\sigma^2_{T_i} + \\sigma^2_{E_i}\\). Nei termini del modello fattoriale, la varianza della componente vera del punteggio totale del test, \\(\\sigma^2_{T_i}\\), è data dal quadrato della somma delle satutazioni fattoriali: \\[\\begin{equation} \\begin{aligned} \\sigma^2_{T_i} &amp;= \\mathbb{V}\\left[ \\left( \\sum_{j=1}^p \\lambda_j \\right) \\xi_i \\right]\\notag\\\\ &amp;= \\left( \\sum_{j=1}^p \\lambda_j \\right)^2 \\mathbb{V}(\\xi_i)\\notag\\\\ &amp;= \\left( \\sum_{j=1}^p \\lambda_j \\right)^2 \\notag \\end{aligned} \\end{equation}\\] Nei termini del modello fattoriale, se consideriamo il punteggio totale del test, la varianza della componente dell’errore della misurazione, \\(\\sigma^2_{E_i}\\), è data dalla somma delle unicità: \\[\\begin{equation} \\begin{aligned} \\sigma^2_{E_i} &amp;= \\mathbb{V}\\left( \\sum_{j=1}^p \\delta_{ji} \\right)\\notag\\\\ &amp;= \\sum_{j=1}^p \\mathbb{V}\\left( \\delta_{ji} \\right)\\notag\\\\ &amp;= \\sum_{j=1}^p \\Psi_j\\notag \\end{aligned} \\end{equation}\\] Nei termini del modello fattoriale, dunque, una stima dell’errore standard della misurazione del punteggio totale del test è data dalla radice quadrata della quantità precedente, ovvero: \\[\\begin{equation} \\sigma_{E} = \\sqrt{\\sum_{j=1}^p \\Psi_j} \\tag{7.1} \\end{equation}\\] 7.7.1 Un caso concreto Applichiamo ora il risultato precedente ad un caso concreto. Consideriamo i dati utilizzati nella validazione italiana del Cognitive Style Questionnaire - Short Form (CSQ-SF, Meins et al. 2012). Il CSQ-SF viene utilizzato per misurare la vulnerabilità all’ansia e alla depressione. È costituito da cinque sottoscale: Internality, Globality, Stability, Negative consequences e Self-worth. Leggiamo i dati in \\(\\textsf{R}\\): csq &lt;- rio::import(here::here(&quot;data&quot;, &quot;csq540.csv&quot;)) Il numero di partecipanti è n &lt;- nrow(csq) n #&gt; [1] 540 Le statistiche descrittive si ottengono con la seguente istruzione: psych::describe(csq, type = 2) #&gt; vars n mean sd median trimmed mad min max range skew kurtosis se #&gt; I 1 540 47.76 5.78 48 47.87 4.45 21 64 43 -0.31 1.07 0.25 #&gt; G 2 540 45.00 11.94 42 44.55 11.86 16 78 62 0.34 -0.70 0.51 #&gt; S 3 540 44.60 12.18 42 44.24 13.34 16 77 61 0.27 -0.77 0.52 #&gt; N 4 540 22.01 6.92 21 21.86 7.41 8 39 31 0.21 -0.74 0.30 #&gt; W 5 540 44.05 13.10 43 43.66 13.34 16 79 63 0.31 -0.53 0.56 Esaminiamo la matrice di correlazione: psych::pairs.panels(csq) Specifichiamo il modello unifattoriale nella sintassi di lavaan: mod_csq &lt;- &quot; F =~ NA*I + G + S + N + W F ~~ 1*F &quot; Adattiamo il modello ai dati: fit &lt;- lavaan:::cfa( mod_csq, data = csq ) Esaminiamo i risultati: summary( fit, standardized = TRUE, fit.measures = TRUE ) #&gt; lavaan 0.6.14 ended normally after 26 iterations #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of model parameters 10 #&gt; #&gt; Number of observations 540 #&gt; #&gt; Model Test User Model: #&gt; #&gt; Test statistic 46.716 #&gt; Degrees of freedom 5 #&gt; P-value (Chi-square) 0.000 #&gt; #&gt; Model Test Baseline Model: #&gt; #&gt; Test statistic 2361.816 #&gt; Degrees of freedom 10 #&gt; P-value 0.000 #&gt; #&gt; User Model versus Baseline Model: #&gt; #&gt; Comparative Fit Index (CFI) 0.982 #&gt; Tucker-Lewis Index (TLI) 0.965 #&gt; #&gt; Loglikelihood and Information Criteria: #&gt; #&gt; Loglikelihood user model (H0) -8741.781 #&gt; Loglikelihood unrestricted model (H1) -8718.423 #&gt; #&gt; Akaike (AIC) 17503.562 #&gt; Bayesian (BIC) 17546.478 #&gt; Sample-size adjusted Bayesian (SABIC) 17514.734 #&gt; #&gt; Root Mean Square Error of Approximation: #&gt; #&gt; RMSEA 0.124 #&gt; 90 Percent confidence interval - lower 0.093 #&gt; 90 Percent confidence interval - upper 0.158 #&gt; P-value H_0: RMSEA &lt;= 0.050 0.000 #&gt; P-value H_0: RMSEA &gt;= 0.080 0.989 #&gt; #&gt; Standardized Root Mean Square Residual: #&gt; #&gt; SRMR 0.033 #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Standard #&gt; Information Expected #&gt; Information saturated (h1) model Structured #&gt; #&gt; Latent Variables: #&gt; Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all #&gt; F =~ #&gt; I 0.725 0.253 2.867 0.004 0.725 0.126 #&gt; G -11.322 0.384 -29.481 0.000 -11.322 -0.949 #&gt; S -11.342 0.398 -28.513 0.000 -11.342 -0.932 #&gt; N -6.163 0.233 -26.398 0.000 -6.163 -0.891 #&gt; W -11.598 0.444 -26.137 0.000 -11.598 -0.886 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all #&gt; F 1.000 1.000 1.000 #&gt; .I 32.840 2.000 16.420 0.000 32.840 0.984 #&gt; .G 14.038 1.473 9.532 0.000 14.038 0.099 #&gt; .S 19.508 1.718 11.353 0.000 19.508 0.132 #&gt; .N 9.847 0.725 13.573 0.000 9.847 0.206 #&gt; .W 36.892 2.685 13.737 0.000 36.892 0.215 Recuperiamo le specificità: psi &lt;- parameterEstimates(fit)$est[7:11] psi #&gt; [1] 32.839665 14.037578 19.508119 9.846927 36.891617 Stimiamo l’errore standard della misurazione con la (7.1): sqrt(sum(psi)) #&gt; [1] 10.63597 Applichiamo ora la formula della TCT: \\[ \\sigma_E = \\sigma_X \\sqrt{1 -\\rho_{XX^\\prime}}. \\] Per trovare \\(\\sigma\\) calcoliamo prima il punteggio totale: tot_score &lt;- rowSums(csq) La deviazione standard di tot_score ci fornisce una stima di \\(\\sigma_X\\): sigma &lt;- sd(tot_score) sigma #&gt; [1] 41.26414 Per applicare la formula della TCT abbiamo bisogno dell’attendibilità. La stimiamo usando la funzione reliability del pacchetto semTools dall’oggetto creato da lavaan:::cfa(): rel &lt;- semTools::reliability(fit) rel #&gt; F #&gt; alpha 0.8506572 #&gt; omega 0.9330313 #&gt; omega2 0.9330313 #&gt; omega3 0.9273385 #&gt; avevar 0.7916575 Utilizzando \\(\\Omega\\) otteniamo: sigma * sqrt(1 - rel[2]) #&gt; [1] 10.67846 Si noti come il risultato sia quasi identico a quello trovato con la formula della TCT. "],["il-modello-multifattoriale.html", "Capitolo 8 Il modello multifattoriale ", " Capitolo 8 Il modello multifattoriale "],["modello-multifattoriale-fattori-ortogonali.html", "8.1 Modello multifattoriale: fattori ortogonali", " 8.1 Modello multifattoriale: fattori ortogonali La teoria dei due fattori ha orientato per diversi anni le ricerche sull’intelligenza, finché Thurstone (1945) non propose una sua modifica, conosciuta come teoria multifattoriale. Secondo Thurstone la covariazione tra le variabili manifeste non può essere spiegata da un unico fattore generale. Invece è necessario ipotizzare l’azione causale di diversi fattori, definiti comuni, i quali si riferiscono solo ad alcune delle variabili considerate. Il modello plurifattoriale assume che ciascuna variabile manifesta sia espressa come funzione lineare di un certo numero \\(m\\) di fattori comuni, \\(\\xi_1, \\xi_2, \\dots, \\xi_m\\), responsabili della correlazione con le altre variabili, e di un solo fattore specifico (termine d’errore), responsabile della variabilità della variabile stessa. Per \\(p\\) variabili manifeste, \\(Y_1, Y_2, \\dots, Y_p\\), il modello fattoriale diventa quello indicato dal sistema di equazioni lineari descritto di seguito. Idealmente, \\(m\\) dovrebbe essere molto più piccolo di \\(p\\) così da consentire una descrizione parsimoniosa delle variabili manifeste in funzione di pochi fattori soggiacenti. Le variabili manifeste \\(Y\\) sono indicizzate da \\(i = 1, \\dots, p.\\) Le variabili latenti \\(\\xi\\) (fattori) sono indicizzate da \\(j = 1, \\dots, m.\\) I fattori specifici \\(\\delta\\) sono indicizzati da \\(i = 1, \\dots, p.\\) Le saturazioni fattoriali si distinguono dunque tramite due indici, \\(i\\) e \\(j\\): il primo indice si riferisce alle variabili manifeste, il secondo si riferisce ai fattori latenti. Indichiamo con \\(\\mu_i\\), con \\(i=1, \\dots, p\\) le medie delle \\(p\\) variabili manifeste \\(Y_1, Y_2, \\dots, Y_p\\). Se non vi è alcun effetto delle variabili comuni latenti, allora la variabile \\(Y_{ijk}\\), dove \\(k\\) è l’indice usato per i soggetti, sarà uguale a: \\[\\begin{equation} \\begin{cases} Y_{1k} &amp;= \\mu_1 + \\delta_{1k} \\\\ &amp;\\vdots\\\\ Y_{ik} &amp;= \\mu_i + \\delta_{ik}\\\\ &amp;\\vdots\\\\ Y_{pk} &amp;= \\mu_p + \\delta_{pk} \\notag \\end{cases} \\end{equation}\\] Se invece le variabili manifeste rappresentano la somma dell’effetto causale di \\(m\\) fattori comuni e di \\(p\\) fattori specifici, allora possiamo scrivere: \\[\\begin{equation} \\begin{cases} Y_1 - \\mu_1 &amp;= \\lambda_{11}\\xi_1 + \\dots + \\lambda_{1k}\\xi_k \\dots +\\lambda_{1m}\\xi_m + \\delta_1 \\\\ &amp;\\vdots\\\\ Y_i - \\mu_i &amp;= \\lambda_{i1}\\xi_1 + \\dots + \\lambda_{ik}\\xi_k \\dots +\\lambda_{im}\\xi_m + \\delta_i\\\\ &amp;\\vdots\\\\ Y_p - \\mu_p &amp;= \\lambda_{p1}\\xi_1 + \\dots + \\lambda_{pk}\\xi_k \\dots +\\lambda_{pm}\\xi_m + \\delta_p \\notag \\end{cases} \\end{equation}\\] Nel precedente sistema di equazioni lineari, \\(\\xi_j\\), con \\(j=1, \\dots, m\\), rappresenta la \\(j\\)-esima variabile inosservabile a fattore comune (ossia il \\(j\\)-esimo fattore comune a tutte le variabili \\(Y_i\\)); \\(\\lambda_{ij}\\) rappresenta il parametro, detto saturazione o peso fattoriale, che riflette l’importanza del \\(j\\)-esimo fattore comune nella composizione della \\(i\\)-esima variabile osservabile; \\(\\delta_i\\) rappresenta il fattore specifico (o unico) di ogni variabile manifesta \\(Y_i\\). In conclusione, secondo il modello multifattoriale, le variabili manifeste \\(Y_i\\), con \\(i=1, \\dots, p\\), sono il risultato di una combinazione lineare di \\(m &lt; p\\) fattori inosservabili ad esse comuni \\(\\xi_j\\), con \\(j=1, \\dots, m\\), e di \\(p\\) fattori specifici \\(\\delta_i\\), con \\(i=1, \\dots, p\\), anch’essi inosservabili e di natura residua. 8.1.1 Assunzioni del modello multifattoriale Le variabili inosservabili a fattore comune \\(\\xi_j\\), con \\(j=1, \\dots, m\\), in quanto latenti, non possiedono unità di misura. Pertanto, per semplicità si assume che abbiano media zero, \\(\\mathbb{E}(\\xi_j)=0\\), abbiano varianza unitaria, \\(\\mathbb{V} (\\xi_j)= \\mathbb{E}(\\xi_j^2) - [\\mathbb{E}(\\xi_j)]^2=1\\), e siano incorrelate tra loro, \\(\\mbox{Cov}(\\xi_j, \\xi_h)=0\\), con \\(j, h = 1, \\dots, m; \\;j \\neq h\\). Si assume inoltre che le variabili a fattore specifico \\(\\delta_i\\) siano tra loro incorrelate, \\(\\mbox{Cov}(\\delta_i,\\delta_k)=0\\), con \\(i, k = 1, \\dots, p, \\; i \\neq k\\), abbiano media zero, \\(\\mathbb{E}(\\delta_i)=0\\), e varianza uguale a \\(\\mathbb{V} (\\delta_i) = \\psi_{ii}\\). La varianza \\(\\psi_{ii}\\) è detta varianza specifica o unicità della \\(i\\)-esima variabile manifesta \\(Y_i\\). Si assume infine che i fattori specifici siano linearmente incorrelati con i fattori comuni, ovvero \\(\\mbox{Cov}(\\xi_j, \\delta_i)=0\\) per ogni \\(j=1, \\dots, m\\) e per ogni \\(i=1\\dots,p\\). 8.1.2 Interpretazione dei parametri del modello Quale esempio, consideriamo il caso di \\(p=5\\) variabili osservabili e \\(m=2\\) fattori ortogonali. Se le variabili manifeste sono ‘centrate’ (ovvero, se a ciascuna di esse sottraiamo la rispettiva media), allora il modello multifattoriale diventa + \\[\\begin{equation} \\begin{aligned} Y_1 &amp;= \\lambda_{11} \\xi_1 + \\lambda_{12} \\xi_2 + \\delta_1,\\notag\\\\ Y_2 &amp;= \\lambda_{21} \\xi_1 + \\lambda_{22} \\xi_2 + \\delta_2,\\notag\\\\ Y_3 &amp;= \\lambda_{31} \\xi_1 + \\lambda_{32} \\xi_2 + \\delta_3,\\notag\\\\ Y_4 &amp;= \\lambda_{41} \\xi_1 + \\lambda_{42} \\xi_2 + \\delta_4,\\notag\\\\ Y_5 &amp;= \\lambda_{51} \\xi_1 + \\lambda_{52} \\xi_2 + \\delta_5.\\notag \\end{aligned} \\end{equation}\\] 8.1.3 Covarianza tra variabili e fattori Nell’ipotesi che le variabili \\(Y_i\\) abbiano media nulla, la covarianza tra \\(Y_i\\) e \\(\\xi_j\\) è uguale alla saturazione fattoriale \\(\\lambda_{ij}\\): \\[ \\begin{equation} \\begin{aligned} \\mbox{Cov}(Y_i, \\xi_j) &amp;= \\mathbb{E}(Y_i \\xi_j)\\notag\\\\ &amp;=\\mathbb{E}\\left[(\\lambda_{i1} \\xi_1 + \\dots + \\lambda_{im} \\xi_m + \\delta_i)\\xi_j \\right]\\notag\\\\ &amp;= \\lambda_{i1}\\underbrace{\\mathbb{E}(\\xi_1\\xi_j)}_{=0} + \\dots + \\lambda_{ij}\\underbrace{\\mathbb{E}(\\xi_j^2)}_{=1} + \\dots \\notag\\\\ &amp; \\; + \\lambda_{im}\\underbrace{\\mathbb{E}(\\xi_m\\xi_j)}_{=0} + \\underbrace{\\mathbb{E}(\\delta_i \\xi_j)}_{=0}\\notag\\\\ &amp;= \\lambda_{ij}.\\notag \\end{aligned} \\end{equation} \\] Anche nel modello multifattoriale, dunque, le saturazioni fattoriali rappresentano le covarianze tra le variabili e i fattori: \\[ \\mbox{Cov}(Y_i, \\xi_j) = \\lambda_{ij} \\qquad i=1, \\dots, p; \\quad j= 1, \\dots, m. \\] Naturalmente, se le variabili sono standardizzate, le saturazioni fattoriali diventano correlazioni: \\[ r_{ij} = \\lambda_{ij}. \\] 8.1.4 Espressione fattoriale della varianza Come nel modello monofattoriale, la varianza delle variabili manifeste si decompone in una componente dovuta ai fattori comuni, chiamata comunalità, e in una componente specifica alle \\(Y_i\\), chiamata unicità. Nell’ipotesi che le variabili \\(Y_i\\) abbiano media nulla, la varianza di \\(Y_i\\) è uguale a \\[\\begin{equation} \\begin{aligned} \\mathbb{V} (Y_i) &amp;=\\mathbb{E}\\left[ (\\lambda_{i1} \\xi_1 + \\dots + \\lambda_{im} \\xi_m + \\delta_i)^2 \\right]. \\end{aligned} \\tag{8.1} \\end{equation}\\] Come si sviluppa il polinomio precedente? Il quadrato di un polinomio è uguale alla somma dei quadrati di tutti i termini più il doppio prodotto di ogni termine per ciascuno di quelli che lo seguono. Il valore atteso del quadrato del primo termine è uguale a \\(\\lambda_{i1}^2\\mathbb{E}(\\xi_1^2)\\) ma, essendo la varianza di \\(\\xi_1\\) uguale a \\(1\\), otteniamo semplicemente \\(\\lambda_{i1}^2\\). Lo stesso vale per i quadrati di tutti i termini seguenti tranne l’ultimo. Infatti, \\(\\mathbb{E}(\\delta_i^2)=\\psi_{ii}\\). Per quel che riguarda i doppi prodotti, sono tutti nulli. In primo luogo perché, nel caso di fattori ortogonali, la covarianza tra i fattori comuni è nulla, \\(\\mathbb{E}(\\xi_j \\xi_h)=0\\), con \\(j \\neq h\\). In secondo luogo perché il fattori comuni cono incorrelati con i fattori specifici, quindi \\(\\mathbb{E}(\\delta_i \\xi_j)=0\\). In conclusione, \\[\\begin{equation} \\begin{aligned} \\mathbb{V}(Y_i) &amp;= \\lambda_{i1}^2 + \\lambda_{i2}^2 + \\dots + \\lambda_{im}^2 + \\psi_{ii} \\notag\\\\ &amp;= \\sum_{j=1}^m \\lambda_{ij}^2 + \\psi_{ii}\\notag\\\\ &amp;= h_i^2 + \\psi_{ii}\\notag\\\\ &amp;=\\text{communalità} + \\text{unicità},\\notag \\end{aligned} \\end{equation}\\] la varianza della variabile manifesta \\(Y_i\\) è suddivisa in due parti: il primo addendo è definito comunalità poiché rappresenta la parte di variabilità della \\(Y_i\\) spiegata dai fattori comuni; il secondo addendo è invece definito varianza specifica (o unicità) poiché esprime la parte di variabilità della \\(Y_i\\) non spiegata dai fattori comuni. 8.1.5 Espressione fattoriale della covarianza Per semplificare, consideriamo il caso particolare esaminato prima, ovvero quello con \\(p=5\\) variabili osservabili e \\(m=2\\) fattori ortogonali. Nell’ipotesi che le variabili \\(Y_i\\) abbiano media nulla, la covarianza tra \\(Y_1\\) e \\(Y_2\\), ad esempio, è uguale a: \\[\\begin{equation} \\begin{aligned} \\mbox{Cov}(Y_1, Y_2) &amp;= \\mathbb{E}\\left( Y_1 Y_2\\right) \\notag\\\\ &amp;= \\mathbb{E}\\left[ (\\lambda_{11} \\xi_1 + \\lambda_{12} \\xi_2 + \\delta_1) (\\lambda_{21} \\xi_1 + \\lambda_{22} \\xi_2 + \\delta_2) \\right]\\notag\\\\ &amp;= \\lambda_{11} \\lambda_{21} \\mathbb{E}(\\xi_1^2) + \\lambda_{11} \\lambda_{22} \\mathbb{E}(\\xi_1 \\xi_2) +\\notag \\lambda_{11} \\mathbb{E}(\\xi_1 \\delta_2) +\\notag\\\\ &amp;\\quad \\lambda_{12} \\lambda_{21}\\mathbb{E}(\\xi_1 \\xi_2)\\, + \\lambda_{12} \\lambda_{22}\\mathbb{E}(\\xi^2_2)\\, + \\lambda_{12} \\mathbb{E}(\\xi_2\\delta_2) +\\notag\\\\ &amp;\\quad \\lambda_{21} \\mathbb{E}(\\xi_1\\delta_1) +\\notag \\lambda_{22} \\mathbb{E}(\\xi_2\\delta_1) + \\mathbb{E}(\\delta_1 \\delta_2)\\notag\\\\ &amp;= \\lambda_{11} \\lambda_{21} + \\lambda_{12} \\lambda_{22}.\\notag \\end{aligned} \\end{equation}\\] In conclusione, la covarianza tra le variabili manifeste \\(Y_l\\) e \\(Y_m\\) riprodotta dal modello è data dalla somma dei prodotti delle saturazioni \\(\\lambda_l \\lambda_m\\) nei due fattori. Esercizio 8.1 Consideriamo i dati riportati da Brown (2015), ovvero otto misure di personalità raccolte su un campione di 250 pazienti che hanno concluso un programma di psicoterapia. Le scale sono le seguenti: anxiety (N1), hostility (N2), depression (N3), self-consciousness (N4), warmth (E1), gregariousness (E2), assertiveness (E3), positive emotions (E4). varnames &lt;- c(&quot;N1&quot;, &quot;N2&quot;, &quot;N3&quot;, &quot;N4&quot;, &quot;E1&quot;, &quot;E2&quot;, &quot;E3&quot;, &quot;E4&quot;) sds &lt;- &quot;5.7 5.6 6.4 5.7 6.0 6.2 5.7 5.6&quot; cors &lt;- &quot; 1.000 0.767 1.000 0.731 0.709 1.000 0.778 0.738 0.762 1.000 -0.351 -0.302 -0.356 -0.318 1.000 -0.316 -0.280 -0.300 -0.267 0.675 1.000 -0.296 -0.289 -0.297 -0.296 0.634 0.651 1.000 -0.282 -0.254 -0.292 -0.245 0.534 0.593 0.566 1.000&quot; psychot_cor_mat &lt;- getCov(cors, names = varnames) n &lt;- 250 Eseguiamo l’analisi fattoriale esplorativa con il metodo della massima verosimiglianza ipotizzando due fattori comuni incorrelati: n_facs &lt;- 2 fit_efa &lt;- factanal( covmat = psychot_cor_mat, factors = n_facs, rotation = &quot;varimax&quot;, n.obs = n ) Esaminiamo le saturazioni fattoriali: lambda &lt;- fit_efa$loadings lambda #&gt; #&gt; Loadings: #&gt; Factor1 Factor2 #&gt; N1 0.854 -0.228 #&gt; N2 0.826 -0.194 #&gt; N3 0.811 -0.233 #&gt; N4 0.865 -0.186 #&gt; E1 -0.202 0.773 #&gt; E2 -0.139 0.829 #&gt; E3 -0.158 0.771 #&gt; E4 -0.147 0.684 #&gt; #&gt; Factor1 Factor2 #&gt; SS loadings 2.923 2.526 #&gt; Proportion Var 0.365 0.316 #&gt; Cumulative Var 0.365 0.681 La soluzione fattoriale conferma la presenza di due fattori: il primo fattore satura sulle scale di neutoricismo, il secono sulle scale di estroversione. La correlazione riprodotta \\(r_{12}\\) è uguale a \\(\\lambda_{11}\\lambda_{21} + \\lambda_{12}\\lambda_{22}\\) lambda[1, 1] * lambda[2, 1] + lambda[1, 2] * lambda[2, 2] #&gt; [1] 0.7492844 e corrisponde da vicino alla correlazione osservata 0.767. L’intera matrice di correlazioni riprodotte è \\(\\boldsymbol{\\Lambda} \\boldsymbol{\\Lambda}^{\\ensuremath{\\mathsf{T}}} + \\boldsymbol{\\psi}\\): Rr &lt;- lambda %*% t(lambda) + diag(fit_efa$uniq) Rr %&gt;% round(3) #&gt; N1 N2 N3 N4 E1 E2 E3 E4 #&gt; N1 1.000 0.749 0.745 0.781 -0.348 -0.307 -0.311 -0.281 #&gt; N2 0.749 1.000 0.715 0.751 -0.317 -0.276 -0.281 -0.254 #&gt; N3 0.745 0.715 1.000 0.745 -0.344 -0.306 -0.308 -0.279 #&gt; N4 0.781 0.751 0.745 1.000 -0.318 -0.274 -0.280 -0.254 #&gt; E1 -0.348 -0.317 -0.344 -0.318 1.000 0.669 0.628 0.558 #&gt; E2 -0.307 -0.276 -0.306 -0.274 0.669 1.000 0.661 0.587 #&gt; E3 -0.311 -0.281 -0.308 -0.280 0.628 0.661 1.000 0.550 #&gt; E4 -0.281 -0.254 -0.279 -0.254 0.558 0.587 0.550 1.000 La differenza tra la matrice di correlazioni riprodotte e la matrice di correlazioni osservate è uguale a: (psychot_cor_mat - Rr) %&gt;% round(3) #&gt; N1 N2 N3 N4 E1 E2 E3 E4 #&gt; N1 0.000 0.018 -0.014 -0.003 -0.003 -0.009 0.015 -0.001 #&gt; N2 0.018 0.000 -0.006 -0.013 0.015 -0.004 -0.008 0.000 #&gt; N3 -0.014 -0.006 0.000 0.017 -0.012 0.006 0.011 -0.013 #&gt; N4 -0.003 -0.013 0.017 0.000 0.000 0.007 -0.016 0.009 #&gt; E1 -0.003 0.015 -0.012 0.000 0.000 0.006 0.006 -0.024 #&gt; E2 -0.009 -0.004 0.006 0.007 0.006 0.000 -0.010 0.006 #&gt; E3 0.015 -0.008 0.011 -0.016 0.006 -0.010 0.000 0.016 #&gt; E4 -0.001 0.000 -0.013 0.009 -0.024 0.006 0.016 0.000 Esercizio 8.2 Consideriamo nuovamente i dati precedenti ma, in questo caso, eseguiamo un’analisi fattoriale confermativa. Usando lavaan il modello diventa: cfa_mod &lt;- &quot; N =~ N1 + N2 + N3 + N4 E =~ E1 + E2 + E3 + E4 &quot; fit_cfa &lt;- lavaan::cfa( cfa_mod, sample.cov = psychot_cor_mat, sample.nobs = n, orthogonal = TRUE, std.lv = TRUE ) Il path diagram si ottiene nel modo seguente: semPaths( fit_cfa, &quot;std&quot;, posCol = c(&quot;black&quot;), edge.label.cex = 1.2, sizeMan = 7 ) Esaminiamo le saturazioni fattoriali: parameterEstimates(fit_cfa, standardized = TRUE) %&gt;% dplyr::filter(op == &quot;=~&quot;) %&gt;% dplyr::select( &quot;Latent Factor&quot; = lhs, Indicator = rhs, B = est, SE = se, Z = z, &quot;p-value&quot; = pvalue, Beta = std.all ) %&gt;% knitr::kable( digits = 3, booktabs = TRUE, format = &quot;markdown&quot;, caption = &quot;Factor Loadings&quot; ) TABELLA 8.1: Factor Loadings Latent Factor Indicator B SE Z p-value Beta N N1 0.882 0.051 17.422 0 0.884 N N2 0.847 0.052 16.340 0 0.849 N N3 0.840 0.052 16.134 0 0.842 N N4 0.882 0.051 17.432 0 0.884 E E1 0.795 0.056 14.276 0 0.796 E E2 0.838 0.054 15.369 0 0.839 E E3 0.788 0.056 14.097 0 0.789 E E4 0.697 0.058 11.942 0 0.699 Il risultato sembra sensato: le saturazioni su ciascun fattore sono molto alte. Tuttavia, la matrice delle correlazioni residue cor_table &lt;- residuals(fit_cfa, type = &quot;cor&quot;)$cov knitr::kable( cor_table, digits = 3, format = &quot;markdown&quot;, booktabs = TRUE ) N1 N2 N3 N4 E1 E2 E3 E4 N1 0.000 0.017 -0.013 -0.003 -0.351 -0.316 -0.296 -0.282 N2 0.017 0.000 -0.006 -0.012 -0.302 -0.280 -0.289 -0.254 N3 -0.013 -0.006 0.000 0.018 -0.356 -0.300 -0.297 -0.292 N4 -0.003 -0.012 0.018 0.000 -0.318 -0.267 -0.296 -0.245 E1 -0.351 -0.302 -0.356 -0.318 0.000 0.007 0.006 -0.022 E2 -0.316 -0.280 -0.300 -0.267 0.007 0.000 -0.011 0.007 E3 -0.296 -0.289 -0.297 -0.296 0.006 -0.011 0.000 0.015 E4 -0.282 -0.254 -0.292 -0.245 -0.022 0.007 0.015 0.000 rivela che il modello ipotizzato dall’analisi fattoriale confermativa non è adeguato. References "],["modello-fattoriale-fattori-obliqui.html", "8.2 Modello fattoriale: Fattori obliqui", " 8.2 Modello fattoriale: Fattori obliqui Anche nel caso di fattori comuni correlati è possibile esprimere nei termini dei parametri del modello la covarianza teorica tra una variabile manifesta \\(Y_i\\) e uno dei fattori comuni, la covarianza teorica tra due variabili manifeste, e la comunalità di ciascuna variabile manifesta. Dato però che i fattori comuni risultano correlati, l’espressione fattoriale di tali quantità è più complessa che nel caso di fattori comuni ortogonali. 8.2.1 Covarianza teorica tra variabili e fattori In base al modello multifattoriale con \\(m\\) fattori comuni la variabile \\(Y_i\\) è \\[ Y_i = \\lambda_{i1} \\xi_1 + \\dots + \\lambda_{im} \\xi_m + \\delta_i. \\tag{8.2} \\] Poniamoci il problema di trovare la covarianza teorica tra la variabile manifesta \\(Y_i\\) e il fattore comune \\(\\xi_j\\). Come in precedenza, il problema si riduce a quello di trovare \\(\\mathbb{E}(Y_i \\xi_j)\\). Ne segue che \\[ \\begin{equation} \\begin{aligned} \\mbox{Cov}(Y_i, \\xi_j) &amp;= \\mathbb{E}(Y_i \\xi_j)\\notag\\\\ &amp;=\\mathbb{E}\\left[(\\lambda_{i1} \\xi_1 + \\dots + \\lambda_{ij} \\xi_j + \\dots + \\lambda_{im} \\xi_m + \\delta_i)\\xi_j \\right]\\notag\\\\ &amp;= \\lambda_{i1}\\underbrace{\\mathbb{E}(\\xi_1\\xi_j)}_{\\neq 0} + \\dots + \\lambda_{ij}\\underbrace{\\mathbb{E}(\\xi_j^2)}_{=1} + \\dots \\notag\\\\ &amp; \\quad + \\lambda_{im}\\underbrace{\\mathbb{E}(\\xi_m\\xi_j)}_{\\neq 0} + \\underbrace{\\mathbb{E}(\\delta_i \\xi_j)}_{=0}\\notag\\\\ &amp;= \\lambda_{ij} + \\lambda_{i1} \\mbox{Cov}(\\xi_1, \\xi_j) + \\dots + \\lambda_{im} \\mbox{Cov}(\\xi_m, \\xi_j). \\end{aligned} \\end{equation} \\] Ad esempio, nel caso di tre fattori comuni \\(\\xi_1, \\xi_2, \\xi_3\\), la covarianza tra \\(Y_1\\) e \\(\\xi_{1}\\) diventa \\[ \\lambda_{11} + \\lambda_{12}\\mbox{Cov}(\\xi_1, \\xi_2) + \\lambda_{13}\\mbox{Cov}(\\xi_1, \\xi_3). \\] 8.2.2 Espressione fattoriale della varianza Poniamoci ora il problema di trovare la varianza teorica della variabile manifesta \\(Y_i\\). In base al modello fattoriale, la variabile \\(Y_i\\) è specificata come nella (8.2). La varianza di \\(Y_i\\) è \\(\\mathbb{V}(Y_i) = \\mathbb{E}(Y_i^2) -[\\mathbb{E}(Y_i)]^2\\). Però, avendo espresso \\(Y_i\\) nei termini della differenza dalla sua media, l’espressione della varianza si riduce a \\(\\mathbb{V}(Y_i) = \\mathbb{E}(Y_i^2)\\). Dobbiamo dunque sviluppare l’espressione \\[ \\mathbb{E}(Y_i^2) = \\mathbb{E}[(\\lambda_{i1} \\xi_1 + \\dots + \\lambda_{im} \\xi_m + \\delta_i)^2]. \\] In conclusione, la varianza teorica di \\(Y_i\\) è uguale a \\[\\begin{equation} \\begin{split} \\mathbb{V}(Y_i) &amp;= \\lambda_{i1}^2 + \\lambda_{i2}^2 + \\dots + \\lambda_{im}^2 + \\\\ &amp;\\quad 2 \\lambda_{i1} \\lambda_{i2} \\mbox{Cov}(\\xi_1, \\xi_2) + \\dots + 2 \\lambda_{i,m-1} \\lambda_{im} \\mbox{Cov}(\\xi_{m-1}, \\xi_m) + \\\\ &amp;\\quad \\psi_{ii}.\\notag \\end{split} \\end{equation}\\] Ad esempio, nel caso di tre fattori comuni, \\(\\xi_1, \\xi_2, \\xi_3\\), la varianza di \\(Y_1\\) è \\[\\begin{equation} \\begin{split} \\mathbb{V}(Y_1) = &amp;\\lambda_{11}^2 + \\lambda_{12}^2 + \\lambda_{13}^2 +\\\\ &amp;\\quad 2 \\lambda_{11} \\lambda_{12} \\mbox{Cov}(\\xi_1, \\xi_2) + \\\\ &amp;\\quad 2 \\lambda_{11} \\lambda_{13} \\mbox{Cov}(\\xi_1, \\xi_3) + \\\\ &amp;\\quad 2 \\lambda_{12} \\lambda_{13} \\mbox{Cov}(\\xi_2, \\xi_3) + \\\\ &amp;\\quad \\psi_{11}. \\notag \\end{split} \\end{equation}\\] 8.2.3 Covarianza teorica tra due variabili Consideriamo ora il caso più semplice di due soli fattori comuni correlati e calcoliamo la covarianza tra \\(Y_1\\) e \\(Y_2\\): \\[\\begin{equation} \\begin{aligned} \\mathbb{E}(Y_1 Y_2) =\\mathbb{E}[(&amp;\\lambda_{11}\\xi_1 + \\lambda_{12}\\xi_2+\\delta_1) (\\lambda_{21}\\xi_1 + \\lambda_{22}\\xi_2+\\delta_2)]\\notag\\\\ =\\mathbb{E}( &amp;\\lambda_{11}\\lambda_{21}\\xi_1^2 + \\lambda_{11}\\lambda_{22}\\xi_1\\xi_2 + \\lambda_{11}\\xi_1\\delta_2 +\\notag\\\\ +&amp;\\lambda_{12}\\lambda_{21}\\xi_1\\xi_2 + \\lambda_{12}\\lambda_{22}\\xi_2^2 + \\lambda_{12}\\xi_2\\delta_2 +\\notag\\\\ +&amp;\\lambda_{21}\\xi_1\\delta_1 + \\lambda_{22}\\xi_2\\delta_1 + \\delta_1\\delta_2).\\notag \\end{aligned} \\end{equation}\\] Distribuendo l’operatore di valore atteso, dato che \\(\\mathbb{E}(\\xi^2)=1\\) e \\(\\mathbb{E}(\\xi \\delta)=0\\), otteniamo \\[ \\mbox{Cov}(Y_1, Y_2) = \\lambda_{11} \\lambda_{21} + \\lambda_{12} \\lambda_{22} + \\lambda_{12} \\lambda_{21}\\mbox{Cov}(\\xi_1, \\xi_2) +\\lambda_{11} \\lambda_{22}\\mbox{Cov}(\\xi_1, \\xi_2). \\] In termini matriciali si scrive \\[ \\boldsymbol{\\Sigma} =\\boldsymbol{\\Lambda} \\boldsymbol{\\Phi} \\boldsymbol{\\Lambda}^{\\mathsf{T}} + \\boldsymbol{\\Psi}, \\] dove \\(\\boldsymbol{\\Phi}\\) è la matrice di ordine \\(m \\times m\\) di varianze e covarianze tra i fattori comuni e \\(\\boldsymbol{\\Psi}\\) è una matrice diagonale di ordine \\(p\\) con le unicità delle variabili. Esercizio 8.3 Consideriamo nuovamente i dati esaminati negli esercizi precedenti, ma questa volta il modello consente una correlazione tra i due fattori comuni: fit2_cfa &lt;- lavaan::cfa( cfa_mod, sample.cov = psychot_cor_mat, sample.nobs = n, orthogonal = FALSE, std.lv = TRUE ) Visualizziamo il modello nel modo seguente: semPaths( fit2_cfa, &quot;std&quot;, posCol = c(&quot;black&quot;), edge.label.cex = 1.1, sizeMan = 7 ) Esaminiamo le saturazioni fattoriali: parameterEstimates(fit2_cfa, standardized = TRUE) %&gt;% dplyr::filter(op == &quot;=~&quot;) %&gt;% dplyr::select( &quot;Latent Factor&quot; = lhs, Indicator = rhs, B = est, SE = se, Z = z, &quot;p-value&quot; = pvalue, Beta = std.all ) %&gt;% knitr::kable( digits = 3, booktabs = TRUE, format = &quot;markdown&quot;, caption = &quot;Factor Loadings&quot; ) TABELLA 8.2: Factor Loadings Latent Factor Indicator B SE Z p-value Beta N N1 0.883 0.051 17.472 0 0.885 N N2 0.847 0.052 16.337 0 0.849 N N3 0.842 0.052 16.190 0 0.844 N N4 0.880 0.051 17.381 0 0.882 E E1 0.800 0.055 14.465 0 0.802 E E2 0.832 0.054 15.294 0 0.834 E E3 0.788 0.056 14.150 0 0.789 E E4 0.698 0.058 11.974 0 0.699 Le saturazioni sono simili a quelle che abbiamo trovato in precedenza, In questo caso, però, la matrice delle correlazioni residue è adeguata: cor_table &lt;- residuals(fit2_cfa, type = &quot;cor&quot;)$cov knitr::kable( cor_table, digits = 3, format = &quot;markdown&quot;, booktabs = TRUE ) N1 N2 N3 N4 E1 E2 E3 E4 N1 0.000 0.016 -0.015 -0.002 -0.042 0.005 0.008 -0.013 N2 0.016 0.000 -0.007 -0.010 -0.006 0.028 0.002 0.004 N3 -0.015 -0.007 0.000 0.018 -0.062 0.006 -0.007 -0.035 N4 -0.002 -0.010 0.018 0.000 -0.010 0.053 0.007 0.023 E1 -0.042 -0.006 -0.062 -0.010 0.000 0.006 0.001 -0.027 E2 0.005 0.028 0.006 0.053 0.006 0.000 -0.007 0.010 E3 0.008 0.002 -0.007 0.007 0.001 -0.007 0.000 0.014 E4 -0.013 0.004 -0.035 0.023 -0.027 0.010 0.014 0.000 Esercizio 8.4 Esaminiamo più da vicino la matrice di correlazioni riprodotta dal modello, nel caso di fattori obliqui. Le saturazioni fattoriali sono: lambda &lt;- inspect(fit2_cfa, what = &quot;std&quot;)$lambda lambda #&gt; N E #&gt; N1 0.885 0.000 #&gt; N2 0.849 0.000 #&gt; N3 0.844 0.000 #&gt; N4 0.882 0.000 #&gt; E1 0.000 0.802 #&gt; E2 0.000 0.834 #&gt; E3 0.000 0.789 #&gt; E4 0.000 0.699 La matrice di intercorrelazoni fattoriali è Phi &lt;- inspect(fit2_cfa, what = &quot;std&quot;)$psi Phi #&gt; N E #&gt; N 1.000 #&gt; E -0.435 1.000 Le varianze residue sono: Psi &lt;- inspect(fit2_cfa, what = &quot;std&quot;)$theta Psi #&gt; N1 N2 N3 N4 E1 E2 E3 E4 #&gt; N1 0.217 #&gt; N2 0.000 0.280 #&gt; N3 0.000 0.000 0.288 #&gt; N4 0.000 0.000 0.000 0.222 #&gt; E1 0.000 0.000 0.000 0.000 0.357 #&gt; E2 0.000 0.000 0.000 0.000 0.000 0.305 #&gt; E3 0.000 0.000 0.000 0.000 0.000 0.000 0.377 #&gt; E4 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.511 Mediante i parametri del modello la matrice di correlazione si riproduce nel modo seguente: \\[ \\boldsymbol{\\Sigma} =\\boldsymbol{\\Lambda} \\boldsymbol{\\Phi} \\boldsymbol{\\Lambda}^{\\mathsf{T}} + \\boldsymbol{\\Psi}. \\] Le corrispondenti istruzioni \\(\\textsf{R}\\) sono: R_hat &lt;- lambda %*% Phi %*% t(lambda) + Psi R_hat %&gt;% round(3) #&gt; N1 N2 N3 N4 E1 E2 E3 E4 #&gt; N1 1.000 #&gt; N2 0.751 1.000 #&gt; N3 0.746 0.716 1.000 #&gt; N4 0.780 0.748 0.744 1.000 #&gt; E1 -0.309 -0.296 -0.294 -0.308 1.000 #&gt; E2 -0.321 -0.308 -0.306 -0.320 0.669 1.000 #&gt; E3 -0.304 -0.291 -0.290 -0.303 0.633 0.658 1.000 #&gt; E4 -0.269 -0.258 -0.257 -0.268 0.561 0.583 0.552 1.000 Le correlazioni residue sono: (psychot_cor_mat - R_hat) %&gt;% round(3) #&gt; N1 N2 N3 N4 E1 E2 E3 E4 #&gt; N1 0.000 #&gt; N2 0.016 0.000 #&gt; N3 -0.015 -0.007 0.000 #&gt; N4 -0.002 -0.010 0.018 0.000 #&gt; E1 -0.042 -0.006 -0.062 -0.010 0.000 #&gt; E2 0.005 0.028 0.006 0.053 0.006 0.000 #&gt; E3 0.008 0.002 -0.007 0.007 0.001 -0.007 0.000 #&gt; E4 -0.013 0.004 -0.035 0.023 -0.027 0.010 0.014 0.000 Per fare un esempio, calcoliamo la correlazione predetta dal modello tra le variabili \\(Y_1\\) e \\(Y_2\\): lambda[1, 1] * lambda[2, 1] + lambda[1, 2] * lambda[2, 2] + lambda[1, 1] * lambda[2, 2] * Phi[1, 2] + lambda[1, 2] * lambda[2, 1] * Phi[1, 2] #&gt; [1] 0.7507823 Questo valore si avvicina al valore contenuto dell’elemento (1, 2) della matrice di correlazioni osservate: psychot_cor_mat[1, 2] #&gt; [1] 0.767 Usando le funzonalità di lavaan la matrice di correlazione predetta si ottiene con: fitted(fit2_cfa)$cov #&gt; N1 N2 N3 N4 E1 E2 E3 E4 #&gt; N1 0.996 #&gt; N2 0.748 0.996 #&gt; N3 0.743 0.713 0.996 #&gt; N4 0.777 0.745 0.741 0.996 #&gt; E1 -0.307 -0.295 -0.293 -0.306 0.996 #&gt; E2 -0.320 -0.306 -0.305 -0.319 0.666 0.996 #&gt; E3 -0.303 -0.290 -0.289 -0.302 0.630 0.656 0.996 #&gt; E4 -0.268 -0.257 -0.255 -0.267 0.558 0.580 0.550 0.996 La matrice dei residui è resid(fit2_cfa)$cov #&gt; N1 N2 N3 N4 E1 E2 E3 E4 #&gt; N1 0.000 #&gt; N2 0.016 0.000 #&gt; N3 -0.015 -0.007 0.000 #&gt; N4 -0.002 -0.010 0.018 0.000 #&gt; E1 -0.042 -0.006 -0.062 -0.010 0.000 #&gt; E2 0.005 0.028 0.006 0.053 0.006 0.000 #&gt; E3 0.008 0.002 -0.007 0.007 0.001 -0.007 0.000 #&gt; E4 -0.013 0.004 -0.035 0.023 -0.026 0.010 0.014 0.000 La matrice dei residui standardizzati è resid(fit2_cfa, type = &quot;standardized&quot;)$cov #&gt; N1 N2 N3 N4 E1 E2 E3 E4 #&gt; N1 0.000 #&gt; N2 1.674 0.000 #&gt; N3 -1.769 -0.569 0.000 #&gt; N4 -0.350 -1.152 1.746 0.000 #&gt; E1 -1.214 -0.161 -1.646 -0.294 0.000 #&gt; E2 0.154 0.794 0.168 1.626 0.637 0.000 #&gt; E3 0.219 0.062 -0.191 0.193 0.075 -0.693 0.000 #&gt; E4 -0.314 0.092 -0.824 0.552 -1.481 0.624 0.690 0.000 "],["efa-con-lavaan.html", "8.3 EFA con lavaan", " 8.3 EFA con lavaan Una funzionalità sperimentale di lavaan (ancora non ufficiale) è quella che consente di svolgere l’analisi fattoriale esplorativa con la funzione efa(). Consideriamo nuovamente i dati di Brown (2015), ovvero otto misure di personalità raccolte su un campione di 250 pazienti che hanno concluso un programma di psicoterapia. # 1-factor model f1 &lt;- &#39; efa(&quot;efa&quot;)*f1 =~ N1 + N2 + N3 + N4 + E1 + E2 + E3 + E4 &#39; # 2-factor model f2 &lt;- &#39; efa(&quot;efa&quot;)*f1 + efa(&quot;efa&quot;)*f2 =~ N1 + N2 + N3 + N4 + E1 + E2 + E3 + E4 &#39; efa_f1 &lt;- cfa( model = f1, sample.cov = psychot_cor_mat, sample.nobs = 250, rotation = &quot;oblimin&quot; ) summary( efa_f1, fit.measures = TRUE, standardized = TRUE, rsquare = TRUE ) #&gt; lavaan 0.6.14 ended normally after 2 iterations #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of model parameters 16 #&gt; #&gt; Rotation method OBLIMIN OBLIQUE #&gt; Oblimin gamma 0 #&gt; Rotation algorithm (rstarts) GPA (30) #&gt; Standardized metric TRUE #&gt; Row weights None #&gt; #&gt; Number of observations 250 #&gt; #&gt; Model Test User Model: #&gt; #&gt; Test statistic 375.327 #&gt; Degrees of freedom 20 #&gt; P-value (Chi-square) 0.000 #&gt; #&gt; Model Test Baseline Model: #&gt; #&gt; Test statistic 1253.791 #&gt; Degrees of freedom 28 #&gt; P-value 0.000 #&gt; #&gt; User Model versus Baseline Model: #&gt; #&gt; Comparative Fit Index (CFI) 0.710 #&gt; Tucker-Lewis Index (TLI) 0.594 #&gt; #&gt; Loglikelihood and Information Criteria: #&gt; #&gt; Loglikelihood user model (H0) -2394.637 #&gt; Loglikelihood unrestricted model (H1) -2206.974 #&gt; #&gt; Akaike (AIC) 4821.275 #&gt; Bayesian (BIC) 4877.618 #&gt; Sample-size adjusted Bayesian (SABIC) 4826.897 #&gt; #&gt; Root Mean Square Error of Approximation: #&gt; #&gt; RMSEA 0.267 #&gt; 90 Percent confidence interval - lower 0.243 #&gt; 90 Percent confidence interval - upper 0.291 #&gt; P-value H_0: RMSEA &lt;= 0.050 0.000 #&gt; P-value H_0: RMSEA &gt;= 0.080 1.000 #&gt; #&gt; Standardized Root Mean Square Residual: #&gt; #&gt; SRMR 0.187 #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Standard #&gt; Information Expected #&gt; Information saturated (h1) model Structured #&gt; #&gt; Latent Variables: #&gt; Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all #&gt; f1 =~ efa #&gt; N1 0.879 0.051 17.333 0.000 0.879 0.880 #&gt; N2 0.841 0.052 16.154 0.000 0.841 0.842 #&gt; N3 0.841 0.052 16.175 0.000 0.841 0.843 #&gt; N4 0.870 0.051 17.065 0.000 0.870 0.872 #&gt; E1 -0.438 0.062 -7.041 0.000 -0.438 -0.439 #&gt; E2 -0.398 0.063 -6.327 0.000 -0.398 -0.398 #&gt; E3 -0.398 0.063 -6.342 0.000 -0.398 -0.399 #&gt; E4 -0.364 0.063 -5.746 0.000 -0.364 -0.364 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all #&gt; .N1 0.224 0.028 7.915 0.000 0.224 0.225 #&gt; .N2 0.289 0.033 8.880 0.000 0.289 0.290 #&gt; .N3 0.288 0.032 8.866 0.000 0.288 0.289 #&gt; .N4 0.239 0.029 8.174 0.000 0.239 0.240 #&gt; .E1 0.804 0.073 10.963 0.000 0.804 0.807 #&gt; .E2 0.838 0.076 11.008 0.000 0.838 0.841 #&gt; .E3 0.837 0.076 11.007 0.000 0.837 0.841 #&gt; .E4 0.864 0.078 11.041 0.000 0.864 0.867 #&gt; f1 1.000 1.000 1.000 #&gt; #&gt; R-Square: #&gt; Estimate #&gt; N1 0.775 #&gt; N2 0.710 #&gt; N3 0.711 #&gt; N4 0.760 #&gt; E1 0.193 #&gt; E2 0.159 #&gt; E3 0.159 #&gt; E4 0.133 efa_f2 &lt;- cfa( model = f2, sample.cov = psychot_cor_mat, sample.nobs = 250, rotation = &quot;oblimin&quot; ) summary( efa_f2, fit.measures = TRUE, standardized = TRUE, rsquare = TRUE ) #&gt; lavaan 0.6.14 ended normally after 1 iteration #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of model parameters 23 #&gt; #&gt; Rotation method OBLIMIN OBLIQUE #&gt; Oblimin gamma 0 #&gt; Rotation algorithm (rstarts) GPA (30) #&gt; Standardized metric TRUE #&gt; Row weights None #&gt; #&gt; Number of observations 250 #&gt; #&gt; Model Test User Model: #&gt; #&gt; Test statistic 9.811 #&gt; Degrees of freedom 13 #&gt; P-value (Chi-square) 0.709 #&gt; #&gt; Model Test Baseline Model: #&gt; #&gt; Test statistic 1253.791 #&gt; Degrees of freedom 28 #&gt; P-value 0.000 #&gt; #&gt; User Model versus Baseline Model: #&gt; #&gt; Comparative Fit Index (CFI) 1.000 #&gt; Tucker-Lewis Index (TLI) 1.006 #&gt; #&gt; Loglikelihood and Information Criteria: #&gt; #&gt; Loglikelihood user model (H0) -2211.879 #&gt; Loglikelihood unrestricted model (H1) -2206.974 #&gt; #&gt; Akaike (AIC) 4469.758 #&gt; Bayesian (BIC) 4550.752 #&gt; Sample-size adjusted Bayesian (SABIC) 4477.840 #&gt; #&gt; Root Mean Square Error of Approximation: #&gt; #&gt; RMSEA 0.000 #&gt; 90 Percent confidence interval - lower 0.000 #&gt; 90 Percent confidence interval - upper 0.048 #&gt; P-value H_0: RMSEA &lt;= 0.050 0.957 #&gt; P-value H_0: RMSEA &gt;= 0.080 0.001 #&gt; #&gt; Standardized Root Mean Square Residual: #&gt; #&gt; SRMR 0.010 #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Standard #&gt; Information Expected #&gt; Information saturated (h1) model Structured #&gt; #&gt; Latent Variables: #&gt; Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all #&gt; f1 =~ efa #&gt; N1 0.874 0.053 16.592 0.000 0.874 0.876 #&gt; N2 0.851 0.055 15.551 0.000 0.851 0.853 #&gt; N3 0.826 0.054 15.179 0.000 0.826 0.828 #&gt; N4 0.896 0.053 16.802 0.000 0.896 0.898 #&gt; E1 -0.046 0.040 -1.138 0.255 -0.046 -0.046 #&gt; E2 0.035 0.034 1.030 0.303 0.035 0.035 #&gt; E3 0.000 0.040 0.010 0.992 0.000 0.000 #&gt; E4 -0.006 0.049 -0.131 0.896 -0.006 -0.006 #&gt; f2 =~ efa #&gt; N1 -0.017 0.032 -0.539 0.590 -0.017 -0.017 #&gt; N2 0.011 0.035 0.322 0.748 0.011 0.011 #&gt; N3 -0.035 0.036 -0.949 0.343 -0.035 -0.035 #&gt; N4 0.031 0.031 0.994 0.320 0.031 0.031 #&gt; E1 0.776 0.059 13.125 0.000 0.776 0.778 #&gt; E2 0.854 0.058 14.677 0.000 0.854 0.855 #&gt; E3 0.785 0.060 13.106 0.000 0.785 0.787 #&gt; E4 0.695 0.063 10.955 0.000 0.695 0.697 #&gt; #&gt; Covariances: #&gt; Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all #&gt; f1 ~~ #&gt; f2 -0.432 0.059 -7.345 0.000 -0.432 -0.432 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all #&gt; .N1 0.218 0.028 7.790 0.000 0.218 0.219 #&gt; .N2 0.279 0.032 8.693 0.000 0.279 0.280 #&gt; .N3 0.287 0.032 8.907 0.000 0.287 0.289 #&gt; .N4 0.216 0.029 7.578 0.000 0.216 0.217 #&gt; .E1 0.361 0.044 8.226 0.000 0.361 0.362 #&gt; .E2 0.292 0.043 6.787 0.000 0.292 0.293 #&gt; .E3 0.379 0.046 8.315 0.000 0.379 0.381 #&gt; .E4 0.509 0.053 9.554 0.000 0.509 0.511 #&gt; f1 1.000 1.000 1.000 #&gt; f2 1.000 1.000 1.000 #&gt; #&gt; R-Square: #&gt; Estimate #&gt; N1 0.781 #&gt; N2 0.720 #&gt; N3 0.711 #&gt; N4 0.783 #&gt; E1 0.638 #&gt; E2 0.707 #&gt; E3 0.619 #&gt; E4 0.489 # define the fit measures fit_measures_robust &lt;- c( &quot;chisq&quot;, &quot;df&quot;, &quot;pvalue&quot;, &quot;cfi&quot;, &quot;rmsea&quot;, &quot;srmr&quot; ) # collect them for each model rbind( fitmeasures(efa_f1, fit_measures_robust), fitmeasures(efa_f2, fit_measures_robust) ) %&gt;% # wrangle data.frame() %&gt;% mutate( chisq = round(chisq, digits = 0), df = as.integer(df), pvalue = ifelse(pvalue == 0, &quot;&lt; .001&quot;, pvalue) ) %&gt;% mutate_at(vars(cfi:srmr), ~ round(., digits = 3)) #&gt; chisq df pvalue cfi rmsea srmr #&gt; 1 375 20 &lt; .001 0.71 0.267 0.187 #&gt; 2 10 13 0.709310449320062 1.00 0.000 0.010 I risultati mostrano come la funzione efa() sia effettivamente in grado di distinguere in maniera chiara tra i due fattori. Il confronto tra modelli mostra la superiorità del modello a due fattori. References "],["i-punteggi-fattoriali.html", "Capitolo 9 I punteggi fattoriali", " Capitolo 9 I punteggi fattoriali Uno dei momenti più difficili nel processo di sviluppo di un test psicometrico è quello dell’interpretazione dei fattori. La verifica del livello di affidabilità rivela il grado di precisione delle misure ottenute ma non fornisce alcuna informazione sulla natura di ciò che si sta misurando. Non esistono specifiche indicazioni che guidino il lavoro interpretativo. Dipende, perciò, dalla capacità e dall’esperienza del ricercatore cogliere il significato comune delle variabili confluite in un fattore, attenendosi alla realtà delle singole variabili senza fornire interpretazioni fantasiose. È importante rendersi conto che sia la scelta del metodo di estrazione dei fattori, sia il problema del numero dei fattori da estrarre, sia la scelta del metodo con cui effettuare la rotazione, rendono molto arbitraria l’interpretazione della soluzione fattoriale. I passaggi teorici necessari per interpretare una matrice fattoriale ruotata possono essere descritti nel modo seguente. Si definisce un livello arbitrario per le saturazioni che ci indichi il limite oltre il quale non riteniamo le variabili sufficientemente importanti per caratterizzare quel determinato fattore. Solitamente si sceglie la soglia di .40. In casi particolari è possibile usare valori maggiori o minori di questo, a seconda che si abbia un numero ristretto o troppo ampio di variabili da interpretare. Si ordinano le saturazioni delle variabili del fattore in ordine decrescente (in valore assoluto), fermandosi al livello prescelto. Si scrive accanto ad ogni saturazione la denominazione della variabile corrispondente (o il testo dell’item). Tenendo presente il dominio di indagine, le teorie di riferimento ed eventuali risultati precedenti, si cerca di stabilire quale sia il tratto, caratteristica, aspetto …che queste variabili abbiano in comune, in modo da poter in modo da poter “nominare” il fattore che definisce questo tratto comune. In questo processo interpretativo gli item con le saturazioni maggiori contribuiscono in misura maggiore alla definizione del carattere comune del fattore e, viceversa, ciò che è stato individuato come tratto comune delle variabili deve comparire in maggior grado nelle variabili più sature. Il segno negativo di una saturazione indica solamente un’opposizione rispetto alle saturazioni positive. Il tratto comune alle variabili dovrebbe essere pensato come un continuum che passa dalla sua massima presenza al suo opposto. Per procedere all’interpretazione conviene iniziare dalle variabili il cui segno è più frequente e considerarle come se fossero positive; di conseguenza, le altre (siano esse di segno positivo o negativo) devono essere considerate di segno opposto. Nel caso in cui non si riesca a riscontrare nessun tratto comune alle variabili del fattore, si dovrà concludere che il fattore non è interpretabile e che le variabili sono state tra loro associate per un errore attribuibile o al campione o alla misurazione delle variabili stesse. Normalmente i “primi” fattori estratti sono facilmente interpretabili mentre gli “ultimi”, soprattutto se ne sono stati estratti molti o se la matrice delle correlazioni iniziale fra le variabili contiene molti valori bassi, sono spesso difficilmente interpretabili o saturi di una sola variabile e quindi fattori specifici di quella variabile. In linea di massima se i fattori non interpretabili sono molti è meglio non considerare affatto i risultati dell’analisi fattoriale. 9.0.1 Esempio di interpretazione Il WISC-III (Wechsler Intelligence Scale For Children - III) valuta l’abilità intellettiva di soggetti dai 6 ai 16 anni e 11 mesi. I subtest sono stati selezionati per valutare diverse abilità mentali, che tutte insieme indicano l’abilità intellettiva generale del bambino. Alcuni gli richiedono un ragionamento astratto, altri si focalizzano sulla memoria, altri ancora richiedono certe abilità percettive e così via. Si consideri la matrice di correlazione tra i subtest della scala WISC-III riportata dal manuale. lower &lt;- &quot; 1 .66 1 .57 .55 1 .70 .69 .54 1 .56 .59 .47 .64 1 .34 .34 .43 .35 .29 1 .47 .45 .39 .45 .38 .25 1 .21 .20 .27 .26 .25 .23 .18 1 .40 .39 .35 .40 .35 .20 .37 .28 1 .48 .49 .52 .46 .40 .32 .52 .27 .41 1 .41 .42 .39 .41 .34 .26 .49 .24 .37 .61 1 .35 .35 .41 .35 .34 .28 .33 .53 .36 .45 .38 1 .18 .18 .22 .17 .17 .14 .24 .15 .23 .31 .29 .24 1 &quot; wisc_III_cov &lt;- getCov( lower, names = c( &quot;INFO&quot;, &quot;SIM&quot;, &quot;ARITH&quot;, &quot;VOC&quot;, &quot;COMP&quot;, &quot;DIGIT&quot;, &quot;PICTCOM&quot;, &quot;CODING&quot;, &quot;PICTARG&quot;, &quot;BLOCK&quot;, &quot;OBJECT&quot;, &quot;SYMBOL&quot;, &quot;MAZES&quot; ) ) Eseguiamo l’analisi fattoriale con il metodo delle componenti principali e una rotazione Varimax: f_pc &lt;- psych::principal(wisc_III_cov, nfactors = 3, rotate = &quot;varimax&quot;) f_pc #&gt; Principal Components Analysis #&gt; Call: psych::principal(r = wisc_III_cov, nfactors = 3, rotate = &quot;varimax&quot;) #&gt; Standardized loadings (pattern matrix) based upon correlation matrix #&gt; RC1 RC3 RC2 h2 u2 com #&gt; INFO 0.80 0.25 0.09 0.72 0.28 1.2 #&gt; SIM 0.81 0.25 0.08 0.72 0.28 1.2 #&gt; ARITH 0.65 0.26 0.28 0.57 0.43 1.7 #&gt; VOC 0.83 0.19 0.13 0.75 0.25 1.2 #&gt; COMP 0.75 0.14 0.16 0.60 0.40 1.2 #&gt; DIGIT 0.45 0.06 0.36 0.34 0.66 2.0 #&gt; PICTCOM 0.43 0.61 0.02 0.56 0.44 1.8 #&gt; CODING 0.10 0.09 0.88 0.79 0.21 1.0 #&gt; PICTARG 0.34 0.45 0.27 0.39 0.61 2.6 #&gt; BLOCK 0.41 0.66 0.22 0.66 0.34 1.9 #&gt; OBJECT 0.31 0.71 0.14 0.62 0.38 1.5 #&gt; SYMBOL 0.23 0.32 0.74 0.70 0.30 1.6 #&gt; MAZES -0.06 0.71 0.11 0.51 0.49 1.1 #&gt; #&gt; RC1 RC3 RC2 #&gt; SS loadings 3.80 2.37 1.74 #&gt; Proportion Var 0.29 0.18 0.13 #&gt; Cumulative Var 0.29 0.47 0.61 #&gt; Proportion Explained 0.48 0.30 0.22 #&gt; Cumulative Proportion 0.48 0.78 1.00 #&gt; #&gt; Mean item complexity = 1.5 #&gt; Test of the hypothesis that 3 components are sufficient. #&gt; #&gt; The root mean square of the residuals (RMSR) is 0.07 #&gt; #&gt; Fit based upon off diagonal values = 0.97 Si noti che i primi cinque subtest possiedono saturazioni maggiori di \\(0.6\\) sul primo fattore. Dato che questi test sono tutti presentati verbalmente e richiedono delle risposte verbali, tale fattore può essere denominato Comprensione Verbale. I subtest “Cifrario” e “Ricerca di simboli” saturano sul secondo fattore. Entrambi i subtest misurano la velocità dei processi di codifica o ricerca. Questo fattore, dunque, può essere denominato Velocità di elaborazione. Infine, i subtest “Completamento di figure,” “Disegno con i cubi,” “Riordinamento di storie figurate” e “Labirinti” saturano sul terzo fattore. Tutti questi test condividono una componente geometrica o configurazionale: misurano infatti le abilità necessarie per la manipolazione o la disposizione di immagini, oggetti, blocchi. Questo fattore, dunque, può essere denominato Organizzazione percettiva. Nel caso di una rotazione ortogonale, la comunalità di ciascuna sottoscala è uguale alla somma dei coefficienti di impatto al quadrato della sottoscala nei fattori. Per le 13 sottoscale del WISC-III abbiamo dunque h2 &lt;- rep(0, 13) for (i in 1:13) { h2[i] &lt;- sum(f_pc$loadings[i, ]^2) } round(h2, 2) #&gt; [1] 0.72 0.72 0.57 0.75 0.60 0.34 0.56 0.79 0.39 0.66 0.62 0.70 0.51 Questi risultati replicano quelli riportati nel manuale del test WISC-III. "],["punteggi-fattoriali.html", "9.1 Punteggi fattoriali", " 9.1 Punteggi fattoriali Fino ad ora abbiamo considerato le strategie di costruzione del modello basate sulla stima e sull’interpretazione delle saturazioni fattoriali e delle comunalità. Questo è il primo passo nella costruzione del modello fattoriale. È però possibile compiere un passo ulteriore, ovvero quello della stima dei punteggi fattoriali (factor scores) i quali risultano utili sia per interpretare i risultati dell’analisi fattoriale che per fare diagnostica. I punteggi fattoriali forniscono le previsioni dei livelli dei fattori latenti per ogni rispondente. Esistono vari metodi di stima dei punteggi fattoriali. Tra questi troviamo il metodo di Thomson basato sulla regressione e il metodo di Bartlett basato sulla massima verosimiglianza. Entrambi questi metodi sono implementati nel software . 9.1.1 Stima dei punteggi fattoriali Si definiscono punteggi fattoriali i valori assunti dai fattori comuni (inosservabili) in corrispondenza delle osservazioni campionarie. Il metodo di Thomson stima i punteggi fattoriali in base all’approccio della regressione multipla, ovvero, impiegando la matrice delle correlazioni tra le variabili e la matrice di struttura (ovvero, la matrice delle correlazioni delle variabili con i fattori). Per ottenere le stime dei punteggi fattoriali con il metodo di Thomson è necessario specificare nella funzione factanal() l’opzione scores = \"regression\". 9.1.2 Dimostrazione di Thurstone Prima di descrivere il metodo della regressione, esaminiamo la dimostrazione che Thurstone (1947) ha fornito per illustrare il significato dei punteggi fattoriali (si veda Loehlin, 1987). L’idea è quella di esaminare la stima dei punteggi fattoriali in una situazione in cui i tali punteggi sono conosciuti, in maniera tale da potere controllare il risultato dell’analisi. Si consideri un insieme di 1000 scatole di cui conosciamo le dimensioni \\(x, y, z\\): set.seed(123) n &lt;- 1e3 x &lt;- rnorm(n, 100, 1.5) y &lt;- rnorm(n, 200, 1.5) z &lt;- rnorm(n, 300, 1.5) Il problema è quello di stimare le dimensioni delle scatole disponendo soltanto di una serie di misure indirette, corrotte dal rumore di misura. Thurstone (1947) utilizzò le seguenti trasformazioni delle dimensioni delle scatole (si veda Jennrich, 2007). s &lt;- 40 y1 &lt;- rnorm(n, mean(x), s) y2 &lt;- rnorm(n, mean(y), s) y3 &lt;- rnorm(n, mean(z), s) y4 &lt;- x * y + rnorm(n, 0, s) y5 &lt;- x * z + rnorm(n, 0, s) y6 &lt;- y * z + rnorm(n, 0, s) y7 &lt;- x^2 * y + rnorm(n, 0, s) y8 &lt;- x * y^2 + rnorm(n, 0, s) y9 &lt;- x^2 * z + rnorm(n, 0, s) y10 &lt;- x * z^2 + rnorm(n, 0, s) y11 &lt;- y^2 * z + rnorm(n, 0, s) y12 &lt;- y * z^2 + rnorm(n, 0, s) y13 &lt;- y^2 * z + rnorm(n, 0, s) y14 &lt;- y * z^2 + rnorm(n, 0, s) y15 &lt;- x / y + rnorm(n, 0, s) y16 &lt;- y / x + rnorm(n, 0, s) y17 &lt;- x / z + rnorm(n, 0, s) y18 &lt;- z / x + rnorm(n, 0, s) y19 &lt;- y / z + rnorm(n, 0, s) y20 &lt;- z / y + rnorm(n, 0, s) y21 &lt;- 2 * x + 2 * y + rnorm(n, 0, s) y22 &lt;- 2 * x + 2 * z + rnorm(n, 0, s) y23 &lt;- 2 * y + 2 * z + rnorm(n, 0, s) Eseguiamo l’analisi fattoriale con una soluzione a tre fattori sui dati così creati. Y &lt;- cbind( y1, y2, y3, y4, y5, y6, y7, y8, y9, y10, y11, y12, y13, y14, y15, y16, y17, y18, y19, y20, y21, y22, y23 ) fa &lt;- factanal( Y, factors = 3, scores = &quot;regression&quot;, lower = 0.01 ) L’opzione scores = \"regression\" richiede il calcolo dei punteggi fattoriali con il metodo della regressione. Nel caso di una rotazione Varimax (default della funzione factanal()), i punteggi fattoriali risultano ovviamente incorrelati: cor( cbind(fa$scores[, 1], fa$scores[, 2], fa$scores[, 3]) ) %&gt;% round(3) #&gt; [,1] [,2] [,3] #&gt; [1,] 1.000 0.002 -0.001 #&gt; [2,] 0.002 1.000 0.005 #&gt; [3,] -0.001 0.005 1.000 Generiamo ora i diagrammi di dispersione che mettono in relazione le dimensioni originarie delle scatole (\\(x, y, z\\)) con i punteggi fattoriali sui tre fattori. Se l’analisi ha successo, ci aspettiamo un’alta correlazione tra i punteggi fattoriali di ogni fattore e una sola delle dimensioni delle scatole \\(x\\), \\(y\\), \\(z\\). p1 &lt;- tibble(x, fs1 = fa$scores[, 1]) %&gt;% ggplot(aes(x, fs1)) + geom_point(alpha = 0.2) p2 &lt;- tibble(y, fs1 = fa$scores[, 1]) %&gt;% ggplot(aes(y, fs1)) + geom_point(alpha = 0.2) p3 &lt;- tibble(z, fs1 = fa$scores[, 1]) %&gt;% ggplot(aes(z, fs1)) + geom_point(alpha = 0.2) p4 &lt;- tibble(x, fs2 = fa$scores[, 2]) %&gt;% ggplot(aes(x, fs2)) + geom_point(alpha = 0.2) p5 &lt;- tibble(y, fs2 = fa$scores[, 2]) %&gt;% ggplot(aes(y, fs2)) + geom_point(alpha = 0.2) p6 &lt;- tibble(z, fs2 = fa$scores[, 2]) %&gt;% ggplot(aes(z, fs2)) + geom_point(alpha = 0.2) p7 &lt;- tibble(x, fs3 = fa$scores[, 3]) %&gt;% ggplot(aes(x, fs3)) + geom_point(alpha = 0.2) p8 &lt;- tibble(y, fs3 = fa$scores[, 3]) %&gt;% ggplot(aes(y, fs3)) + geom_point(alpha = 0.2) p9 &lt;- tibble(z, fs3 = fa$scores[, 3]) %&gt;% ggplot(aes(z, fs3)) + geom_point(alpha = 0.2) (p1 | p2 | p3) / (p4 | p5 | p6) / (p7 | p8 | p9) I risultati riportati nella figura confermano le aspettative. Il metodo della regressione pone il problema della stima dei punteggi fattoriali nei termini di una ideale regressione di ogni fattore rispetto a tutte le variabili osservate. Per il fattore \\(j\\)-esimo, si può scrivere la seguente equazione: \\[ \\begin{aligned} F_j =&amp; \\beta_{1j}y_1 + \\dots + \\beta_{pm}y_p + \\varepsilon_j \\end{aligned} \\] dove \\(F_j\\) sono i punteggi fattoriali e \\(y\\) sono le variabili osservate standardizzate \\((Y-\\bar{Y})/s\\). In forma matriciale, il modello diventa \\[ \\textbf{F} = \\textbf{y} \\textbf{B} + \\boldsymbol{\\varepsilon} \\] I coefficienti parziali di regressione B sono ignoti. Tuttavia, possono essere calcolati utilizzando i metodi della regressione lineare. Nel modello di regressione, infatti, i coefficienti dei minimi quadrati possono essere calcolati utilizzando due matrici di correlazioni: la matrice \\(\\textbf{R}_{xx}\\) (le correlazioni tra le variabili \\(X\\)) e la matrice \\(\\textbf{R}_{xy}\\) (le correlazioni tra le variabili \\(X\\) e la variabile \\(Y\\): \\[ \\hat{\\textbf{B}} = \\textbf{R}_{xx}^{-1}\\textbf{R}_{xy} \\] Nel caso dell’analisi fattoriale, \\(\\textbf{R}_{xx}\\) corrisponde alla matrice delle correlazioni tra le variabili osservate e \\(\\textbf{R}_{xy}\\) corrisponde alla matrice di struttura (la matrice delle correlazioni tra le variabili osservate e i fattori). Se i fattori sono ortogonali, la matrice di struttura coincide con la matrice dei pesi fattoriali \\(\\hat{\\boldsymbol{\\Lambda}}\\). I coefficienti B dell’equazione precedente possono dunque essere trovati nel modo seguente: \\[\\begin{equation} \\hat{\\textbf{B}} = \\textbf{R}_{yy}^{-1}\\textbf{R}_{xf}= \\textbf{R}^{-1}\\hat{\\boldsymbol{\\Lambda}} \\end{equation}\\] Una volta stimati i coefficienti \\(\\hat{\\textbf{B}}\\), i punteggi fattoriali si calcolano allo stesso modo dei punteggi teorici del modello di regressione: \\[\\begin{equation} \\hat{\\textbf{F}} = \\textbf{y} \\hat{\\textbf{B}} = \\textbf{y} \\textbf{R}^{-1}\\hat{\\boldsymbol{\\Lambda}}, \\end{equation}\\] dove \\(\\textbf{y}\\) è la matrice delle variabili osservate standardizzate \\((Y-\\bar{Y})/s\\). "],["visualizzare-il-modelli-di-equazioni-strutturali.html", "Capitolo 10 Visualizzare il modelli di equazioni strutturali", " Capitolo 10 Visualizzare il modelli di equazioni strutturali Le visualizzazioni sono strumenti essenziali per comunicare relazioni complesse tra variabili in modo accessibile e succinto. Poiché i modelli di equazioni strutturali (SEM) sono, di natura, multivariati, esprimendo spesso una complessa rete di relazioni direzionali e non direzionali tra variabili manifeste e latenti, i ricercatori utilizzano strumenti grafici per facilitare la specificazione e l’espressione del modello, e per presentare i propri risultati. La path analysis è un metodo per decomporre la correlazione (o la covarianza) in componenti differenti al fine di descrivere le relazioni tra variabili. Lo sviluppo di diagrammi di percorso per descrivere i modelli di equazioni strutturali è attribuito a Wright (1920). La path analysis comprende due parti principali: la rappresentazione grafica delle interrelazioni tra le variabili e la scomposizione delle correlazioni (o covarianze) nei termini dei parametri del modello. "],["path-diagram.html", "10.1 Path diagram", " 10.1 Path diagram Il path diagram fornisce una rappresentazione grafica delle relazioni esistenti tra le variabili oggetto di interesse. In tale diagramma, le variabili non osservate o latenti sono racchiuse in un cerchio o ellisse; le variabili osservate sono racchiuse in un quadrato o rettangolo. Due classi di variabili vengono rappresentate in un path diagram: quelle che non ricevono effetti causali da altre variabili e quelle che li ricevono. Una variabile esogena (cioè esterna) svolge sempre e soltanto funzione di variabile indipendente, ovvero di variabile che causa un effetto. Una variabile endogena (cioè interna) può essere effetto di alcune variabili e contemporaneamente causa per altre, oppure può svolgere solo il ruolo di variabile dipendente. Le fonti causali delle variabili endogene sono interne al path diagram; le fonti causali delle variabili esogene sono esterne al path diagram. La distinzione tra variabili esogene e endogene ha delle ovvie assonanze con la distinzione tra variabili indipendenti e dipendenti propria dei modelli lineari. Le frecce che connettono le variabili nel diagramma denotano nessi causali o mere associazioni. Una freccia orientata rappresenta un nesso causale tra le variabili implicate: la variabile che riceve la freccia dipende dalla variabile da cui parte la freccia. Una freccia curva a due direzioni indica, invece, un’associazione non causale tra due variabili. Il fatto che due variabili non siano collegate nel diagramma equivale ad assumere che tali variabili siano incorrelate. Un esempio è fornito nella Figura 10.1 la quale rende esplicite le relazioni tra tre variabili latenti e nove variabili manifeste. FIGURA 10.1: Esempio di path diagram. "],["path-analysis-e-regressione-multipla.html", "10.2 Path analysis e regressione multipla", " 10.2 Path analysis e regressione multipla Vi è una stretta relazione tra path analysis e regressione multipla, tanto che la regressione può essere considerata un caso particolare di path analysis. Per semplicità, si supponga che le variabili siano state standardizzate, anche se la stessa analisi può essere condotta per variabili grezze. Il path diagram mostra la relazione tra tutte le variabili, comprendendo anche i fattori di disturbo, e fornisce dunque la rappresentazione grafica di un sistema di equazioni simultanee. Nel caso di due regressori, il modello di regressione multipla può essere rappresentato tramite il path diagram riportato nella Figura 10.2. FIGURA 10.2: Path diagram per il modello di regressione multipla con due regressori. I coefficienti di percorso associati alle frecce orientate esprimono la portata del nesso causale e corrispondono ai pesi beta (ovvero ai coefficienti parziali di regressione standardizzati). Le frecce non orientate esprimono la portata della pura associazione tra variabili e dunque corrispondono alle correlazioni. Nel caso di due variabili esogene \\(x_1\\) e \\(x_2\\), il modello di regressione diventa \\[ y = b_{1} x_1 + b_{2} x_2 + 1 \\cdot e, \\] dove \\(y\\) è la variabile endogena ed \\(e\\) è il fattore di disturbo. Tale modello di regressione può essere rappresentato graficamente come indicato nella figura precedente. Nella figura, le frecce dritte indicano un’influenza causale dalla variabile da cui parte la freccia a quella a cui la freccia arriva. A tali frecce dritte sono associati i coefficienti di percorso \\(b_1\\) e \\(b_2\\) (ovvero i pesi beta). Il coefficiente 1 rappresenta l’effetto del fattore di disturbo \\(e\\) sulla variabile endogena \\(y\\), implicito nelle equazioni e reso esplicito nella figura. Si noti che si hanno tante equazioni quante sono le variabili endogene. Nel caso presente, c’è un’unica equazione in quanto vi è una sola variabile endogena (ovvero la \\(y\\), le cui cause sono interne al path diagram). All’interno di ciascuna equazione, inoltre, ci saranno tanti termini quante sono le frecce dritte che puntano verso la variabile endogena. Nell’esempio, ci sono tre termini, uno per ciascun freccia dritta. "],["effetti-diretti-e-indiretti.html", "10.3 Effetti diretti e indiretti", " 10.3 Effetti diretti e indiretti La path analysis fornisce un metodo per distinguere tra i diversi tipi di effetti che influenzano le variabili: l’effetto diretto, l’effetto indiretto e l’effetto totale. Gli effetti diretti sono quelli non mediati da altre variabili. Gli effetti indiretti operano attraverso l’intervento di almeno una variabile. L’effetto totale è la somma di tutti gli effetti diretti e indiretti. Nella Figura 10.3 la variable \\(y_1\\) ha un effetto diretto sulla \\(y_2\\). La variabile \\(y_1\\) ha un effetto indiretto sulla \\(y_3\\) in quanto non c’è una freccia causale che colleghi direttamente la variabile \\(y_1\\) alla \\(y_3\\). La variabile \\(y_1\\) è una variabile esogena e le varibili \\(y_2\\) e \\(y_3\\) sono variabili endogene. FIGURA 10.3: Path diagram per una relazione a catena. Nella Figura 10.3, la variabile \\(x_1\\) ha un effetto diretto sulla \\(y\\), ma anche un effetto indiretto sulla \\(y\\) derivante dalla correlazione tra \\(x_1\\) e \\(x_2\\). In un path diagram, l’effetto diretto è rappresentato da una freccia dritta (es., \\(b_{1}\\)). L’effetto indiretto tra due variabili è rappresentato da un percorso composto che include una o più frecce dritte e non più di una linea curva – per es., \\(s_{12} b_{2}\\). "],["le-regole-di-wright.html", "10.4 Le regole di Wright", " 10.4 Le regole di Wright Lo scopo della path analysis è quello di decomporre la correlazione (o la covarianza) nei termini della somma di tutti i percorsi (diretti e indiretti) che legano le due variabili tramite i coefficienti detti path coefficients. Usando il path diagram, Sewall Wright (1921, 1934) enunciò le regole che, attraverso le cosiddette tracing rules, legano le correlazioni (o covarianze) delle variabili ai parametri del modello. Le tracing rules possono essere espresse nei termini seguenti: è possibile procedere prima all’indietro lungo una freccia e poi in avanti, seguendo la direzione di una freccia, ma non si può andare prima avanti e poi tornare indietro; un percorso composto non deve transitare due volte per la stessa variabile (non devono esserci loop); un percorso non può comprendere più di una linea curva. Si chiama “percorso” il tracciato che unisce due variabili; è costituito da sequenze di frecce direzionali e di curve non direzionali. A ciascun percorso legittimo (ovvero, che soddisfa le regole di Wright) viene assegnato un valore numerico pari al prodotto dei coefficienti incontrati sul percorso medesimo. I coefficienti di percorso possono essere o coefficienti parziali di regressione standardizzati, se il legame ha una direzione, oppure coefficienti di correlazione, se il legame è bidirezionale. 10.4.1 Scomposizione delle correlazioni (covarianze) Il principio di base è stato espresso da Sewall Wright (1934) nel modo seguente: “Any correlation between variables in a network of sequential relations can be analyzed into contributions from all the paths (direct or through common factors) by which the two variables are connected, such that the value of each contribution is the product of the coefficients pertaining to the elementary paths. If residual correlations are present (represented by bidirectional arrows) one (but never more than one) of the coefficients thus multiplied together to give the contribution of the connecting path, may be a correlation coefficient. The others are all path coefficients.” Possiamo così enunciare la regola di scomposizione della correlazione. Definizione 10.1 La correlazione fra due variabili può essere decomposta in tanti addendi quanto sono i percorsi che le collegano; ogni addendo è dato dal prodotto dei coefficienti incontrati sul percorso. Si consideri il diagramma rappresesentato nella Figura 10.2. La variabile endogena è la \\(y\\). Le variabili esogene, correlate tra loro, sono \\(x_1\\) e \\(x_2\\). Il diagramma di percorso corrisponde alla seguente equazione: \\[ y = 0.50 x_1 + 0.40 x_2 + e, \\] dove le variabili \\(x_1\\) e \\(x_2\\) sono incorrelate con \\(e\\). La correlazione tra \\(y\\) e \\(x_1\\) è uguale alla somma dell’effetto diretto che \\(x_1\\) esercita sulla \\(y\\) e dell’effetto indiretto che \\(x_1\\) esercita sulla \\(y\\) tramite la correlazione con \\(x_2\\). In base alle regole di Wright, \\(x_1\\) e \\(y\\) risultano collegate da due percorsi legittimi: il percorso costituito dalla freccia dritta \\(x_1 \\rightarrow y\\); il percorso composto dalla freccia dritta \\(x_2 \\rightarrow y\\) e dalla curva non direzionale \\(x_1 \\leftrightarrow x_2\\). Il valore numerico del primo percorso è \\(0.50\\). Il valore numerico del secondo percorso è \\(0.50\\times 0.40\\). La correlazione tra le variabili \\(x_1\\) e \\(y\\) è dunque uguale alla somma dei valori numerici dei due percorsi legittimi che legano \\(x_1\\) alla \\(y\\): \\[\\begin{equation} \\begin{aligned} r_{x_1,y} &amp;= \\beta_{y,x_1} + r_{x_1,x_2} \\beta_{y,x_2}\\notag\\\\ &amp;= 0.50 + 0.50 \\times 0.40 = 0.70.\\notag \\end{aligned} \\end{equation}\\] La correlazione tra \\(x_2\\) e \\(y\\) è invece uguale a: \\[\\begin{equation} \\begin{aligned} r_{yx_2} &amp;=\\beta_{yx_2} + r_{x_1x_2} \\beta_{yx_1}\\notag\\\\ &amp;= 0.40 + 0.50 \\times 0.50 = 0.65.\\notag \\end{aligned} \\end{equation}\\] 10.4.2 Scomposizione della varianza La varianza di una variabile endogena si decompone in una quota di varianza spiegata dalle variabili agenti causalmente su di essa e in una quota di varianza non spiegata. Definizione 10.2 La varianza spiegata è data dalla somma di tanti addendi quanti sono i percorsi che consentono di collegare la variabile a se stessa rispettando le tracing rules di Wright. Facendo riferimento alla Figura 10.2, si possono individuare quattro percorsi legittimi che collegano \\(y\\) a se stessa: \\(0.50 \\times 1.00 \\times 0.50\\), \\(0.40 \\times 1.00 \\times 0.40\\), \\(0.50 \\times 0.50 \\times 0.40\\), \\(0.40 \\times 0.50 \\times 0.50\\). La varianza della variabile endogena \\(y\\) che viene spiegata dalle variabili esogene \\(x_1\\) e \\(x_2\\) è dunque uguale a \\[ 0.25 + 0.16 + 0.10 + 0.10= 0.61. \\] Inoltre, dato che le variabili rappresentate nel diagramma sono standardizzate, la varianza complessiva della \\(y\\) è uguale a 1.00. La varianza della \\(y\\) non spiegata dalle variabili \\(x_1\\) e \\(x_2\\) è quindi uguale a \\[ 1-0.61 = 0.39. \\] "],["come-calcolare-i-coefficienti-di-percorso.html", "10.5 Come calcolare i coefficienti di percorso?", " 10.5 Come calcolare i coefficienti di percorso? Data una matrice di correlazione, i coefficienti di percorso possono essere calcolati risolvendo un sistema di equazioni simultanee. Si supponga che, per le tre variabili della figura precedente, vi sia la seguente matrice di correlazione: \\(y\\) \\(x_1\\) \\(x_2\\) \\(y\\) 1.00 \\(x_1\\) 0.70 1.00 \\(x_2\\) 0.65 0.50 1.00 Esprimendo le tre correlazioni nei termini dei coefficienti del path diagram otteniamo: \\[\\begin{equation} \\begin{cases} r_{x_1x_2} &amp;= 0.50\\\\ r_{yx_2} &amp;= \\beta_{yx_2} + 0.50 \\beta_{yx_1} = 0.65\\\\ r_{x_1y} &amp;= \\beta_{yx_1} + 0.50 \\beta_{yx_2} = 0.70 \\end{cases} \\end{equation}\\] Risolvendo il sistema di equazioni simultanee, si ottengono i valori dei coefficienti di percorso: \\[\\begin{equation} \\begin{aligned} \\beta_{yx_1} &amp;= 0.50\\notag\\\\ \\beta_{yx_2} &amp;= 0.40\\notag \\end{aligned} \\end{equation}\\] "],["path-analysis-con-lavaan.html", "10.6 Path analysis con lavaan", " 10.6 Path analysis con lavaan Usiamo lavaan per svolgere l’analisi statistica descritta nell’esempio precedente. Esercizio 10.1 La matrice di correlazioni di partenza è: lower &lt;- &quot; 1 .70 1 .65 .50 1 &quot; Converto tali dati in una matrice simmetrica. dat.cov &lt;- getCov(lower, names = c(&quot;y&quot;, &quot;x1&quot;, &quot;x2&quot;)) dat.cov #&gt; y x1 x2 #&gt; y 1.00 0.7 0.65 #&gt; x1 0.70 1.0 0.50 #&gt; x2 0.65 0.5 1.00 Specifico il modello con la sintassi di lavaan. mr_model &lt;- &quot;y ~ x1 + x2&quot; Adatto il modello ai dati. fit &lt;- sem(mr_model, sample.cov = dat.cov, sample.nobs = 100) Esamino i risultati. summary(fit, standardized = TRUE) #&gt; lavaan 0.6.14 ended normally after 1 iteration #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of model parameters 3 #&gt; #&gt; Number of observations 100 #&gt; #&gt; Model Test User Model: #&gt; #&gt; Test statistic 0.000 #&gt; Degrees of freedom 0 #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Standard #&gt; Information Expected #&gt; Information saturated (h1) model Structured #&gt; #&gt; Regressions: #&gt; Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all #&gt; y ~ #&gt; x1 0.500 0.072 6.934 0.000 0.500 0.500 #&gt; x2 0.400 0.072 5.547 0.000 0.400 0.400 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all #&gt; .y 0.386 0.055 7.071 0.000 0.386 0.390 Con la funzione sem() del pacchetto lavaan abbiamo dunque replicato i risultati ottenuti in precedenza. Il valore \\(0.386\\) rappresenta la quota di varianza della \\(y\\) non spiegata dalle variabili esogene. Esercizio 10.2 Ripeto ora la stessa procedura simulando 100 osservazioni su tre variabili, in maniera tale da avere a disposizione i dati grezzi. Imponendo un effetto causale diretto delle variabili \\(x_1\\) e \\(x_2\\) sulla \\(y\\) e una correlazione \\(&gt; 0\\) tra le variabili \\(x_1\\) e \\(x_2\\), otteniamo i dati seguenti. set.seed(3) n &lt;- 100 x1 &lt;- rnorm(n, 100, 9) x2 &lt;- x1 + rnorm(n, 0, 10) cor(x1, x2) #&gt; [1] 0.5346271 y &lt;- 10 + 3 * x1 + 1.5 * x2 + rnorm(n, 0, 15) dd &lt;- data.frame(y, x1, x2) print(cor(dd), 3) #&gt; y x1 x2 #&gt; y 1.000 0.831 0.786 #&gt; x1 0.831 1.000 0.535 #&gt; x2 0.786 0.535 1.000 Per fare un esempio, immaginiamo che queste correlazioni siano state ricavate da qualche fonte e dunque le leggiamo nella memoria di lavoro di \\(\\mathsf{R}\\) nel modo seguente. lower &lt;- &quot; 1 .831 1 .786 .535 1 &quot; dat.cov &lt;- getCov(lower, names = c(&quot;y&quot;, &quot;x1&quot;, &quot;x2&quot;)) dat.cov #&gt; y x1 x2 #&gt; y 1.000 0.831 0.786 #&gt; x1 0.831 1.000 0.535 #&gt; x2 0.786 0.535 1.000 Data una matrice di correlazioni e data la specificazione delle relazioni tra le variabili, la funzione sem() contenuta nel pacchetto lavaan consente di stimare i coefficienti di percorso. mr.model &lt;- &quot;y ~ x1 + x2&quot; fit &lt;- sem(mr.model, sample.cov = dat.cov, sample.nobs = 100) Esaminiamo i risultati con la funzione summary(). summary(fit, standardized = TRUE) #&gt; lavaan 0.6.14 ended normally after 1 iteration #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of model parameters 3 #&gt; #&gt; Number of observations 100 #&gt; #&gt; Model Test User Model: #&gt; #&gt; Test statistic 0.000 #&gt; Degrees of freedom 0 #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Standard #&gt; Information Expected #&gt; Information saturated (h1) model Structured #&gt; #&gt; Regressions: #&gt; Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all #&gt; y ~ #&gt; x1 0.575 0.045 12.710 0.000 0.575 0.575 #&gt; x2 0.478 0.045 10.571 0.000 0.478 0.478 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all #&gt; .y 0.145 0.020 7.071 0.000 0.145 0.146 Ora calcoliamo i coefficienti del modello di regressione multipla usando i dati grezzi (standardizzati). Si noti che i risultati ottenuti da lavaan sono identici a quelli prodotti dal modello di regressione multipla – nel caso presente, infatti, il modello statistico esaminato da sem() non era altro che il modello di regressione multipla. summary(lm(scale(y) ~ scale(x1) + scale(x2))) #&gt; #&gt; Call: #&gt; lm(formula = scale(y) ~ scale(x1) + scale(x2)) #&gt; #&gt; Residuals: #&gt; Min 1Q Median 3Q Max #&gt; -0.87200 -0.24623 0.01628 0.25714 0.90382 #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error t value Pr(&gt;|t|) #&gt; (Intercept) -7.472e-16 3.867e-02 0.0 1 #&gt; scale(x1) 5.748e-01 4.599e-02 12.5 &lt;2e-16 *** #&gt; scale(x2) 4.785e-01 4.599e-02 10.4 &lt;2e-16 *** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; #&gt; Residual standard error: 0.3867 on 97 degrees of freedom #&gt; Multiple R-squared: 0.8535, Adjusted R-squared: 0.8505 #&gt; F-statistic: 282.6 on 2 and 97 DF, p-value: &lt; 2.2e-16 La quota di varianza non spiegata della variabile endogena è: 1 - .145 #&gt; [1] 0.855 "],["oltre-la-regressione-multipla.html", "10.7 Oltre la regressione multipla", " 10.7 Oltre la regressione multipla In generale, lo psicologo ha a che fare con diagrammi di percorso nei quali sono presenti variabili non osservabili (latenti) e quindi l’approccio della regressione multipla non può essere applicato. È necessario invece descrivere il diagramma di percorso mediante un insieme di equazioni strutturali, definendo un numero di equazioni almeno altrettanto grande quanto il numero delle incognite. Tale soluzione viene solitamente fornita da un software. Consideriamo di seguito alcuni esempi in cui vengono applicate le regole di Wright per diagrammi di percorso che non possono essere descritti nei termini di un modello di regressione multipla. Un esempio di path diagram che non si riduce al modello di regressione multipla è quello fornito nella Figura 10.1. La path analysis è anche usata in quel campo della psicologia interessato alla misurazione dei costrutti psicologici quali i tratti della personalità, le capacità cognitive e i disturbi psicopatologici. Questa è la ragione per cui la discutiamo qui. Esercizio 10.3 Weiss, Forkus, Contractor, e Schick (2018) esaminano con una path analisi la relazione tra la difficiltà di regolare le emozioni positive e l’abuso di alcol e di sostanze. La difficoltà di regolare le emozioni positive viene misurata con la Difficulties in Emotion Regulation Scale – Positive (DERS-P; Weiss, Gratz, &amp; Lavender, 2015), che comprende le sottoscale di Acceptance, Impulse, e Goals. L’abuso di sostanze viene misurato con la Drug Abuse Screening Test (DAST; Skinner, 1982). L’abuso di alcol viene misurato con la Alcohol Use Disorder Identification Test (AUDIT; Saunders, Aasland, Babor, De la Fuente, &amp; Grant, 1993), con le sottoscale di Hazardous Consumption, Dependence, e Consequences. I dati di un campione di 284 partecipanti sono riportati nella forma di una matrice di correlazione. lower &lt;- &quot; 1 .38 1 .41 .64 1 .34 .44 .30 1 .29 .12 .27 .06 1 .29 .22 .20 .17 .54 1 .30 .15 .23 .09 .73 .69 1 &quot; dat_cov &lt;- lavaan::getCov( lower, names = c(&quot;dmis&quot;, &quot;con&quot;, &quot;dep&quot;, &quot;consu&quot;, &quot;acc&quot;, &quot;goal&quot;, &quot;imp&quot;) ) dat_cov #&gt; dmis con dep consu acc goal imp #&gt; dmis 1.00 0.38 0.41 0.34 0.29 0.29 0.30 #&gt; con 0.38 1.00 0.64 0.44 0.12 0.22 0.15 #&gt; dep 0.41 0.64 1.00 0.30 0.27 0.20 0.23 #&gt; consu 0.34 0.44 0.30 1.00 0.06 0.17 0.09 #&gt; acc 0.29 0.12 0.27 0.06 1.00 0.54 0.73 #&gt; goal 0.29 0.22 0.20 0.17 0.54 1.00 0.69 #&gt; imp 0.30 0.15 0.23 0.09 0.73 0.69 1.00 I dati vengono analizzati con due modelli di path analysis. Nel primo modello si ipotizza che la difficoltà di regolare le emozioni positive sia una variabile esogena che influenza sia l’abuso di sostanze sia l’abuso di alcol. Si ipotizza inoltre che abuso di sostanze e abuso di alcol siano correlate. La difficoltà di regolare le emozioni positive è indicata da drpe; l’abuso di alcolo è denotato da amis; l’abuso di sostanze è denotato da dmis. mod &lt;- &quot; drpe =~ NA*acc + goal + imp amis =~ NA*con + dep + consu amis ~ drpe dmis ~ drpe dmis ~~ amis drpe ~~ 1*drpe amis ~~ 1*amis &quot; Svolgiamo l’analisi statistica con sem(). fit &lt;- lavaan::sem(mod, sample.cov = dat_cov, sample.nobs = 284) Esaminiamo i risultati. summary(fit, fit.measures = TRUE, standardized = TRUE, rsquare = TRUE) #&gt; lavaan 0.6.14 ended normally after 18 iterations #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of model parameters 16 #&gt; #&gt; Number of observations 284 #&gt; #&gt; Model Test User Model: #&gt; #&gt; Test statistic 38.211 #&gt; Degrees of freedom 12 #&gt; P-value (Chi-square) 0.000 #&gt; #&gt; Model Test Baseline Model: #&gt; #&gt; Test statistic 741.324 #&gt; Degrees of freedom 21 #&gt; P-value 0.000 #&gt; #&gt; User Model versus Baseline Model: #&gt; #&gt; Comparative Fit Index (CFI) 0.964 #&gt; Tucker-Lewis Index (TLI) 0.936 #&gt; #&gt; Loglikelihood and Information Criteria: #&gt; #&gt; Loglikelihood user model (H0) -2465.787 #&gt; Loglikelihood unrestricted model (H1) -2446.682 #&gt; #&gt; Akaike (AIC) 4963.574 #&gt; Bayesian (BIC) 5021.958 #&gt; Sample-size adjusted Bayesian (SABIC) 4971.221 #&gt; #&gt; Root Mean Square Error of Approximation: #&gt; #&gt; RMSEA 0.088 #&gt; 90 Percent confidence interval - lower 0.057 #&gt; 90 Percent confidence interval - upper 0.120 #&gt; P-value H_0: RMSEA &lt;= 0.050 0.023 #&gt; P-value H_0: RMSEA &gt;= 0.080 0.688 #&gt; #&gt; Standardized Root Mean Square Residual: #&gt; #&gt; SRMR 0.046 #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Standard #&gt; Information Expected #&gt; Information saturated (h1) model Structured #&gt; #&gt; Latent Variables: #&gt; Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all #&gt; drpe =~ #&gt; acc 0.769 0.053 14.440 0.000 0.769 0.770 #&gt; goal 0.727 0.054 13.473 0.000 0.727 0.728 #&gt; imp 0.943 0.050 18.956 0.000 0.943 0.945 #&gt; amis =~ #&gt; con 0.808 0.058 13.855 0.000 0.835 0.837 #&gt; dep 0.730 0.058 12.607 0.000 0.755 0.756 #&gt; consu 0.477 0.060 7.973 0.000 0.493 0.494 #&gt; #&gt; Regressions: #&gt; Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all #&gt; amis ~ #&gt; drpe 0.263 0.073 3.614 0.000 0.254 0.254 #&gt; dmis ~ #&gt; drpe 0.333 0.060 5.534 0.000 0.333 0.334 #&gt; #&gt; Covariances: #&gt; Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all #&gt; .amis ~~ #&gt; .dmis 0.431 0.060 7.216 0.000 0.431 0.458 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all #&gt; drpe 1.000 1.000 1.000 #&gt; .amis 1.000 0.936 0.936 #&gt; .acc 0.406 0.045 9.020 0.000 0.406 0.407 #&gt; .goal 0.468 0.047 9.876 0.000 0.468 0.470 #&gt; .imp 0.106 0.045 2.385 0.017 0.106 0.107 #&gt; .con 0.299 0.064 4.690 0.000 0.299 0.300 #&gt; .dep 0.427 0.060 7.072 0.000 0.427 0.428 #&gt; .consu 0.753 0.069 10.979 0.000 0.753 0.756 #&gt; .dmis 0.886 0.075 11.771 0.000 0.886 0.889 #&gt; #&gt; R-Square: #&gt; Estimate #&gt; amis 0.064 #&gt; acc 0.593 #&gt; goal 0.530 #&gt; imp 0.893 #&gt; con 0.700 #&gt; dep 0.572 #&gt; consu 0.244 #&gt; dmis 0.111 Creiamo un path diagram. semPaths( fit, &quot;std&quot;, posCol = c(&quot;black&quot;), edge.label.cex = 1.2, sizeMan = 7 ) Gli autori esplorano un modello alternativo nel quale le relazioni causali vengono rovesciate: in questo caso è la difficoltà di regolazione delle emozioni positive ad essere la variabile esogena, e l’abuso di sostanze e l’abuso di alcol sono le variabili esogene. mod_alt &lt;- &quot; drpe =~ NA*acc + goal + imp amis =~ NA*con + dep + consu drpe ~ amis + dmis dmis ~~ amis drpe ~~ 1*drpe amis ~~ 1*amis &quot; Adattiamo il modello ai dati. fit_alt &lt;- sem(mod_alt, sample.cov = dat_cov, sample.nobs = 311) Esaminiamo i risultati. summary(fit_alt, fit.measures = TRUE, standardized = TRUE, rsquare = TRUE) #&gt; lavaan 0.6.14 ended normally after 19 iterations #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of model parameters 16 #&gt; #&gt; Number of observations 311 #&gt; #&gt; Model Test User Model: #&gt; #&gt; Test statistic 41.844 #&gt; Degrees of freedom 12 #&gt; P-value (Chi-square) 0.000 #&gt; #&gt; Model Test Baseline Model: #&gt; #&gt; Test statistic 811.802 #&gt; Degrees of freedom 21 #&gt; P-value 0.000 #&gt; #&gt; User Model versus Baseline Model: #&gt; #&gt; Comparative Fit Index (CFI) 0.962 #&gt; Tucker-Lewis Index (TLI) 0.934 #&gt; #&gt; Loglikelihood and Information Criteria: #&gt; #&gt; Loglikelihood user model (H0) -2700.544 #&gt; Loglikelihood unrestricted model (H1) -2679.623 #&gt; #&gt; Akaike (AIC) 5433.089 #&gt; Bayesian (BIC) 5492.925 #&gt; Sample-size adjusted Bayesian (SABIC) 5442.179 #&gt; #&gt; Root Mean Square Error of Approximation: #&gt; #&gt; RMSEA 0.089 #&gt; 90 Percent confidence interval - lower 0.061 #&gt; 90 Percent confidence interval - upper 0.120 #&gt; P-value H_0: RMSEA &lt;= 0.050 0.014 #&gt; P-value H_0: RMSEA &gt;= 0.080 0.727 #&gt; #&gt; Standardized Root Mean Square Residual: #&gt; #&gt; SRMR 0.046 #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Standard #&gt; Information Expected #&gt; Information saturated (h1) model Structured #&gt; #&gt; Latent Variables: #&gt; Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all #&gt; drpe =~ #&gt; acc 0.721 0.048 15.117 0.000 0.769 0.770 #&gt; goal 0.682 0.048 14.097 0.000 0.727 0.728 #&gt; imp 0.885 0.046 19.287 0.000 0.944 0.945 #&gt; amis =~ #&gt; con 0.835 0.057 14.742 0.000 0.835 0.837 #&gt; dep 0.755 0.057 13.273 0.000 0.755 0.756 #&gt; consu 0.494 0.059 8.366 0.000 0.494 0.494 #&gt; #&gt; Regressions: #&gt; Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all #&gt; drpe ~ #&gt; amis 0.123 0.080 1.532 0.125 0.115 0.115 #&gt; dmis 0.294 0.073 4.030 0.000 0.276 0.276 #&gt; #&gt; Covariances: #&gt; Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all #&gt; amis ~~ #&gt; dmis 0.502 0.059 8.521 0.000 0.502 0.503 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all #&gt; .drpe 1.000 0.879 0.879 #&gt; amis 1.000 1.000 1.000 #&gt; .acc 0.406 0.043 9.439 0.000 0.406 0.407 #&gt; .goal 0.468 0.045 10.335 0.000 0.468 0.470 #&gt; .imp 0.106 0.043 2.496 0.013 0.106 0.107 #&gt; .con 0.299 0.061 4.908 0.000 0.299 0.300 #&gt; .dep 0.427 0.058 7.401 0.000 0.427 0.428 #&gt; .consu 0.753 0.066 11.489 0.000 0.753 0.756 #&gt; dmis 0.997 0.080 12.470 0.000 0.997 1.000 #&gt; #&gt; R-Square: #&gt; Estimate #&gt; drpe 0.121 #&gt; acc 0.593 #&gt; goal 0.530 #&gt; imp 0.893 #&gt; con 0.700 #&gt; dep 0.572 #&gt; consu 0.244 Creiamo il diagramma di percorso. semPaths( fit_alt, &quot;std&quot;, posCol = c(&quot;black&quot;), edge.label.cex = 1.2, sizeMan = 7 ) In entrambi i casi i risultati replicano quanto riportato dagli autori. "],["attendibilità-e-modello-fattoriale.html", "Capitolo 11 Attendibilità e modello fattoriale", " Capitolo 11 Attendibilità e modello fattoriale McDonald (2013) mostra come la teoria classica dei test possa essere messa in relazione con il modello dell’analisi fattoriale. La figura 11.1 descrive nei termini del modello fattoriale la relazione che intercorre tra i punteggi \\(Y\\) ottenuti dalla somministrazione di un test con cinque item e i punteggi veri. FIGURA 11.1: Modello fattoriale che mette in relazione i punteggi osservati e i punteggi veri. Il metodo delle forme parallele proposto dalla teoria classica dei test fornisce una risposta solo in parte soddisfacente al problema della stima del coefficiente di attendibilità. Ricordiamo che il metodo delle forme parallele consiste nel somministrare due questionari \\(X\\) e \\(X^\\prime\\), espressione dello stesso costrutto, nella stessa occasione allo stesso campione di soggetti. In tali circostanze \\(\\rho^2_{XT} = \\rho_{XX^\\prime}\\). Affinché la relazione definita dall’equazione precedente sia vera, le due forme del test devono essere parallele, nel senso descritto della teoria classica dei test. In pratica, però, è impossibile somministrare lo stesso test due volte agli stessi rispondenti nelle medesime condizioni. È dunque necessario basare la stima del coefficiente di attendibilità sui dati acquisiti mediante un’unica somministrazione del test. Vi sono vari metodi per la stima dell’attendibilità nel caso di un’unica somministrazione di un test. Considereremo qui tre metodi che possono essere applicati mediante l’utilizzo dell’analisi fattoriale: l’\\(\\alpha\\) di Cronbach, l’\\(\\omega\\) di McDonald e il metodo di Spearman-Brown. Il coefficiente \\(\\alpha\\) è la misura più utilizzata per la stima dell’attendibilità quale coerenza interna, o omogeneità. Vedremo come tale indice costituisca il limite inferiore dell’attendibilità di un test, se alcune assunzioni sono soddisfatte, mentre risulta uno stimatore distorto dell’attendibilità se le assunzioni che descriveremo risultano violate. Per discutere i diversi metodi di stima dell’attendibilità quale coerenza interna è prima necessario distinguere tra tre diverse forme che il modello mono-fattoriale può assumere. Queste tre forme sono quelle del modello con indicatori congenerici, \\(\\tau\\)-equivalenti e paralleli. "],["modello-fattoriale-e-ctt.html", "11.1 Modello fattoriale e CTT", " 11.1 Modello fattoriale e CTT Sia \\(X_1, X_2, \\dots, X_p\\), con \\(p&gt;2\\), un insieme di item osservati. I punteggi ottenuti su tali item sono costituiti da una componente di punteggio vero e da una componente d’errore: \\[\\begin{equation} \\begin{aligned} X_1 &amp;=T_1+E_1,\\notag\\\\ X_2 &amp;=T_2+E_2,\\notag\\\\ &amp;\\dots\\notag\\\\ X_p &amp;=T_p+E_p.\\notag \\end{aligned} \\end{equation}\\] Seguendo McDonald (1999), tale scomposizione in una componente vera e in una componente d’errore può essere espressa nei termini dei parametri del modello fattoriale. L’espressione \\(X_i = T_i + E_i\\) può infatti essere riscritta come \\[ X_i = \\lambda_i \\xi + \\delta_i, \\quad{i=1, \\dots, p}, \\] dove \\(X_i\\) denota il punteggio osservato per l’item \\(i\\)-esimo, \\(\\lambda_i\\) è il peso fattoriale \\(i\\)-esimo, \\(\\xi\\) è il fattore comune e \\(\\delta_i\\) è la componente erratica del punteggio osservato \\(i\\)-esimo. Valgono le assunzioni del modello monofattoriale. Ovvero, si assume che \\(\\xi\\) e \\(\\delta_i\\) siano incorrelati per ciascun item \\(i\\)-esimo e che \\(\\delta_i\\) e \\(\\delta_k\\) siano incorrelati per ciascuna coppia \\(i \\neq k\\). "],["classi-di-modelli.html", "11.2 Classi di modelli", " 11.2 Classi di modelli Si possono distinguere tre importanti casi del modello mono-fattoriale: il modello con indicatori congenerici, il modello con indicatori \\(\\tau\\)-equivalenti, il modello con indicatori paralleli. Il modello con indicatori congenerici rappresenta il caso più generale, mentre gli indicatori \\(\\tau\\)-equivalenti e paralleli sono casi particolari, ovvero impongono restrizioni al modello con indicatori congenerici. 11.2.1 Indicatori congenerici Indicatori congenerici misurano lo stesso costrutto, ma non necessariamente nella stessa misura. Nel caso di indicatori congenerici, nel modello mono-fattoriale non viene imposto alcun vincolo né sulle saturazioni fattoriali né sulle specificità: \\[ \\lambda_1\\neq \\lambda_2 \\neq \\dots\\neq \\lambda_p, \\] \\[ \\psi_{11}\\neq \\psi_{22} \\neq \\dots\\neq \\psi_{pp}. \\] Il modello mono-fattoriale con indicatori congenerici è dunque \\[\\begin{equation} X_i = \\lambda_i \\xi + \\delta_i. \\tag{11.1} \\end{equation}\\] Dalle assunzioni precedenti possiamo derivare la matrice \\(\\boldsymbol{\\Sigma}\\) riprodotta in base al modello congenerico la quale risulta essere uguale a \\[ \\boldsymbol{\\Sigma}=\\left[ \\begin{array}{ c c c c } \\sigma_{11} &amp; \\sigma_{12} &amp; \\dots &amp; \\sigma_{1p}, \\\\ \\sigma_{21} &amp; \\sigma_{22} &amp; \\dots &amp; \\sigma_{2p}. \\\\ \\vdots &amp; \\vdots &amp; &amp; \\vdots\\\\ \\sigma_{p1} &amp; \\sigma_{p2} &amp; \\dots &amp; \\sigma_{pp} \\end{array} \\right]. \\] Si noti come tutte le varianze e tutte le covarianze siano tra loro diverse. 11.2.2 Indicatori tau-equivalenti Nel caso di indicatori \\(\\tau\\)-equivalenti, si ha che \\[ \\lambda_1=\\lambda_2=\\dots=\\lambda_p=\\lambda, \\] \\[ \\psi_{11}\\neq \\psi_{22} \\neq \\dots\\neq \\psi_{pp}. \\] Il modello monofattoriale con indicatori \\(\\tau\\)-equivalenti diventa dunque \\[\\begin{equation} X_i = \\lambda \\xi + \\delta_i, \\tag{11.1} \\end{equation}\\] ovvero \\[\\begin{equation} X_i = \\tau + \\delta_i, \\tag{11.2} \\end{equation}\\] dove \\(\\tau=\\lambda \\xi\\) è l’attributo comune scalato nell’unità di misura dell’indicatore. Secondo il modello (11.1), tutte le \\(p(p-1)\\) covarianze tra gli item del test devono essere uguali, ovvero \\[\\begin{equation} \\sigma_{ik} = \\lambda^2=\\sigma^2_T, \\tag{11.3} \\end{equation}\\] per \\(i\\neq k\\). Gli elementi sulla diagonale principale della matrice di varianze e covarianze saranno invece \\[\\begin{equation} \\sigma_{ii} = \\lambda^2 + \\psi_{ii} =\\sigma^2_T + \\psi_{ii}. \\tag{11.4} \\end{equation}\\] La matrice \\(\\boldsymbol{\\Sigma}\\) riprodotta in base al modello \\(\\tau\\)-equivalente è dunque uguale a \\[\\begin{equation} \\boldsymbol{\\Sigma}=\\left[ \\begin{array}{ c c c c } \\sigma_{T}^2 + \\psi_{11} &amp; \\sigma_{T}^2 &amp; \\dots &amp; \\sigma_{T}^2 \\\\ \\sigma_{T}^2 &amp; \\sigma_{T}^2 + \\psi_{22} &amp; \\dots &amp; \\sigma_{T}^2 \\\\ \\vdots &amp; \\vdots &amp; &amp; \\vdots\\\\ \\sigma_{T}^2 &amp; \\sigma_{T}^2 &amp; \\dots &amp; \\sigma_{T}^2 + \\psi_{pp} \\end{array} \\right]. \\tag{11.5} \\end{equation}\\] Tutte le covarianze sono uguali, mentre le varianze sono tra loro diverse. 11.2.3 Indicatori paralleli Nel caso di indicatori paralleli si ha che \\[ \\lambda_1=\\lambda_2=\\dots=\\lambda_p=\\lambda, \\] \\[ \\psi_{11}=\\psi_{22}=\\dots=\\psi_{pp}=\\psi. \\] Il modello costituito da indicatori paralleli impone dunque un’ulteriore restrizione che riguarda le varianze degli item, ovvero: \\[ \\sigma_{ii} = \\lambda^2 + \\psi =\\sigma^2_T + \\sigma^2. \\] La struttura di varianze e covarianze imposta dal modello per indicatori paralleli è dunque tale da richiedere l’uguaglianza tra tutte le covarianze tra gli item e l’uguaglianza tra tutte le varianze degli item. La matrice \\(\\boldsymbol{\\Sigma}\\) riprodotta in base al modello con indicatori paralleli è dunque uguale a \\[ \\boldsymbol{\\Sigma}=\\left[ \\begin{array}{ c c c c } \\sigma_{T}^2 + \\sigma^2 &amp; \\sigma_{T}^2 &amp; \\dots &amp; \\sigma_{T}^2 \\\\ \\sigma_{T}^2 &amp; \\sigma_{T}^2 + \\sigma^2 &amp; \\dots &amp; \\sigma_{T}^2 \\\\ \\vdots &amp; \\vdots &amp; &amp; \\vdots\\\\ \\sigma_{T}^2 &amp; \\sigma_{T}^2 &amp; \\dots &amp; \\sigma_{T}^2 +\\sigma^2 \\notag \\end{array} \\right]. \\] 11.2.4 Indicatori strettamente paralleli L’aggiunta di un ulteriore vincolo a quelli definiti dal modello costituito da indicatori paralleli, ovvero quello dell’eguaglianza delle medie, definisce gli indicatori detti strettamente paralleli (McDonald, 1999). "],["metodo-dei-minimi-quadrati-non-pesati.html", "11.3 Metodo dei minimi quadrati non pesati", " 11.3 Metodo dei minimi quadrati non pesati Nel modello uni-fattoriale, la varianza di ciascun indicatore viene scomposta nella somma di due componenti: la componente \\(\\sigma^2_T\\) dovuta all’effetto del fattore latente comune e la componente \\(\\psi\\) dovuta all’effetto del fattore specifico. McDonald (2013) illustra come sia possibile stimare tali componenti dai dati osservati. Tali stime vengono poi utilizzate per calcolare la coerenza interna del test tramite le formule degli indici \\(\\alpha\\) di Cronbach e \\(\\omega\\) di McDonald. In precedenza abbiamo visto come la varianza del punteggio vero sia uguale alla covarianza tra due forme parallele dello stesso test: \\(\\sigma^2_T = \\sigma_{XX^\\prime}\\). Se gli indicatori sono \\(\\tau\\)-equivalenti, la matrice la matrice \\(\\boldsymbol{\\Sigma}\\) riprodotta dal modello è uguale a \\[ \\boldsymbol{\\Sigma}=\\left[ \\begin{array}{ c c c c } \\sigma_{T}^2 + \\psi_{11} &amp; \\sigma_{T}^2 &amp; \\dots &amp; \\sigma_{T}^2 \\\\ \\sigma_{T}^2 &amp; \\sigma_{T}^2 + \\psi_{22} &amp; \\dots &amp; \\sigma_{T}^2 \\\\ \\vdots &amp; \\vdots &amp; &amp; \\vdots\\\\ \\sigma_{T}^2 &amp; \\sigma_{T}^2 &amp; \\dots &amp; \\sigma_{T}^2 + \\psi_{pp} \\notag \\end{array} \\right], \\] ovvero, tutte le covarianze sono tra loro uguali. Nel caso di indicatori \\(\\tau\\)-equivalenti, dunque, una stima \\(\\hat{\\sigma}^2_T\\) di \\(\\sigma^2_T\\) è data dalla media delle covarianze della matrice S: \\[\\begin{equation} \\hat{\\sigma}_T^2 = \\frac{1}{p(p-1)} \\sideset{}{} {\\sum \\sum}_{i \\neq k} s_{ik}. \\tag{11.6} \\end{equation}\\] Tale medoto di stima di \\(\\sigma^2_T\\) viene chiamato “metodo dei minimi quadrati non pesati” (McDonald, 2013). Inoltre, nel caso di indicatori \\(\\tau\\)-equivalenti, la stima di \\(\\psi_{ii}\\) nella (11.4) è data da \\[ \\hat{\\psi}_{ii }= s_{ii} - \\hat{\\sigma}_T^2, \\] per ciascun item. Nel caso di indicatori paralleli, la stima di \\(\\sigma^2_T\\) è ancora data dalla (11.6), ovvero dalla media delle covarianze della matrice \\(\\boldsymbol{\\Sigma}\\). La stima del valore costante \\(\\psi\\) è invece data da \\[\\begin{equation} \\hat{\\psi} = \\frac{1}{p} \\sum_i (s_{ii} - \\hat{\\sigma}_T^2) \\tag{11.7} \\end{equation}\\] "],["varianza-del-punteggio-totale-di-un-test.html", "11.4 Varianza del punteggio totale di un test", " 11.4 Varianza del punteggio totale di un test Il punteggio totale \\(Y\\) di un test omogeneo è uguale alla somma dei punteggi \\(X_i\\) sui \\(p\\) item di cui è composto il test: \\(Y = \\sum_{i=1}^p X_i.\\) Poniamoci ora il problema di descrivere la varianza del punteggio totale del test nei termini dei parametri del modello uni-fattoriale. Nel caso di un modello congenerico ad un fattore comune, la varianza del punteggio totale \\(Y\\) del test può essere scomposta in due componenti: il quadrato della somma delle saturazioni fattoriali, corrispondentente alla varianza attribuibile al punteggio vero (ovvero la quota di varianza derivante dall’attributo di cui gli item sono indicatori) e la somma delle varianze specifiche dei \\(p\\) indicatori, corrispondente alla varianza degli errori della misura del punteggio totale del test, ovvero \\[\\begin{equation} \\mathbb{V}(Y) = \\left( \\sum_i \\lambda_i\\right)^2 + \\sum_i \\psi_{ii} \\tag{11.8} \\end{equation}\\] Dimostrazione. Per un modello congenerico, la varianza del punteggio totale \\(Y\\) è uguale a: \\[\\begin{equation} \\begin{aligned} \\mathbb{V}(Y) &amp;= \\mathbb{V}\\left[ \\sum_i \\left(\\lambda_i \\xi + \\delta_i\\right) \\right]\\notag\\\\ &amp;= \\mathbb{V}\\left[ (\\lambda_1 \\xi + \\delta_1) + (\\lambda_2 \\xi + \\delta_2) + \\dots + (\\lambda_p \\xi + \\delta_p) \\right]\\notag\\\\ &amp;= \\mathbb{V}\\left[ \\left( \\sum_i \\lambda_i\\right) \\xi + \\sum_i \\delta_i\\right]\\notag\\\\ &amp;= \\left(\\sum_i \\lambda_i\\right)^2 \\underbrace{\\mathbb{V}(\\xi)}_{=1} + \\sum_i \\mathbb{V}(\\delta_i)\\notag\\\\ &amp;= \\left(\\sum_i \\lambda_i\\right)^2 + \\sum_i \\psi_{ii}.\\notag \\end{aligned} \\end{equation}\\] "],["stima-dellattendibilità.html", "11.5 Stima dell’attendibilità", " 11.5 Stima dell’attendibilità 11.5.1 Coefficiente omega Avendo scomposto la varianza del punteggio totale di un test come indicato nella (11.8) \\[ \\mathbb{V}(Y) = \\left( \\sum_i \\lambda_i\\right)^2 + \\sum_i \\psi_{ii}. \\] McDonald (1999) definisce il coefficiente di attendibilità \\(\\omega\\) come il rapporto tra la varianza “vera” (attribuibile all’attributo comune) e la varianza totale. Nei termini dei parametri del modello uni-fattoriale, il coefficiente \\(\\omega\\) diventa: \\[\\begin{equation} \\begin{aligned} \\omega &amp;= \\frac{\\left( \\sum_{i=1}^p \\lambda_i \\right)^2}{\\sigma_Y^2} \\notag\\\\ &amp;= \\frac{\\left( \\sum_{i=1}^p \\lambda_i \\right)^2}{\\left( \\sum_{i=1}^p \\lambda_i \\right)^2 + \\sum_{i=1}^p \\psi_{ii}} \\end{aligned} \\tag{11.9} \\end{equation}\\] Il coefficiente \\(\\omega\\) consente dunque di stimare il coefficiente di attendibilità nei termini dei parametri del modello fattoriale congenerico, utilizzando i dati ottenuti in un’unica somministrazione del test. 11.5.1.1 Un esempio concreto Per illustrare la procedura per il calcolo del coefficiente \\(\\omega\\), McDonald (1999) utilizza i dati derivanti dalla somministrazione del test Satisfaction With Life Scale (SWLS) a 215 rispondenti. Tale test è costituito da 14 item ma, per semplificare la discussione, McDonald ne utilizza solo 5. SWLS &lt;- matrix( c( 2.565, 1.424, 1.481, 1.328, 1.529, 1.424, 2.493, 1.267, 1.051, 1.308, 1.481, 1.267, 2.462, 1.093, 1.360, 1.328, 1.051, 1.093, 2.769, 1.128, 1.529, 1.308, 1.360, 1.128, 3.355 ), ncol = 5, byrow = TRUE ) SWLS #&gt; [,1] [,2] [,3] [,4] [,5] #&gt; [1,] 2.565 1.424 1.481 1.328 1.529 #&gt; [2,] 1.424 2.493 1.267 1.051 1.308 #&gt; [3,] 1.481 1.267 2.462 1.093 1.360 #&gt; [4,] 1.328 1.051 1.093 2.769 1.128 #&gt; [5,] 1.529 1.308 1.360 1.128 3.355 Eseguiamo l’analisi fattoriale con il metodo della massima verosimiglianza: fa &lt;- factanal(covmat = SWLS, factors = 1, n.obs = 215) Le saturazioni fattoriali sono: fa$load #&gt; #&gt; Loadings: #&gt; Factor1 #&gt; [1,] 0.817 #&gt; [2,] 0.694 #&gt; [3,] 0.726 #&gt; [4,] 0.591 #&gt; [5,] 0.643 #&gt; #&gt; Factor1 #&gt; SS loadings 2.438 #&gt; Proportion Var 0.488 Le specificità sono uguali a fa$uniq #&gt; [1] 0.3330087 0.5181701 0.4732399 0.6512151 0.5866640 Il coefficiente \\(\\omega\\) \\[ \\omega = \\frac{\\left( \\sum_{i=1}^p \\lambda_i \\right)^2}{\\left( \\sum_{i=1}^p \\lambda_i \\right)^2 + \\sum_{i=1}^p \\psi_{ii}} \\] può essere calcolato nel modo seguente: (sum(fa$load))^2 / (sum((fa$load))^2 + sum(fa$uniq)) #&gt; [1] 0.8245477 Nel caso presente, il coefficiente di attendibilità \\(\\omega=0.82\\) ci dice che l’\\(82\\)% della varianza del punteggio totale \\(Y\\) del test viene spiegato dal fattore comune latente. 11.5.1.2 Coefficiente \\(\\omega\\) e assunzioni della teoria classica dei test Il calcolo di \\(\\omega\\) è basato sull’assunzione (tipica della teoria classica dei test) che \\(\\psi_{ik}=0\\) per \\(i\\neq k\\). Tale assunzione però potrebbe non essere soddisfatta nel caso di dati empirici. In tal caso, come indicato da Bollen (1980), la (11.9) diventa \\[\\begin{equation} \\omega = \\frac{\\left( \\sum_{i=1}^p \\lambda_i \\right)^2}{\\left( \\sum_{i=1}^p \\lambda_i \\right)^2 + \\sum_{i=1}^p \\psi_{ii} + \\sum_{i, k, i\\neq k}^p \\psi_{ik}}. \\tag{11.10} \\end{equation}\\] L’appropriatezza dell’assunzione dell’incorrelazione dei fattori specifici può essere verificata mediante un’analisi fattoriale confermativa. Se vi sono molte coppie di fattori specifici correlati, allora può essere necessario introdurre nel modello dei fattori aggiuntivi che rendano conto di queste covarianze. In questo caso, la scala non sarà più unidimensionale: la presenza di più fattori indica la presenza di più sottoscale. Il problema presentato sopra, tuttavia, non sempre può essere risolto individuando delle sottoscale perché, anche in tal caso, possono rimanere delle covarianze tra i fattori specifici che non sono spiegate dai fattori che individuano le sottoscale. In questi casi, per calcolare \\(\\omega\\) sarà necessario utilizzare la (11.10). McDonald (1999) attribuisce al coefficiente \\(\\omega\\) le seguenti interpretazioni: \\(\\omega\\) è uguale al quadrato della correlazione tra la \\(Y\\) e il fattore comune \\(\\xi\\) o, in maniera equivalente, tra la \\(Y\\) e il punteggio vero (in base alla definizione di attendibilità: \\(\\rho_{XT}^2=\\sigma^2_{\\tau}/\\sigma^2_X\\)); \\(\\omega\\) è uguale alla correlazione tra due test \\(Y\\) e \\(Y&#39;\\) aventi la stessa somma (o media) delle saturazioni nel modello ad un fattore e la stessa somma (o media) delle varianze specifiche nel modello ad un fattore; \\(\\omega\\) è uguale al quadrato della correlazione tra il punteggio totale di \\(p\\) item e il punteggio medio di un insieme infinito di item di un dominio omogeneo di cui i \\(p\\) item costituisciono un sottoinsieme. 11.5.2 Coefficiente \\(\\alpha\\) di Cronbach Il coefficiente \\(\\omega\\) consente di stimare il coefficiente di attendibilità nel caso di un modello monofattoriale congenerico. Invece, il coefficiente \\(\\alpha\\) fornisce una stima del coefficiente di attendibilità nel caso di un modello con indicatori \\(\\tau\\)-equivalenti. Se \\(p\\) item soddisfano il modello di \\(\\tau\\)-equivalenza, la varianza di ciascun item può essere scomposta in una componente attribuibile al valore vero e in una componente d’errore, come indicato nella (11.4), ovvero, \\(\\sigma_{ii} = \\lambda^2 + \\psi_{ii} =\\sigma^2_T + \\sigma^2_i\\). In base al principio di \\(\\tau\\)-equivalenza, le varianze e covarianze riprodotte dal modello uni-fattoriale hanno le caratteristiche descritte nella matrice (11.5). Dato che tutti gli item hanno la stessa saturazione fattoriale \\(\\lambda\\), la formula per il calcolo del coefficiente \\(\\omega\\) si riduce a \\[ \\omega = \\frac{\\left( \\sum_i \\lambda_i \\right)^2}{\\left( \\sum_i \\lambda_i \\right)^2 + \\sum_i \\psi_{ii}} = \\frac{p^2 \\lambda^2}{\\sigma^2_Y} = \\frac{p^2 \\sigma_T^2}{\\sigma_Y^2} \\] dove \\(Y\\) è il punteggio totale del test. Usando il metodo dei minimi quadrati non pesati, una stima di \\(\\omega\\) può essere ottenuta nel modo seguente: \\[\\begin{equation} \\hat{\\omega} = \\frac{p^2 \\hat{\\sigma}_T^2}{s_Y^2} \\tag{11.11} \\end{equation}\\] dove una stima di \\(\\sigma_T^2\\) viene fornita dalla (11.6), ovvero \\[\\begin{equation} \\hat{\\sigma}_T^2 = \\frac{1}{p(p-1)} \\sideset{}{} {\\sum \\sum}_{i \\neq k} s_{ik} \\tag{11.12} \\end{equation}\\] Inserendo la (11.12) nella (11.11), otteniamo \\[\\begin{equation} \\hat{\\omega} = \\frac{p}{p-1}\\frac{\\sideset{}{} {\\sum \\sum}_{i \\neq k} s_{ik}}{s_Y^2} \\end{equation}\\] In conclusione, nel caso di indicatori \\(\\tau\\)-eqivalenti, una stima del coefficiente \\(\\omega\\) è data da \\[\\begin{equation} \\begin{aligned} \\hat{\\omega} &amp;= \\frac{p}{p-1}\\frac{\\sideset{}{} {\\sum \\sum}_{i \\neq k} s_{ik}}{s_Y^2} \\notag\\\\ &amp;= \\frac{p}{p-1}\\left(1-\\frac{\\sum_i s_{ii}}{s_Y^2}\\right) \\end{aligned} \\tag{11.13} \\end{equation}\\] La stima dell’attendibilità fornita dalla (11.13) trova il suo corrispettivo per i valori della popolazione nell’equazione seguente: \\[\\begin{equation} \\begin{aligned} \\alpha &amp;= \\frac{p}{p-1}\\left(1-\\frac{\\sum_{i=1}^p \\sigma_{ii}}{\\sigma_Y^2}\\right) &amp;= \\frac{p}{p-1}\\frac{\\sum_{i\\neq k}^p \\mbox{Cov}(X_i, X_k)}{\\mathbb{V}(Y)} \\end{aligned} \\tag{11.14} \\end{equation}\\] La (11.14) definisce quello che è conosciuto come il coefficiente \\(\\alpha\\). Il coefficiente \\(\\alpha\\) fu scoperto da Guttman nel 1945 e incorrettamente attribuito a Cronbach. Viene spesso chiamato coefficiente \\(\\alpha\\) di Guttman-Cronbach, o G-C \\(\\alpha\\). Se gli indicatori soddisfano i requisiti del modello di \\(\\tau\\)-equivalenza, i coefficienti \\(\\alpha\\) e \\(\\omega\\) sono uguali. Se il modello di \\(\\tau\\)-equivalenza è appropriato, il coefficiente \\(\\alpha\\) fornisce un limite inferiore del coefficiente \\(\\omega\\) (ovvero, fornisce una sottostima di \\(\\omega\\)): \\(\\omega \\geq \\alpha\\). A causa del fatto che fornisce una stima conservativa del coefficiente di attendibilità, \\(\\alpha\\) viene preferito ad \\(\\omega\\) da alcuni ricercatori. Si noti però che \\(\\alpha\\) possiede tale carattere conservativo solo nel caso in cui le assunzioni del modello \\(\\tau\\)-equivalente siano soddisfatte. 11.5.2.1 Un esempio concreto consideriamo nuovamente la matrice di varianze e covarianze SWLS. Il coefficiente \\(\\alpha\\) si calcola usando la (11.13) e, per i dati presenti, risulta essere uguale a p &lt;- 5 alpha &lt;- (p / (p - 1)) * (1 - tr(SWLS) / sum(SWLS)) alpha #&gt; [1] 0.8191223 Lo stesso risultato si ottiene utilizzando la funzione alpha() contenuta nel pacchetto psych: alpha(SWLS) #&gt; #&gt; Reliability analysis #&gt; Call: alpha(x = SWLS) #&gt; #&gt; raw_alpha std.alpha G6(smc) average_r S/N median_r #&gt; 0.82 0.82 0.79 0.48 4.6 0.49 #&gt; #&gt; 95% confidence boundaries #&gt; lower alpha upper #&gt; Feldt 0.33 0.82 0.98 #&gt; #&gt; Reliability if an item is dropped: #&gt; raw_alpha std.alpha G6(smc) average_r S/N var.r med.r #&gt; V1 0.75 0.76 0.70 0.44 3.1 0.0027 0.44 #&gt; V2 0.78 0.79 0.74 0.48 3.7 0.0060 0.49 #&gt; V3 0.78 0.78 0.73 0.47 3.5 0.0055 0.48 #&gt; V4 0.81 0.81 0.77 0.52 4.3 0.0027 0.52 #&gt; V5 0.80 0.80 0.75 0.50 3.9 0.0057 0.50 #&gt; #&gt; Item statistics #&gt; r r.cor r.drop #&gt; V1 0.83 0.79 0.71 #&gt; V2 0.77 0.68 0.62 #&gt; V3 0.78 0.71 0.64 #&gt; V4 0.70 0.58 0.53 #&gt; V5 0.74 0.63 0.57 11.5.2.2 Violazione dell’assunto di tau-equivalenza Il coefficiente \\(\\alpha\\), la misura di attendibilità maggiormente usata in psicometria, è basato sull’assuzione che il modello di misurazione sia \\(\\tau\\)-equivalente. Come indicato sopra, se tale assunzione è soddisfatta, \\(\\alpha\\) fornisce un limite inferiore dell’attendibilità del test. Nei casi in cui tale assunzione venga violata, però, \\(\\alpha\\) può perdere tale carattere conservativo e può fornire una sovrastima dell’attendibilità del test (Sijtsma, 2009). NKano e Azuma (2003) riportano i risultati di una simulazione che mette in evidenza le conseguenze che risultano dalla violazione dell’assunzione di incorrelazione tra le componenti specifiche del modello monofattoriale. Questi autori trovano che, quando il principio dell’incorrelazione dei fattori specifici è violato, allora le stime dell’attendibilità ottenute mediante il coefficiente \\(\\alpha\\) sono affette da un errore sistematico. Tale errore sistematico aumenta all’aumentare del numero di coppie di fattori specifici che risultano tra loro correlati. In queste circostanze, dunque, il coefficiente \\(\\alpha\\) non fornisce più una stima conservativa dell’attendibilità. In conclusione, il coefficiente \\(\\omega\\) fornisce una stima adeguata dell’attendibilità nel caso di un modello di misurazione congenerico. L’utilizzo del coefficiente \\(\\alpha\\) per la stima dell’attendibilità richiede un modello di misurazione \\(\\tau\\)-equivalente. L’esistenza di fattori specifici correlati invalida sia il coefficiente \\(\\alpha\\), sia il coefficiente \\(\\omega\\) calcolato in base alla (11.9). In tali circostanze l’attendibilità deve essere stimata utilizzando una diversa equazione (Kano &amp; Azuma, 2003; Komaroff, 1997). Questa discussione mette in evidenza un aspetto importante: il coefficiente \\(\\alpha\\) fornisce una stima conservativa dell’attendibilità di un test solo se le variabili osservate sono associate alle variabili latenti come indicato dal modello di misurazione \\(\\tau\\)-equivalente. Se le assunzioni del modello \\(\\tau\\)-equivalente sono violate (per esempio, l’assunzione dell’incorrelazione degli errori), allora \\(\\alpha\\) porta ad una sovrastima stima dell’attendibilità del test. Sijtsma (2009), tra gli altri, sconsiglia l’uso di \\(\\alpha\\) per la stima dell’attendibilità del test in quanto, nelle applicazioni reali, le assunzioni di \\(\\tau\\)-equivalenza e dell’incorrelazione degli errori risultano spesso violate. La violazione dell’assunzione di \\(\\tau\\)-equivalenza porta ad una stima conservativa dell’attendibilità, mentre la violazione dell’assunzione dell’incorrelazione degli errori porta ad una stima liberale dell’attendibilità. In entrambi i casi, l’errore sistematico può essere sostanziale. Un secondo problema è che \\(\\alpha\\) viene spesso preso quale misura della “struttura interna” di un test e quindi come evidenza che gli item del test “misurino la stessa cosa.” Tale interpretazione di \\(\\alpha\\) è sbagliata, in quanto \\(\\alpha\\) non fornisce alcuna informazione a questo proposito. Non è semplice fornire ad \\(\\alpha\\) una chiara interpretazione, anche nel caso in cui siano soddisfatte le assunzioni del modello di misurazione su cui si basa. 11.5.3 La formula “profetica” di Spearman-Brown La formula “profetica” di Spearman-Brown viene usata per misurare l’attendibilità nel caso di un modello di misurazione costituito da indicatori paralleli. Si considerino \\(p\\) item paralleli, tali per cui \\(\\lambda_1=\\lambda_2=\\dots=\\lambda_p=\\lambda\\) e \\(\\psi_{11}=\\psi_{22}=\\dots=\\psi_{pp}=\\psi\\). In tal caso, la quota di varianza del punteggio totale del test che viene spiegata dalla variabile latente è uguale a \\[ \\left(\\sum_i \\lambda_i \\right)^2 = (p \\lambda)^2 = p^2 \\lambda^2. \\] L’attendibilità di un singolo item, che chiamerò \\(\\rho_1\\), è data da \\[ \\rho_1 = \\frac{\\sigma_T^2}{\\sigma_T^2+ \\sigma_E^2} = \\frac{\\lambda^2}{\\lambda^2 + \\psi}. \\] Per \\(p\\) item paralleli avremo che \\[\\begin{equation} \\begin{aligned} \\rho_p &amp;= \\frac{p^2 \\lambda^2}{p^2 \\lambda^2 + p \\psi} \\notag\\\\ &amp;= \\frac{p^2 \\lambda^2}{ p (p \\lambda^2 + \\psi)} \\notag\\\\ &amp;= \\frac{p \\lambda^2}{ p \\lambda^2 + \\psi} \\notag\\\\ &amp;= \\frac{p \\lambda^2}{(p-1) \\lambda^2 + (\\lambda^2 + \\psi)}. \\notag \\end{aligned} \\end{equation}\\] Ricordando che l’attendibilità di ciascun singolo item è \\(\\rho_1 = \\frac{\\lambda^2}{\\lambda^2 + \\psi}\\), abbiamo che \\[\\begin{equation} \\begin{aligned} \\rho_p &amp;= \\frac{p \\frac{\\lambda^2}{\\lambda^2+\\psi}}{(p-1) \\frac{\\lambda^2}{\\lambda^2+\\psi} + \\frac{\\lambda^2 + \\psi}{\\lambda^2+\\psi}} \\notag\\\\ &amp;= \\frac{p \\rho_1}{(p-1)\\rho_1 + 1}. \\end{aligned} \\tag{11.15} \\end{equation}\\] La (11.15) esprime l’attendibilità \\(\\rho_p\\) di un test costituito da \\(p\\) item paralleli come funzione dell’attendibilità che caratterizza un singolo item. La (11.15) è tradizionalmente conosciuta con il nome di formula “profetica” di Spearman-Brown (Spearman-Brown prophecy formula). Nel caso di item paralleli si ha che \\[ \\omega=\\alpha=\\rho_p. \\] 11.5.3.1 Un esempio concreto Poniamoci il problema di calcolare l’attendibilità del test SWLS utilizzando la formula di Spearman-Brown. Ipotizziamo dunque che gli item della scala SWLS siano paralleli. La matrice di correlazione è: R &lt;- cov2cor(SWLS) round(R, 3) #&gt; [,1] [,2] [,3] [,4] [,5] #&gt; [1,] 1.000 0.563 0.589 0.498 0.521 #&gt; [2,] 0.563 1.000 0.511 0.400 0.452 #&gt; [3,] 0.589 0.511 1.000 0.419 0.473 #&gt; [4,] 0.498 0.400 0.419 1.000 0.370 #&gt; [5,] 0.521 0.452 0.473 0.370 1.000 Seguendo McDonald (2013), supponiamo di calcolare l’attendibilità di un singolo item (\\(\\rho_1\\)) come la correlazione media tra gli item: rr &lt;- NULL p &lt;- 5 k &lt;- 1 for (i in 1:p) { for (j in 1:p) { if (j != i) { rr[k] &lt;- R[i, j] } k &lt;- k + 1 } } ro_1 &lt;- mean(rr, na.rm = TRUE) ro_1 #&gt; [1] 0.4797593 Applicando la formula di Spearman-Brown, la stima dell’attendibilità del test diventa pari a (p * ro_1) / ((p - 1) * ro_1 + 1) #&gt; [1] 0.8217766 11.5.3.2 Attenuazione All’aumentare dell’errore di misurazione, la correlazione tra due variabili tende a diminuire. L’errore di misurazione, dunque, “maschera” l’associazione esistente tra le variabili. Tale fenomeno va sotto il nome di attenuazione. Lord e Novick (1967) notano che, volendo determinare la relazione esistente tra due costrutti, uno psicologo può costruire opportune scale per misurarli. Se la relazione tra queste scale è lineare, allora il grado di associazione tra le scale può essere misurato dal coefficiente di correlazione. Le scale, però, contengono una componente di errore e, quindi, la correlazione empirica tra le due scale assume un valore minore della “reale” correlazione tra i costrutti. In tali circostanze, possono essere usate opportune formule per stimare il valore della correlazione disattenuata tra i tratti latenti. Si può dimostrare che la correlazione tra i punteggi veri di due costrutti, \\(T_y\\) e \\(T_y\\), può essere espressa nei termini della correlazione \\(\\rho_{XY}\\) tra i punteggi osservati \\(X\\) e \\(Y\\), e nei termini dei coefficienti di attenibilità \\(\\rho_{XX^\\prime}\\), \\(\\rho_{YY^\\prime}\\) dei due test: \\[\\begin{equation} \\rho(T_X, T_Y) = \\frac{\\rho_{XY}}{\\sqrt{\\rho_{XX^\\prime} \\rho_{YY^\\prime}}} \\tag{11.16} \\end{equation}\\] Inoltre, può essere dimostrato che la correlazione tra i punteggi di un test e i punteggi veri di un secondo test può essere espressa nei termini delle correlazioni tra i punteggi osservati dei due test e del coefficiente di attendibilità del secondo test: \\[\\begin{equation} \\rho(X, T_Y) = \\frac{\\rho_{XY}}{\\sqrt{\\rho_{YY^\\prime}}}. \\tag{11.17} \\end{equation}\\] 11.5.3.3 Correlazioni disattenuate Le (11.16) e (11.17) consentono di calcolare le cosiddette correlazioni disattenuate. L’idea è che le correlazioni tra i punteggi veri di due test sono sottostimate dalle correlazioni tra i punteggi osservati dei test, a causa dell’errore di misura. Se le attendibilità dei test sono conosciute, le (11.16) e (11.17) possono essere usate per stimare le correlazioni tra i corrispondenti punteggi veri. La teoria dell’attenuazione costituisce un’ulteriore applicazione del coefficiente di attendibilità nell’ambito della teoria classica dei test. Le correlazioni disattenuate sono state usate già a partire dal 1904 da Spearman. Nell’esempio di Spearman, \\(X\\) era una misura di discriminazione dell’altezza di un suono (pitch discrimination) e \\(Y\\) era una misura di intelligenza fornita da un insegnante. La correlazione tra queste due misure era \\(\\hat{\\rho}_{XY}=0.38\\). Le attendibilità delle due misure erano pari a, rispettivamente, \\(\\hat{\\rho}_{XX&#39;}= 0.25\\) e \\(\\hat{\\rho}_{YY&#39;}= 0.55\\). In base alla (11.17) \\[ \\rho(X, T_Y) = \\frac{\\rho_{XY}}{\\sqrt{\\rho_{YY^\\prime}}} \\] la correlazione predetta tra i valori veri di pitch discrimination e i valori empirici dell’intelligenza è \\[ \\hat{\\rho}(X, T_Y) =\\frac{0.38}{\\sqrt{0.25}}=0.76. \\] In base alla (11.16) \\[\\rho(T_X, T_Y) = \\frac{\\rho_{XY}}{\\sqrt{\\rho_{XX&#39;} \\rho_{YY&#39;}}}\\] la correlazione tra i valori veri di pitch discrimination e i valori veri dell’intelligenza è \\[\\hat{\\rho}(T_X, T_Y) =\\frac{0.38}{\\sqrt{0.25 \\times 0.55}}=1.025.\\] Si noti come i limiti di questa procedura emergano già dall’esempio fornito da Spearman: le correlazioni disattenuate possono facilmente produrre una sovrastima. Questa formula originò una controversia tra Charles Spearman e Karl Pearson. In un suo articolo del 1904 (lo stesso anno dei famosi articoli di Spearman), Pearson riportò diverse correlazioni nell’intorno di 0.5 che riguardavano la misurazione empirica di caratteristiche quali la vivacità e l’introspezione. Spearman criticò l’articolo di Pearson affermando che le osservazioni probabilmente contenevano un sostanziale errore di misurazione, il che determinava il fatto che fossero così basse. Le corrispondenti correlazioni disattenuate erano, secondo Spearman, probabilmente molto più alte. Tale critica venne del tutto ignorata da Pearson sulla base del fatto che la formula di Spearman poteva condurre a correlazioni maggiori di uno. Inoltre, Pearson non accettava i riferimenti a quantità inosservabili. Spearman, d’altra parte, eseguì diversi studi su variabili psicologiche alle quali applicò la sua formula per le correlazioni disattenuate. In molti casi, trovò che le correlazioni disattenuate erano vicine ad uno. Questo suggeriva che tali variabili psicologiche erano indicatori dello stesso fenomeno. Queste considerazioni spinsero Spearman a procedere in questa direzione, giungendo ad inventare l’analisi fattoriale così com’è riportata nell’articolo del 1904 “General intelligence”, objectively determined and measured. McDonald (1999) afferma che le correlazioni disattenuate devono essere usate con cautela. Un metodo migliore per calcolare le correlazioni tra le variabili latenti (ovvero, le correlazioni non “inquinate” dagli errori di misura) è quello di costruire un modello di equazioni strutturali nel quale diverse ipotesi possono essere direttamente verificate, compresa quella della correlazione tra le variabili latenti. References "],["attendibilità-e-scala-di-misura.html", "11.6 Attendibilità e scala di misura", " 11.6 Attendibilità e scala di misura McDonald (2013) fa notare che i coefficienti \\(\\omega\\) e \\(\\alpha\\), ma non il coefficiente di Spearman-Brown, dipendono dalla scala di misura degli item. Stimare \\(\\omega\\) utilizzando una matrice di correlazione anziché una matrice di varianze e di covarianze è equivalente a stimare il coefficiente di attendibilità di una somma di item standardizzati. Il risultato ottenuto mediante \\(\\omega\\) e \\(\\alpha\\) non si generalizza però al caso in cui si voglia valutare l’attendibilità del punteggio totale di un test calcolato sui valori grezzi degli item. Il modello ad un fattore comune non dipende dall’unità di misura degli indicatori e può essere adattato sia ad una matrice di correlazione sia ad una matrice di varianze e di covarianze. Il calcolo dei coefficienti \\(\\omega\\) e \\(\\alpha\\), invece, deve essere fatto sulla soluzione trovata utilizzando una matrice di varianze e di covarianze. "],["quale-indice-usare.html", "11.7 Quale indice usare?", " 11.7 Quale indice usare? L’indice di attendibilità più diffuso in letteratura è il coefficiente \\(\\alpha\\) di Cronbach. Affinché \\(\\alpha\\) fornisca una stima dell’attendibilità del test, però, gli item devono essere \\(\\tau\\)-equivalenti. Il modello di \\(\\tau\\)-equivalenza richiede l’unidimensionalità del tratto latente. In pratica, tale assunzione viene spesso violata, dato che la maggior parte dei test, oltre ad un fattore generale, misurano anche altri fattori. Anche nel caso di un test unidimensionale, le comunalità degli item non sono mai uguali tra loro, violando così l’assunzione di \\(\\tau\\)-equivalenza. In tali circostanze, se risulta soddisfatta l’assunzione di incorrelazione degli errori, il coefficiente \\(\\alpha\\) sottostima l’attendibilità del test. Se invece l’assunzione di incorrelazione degli errori non risulta soddisfatta, allora il coefficiente \\(\\alpha\\) sovrastima l’attendibilità del test. Per tali ragioni, l’utilità del coefficiente \\(\\alpha\\) di Cronbach è molto limitata e, in generale, è preferibile usare il coefficiente \\(\\omega\\) (McDonald, 1999). Altre alternative sono gli indici \\(glb\\) (Greatest Lower Bound; si veda, ad esempio, Ten Berge e Sočan, 2004) e \\(\\beta\\) (Revelle, 1979). "],["cfa-confronto-tra-modelli.html", "Capitolo 12 CFA: confronto tra modelli", " Capitolo 12 CFA: confronto tra modelli In un modello CFA, i parametri possono essere stimati senza vincoli, possono essere fissi o possono essre stimati sulla base di alcuni vincoli. Un parametro libero è sconosciuto e il ricercatore consente all’algoritmo di stima di trovare il suo valore ottimale che, insime agli altri parametri del modello, riduce al minimo le differenze tra le matrici di varianze-covarianze osservate e quelle predette dal modello. Un parametro fisso è pre-specificato dal ricercatore ad un valore specifico, più comunemente 1.0 (ad esempio, per definire la metrica di una variabile latente) o 0 (ad esempio, l’assenza di saturazionoi fattoriali o di covarianze di errore). Come per un parametro libero, anche un parametro vincolato è sconosciuto; tuttavia, un tale parametro non può assumere un valore qualsiasi, ma deve rispettare le restrizioni su suoi valori che il ricercatore ha imposto. I vincoli più comuni sono i vincoli di uguaglianza, in cui i parametri non standardizzati devono assumere valori uguali (ad esempio, in diversi gruppi). Consideriamo un esempio discusso da Brown (2015). Viene qui considerato un set di dati in cui le prime tre misure osservate (X1, X2, X3) sono indicatori di un costrutto latente corrispondente alla Memoria uditiva e il secondo insieme di misure (X4, X5, X6) sono indicatori di un altro costrutto latente, Memoria visiva. Le tre misure usate quali indicatori del costrutto di memoria uditiva sono: X1 = memoria logica, X2 = associazione verbale a coppie, X3 = liste di parole; le tre misure usate come indicatori del costrutto di memoria visiva sono: X4 = immagini di facce, X5 = foto di famiglia, X6 = generiche riproduzioni visive. I dati sono i seguenti: sds &lt;- &quot;2.610 2.660 2.590 1.940 2.030 2.050&quot; cors &lt;- &quot; 1.000 0.661 1.000 0.630 0.643 1.000 0.270 0.300 0.268 1.000 0.297 0.265 0.225 0.805 1.000 0.290 0.287 0.248 0.796 0.779 1.000&quot; covs &lt;- getCov(cors, sds = sds, names = paste(&quot;x&quot;, 1:6, sep = &quot;&quot;)) Adattiamo i cinque modelli discussi da Brown (2015). References "],["modello-congenerico.html", "12.1 Modello congenerico", " 12.1 Modello congenerico model.congeneric &lt;- &quot; auditorymemory =~ x1 + x2 + x3 visualmemory =~ x4 + x5 + x6 &quot; fit.congeneric &lt;- cfa( model.congeneric, sample.cov = covs, sample.nobs = 200, std.lv = TRUE ) L’output (qui non fornito) si ottiene con: summary( fit.congeneric, fit.measures = TRUE, standardized = TRUE, rsquare = TRUE ) "],["modello-tau-equivalente.html", "12.2 Modello tau-equivalente", " 12.2 Modello tau-equivalente Solo memoria auditiva: model.tau.a &lt;- &quot; auditorymemory =~ x1 + v1*x1 + v1*x2 + v1*x3 visualmemory =~ x4 + x5 + x6 &quot; fit.tau.a &lt;- cfa( model.tau.a, sample.cov = covs, sample.nobs = 200, std.lv = TRUE ) Memoria auditiva e visiva: model.tau.av &lt;- &quot; auditorymemory =~ x1 + v1*x1 + v1*x2 + v1*x3 visualmemory =~ x4 + v2*x4 + v2*x5 + v2*x6 &quot; fit.tau.av &lt;- cfa( model.tau.av, sample.cov = covs, sample.nobs = 200, std.lv = TRUE ) "],["modello-parallelo.html", "12.3 Modello parallelo", " 12.3 Modello parallelo Solo memoria auditiva: model.parallel.a &lt;- &quot; auditorymemory =~ x1 + v1*x1 + v1*x2 + v1*x3 visualmemory =~ x4 + v2*x4 + v2*x5 + v2*x6 x1 ~~ v3 * x1 x2 ~~ v3 * x2 x3 ~~ v3 * x3 &quot; fit.parallel.a &lt;- cfa( model.parallel.a, sample.cov = covs, sample.nobs = 200, std.lv = TRUE ) Memoria auditiva e visiva: model.parallel.av &lt;- &quot; auditorymemory =~ x1 + v1*x1 + v1*x2 + v1*x3 visualmemory =~ x4 + v2*x4 + v2*x5 + v2*x6 x1 ~~ v3 * x1 x2 ~~ v3 * x2 x3 ~~ v3 * x3 x4 ~~ v4 * x4 x5 ~~ v4 * x5 x6 ~~ v4 * x6 &quot; fit.parallel.av &lt;- cfa( model.parallel.av, sample.cov = covs, sample.nobs = 200, std.lv = TRUE ) "],["il-test-del-chi2.html", "12.4 Il test del \\(\\chi^2\\)", " 12.4 Il test del \\(\\chi^2\\) Il confronto tra modelli nidificati procede attraverso il test \\(\\chi^2\\). Tale test si basa su una proprietà delle variabili casuali distribuite come \\(\\chi^2\\): la differenza tra due v.c. \\(X_1\\) e \\(X_2\\) che seguono la distribuzione \\(\\chi^2\\), rispettivamente con \\(\\nu_1\\) e \\(\\nu_2\\), con \\(\\nu_1 &gt; \\nu_2\\), è una variabile causale che segue la distribuzione \\(\\chi^2\\) con gradi di libertà pari a \\(\\nu_1 - \\nu_2\\). Un modello nidificato è un modello che impone dei vincoli sui parametri del modello di partenza. L’imposizione di vincoli sui parametri ha la conseguenza che vi sarà un numero minore di parametri da stimare. Il confronto tra i modelli si esegue valutando in maniera relativa la bontà di adattamento di ciascun modello per mezzo della statistica chi-quadrato. La statistica così calcolata avrà un numero di gradi di libertà uguale alla differenza tra i gradi di libertà dei due modelli. Nel caso dell’esempio in dicussione, abbiamo anova( fit.congeneric, fit.tau.a, fit.tau.av, fit.parallel.a, fit.parallel.av, test = &quot;chisq&quot; ) #&gt; #&gt; Chi-Squared Difference Test #&gt; #&gt; Df AIC BIC Chisq Chisq diff RMSEA Df diff Pr(&gt;Chisq) #&gt; fit.congeneric 8 4702.0 4744.8 4.8773 #&gt; fit.tau.a 10 4698.7 4735.0 5.6597 0.7823 0.000000 2 0.6763 #&gt; fit.tau.av 12 4695.0 4724.6 5.8810 0.2213 0.000000 2 0.8952 #&gt; fit.parallel.a 14 4691.1 4714.1 5.9769 0.0959 0.000000 2 0.9532 #&gt; fit.parallel.av 16 4690.4 4706.9 9.2772 3.3003 0.057016 2 0.1920 I test precedenti indicano come non vi sia una perdita di adattamento passando dal modello congenerico al modello più restrittivo (ovvero, il modello parallelo per entrambi i fattori). Per questi dati, dunque, può essere adottato il modello più semplice, cioè il modello parallelo. "],["tipologie-dei-test-psicometrici.html", "Capitolo 13 Tipologie dei test psicometrici", " Capitolo 13 Tipologie dei test psicometrici Prima di iniziare lo sviluppo di un test psicometrico, il ricercatore deve decidere quale tipologia di strumento sia più utile per affrontare il problema che ha di fronte. Possiamo infatti distinguere tra test orientati al criterio e test riferiti alla norma. 13.0.1 Test orientati al criterio I test orientati al criterio hanno quale scopo il confronto fra gruppi precostituiti di individui. Gli item del test vengono selezionati in base alla loro capacità empirica di discriminare fra gruppi criterio, ad esempio, malati/sani, bocciati/promossi, schizofrenici/depressi. I test orientati al criterio sono costruiti utilizzando metodi empirici e non teorici. Al vantaggio di una chiara utilità pratica si accompagna il grande svantaggio di identificare fattori aventi una scarsa validità di costrutto, i quali risultano inutili per la comprensione dei processi psicologici. Il processo di sviluppo della scala è semplice, in quanto si devono selezionare gli item che mostrano punteggi differenti in gruppi-criterio noti. Se i gruppi criterio possono essere individuati con chiarezza è sempre teoricamente possibile sviluppare test in grado di discriminarli. Tuttavia, non sempre i gruppi possono essere definiti in modo attendibile; oppure, la definizione dei gruppi criterio potrebbe avere senso solo all’interno di una teoria, ma non sia generalizzabile ad altre tradizioni teoriche. In questo caso, il test rischia di essere eccessivamente specifico, dimostrandosi utile solo nelle condizioni per cui è stato sviluppato, ma con scarsa capacità di potere essere utilizzato in condizioni diverse. Lo svantaggio principale dei test orientati al criterio è che il significato psicologico dei punteggi è ignoto. Non avendo una teoria sulle variabili psicologiche che distinguono due gruppi, un buon test discriminante non ci aiuta a capire perché tali gruppi siano diversi. Non è possibile sapere quanti costrutti siano coinvolti nella determinazione di un punteggio. Inoltre, due punteggi uguali non implicano la presenza dei medesime meccanismi psicologici. Date queste ambiguità, utilizzando questi test non è possibile neppure aumentare le nostre conoscenze in maniera incrementale. Il problema maggiore per lo sviluppo di questi strumenti è la definizione del criterio: qual è la variabile numerica che discrimina nella maniera maggiore tra i gruppi in esame (malati/sani)? La batteria di item iniziale deve essere sufficientemente grande e non è necessario che gli item abbiano validità di contenuto o validità di facciata. In generale, la batteria di item deve essere più grande di quelle usate per il metodo fattoriale o di analisi degli item: mancando criteri teorici per la scelta degli item, la scelta iniziale degli item è molto arbitraria ed è dunque necessario partire da un numero molto elevato di item. Ciò è meno vero quando gli item hanno una certa validità di facciata o di contenuto. In seguito, semplicemente si selezionano gli item che discriminano efficacemente fra i gruppi, o gli item fortemente associati con il punteggio criterio. È necessario poi replicare su un diverso campione la capacità discriminativa degli item selezionati. 13.0.2 Test basati sulla norma Le misure riferite ad una norma indicano la posizione del rispondente in riferimento alla distribuzione di punteggi ottenuti nello stesso test da un campione di grandi dimensioni e rappresentativo della popolazione di riferimento. La maggioranza dei test di personalità, attitudinali e cognitivi sono test basati sulla norma. La metrica utilizzata per tale confronto può avere caratteristiche diverse. I punteggi standardizzati (con media \\(0\\) e varianza unitaria) calcolati rispetto al gruppo di riferimento sono spesso convertiti in una scala diversa, per esempio aventi media pari a \\(500\\) e deviazione standard di \\(100\\) (punteggi SAT), o aventi media pari a \\(100\\) e deviazione standard di \\(15\\) (es. punteggi WAIS-VI). È facile operare tale trasformazione. Il punteggio \\(Y\\) di un rispondente può essere trasformato nel modo seguente in un punteggio standard \\(X_i\\), avente una media target pari a \\(\\mu_s\\) e una deviazione standard \\(\\sigma_s\\) \\[X_i = \\mu_s + z_i \\sigma_s\\notag\\] dove \\(z\\) è il punteggio standardizzato \\(z=\\frac{Y-\\bar{Y}}{s_Y}\\). "],["variabili-latenti-e-sviluppo-di-uno-strumento-psicometrico.html", "13.1 Variabili latenti e sviluppo di uno strumento psicometrico", " 13.1 Variabili latenti e sviluppo di uno strumento psicometrico Quando uno psicologo sviluppa una scala di misura è meno interessato agli item della scala che ai costrutti che si intendono misurare: “Scale items are usually a means to the end of construct assessment …they are necessary because many constructs cannot be assessed directly” (p. 2). Dato che non sono osservabili direttamente, i costrutti sono detti variabili latenti. I costrutti sono interpretati come le cause (non visibili) che fanno in modo che gli item assumano un determinato valore per un determinato rispondente in un certo momento del tempo. Mentre alcune variabili, quali l’altezza, il peso, il battito cardiaco, la temperatura, possono essere misurate direttamente, i costrutti psicologici, quali l’ansia, la personalità, la qualità della vita, possono solo essere misurati indirettamente esaminando gli effetti che hanno sugli indicatori osservabili del costrutto. Gli item che vengono misurati tramite uno strumento sono gli indicatori osservati o empirici degli attributi del costrutto. Il dolore, ad esempio, è un costrutto psicologico non direttamente osservabile. Tuttavia, al dolore sono associati molteplici indicatori che sono direttamente osservabili, quali il pallore, la sudorazione profusa, ecc. Allo scopo di misurare le variabili latenti del costrutto di interesse, lo psicologo deve identificare gli indicatori empirici del costrutto che possono essere direttamente osservabili. L’identificazione di tali indicatori empirici avviene attraverso (1) la chiarificazione del costrutto di interesse, (2) l’operazionalizzazione del costrutto, (3) la rassegna della letteratura rilevante, (4) l’analisi concettuale del costrutto. 13.1.1 Chiarificazione del costrutto di interesse Vi sono diverse domande a cui lo psicologo deve rispondere prima di iniziare la selezione degli item, altrimenti rischia di produrre uno strumento con una scarsa validità di costrutto. Qual è lo scopo dello strumento? Che cosa lo strumento dovrà misurare? Quali altri costrutti sono associati al costrutto di interesse? In che misura essi si distinguono dal costrutto di interesse? A tali domande non è semplice dare una risposta se il costrutto di interesse è complesso e astratto. Lo strumento da costruire intende misurare le caratteristiche generali del costrutto di interesse, o intende focalizzarsi su alcuni specifici aspetti del costrutto? Esempio 13.1 Watson et al. (2007) si sono posti il problema di costruire uno strumento atto misurare la depressione superando i limiti degli strumenti già esistenti, quali il Beck Depression Inventory—II (BDI–II; Beck, Steer, &amp; Brown, 1996) e il Center for Epidemiological Studies Depression Scale (CES–D; Radloff, 1977). La scala costruita dagli autori prende il nome di Inventory of Depression and Anxiety Symptoms (IDAS). Per rispondere alla prima domanda, Watson et al. (2007) fanno notare che gli strumenti esistenti comprendono contenuti non specifici, ovvero non direttamente associati alla depressione. Infatti, sia il BDI-2 sia il CES–D contengono item che fanno riferimento a vari tipi di ansia. Di conseguenza, la validità discriminante di questi strumenti risulta compromessa. Inoltre, gli strumenti esistenti non contengono item che coprono tutto il dominio del costrutto della depressione maggiore, così come specificato dal Diagnostic and Statistical Manual of Mental Disorders (4th ed.). Infine, un’altra limitazione degli strumenti esistenti è il fatto che essi sono stati creati per produrre un singolo item della severità dei sintomi e quindi ignorano l’eterogeneità e la multidimensionalità del fenomeno depressivo. Questo si riflette sul fatto che gli strumenti esistenti manifestano una struttura fattoriale poco chiara, nel senso che autori diverse hanno trovato soluzioni fattoriali diverse. Lo strumento che Watson et al. (2007) intendono sviluppare vuole superare queste difficoltà costruendo una scale che direttamente rifletta, in ciascuna delle sue sottoscale, gli aspetti distintivi della depressione, a differenza di quanto accade per gli strumenti BDI–II e CES–D. Per rispondere alla seconda domanda, Watson et al. (2007) fanno notare come la depressione sia inserita in una rete nomologica di costrutti che include, in primo luogo, l’ansia. Diversamente dagli strumenti già esistenti, BDI–II e CES–D, Watson et al. (2007) si propongono espliciatamente di creare scale che riflettano gli aspetti specifici della depressione, distinti dall’ansia. Per fare questo, Watson et al. (2007) iniziano con il considerare un ampio insieme di item che rappresentano sintomi associati all’ansia. In questo modo viene perseguito l’obiettivo, all’interno dello strumento, di esaminare la relazione tra i sintomi d’ansia e quelli della depressione in modo da creare scale distinte per tali dimensioni così da aumentare a validità discriminante dello strumento. Per rispondere alla terza domanda, Watson et al. (2007) affermano di volere sviluppare uno strumento che, nel suo punteggio generale, rifletta le caratteristiche generali della depressione mentre, quando vengono considerate le varie sottoscale che lo costituiscono, consente di misurare con precisione ciascuna delle dimensioni del costrutto esaminato. 13.1.2 Operazionalizzazione del costrutto di interesse La definizione concettuale fornisce il significato teorico generale del costrutto. L’operazionalizzazione è invece una definizione del costrutto che ne consenta la misurazione (Vogt, 1993). Gli indicatori osservabili o empirici sono il prodotto finale di tale processo di operazionalizzazione (Keck, 1998) e diventano gli item dello strumento. Se il costrutto di interesse è stato sviluppato all’interno di un approccio teorico ben articolato, allora diventa più semplice stabilire quali siano le dimensioni che caratterizzano il costrutto, in che modo esse si possano manifestare, e in che modo possano essere misurate. Tuttavia, molti costrutti psicologici vengono spesso caratterizzati in maniera diversa da approcci teorici differenti. Esempio 13.2 Per chiarire il costrutto di depressione, Watson et al. (2007) fanno riferimento al DSM–IV il quale elenca nove criteri sintomatici per un episodio depressivo maggiore: (1) umore depresso per la maggior parte del giorno, quasi ogni giorno, come riportato dal soggetto o come osservato dagli altri, (2) marcata diminuzione di interesse o piacere per tutte, o quasi tutte, le attività per la maggior parte del giorno, quasi ogni giorno (come riportato dal soggetto o come osservato dagli altri), (3) significativa perdita di peso, senza essere a dieta, o aumento di peso, oppure diminuzione o aumento dell’appetito quasi ogni giorno, (4) insonnia o ipersonnia quasi ogni giorno, (5) agitazione o rallentamento psicomotorio quasi ogni giorno (osservabile dagli altri, non semplicemente sentimenti soggettivi di essere irrequieto o rallentato), (6) faticabilità o mancanza di energia quasi ogni giorno, (7) sentimenti di autosvalutazione o di colpa eccessivi o inappropriati (che possono essere deliranti), quasi ogni giorno, (8) ridotta capacità di pensare o di concentrarsi, o indecisione, quasi ogni giorno (come impressione soggettiva o osservata dagli altri), (9) pensieri ricorrenti di morte, ricorrente ideazione suicidaria senza un piano specifico, o un tentativo di suicidio, o l’ideazione di un piano specifico per commettere suicidio. Per massimizzare l’utilità dell’IDAS, Watson et al. (2007) includono item molteplici per ciascuno dei nove criteri sintomatici per un episodio depressivo maggiore. Allo scopo di assicurare che un numero sufficiente di indicatori venga incluso nello strumento per ciascuna di queste dimensioni potenziali, nell’insieme di item preso in considerazione inizialmente, Watson et al. (2007) organizzano gli item potenziali in gruppi chiamati homogeneous item composites (HIC). Essi fanno comunque notare come la costruzione di questi HIC non forza l’emergenza di un corrispondente fattore, ma soltanto consente di campionare tutto il dominio potenziale del costrutto. 13.1.3 Rassegna della letteratura rilevante È importante per lo psicologo conoscere la maggior parte possibile della letteratura rilevante prima di iniziare il processo di costruzione di un nuovo strumento. Una sistematica rassegna della letteratura consente allo psicologo di valutare e organizzare i risultati empirici provenienti da fonti diverse che sono utili per individuare i potenziali indicatori empirici del costrutto. La rassegna della letteratura consente di sintetizzare le scoperte in un campo di ricerca, mette in evidenza gli aspetti metodologici associati al costrutto di interesse, chiarisce quali siano gli approcci teorici all’interno dei quali il costrutto è stato discusso e consente di mettere in evidenza, quando è opportuno, la “dimensione dell’effetto” attraverso le meta-analisi. Esempio 13.3 Nel caso dell’articolo di Watson et al. (2007), gran parte dell’introduzione è dedicata alla rassegna della letteratura che viene discussa allo scopo di mettere in evidenza i limiti degli strumenti esistenti, considerare quali sono le caratteristiche degli item utilizzati, mettere in relazione gli indicatori utilizzati dagli strumenti esistenti con gli approcci teorici disponibili in relazione alla depressione e all’ansia, discutere le soluzioni fattoriali che sono state ottenute dai dati raccolti tramite gli strumenti esistenti, considerare quali aree di contenuto del costrutto non sono state adeguatamente indagate dagli strumenti esistenti. 13.1.4 Analisi concettuale del costrutto L’analisi concettuale del costrutto è un altro metodo che può essere usato per determinare gli indicatori empirici del costrutto di interesse. È necessario stabilire quali siano gli attributi del costrutto di interesse, includendo la specificazione degli antecedenti e delle conseguenze che derivano da esso. Si devono identificare tutti gli usi che, nella letteratura specialistica, sono stati fatti del costrutto in esame. Infine, è necessario elencare tutti gli indicatori empirici che siano mai stati utilizzati per il costrutto esaminato. Esempio 13.4 Allo scopo di campionare efficacemente l’intero dominio del costrutto, Watson et al. (2007) hanno definito 20 HIC: Depressed Mood, Loss of Interest or Pleasure, Appetite Disturbance, Sleep Disturbance, Psychomotor Problems, Fatigue/Anergia, Worthlessness/Guilt, Cognitive Problems, Suicidal Ideation, Hopelessness, Melancholic Depression, Angry/Irritable Mood, High Energy/High Positive Affect, Anxious Mood, Worry, Panic, Agoraphobia, Social Anxiety, Traumatic Intrusions, Obsessive-Compulsive Symptoms. Tredici HIC (per un totale di 117 item) raggruppavano gli indicatori rilevanti per la depressione. Tra questi, nove HICs (per un totale di 79 items) facevano riferimento ai sintomi di base della depressione maggiore così come descritta nel DSM–IV (depressed mood, loss of interest or pleasure, appetite disturbance, sleep disturbance, psychomotor problems, fatigue/anergia, worthlessness and guilt, cognitive problems, suicidal ideation). I quattro rimanenti HIC facevano riferimento alla presenza di sintomi della Hopelessness (Abramson, Metalsky, &amp; Alloy, 1989), ai sintomi specifici della depressione malinconica (Joiner et al., 2005), allo stato d’animo di rabbia/irritabilità (il quale rappresenta una forma alternativa di depressione tra gli adolescenti; DSM–IV, American Psychiatric Association, 1994, p. 327), e infine ad indicatori di energia e affetto positivo (i quali sono stati specificamente associati alla depressione; Mineka et al., 1998). Gli altri sette HIC (per un totale di 63 item) sono stati introdotti per valutare sintomi associati all’ansia. Essi sono stati raggruppati nei termini dello stato d’animo ansioso, della worry, del panico, dell’agorafobia, dell’ansia sociale e delle intrusioni traumatiche associate al PTSD. 13.1.5 Metodi di ricerca qualitativi Metodi di ricerca qualitativi posso anche essere usati allo scopo di identificare i potenziali indicatori empirici del costrutto. In particolare, possono essere usati i metodi della ricerca fenomenologica, dell’indagine naturalistica, i focus group e lo studio del caso singolo. L’indagine fenomenologica is pone l’obiettivo di descrivere il costrutto dal punto di vista di chi fa di esperienza di esso (Carpenter, 1999). Utili a questo proposito sono ovviamente le descrizioni che i soggetti forniscono della propria esperienza. Nell’indagine naturalistica, lo psicologo osserva le conseguenze del costrutto così come si manifestano nel mondo naturale. Uno strumento possibile di raccolta dati è l’intervista con il paziente. Il focus group, originariamente sviluppato in ambito economico per ottenere opinioni su un determinato prodotto (Morse &amp; Field, 1995), ha le caratteristiche di ‘a semi-structured group session, moderated by a group leader, held in an informal setting with the purpose of collecting information on a designated topic’’ (Carry, 1994, p. 226). Un’altra possibile fonte di informazioni è costituita dagli studi sul caso singolo. "],["lo-sviluppo-dello-strumento.html", "13.2 Lo sviluppo dello strumento", " 13.2 Lo sviluppo dello strumento Una volta selezionati gli indicatori empirici del costrutto, deve essere scelta una modalità di presentazione che consenta la raccolta efficiente dei dati. Ciascuno strumento può essere descritto in base a sei caratteristiche: (1) formato, (2) composizione tipografica, (3) istruzioni ai soggetti, (4) la costruzione degli item, (5) formato di risposta, e (6) numero di item. 13.2.1 Formato I formati di scala più usati sono lo scaling Thurstoniano, lo scaling di Guttman, le scale a differenziale semantico, le scale di valutazione grafica, semantic differential scales, graphic rating scales, le scale visive di tipo analogico (visual analog scales) e le scale Likert. Ci concentriamo qui sulle scale Likert per la loro importanza nei test psicometrici basati sull’analisi fattoriale. 13.2.1.1 Scala Likert Sviluppata nel 1932 da Rensis Likert per misurare gli atteggiamenti, una scala Likert è una scala ordinale usata dai rispondenti per valutare il grado di accordo o disaccordo con l’affermazione che viene loro proposta. Di solito le alternative di risposta sono cinque o sette, da “molto d’accordo” a “fortemente contrario.” Essendo una scala ordinale, le risposte possono essere ordinate, ma le distanze tra i livelli della scala non sono quantificabili. Quindi le distanze tra i livelli “sempre,” “spesso” e “talvolta” non sono necessariamente uguali. In altri termini, non possiamo assumere che le differenze tra i livelli di risposta siano equidistanti anche se le differenze tra i valori numerici assegnati ai livelli della scala lo sono. C’è una lunga controversia sulla possibilità di trattare i valori numerici di una scala ordinale come se essi provenissero da una scala ad intervalli. In altri termini, ci si è chiesti se sia appropriato usare statistiche descrittive quali la media e la deviazione standard per i dati a questo livello di scala, e ci si è chiesti se sia appropriato usare i test parametrici per dati a livello di scala Likert. È risaputo che i test non parametrici, i quali non fanno assunzioni sulla forma della distribuzione della popolazione da cui abbiamo campionato i dati, hanno una potenza statistica nettamente inferiore ai test parametrici. Inoltre, concetti quali quelli di media e varianza non hanno senso se i livelli di una scala Likert non vengono considerati a livello di scala ad intervalli. Per queste ragioni alcuni autori ritengono problematico non potere trattare i dati provenienti da scale di tipo Likert come se fossero a livello di scala ad intervalli. È stato risposto a tali difficoltà che sufficienti evidenze mostrano come risulti giustificato trattare i dati a livello di scala Likert come se fossero a livello di scala ad intervalli quando la numerosità campionaria è sufficientemente grande e quando i dati si distribuiscono in maniera approssimativamente normale. Altri autori (es. Jöreskog &amp; Sörbom, 1996) ritengono invece che le scale tipo Likert vadano considerate in ogni caso come ordinali, e debbano essere analizzate di conseguenza. Nel caso dell’analisi fattoriale e dei modelli di equazioni strutturali questo significa semplicemente che l’analisi si deve basare sul calcolo delle correlazioni policoriche. In conclusione, la procedura che sta alla base delle scale Likert consiste nella somma dei punti attribuiti ad ogni singola domanda. I vantaggi della scala Likert consistono nella sua semplicità e applicabilità, mentre i suoi svantaggi sono il fatto che i suoi elementi vengono trattati come scale cardinali pur essendo ordinali e il fatto che il punteggio finale non rappresenta una variabile cardinale. 13.2.2 Composizione tipografica Criteri da considerare nella formattazione tipografica del test di un test psicometrico sono la facilità di lettura, la chiarezza e l’organizzazione. La formattazione dovrebbe tenere in considerazione l’età dei rispondenti e la potenziale difficoltà di lettura. 13.2.3 Istruzioni ai soggetti Le istruzioni devono essere chiare e concise. Oltre ad illustrare la consegna, esse forniscono una cornice di riferimento che deve essere comune a tutti i rispondenti. Le istruzioni seguono un formato simile al seguente: Lo studio ha come obiettivo generale … In particolare, con la ricerca che qui presentiamo, si intendono ottenere dati relativi a … Nel caso tu decida di partecipare allo studio, questa ricerca prevede l’attuazione dei seguenti trattamenti … La ricerca durerà … e vi parteciperanno … individui. Dalla partecipazione a questa ricerca sono prevedibili i seguenti benefici … La partecipazione allo studio non comporta alcun rischio. Sei del tutto libero/a di non partecipare allo studio. La tua adesione a questo programma di ricerca è completamente volontaria e potrà essere ritirata in qualsiasi momento. Ai sensi del Decreto Legislativo 30 giugno 2003 n. 196 in materia di protezione dei dati personali, tratteranno i tuoi dati esclusivamente in funzione della realizzazione dello studio. Lo psicologo che ti seguirà nello studio ti identificherà con un codice: i dati che ti riguardano raccolti nel corso dello studio, ad eccezione del nominativo, saranno registrati, elaborati e conservati unitamente a tale codice, alla data di nascita, al genere. Soltanto il supervisore del progetto di ricerca potrà collegare questo codice al tuo nominativo. I dati, trattati mediante strumenti anche elettronici, saranno diffusi solo in forma rigorosamente anonima, ad esempio attraverso pubblicazioni scientifiche, statistiche e convegni scientifici. La tua partecipazione allo studio implica che il gruppo di ricerca che organizza lo studio e il Comitato etico potranno conoscere i dati che ti riguardano solo attraverso modalità tali da garantire la riservatezza della tua identità. Potrai esercitare i diritti di cui all’art. 7 del Codice in materia di protezione dei Dati Personali (es. accedere ai tuoi dati personali, integrarli, aggiornarli, rettificarli, opporsi al loro trattamento per motivi legittimi, ecc.) rivolgendoti direttamente al responsabile della ricerca. Potrai interrompere in ogni momento e senza fornire alcuna giustificazione la tua partecipazione allo studio: in tal caso, i dati raccolti verranno distrutti. Se lo richiederai, alla fine dello studio potranno esserti comunicati i risultati ottenuti in generale e, in particolare, quelli che ti riguardano. Per ulteriori informazioni e comunicazioni durante la ricerca puoi rivolgerti a … Potrai segnalare qualsiasi fatto che riterrai opportuno evidenziare, relativamente alla ricerca che ti riguarda, al Comitato Etico dell’Università degli Studi di Firenze. La segnalazione dovrà essere inoltrata all’attenzione di … È inoltre necessario che i partecipanti completino una dichiarazione di assenso (consenso informato). Ad esempio: Io sottoscritto … dichiaro di aver ricevuto dal Dottor … esaurienti spiegazioni in merito alla richiesta di partecipazione alla ricerca in oggetto, secondo quanto riportato nella scheda informativa qui allegata, copia della quale mi è stata prima d’ora consegnata (indicare data e ora della consegna). Dichiaro altresì di aver potuto discutere tali spiegazioni, porre tutte le domande che ho ritenuto necessarie e di aver ricevuto risposte soddisfacenti, come pure di aver avuto la possibilità di informarmi in merito ai particolari dello studio con persona di mia fiducia. Accetto dunque liberamente di partecipare alla ricerca, avendo compreso completamente il significato della richiesta e i rischi e benefici che possono derivare da questa partecipazione. Acconsento al trattamento dei miei dati personali per gli scopi della ricerca nei limiti e con le modalità indicate nell’informativa fornitami con il presente documento. Sono stato informato/a, inoltre, del mio diritto ad avere libero accesso alla documentazione relativa alla ricerca ed alla valutazione espressa dal Comitato Etico dell’Università degli Studi di Firenze. 13.2.4 La costruzione degli item La scelta di item tecnicamente adeguati sul piano strutturale e linguistico non è un problema statistico. La formulazione verbale degli item è molto importante in quanto essa contribuisce all’errore di misura. Per ridurre gli errori di misura, gli item devono essere formulati nella forma più chiara e meno ambigua possibile. È ovviamente necessario impiegare contenuti coerenti con la definizione del costrutto, ma non ci sono regole semplici per generare item che fanno emergere il costrutto che si cerca di misurare. Vanno certamente evitati contenuti che inducano atteggiamenti difensive e/o ostili nei rispondenti. La formulazione verbale deve inoltre essere appropriata al livello di scolarità dei rispondenti. Pett, Lackey e Sullivan (2003) forniscono le raccomandazioni seguenti. Evitare affermazioni che si riferiscono al passato a meno che il costrutto faccia direttamente riferimento al passato. Evitare affermazioni fattuali. Evitare affermazioni su cui quasi tutti (o quasi nessuno) sono d’accordo. Evitare l’uso di pronomi personali con un significato ambiguo. Selezionare item che potenzialmente possano coprire l’intera gamma delle possibili risposte concernenti il costrutto di interesse. Se viene fatto riferimento ad argomenti sensibili, la formulazione verbale deve essere la più neutra possibile. Utilizzare un linguaggio chiaro, semplice, diretto. Utilizzare frasi corte, altrimenti non ne è chiaro il senso. Evitare affermazioni ambigue o interpretabili in più modi. Evitare formulazioni sintattiche complesse. Evitare l’uso di parole a bassa frequenza o l’uso di una terminologia che potrebbe non essere capita dai rispondenti. Disporre gli item aventi un contenuto sensibile verso la fine dello strumento. Fare riferimento a comportamenti specifici e non generali. Evitare la duplicazione delle domande. 13.2.4.1 Desiderabilità sociale Quando si sviluppa lo strumento è necessario tenere in considerazione il fatto che i rispondenti tendono a fornire risposte socialmente desiderabili piuttosto che risposte veritiere (Rosenthal &amp; Rosnow, 1991; Waltz et al., 1991). La Desiderabilità sociale non soltanto introduce dei bias nello strumento ma può anche comprometterne la validità. La Desiderabilità Sociale si riferisce al bisogno provato da alcuni individui di approvazione sociale e accettazione, e alla credenza di poterle ottenere attraverso comportamenti appropriati e culturalmente accettati (Marlowe &amp; Crowne, 1961). La Desiderabilità Sociale consiste nella tendenza a fornire risposte molto positive quando vengono poste domande su di sé, con l’obiettivo di risultare positivamente agli occhi dell’altro. Marlowe e Crowne (1960) hanno proposto la scala di valutazione MC-SCS (Marlowe-Crowne Social Desirability Scale), largamente utilizzata per indagare questo costrutto. Un’altra scala di valutazione molto utilizzata è la BIDR (Balanced Inventory of Desirable Responding, 1991) proposta da Paulhus: tale scala contiene 40 item, volti a rilevare la gestione delle impressioni e l’autoinganno. 13.2.4.2 Item marker Quando si anticipa la presenza di più costrutti latenti, è utile utilizzare nell’insieme degli item alcuni item marker, ovvero item che correlano molto con un solo fattore e pochissimo con altri. Questo facilità l’interpretazione dei fattori. I marker consentono infatti di attribuire ai fattori un nome (etichetta) coerente con l’area semantica cui i maker fanno riferimento. 13.2.4.3 Campionamento del dominio Il campionamento del dominio può essere inteso sia come campionamento del contenuto o come campionamento del comportamento. L’adeguatezza del campionamento del contenuto riguarda il fatto che l’insieme degli item sia o meno in grado di rappresentare il dominio di contenuto di interesse. Questa caratteristica è un indice dell’adeguatezza del test nel misurare ciò che intende misurare e dovrebbe garantire che le risposte agli item possano rappresentare una stima della quantità di costrutto posseduta dal rispondente. Il campionamento del comportamento riguarda invece il grado in cui le risposte a un test costituiscono un campione adeguato dei comportamenti che il test intende misurare. In questo caso ci si chiede se il test riflette i comportamenti che intende valutare e possiede dunque un valore descrittivo del comportamento del rispondente. Un item mal formulato determina una distorsione delle risposte e non può essere considerato rappresentativo di nessun dominio di contenuto né di nessun universo di comportamenti. Per la generazione iniziale degli item è molto importante considerare il parere della popolazione target e degli esperti. Interviste accuratamente strutturate e a risposta aperta con esperti o potenziali soggetti permettono non solo di verificare che gli item siano rappresentativi o rilevanti per il costrutto, ma anche che siano formulati correttamente. Questo processo può anche suggerire sfaccettature ulteriori rispetto a quelle progettate inizialmente e la necessità di raffinare il costrutto. Nello sviluppo di un test è molto utile ascoltare il parere di persone inserite nel contesto applicativo del test anche per sapere qual è la terminologia specifica da utilizzare nella formulazione degli item, o se gli item sono chiari, o se la scala di risposta è di facile compilazione. È anche utile rivolgersi a giudici esterni aventi una conoscenza approfondita del dominio di contenuto per ottenere una prospettiva esterna e autorevole che aiuti nell’individuazione degli item da eliminare e di quelli che richiedono un raffinamento. Gli item di un test dovrebbero essere distribuiti in modo che riflettano la relativa importanza delle varie sfaccettature del costrutto target (Nunnally &amp; Bernstein, 1994). Se gli item per una certa sfaccettatura sono troppi o troppo pochi, i punteggi e le inferenze ottenute da questi punteggi saranno distorte. "],["numero-delle-opzioni-di-risposta.html", "13.3 Numero delle opzioni di risposta", " 13.3 Numero delle opzioni di risposta Un item è costituito da due parti: l’item stem, cioè il testo che contiene la domanda o l’affermazione da valutare e le alternative di risposta. In una scala di tipo Likert, le categorie di risposta si dicono a parziale autonomia semantica, ovvero sono tali per cui le modalità di risposta devono essere confrontate con le altre affinché il rispondente sia in grado di stabilire il loro valore. A ciascuna modalità di risposta viene attribuito un punteggio (4, 3, 2, 1 oppure 3, 2, 1, 0), e la somma (o media) dei punteggi alle risposte di ciascun individuo sull’intera batteria rappresenta la posizione dell’individuo sul concetto indagato. Per esempio, \\[\\text{Fortemente d&#39;accordo} \\quad 7\\quad 6 \\quad 5 \\quad 4 \\quad 3 \\quad 2 \\quad 1 \\quad \\text{Fortemente in disaccordo}\\] oppure, \\[\\text{Molto} \\quad \\text{Abbastanza}\\quad \\text{Poco} \\quad \\text{Per niente}\\] Il numero ottimale delle opzioni di risposta è stato dibattuto a lungo. Per esempio, Schutz e Rucker (1975) hanno trovato che “the number of available response categories does not materially affect the cognitive structure derived from the results” (p. 323), il che suggerisce che il numero di opzioni di risposta ha poco effetto sui risultati ottenuti. Tale conclusione, tuttavia, è stata contraddetta da altri ricercatori. Per esempio, Garner (1960) ha suggerito risultati massimamente informativi si ottengono utilizzando più di 20 opzioni di risposta. D’altra parte, Green e Rao (1970), hanno trovato che i risultati migliori si ottengono con sei o sette alternative di risposta, con un guadagno molto piccolo all’aumentare delle categorie di risposta al di là di sette. In un articolo molto citato, Preston e Colman (2000) hanno esaminato le risposte fornite da un campione di rispondenti variando il numero di opzioni di risposta pari a 2, 3, …, 11, e 101. Dopo avere calcolato l’attendibilità test-retest e la validità dello strumento, oltre al potere discriminante degli item, hanno concluso che le scale a 2, 3 e 4 passi hanno prestazioni piuttosto basse, avendo gli indici calcolati valori molto maggiori per le scale di risposta con un numero maggiore di opzioni di risposta. In particolare, i risultati dello studio suggeriscono che scale di valutazione con 7, 9 o 10 opzioni di risposta sono da preferire rispetto ad altri numeri di alternative di risposta. Oltre alle scale Likert è possibile usare le risposte auto-ancoranti, ovvero quelle in cui gli item prevedono solo due aggettivi di risposta, estremi (per esempio, “per niente” e “molto”), legati da un segmento continuo in cui il rispondente deve scegliere la propria posizione. Un esempio è la Visual Analogue Scale usata nella misura dell’umore. Tali scale sono molto più rare delle scale Likert. 13.3.1 Item a codifica inversa Alcuni item correlano fortemente in maniera negativa con gli altri item e con il punteggio totale del test. Tali item richiedono una codifica inversa. Ad esempio, due item del questionario S.T.A.I per la valutazione dell’ansia sono codificati nel modo seguente. “Sono preoccupata.” \\[\\text{Per nulla} \\quad \\text{Un po&#39;}\\quad \\text{Abbastanza} \\quad \\text{Moltissimo}\\] con valori 1, 2, 3 e 4, rispettivamente. “Mi sento bene.” \\[\\text{Per nulla} \\quad \\text{Un po&#39;}\\quad \\text{Abbastanza} \\quad \\text{Moltissimo}\\] con valori 4, 3, 2, e 1, rispettivamente. In ambito psicometrico si è soliti ritenere che due proprietà contrarie giacciano sullo stesso continuum latente. Nella costruzione di un test psicologico viene dunque consigliato di utilizzare sia item con contenuto orientato nella direzione del costrutto (per cui punteggi alti nell’item sono il riflesso di un alto livello del costrutto) sia nella direzione opposta (per cui punteggi alti nell’item sono il riflesso di un basso livello del costrutto). Nel primo caso si parla di straight item, nel secondo di reverse item. Lo scopo centrale degli item reverse è quello di contrastare l’acquiescenza, ovvero di rallentare il soggetto nella compilazione del test, evitando di rispondere in maniera automatica, così da prestare maggiore attenzione al contenuto degli item. "],["numero-di-item.html", "13.4 Numero di item", " 13.4 Numero di item Un test psicometrico, oltre ad essere valido, deve minimizzare l’errore di misura. L’attendibilità di uno strumento sia dall’attendibilità di ciascun item, sia dal numero di item che lo compongono. Tratteremo di questo argomento in un capitolo successivo. Kline (1986) suggerisce di costruire un numero di item almeno doppio del numero di item che andranno a costituire il test finale. La lunghezza del test dipende dal suo scopo. Un Test di valutazione delle abilità per la scuola primaria non deve richiedere più di trenta minuti per essere completato, altrimenti la fatica e la noia finiscono per distorcere i risultati dello strumento. Lo stesso si può dire per un test di personalità per soggetti adulti. Idealmente, un test dovrebbe essere il più breve possibile, a patto di raggiungere un livello adeguato di validità. Come regola euristica, Kline (1986) suggerisce la soglia di almeno 50 item nella forma finale del test. "],["numero-di-soggetti.html", "13.5 Numero di soggetti", " 13.5 Numero di soggetti Vi è poco accordo su quale sia la grandezza del campione necessaria per lo svolgimento dell’analisi fattoriale. Nunnally (1978) ha suggerito che il campione deve essere costituito da almeno 10 soggetti per ciascun item. Comrey e Lee (1992) hanno fornito le seguenti indicazioni: 50—very poor, 100—poor, 200—fair, 300—good, 500—very good, 1,000 or more—excellent. Secondo altri autori “as a general rule of thumb, it is comforting to have at least 300 cases for factor analysis” (Tabachnick e Fidell, 2001). "],["valutazione-della-matrice-di-correlazione.html", "Capitolo 14 Valutazione della matrice di correlazione", " Capitolo 14 Valutazione della matrice di correlazione L’analisi fattoriale, essendo una tecnica di analisi multivariata, richiede la comprensione di almeno alcuni concetti di base dell’algebra matriciale. A livello minimale è necessario capire che cosa sono i vettori e le matrici, che cosa è il determinante di una matrice, e in che modo possano essere eseguite le operazioni algebriche su vettori e matrici (si veda l’Appendice). Dopo avere padroneggiato gli aspetti di base dell’algebra matriciale, possiamo valutare il determinante della matrice da fattorializzare: se il determinante è nullo non si può fare l’analisi. Se invece il determinante non è nullo, ci possiamo chiedere se le correlazioni campionarie siano sufficientemente grandi da giustificare l’analisi fattoriale. Se le correlazioni tra gli item sono di modesta entità, allora la soluzione fornita dall’analisi fattoriale non consentirà una descrizione parsimoniosa delle informazioni contenute nella matrice delle correlazioni. Per rispondere a questa domanda si ricorre all’ispezione visiva della matrice di correlazione e si possono svolgere due test: il test della sfericità di Bartlett e il Kaiser-Meyer-Olkin test. "],["ispezione-visiva-della-matrice-di-correlazione.html", "14.1 Ispezione visiva della matrice di correlazione", " 14.1 Ispezione visiva della matrice di correlazione L’ispezione visiva della matrice di correlazione viene effettuata per vedere che vi siano blocchi di correlazioni alte fra loro e basse con le alte. "],["sfericità-di-bartlett.html", "14.2 Sfericità di Bartlett", " 14.2 Sfericità di Bartlett Il test della sfericità di Bartlett verifica l’ipotesi \\(H_0 : \\boldsymbol{R} = \\boldsymbol{I}\\) (ovvero che gli item siano tra loro incorrelati) tramite la formula: \\[\\chi^2 = -\\bigg[n -1 -\\frac{1}{6} (2p +5)\\bigg] \\ln |\\boldsymbol{R}|,\\] in cui \\(n\\) è il numero dei soggetti, \\(p\\) il numero delle variabili e \\(|\\boldsymbol{R}|\\) il determinante della matrice di correlazione. La statistica del test della sfericità di Bartlett si distribuisce come \\(\\chi^2\\) con \\(p(p - 1)/2\\) gradi di libertà. Se il risultato del test è significativo (ovvero, se il valore della statistica test è sufficientemente grande), significa che \\(\\boldsymbol{R}\\) ha correlazioni sufficientemente elevate da non essere paragonabili a 0; se è non significativo le correlazioni sono basse e non si distinguono da 0. Il limite di questo test è che dipende dal numero delle variabili e dalla numerosità del campione, quindi tende ad essere significativo all’aumentare del campione e del numero delle variabili anche se ci sono correlazioni basse. "],["test-di-adeguatezza-campionaria-di-kaiser-meyer-olkin.html", "14.3 Test di adeguatezza campionaria di Kaiser-Meyer-Olkin", " 14.3 Test di adeguatezza campionaria di Kaiser-Meyer-Olkin Henry Kaiser (1970) ha introdotto una misura di adeguatezza campionaria per le matrici sottoposte ad analisi fattoriale. In seguito, Kaiser and Rice (1974) hanno modificato questo indice che da allora è conosciuto come l’indice Kaiser-Meyer-Olkin (KMO). Il test di adeguatezza campionaria KMO è dato da \\[\\text{KMO} = \\frac{\\sum_i\\sum_j r^2_{ij}}{\\sum_i\\sum_j r^2_{ij} +\\sum_i\\sum_jp^2_{ij}},\\] dove \\(r_{ij}\\) sono le correlazioni osservate e \\(p_{ij}\\) sono le correlazioni parzializzate su tutte le altre. Se le correlazioni parzializzate sono piccole, KMO tende a 1. Secondo Kaiser (1970), se KMO &gt; 0.90, l’adeguatezza campionaria è eccellente, fra .80 e .90 è buona, fra .70 e .80 è accettabile, fra .60 e .70 è mediocre, se è inferiore a .60 è meglio non fare l’analisi. 14.3.1 Matrice anti-immagine La matrice delle correlazioni parzializzate riporta il valore di ogni correlazione dopo aver eliminato il contributo di tutte le altre variabili non implicate. Una correlazione parzializzata alta significa che due variabili sono molto correlate fra loro, ma non hanno legami con nessun altra variabile. L’analisi fattoriale richiede invece che ci siano più di due variabili per fattore. La matrice anti-immagine contiene i complementi a 1 della correlazione parzializzata fra due variabili rispetto a tutte e altre. Valori alti indicano correlazioni parziali basse e viceversa. "],["ch-estrazione.html", "Capitolo 15 L’estrazione dei fattori ", " Capitolo 15 L’estrazione dei fattori "],["motivazione.html", "15.1 Motivazione", " 15.1 Motivazione Lo scopo dell’analisi fattoriale è quello di descrivere in maniera parsimoniosa le relazioni che intercorrono tra un grande numero di item. Ci si chiede se è possibile identificare un piccolo numero di variabili latenti che, quando vengono controllate, rendono uguali a zero le correlazioni parziali tra gli item. Abbiamo visto nel capitolo precedente come sia possibile determinare il numero dei fattori comuni. Chiediamoci ora come sia possibile stimare le saturazioni fattoriali che corrispondono alle correlazioni (o covarianze) tra gli item e i fattori. In termini matriciali, il modello multifattoriale si scrive \\[ \\boldsymbol{\\Sigma} =\\boldsymbol{\\Lambda} \\boldsymbol{\\Phi} \\boldsymbol{\\Lambda}^{\\mathsf{T}} + \\boldsymbol{\\Psi} \\] dove \\(\\boldsymbol{\\Phi}\\) è la matrice di ordine \\(m \\times m\\) di varianze e covarianze tra i fattori comuni e \\(\\boldsymbol{\\Psi}\\) è una matrice diagonale di ordine \\(p\\) con le unicità delle variabili. Poniamoci ora il problema di stimare \\(\\boldsymbol{\\Lambda}\\). "],["metodo-delle-componenti-principali.html", "15.2 Metodo delle componenti principali", " 15.2 Metodo delle componenti principali L’analisi fattoriale eseguita mediante il metodo delle componenti principali, nonostante il nome, non è un’analisi delle componenti principali. Il metodo delle componenti principali costituisce invece un’applicazione del teorema di scomposizione spettrale di una matrice. Il teorema spettrale afferma che “data la matrice simmetrica \\(\\textbf{S}_{p \\times p}\\), è sempre possibile trovare una matrice \\(\\textbf{C}_{p \\times p}\\) ortogonale tale che \\[ \\textbf{S} = \\textbf{C}\\textbf{D}\\textbf{C}^{\\mathsf{T}} \\] con D diagonale.” Il teorema specifica inoltre che gli elementi presenti sulla diagonale di D sono gli autovalori di S, mentre le colonne di C rappresentano i rispettivi autovettori normalizzati associati agli autovalori di S. Facciamo un esempio numerico utilizzando i dati discussi da Rencher(2002). Brown, Williams e Barlow (1984) hanno raccolto le valutazioni di una ragazza dodicenne relativamente a sette persone di sua conoscenza. Ciascuna persona veniva valutata su una scala a nove punti rispetto a cinque variabili: kind, intelligent, happy, likeable e just. La matrice di correlazione per tali variabili è riportata di seguito: R &lt;- matrix( c( 1.000, .296, .881, .995, .545, .296, 1.000, -.022, .326, .837, .881, -.022, 1.000, .867, .130, .995, .326, .867, 1.000, .544, .545, .837, .130, .544, 1.000 ), ncol = 5, byrow = T, dimnames = list( c(&quot;K&quot;, &quot;I&quot;, &quot;H&quot;, &quot;L&quot;, &quot;J&quot;), c(&quot;K&quot;, &quot;I&quot;, &quot;H&quot;, &quot;L&quot;, &quot;J&quot;) ) ) Gli autovalori e gli autovettori si calcolano con la funzione eigen(): e &lt;- eigen(R) print(e, 3) #&gt; eigen() decomposition #&gt; $values #&gt; [1] 3.263377 1.538382 0.167969 0.030030 0.000242 #&gt; #&gt; $vectors #&gt; [,1] [,2] [,3] [,4] [,5] #&gt; [1,] -0.537 -0.186 -0.1899 -0.125 0.791 #&gt; [2,] -0.287 0.651 0.6849 -0.120 0.103 #&gt; [3,] -0.434 -0.474 0.4069 0.614 -0.212 #&gt; [4,] -0.537 -0.169 -0.0953 -0.629 -0.527 #&gt; [5,] -0.390 0.538 -0.5658 0.444 -0.204 Come indicato in precedenza, la matrice R può essere espressa come \\(\\textbf{R} = \\textbf{C}\\textbf{D}\\textbf{C}^{\\ensuremath{\\mathsf{T}}}\\): e$vectors %*% diag(e$values) %*% t(e$vectors) #&gt; [,1] [,2] [,3] [,4] [,5] #&gt; [1,] 1.000 0.296 0.881 0.995 0.545 #&gt; [2,] 0.296 1.000 -0.022 0.326 0.837 #&gt; [3,] 0.881 -0.022 1.000 0.867 0.130 #&gt; [4,] 0.995 0.326 0.867 1.000 0.544 #&gt; [5,] 0.545 0.837 0.130 0.544 1.000 Esaminiamo ora gli autovalori. I primi due autovalori spiegano da soli il 96% della varianza campionaria: (e$values[1] + e$values[2]) / 5 #&gt; [1] 0.9603517 Usando i primi due autovalori e i primi due autovettori sarà dunque possibile riprodurre in maniera soddisfacente la matrice R operando nel contempo una riduzione di dimensionalità dei dati. Per fattorizzare \\(\\textbf{R} = \\textbf{C}\\textbf{D}\\textbf{C}^{\\ensuremath{\\mathsf{T}}}\\) nella forma \\(\\hat{\\boldsymbol{\\Lambda}} \\hat{\\boldsymbol{\\Lambda}}^{\\ensuremath{\\mathsf{T}}}\\) iniziamo a scrivere \\[\\textbf{D}= \\textbf{D}^{1/2} \\textbf{D}^{1/2}\\] dove \\[ \\textbf{D}^{1/2} = \\left[ \\begin{array}{ c c c c } \\sqrt{\\theta_1} &amp; 0 &amp; \\dots &amp; 0 \\\\ 0 &amp; \\sqrt{\\theta_2} &amp; \\dots &amp; 0 \\\\ \\dots &amp; \\dots &amp; &amp; \\dots \\\\ 0 &amp; 0 &amp; \\dots &amp; \\sqrt{\\theta_p} \\end{array} \\right] \\] Viene qui usata la notazione \\(\\theta\\) per denotare gli autovalori anziché il tradizionale \\(\\lambda\\) per evitare la confusione con la notazione \\(\\lambda_{jl}\\) usata per le saturazioni fattoriali. In questo modo, possiamo scrivere \\[\\begin{equation} \\begin{aligned} \\textbf{R} &amp;= \\textbf{C}\\textbf{D}\\textbf{C}^{\\mathsf{T}}\\notag\\\\ &amp;= \\textbf{C}\\textbf{D}^{1/2}\\textbf{D}^{1/2}\\textbf{C}^{\\mathsf{T}}\\notag\\\\ &amp;= (\\textbf{C}\\textbf{D}^{1/2}) (\\textbf{C}\\textbf{D}^{1/2})^{\\mathsf{T}} \\end{aligned} \\end{equation}\\] Non possiamo però limiarci a definire \\(\\hat{\\boldsymbol{\\Lambda}}=\\textbf{C}\\textbf{D}^{1/2}\\) in quanto \\(\\textbf{C}\\textbf{D}^{1/2}\\) è di ordine \\(p \\times p\\) e non otteniamo quindi una riduzione di dimensioni. Quello che cerchiamo è una matrice \\(\\hat{\\boldsymbol{\\Lambda}}\\) di ordine \\(p \\times m\\) con \\(m &lt; p\\). Dunque, definiamo la matrice \\(\\textbf{D}_1= \\text{diag}(\\theta_1, \\theta_2, \\dots, \\theta_m)\\) come la la matrice contenente gli \\(m\\) autovalori più grandi di R e \\(\\textbf{C}_1=( \\textbf{c}_1, \\textbf{c}_2, \\dots, \\textbf{c}_m)\\) come la matrice contenente i rispettivi autovettori. Mediante il metodo delle componenti principali, le saturazioni fattoriali \\(\\hat{\\boldsymbol{\\Lambda}}\\) vengono quindi stimate nel modo seguente: \\[\\begin{equation} \\begin{aligned} \\hat{\\boldsymbol{\\Lambda}} &amp;= \\textbf{C}_1 \\textbf{D}_1^{1/2}\\notag\\\\ &amp;= (\\sqrt{\\theta_1} \\textbf{c}_1, \\sqrt{\\theta_2} \\textbf{c}_2, \\dots, \\sqrt{\\theta_m} \\textbf{c}_m) \\end{aligned} \\end{equation}\\] Per l’esempio presente, con \\(m=2\\) e \\(p=5\\), avremo \\[ \\left[ \\begin{array}{ c c } \\hat{\\lambda}_{11} &amp; \\hat{\\lambda}_{12} \\\\ \\hat{\\lambda}_{21} &amp; \\hat{\\lambda}_{22} \\\\ \\hat{\\lambda}_{31} &amp; \\hat{\\lambda}_{32} \\\\ \\hat{\\lambda}_{41} &amp; \\hat{\\lambda}_{42} \\\\ \\hat{\\lambda}_{51} &amp; \\hat{\\lambda}_{52} \\end{array} \\right] = \\left[ \\begin{array}{ c c } c_{11} &amp; c_{12} \\\\ c_{21} &amp; c_{22} \\\\ c_{31} &amp; c_{32} \\\\ c_{41} &amp; c_{42} \\\\ c_{51} &amp; c_{52} \\end{array} \\right] \\left[ \\begin{array}{ c c } \\sqrt{\\theta_1} &amp; 0\\\\ 0 &amp;\\sqrt{\\theta_2} \\end{array} \\right] \\] Le saturazioni fattoriali stimate sono dunque uguali a \\[ \\left[ \\begin{array}{ c c } \\sqrt{\\theta_1}c_{11} &amp; \\sqrt{\\theta_2}c_{12} \\\\ \\sqrt{\\theta_1}c_{21} &amp; \\sqrt{\\theta_2}c_{22} \\\\ \\sqrt{\\theta_1}c_{31} &amp; \\sqrt{\\theta_2}c_{32} \\\\ \\sqrt{\\theta_1}c_{41} &amp; \\sqrt{\\theta_2}c_{42} \\\\ \\sqrt{\\theta_1}c_{51} &amp; \\sqrt{\\theta_2}c_{52} \\end{array} \\right] \\] Svolgendo i calcoli con \\(\\textsf{R}\\) otteniamo: L &lt;- cbind( e$vectors[, 1] * sqrt(e$values[1]), e$vectors[, 2] * sqrt(e$values[2]) ) round(L, 3) #&gt; [,1] [,2] #&gt; [1,] -0.970 -0.231 #&gt; [2,] -0.519 0.807 #&gt; [3,] -0.785 -0.588 #&gt; [4,] -0.971 -0.210 #&gt; [5,] -0.704 0.667 La matrice di correlazione riprodotta (con le comunalità sulla diagonale principale) diventa round(L %*% t(L), 3) #&gt; [,1] [,2] [,3] [,4] [,5] #&gt; [1,] 0.993 0.317 0.896 0.990 0.529 #&gt; [2,] 0.317 0.921 -0.067 0.335 0.904 #&gt; [3,] 0.896 -0.067 0.961 0.885 0.160 #&gt; [4,] 0.990 0.335 0.885 0.987 0.543 #&gt; [5,] 0.529 0.904 0.160 0.543 0.940 Possiamo ora capire il motivo del nome “metodo delle componenti principali.” Le saturazioni fattoriali sono proporzionali agli autovettori di \\(\\textbf{R}\\). Tuttavia, dopo la rotazione delle saturazioni fattoriali, l’interpretazione dei fattori è diversa da quella che viene assegnata ai risultai dell’analisi delle componenti principali. È possibile condurre l’analisi fattoriale con il metodo delle componenti principali sia utilizzando la matrice \\(\\textbf{S}\\) di varianze-covarianze sia la matrice \\(\\textbf{R}\\) delle correlazioni. Tuttavia, le soluzioni ottenute usando \\(\\textbf{S}\\) o \\(\\textbf{R}\\) non sono legate da una relazione algebrica: il metodo delle componenti principali non è invariante rispetto ai cambiamenti di scala delle osservazioni. Un altro svantaggio del metodo delle componenti principali è che non fornisce un test di bontà di adattamento. Tale test può essere invece svolto quando la soluzione viene trovata con il metodo della massima verosimiglianza. "],["metodo-dei-fattori-principali.html", "15.3 Metodo dei fattori principali", " 15.3 Metodo dei fattori principali Il metodo dei fattori principali (principal factor method, anche detto principal axis method) è uno dei metodi maggiormente usati per la stima delle saturazioni fattoriali e delle comunalità. Il metodo delle componenti principali trascura la specificità \\(\\boldsymbol{\\Psi}\\) e si limita a fattorializzare le covarianze di S o le correlazioni di R. Il metodo dei fattori principali utilizza una procedura simile al metodo delle componenti principali, utilizzando però una matrice ridotta di varianze-covarianze \\(\\textbf{S} - \\hat{\\boldsymbol{\\Psi}}\\) in cui una stima delle comunalità viene sostituita alle varianze presenti sulla diagonale principale. Nel caso della matrice ridotta di correlazioni \\(\\textbf{R} - \\hat{\\boldsymbol{\\Psi}}\\), per la comunalità \\(i\\)-esima \\(\\sum_{j}\\lambda_{ij}^2\\) si sceglie il quadrato del coefficiente di correlazione multipla tra \\(Y_i\\) e tutte le altre \\(p-1\\) variabili. Tale valore si può trovare nel modo seguente: \\[\\hat{h}^2_i=R^2_i=1-\\frac{1}{r^{ii}}\\] dove \\(r^{ii}\\) è l’elemento diagonale \\(i\\)-esimo di \\(\\textbf{R}^{-1}\\). Nel caso di una matrice ridotta di varianze-covarianze \\(\\textbf{S} - \\hat{\\boldsymbol{\\Psi}}\\), le comunalità possono essere stimate calcolando \\[\\hat{h}_i^2=s_{ii}-\\frac{1}{r^{ii}}\\] dove \\(s_{ii}\\) è l’elemento diagonale \\(i\\)-esimo di \\(\\textbf{S}\\). Affinché le stime comunalità possano essere calcolate come descritto sopra, la matrice \\(\\textbf{R}\\) deve essere non singolare. Nel caso in cui \\(\\textbf{R}\\) sia singolare, per la stima della comunalità \\(i\\)-esima, \\(\\hat{h}^2_i\\), si utilizza il valore assoluto del più elevato coefficiente di correlazione lineare tra \\(Y_i\\) e le altre variabili. Scelta la stima della comunalità, la matrice ridotta di varianze-covarianze si ottiene sostituendo alle varianze sulla diagonale principale le stime delle comunalità: \\[ \\textbf{S} - \\hat{\\boldsymbol{\\Psi}} = \\left[ \\begin{array}{ c c c c } \\hat{h}^2_1 &amp; s_{12} &amp; \\dots &amp; s_{1p} \\\\ s_{21} &amp; \\hat{h}^2_2 &amp; \\dots &amp; s_{2p} \\\\ \\dots &amp; \\dots &amp; &amp; \\dots\\\\ s_{p1} &amp; s_{p2} &amp; \\dots &amp; \\hat{h}^2_p \\end{array} \\right] \\] In maniera equivalente, la matrice ridotta di correlazioni si ottiene nel modo seguente: \\[ \\textbf{R} - \\hat{\\boldsymbol{\\Psi}} = \\left[ \\begin{array}{ c c c c } \\hat{h}^2_1 &amp; r_{12} &amp; \\dots &amp; r_{1p} \\\\ r_{21} &amp; \\hat{h}^2_2 &amp; \\dots &amp; r_{2p} \\\\ \\dots &amp; \\dots &amp; &amp; \\dots\\\\ r_{p1} &amp; r_{p2} &amp; \\dots &amp; \\hat{h}^2_p \\end{array} \\right] \\] Verranno ora svolti i calcoli necessari per la stima dei coefficienti di saturazione con il metodo dei fattori principali utilizzando la matrice di correlazione dell’esempio precedente. Quale stima della comunalità \\(i\\)-esima, verrà utilizzato il valore assoluto più elevato nella riga \\(i\\)-esima della matrice R. Per i dati dell’esempio, le stime delle comunalità sono dunque pari a \\(0.995\\), \\(0.837\\), \\(0.881\\), \\(0.995\\) e \\(0.837\\). Inserendo tali valori nella diagonale principale, otteniamo la matrice ridotta delle correlazioni \\(\\textbf{R} - \\hat{\\boldsymbol{\\Psi}}\\): R1 &lt;- R h.hat &lt;- c(.995, .837, .881, .995, .837) R1[cbind(1:5, 1:5)] &lt;- h.hat R1 #&gt; K I H L J #&gt; K 0.995 0.296 0.881 0.995 0.545 #&gt; I 0.296 0.837 -0.022 0.326 0.837 #&gt; H 0.881 -0.022 0.881 0.867 0.130 #&gt; L 0.995 0.326 0.867 0.995 0.544 #&gt; J 0.545 0.837 0.130 0.544 0.837 Gli autovalori della matrice ridotta di correlazioni \\(\\textbf{R} - \\hat{\\boldsymbol{\\Psi}}\\) sono: ee &lt;- eigen(R1) round(ee$values, 3) #&gt; [1] 3.202 1.394 0.029 0.000 -0.080 La somma degli autovalori è uguale a sum(ee$values) #&gt; [1] 4.545 I primi due autovalori di \\(\\textbf{R} - \\hat{\\boldsymbol{\\Psi}}\\) sono: round(ee$vectors[, 1:2], 3) #&gt; [,1] [,2] #&gt; [1,] -0.548 -0.177 #&gt; [2,] -0.272 0.656 #&gt; [3,] -0.431 -0.461 #&gt; [4,] -0.549 -0.159 #&gt; [5,] -0.373 0.549 Moltiplicando tali valori per la radice quadrata dei rispettivi autovalori si ottengono le stime delle saturazioni fattoriali: round(ee$vectors[, 1:2] %*% sqrt(diag(ee$values[1:2])), 3) #&gt; [,1] [,2] #&gt; [1,] -0.981 -0.209 #&gt; [2,] -0.487 0.774 #&gt; [3,] -0.772 -0.544 #&gt; [4,] -0.982 -0.187 #&gt; [5,] -0.667 0.648 Tale risultato replica quello riportato da Rencher (2002). "],["metodo-dei-fattori-principali-iterato.html", "15.4 Metodo dei fattori principali iterato", " 15.4 Metodo dei fattori principali iterato Solitamente, per migliorare la stima della comunalità, la diagonale della matrice \\(\\textbf{S} - \\hat{\\boldsymbol{\\Psi}}\\) o \\(\\textbf{R} - \\hat{\\boldsymbol{\\Psi}}\\) viene ottenuta per iterazione. Dopo avere trovato \\(\\hat{\\boldsymbol{\\Lambda}}\\) a partire da \\(\\textbf{S} - \\hat{\\boldsymbol{\\Psi}}\\) o \\(\\textbf{R} - \\hat{\\boldsymbol{\\Psi}}\\) come indicato in precedenza, utilizzando le stime delle saturazioni fattoriali così ottenute possiamo stimare le comunalità nel modo seguente: \\[\\hat{h}^2_i = \\sum_{i=1}^m \\hat{\\lambda}_{ij}^2.\\] I valori di \\(\\hat{h}^2_i\\) vengono quindi sostituiti nella diagonale della matrice ridotta \\(\\textbf{S} - \\hat{\\boldsymbol{\\Psi}}\\) o \\(\\textbf{R} - \\hat{\\boldsymbol{\\Psi}}\\). A partire da questa nuova matrice, usando il metodo descritto in precedenza, possiamo così ottenere una nuova stima delle saturazioni fattoriali \\(\\hat{\\boldsymbol{\\Lambda}}\\). Mediante questa nuova stima di \\(\\hat{\\boldsymbol{\\Lambda}}\\), possiamo procedere ad una nuova stima delle comunalità. Tale processo continua iterativamente sino alla convergenza. Gli autovalori e gli autovettori della versione finale di \\(\\textbf{S} - \\hat{\\boldsymbol{\\Psi}}\\) o \\(\\textbf{R} - \\hat{\\boldsymbol{\\Psi}}\\) vengono infine usati per stimare i pesi fattoriali. Il metodo dei fattori principali iterato e il metodo delle componenti principali producono risultati molto simili quando \\(m\\) assume un piccolo valore (questo si verifica quando le correlazioni sono alte) e quando \\(p\\) (il numero delle variabili) è grande. 15.4.1 Casi di Heywood Tra gli inconvenienti del metodo dei fattori principali iterato vi è il fatto che può talvolta portare a soluzioni inammissibili (quando viene fattorizzata la matrice R) caratterizzate da valori di comunalità maggiori di uno (caso di Heywood). Se \\(\\hat{h}^2_i &gt; 1\\) allora \\(\\hat{\\psi}_i &lt; 0\\) il che è chiaramente assurdo in quanto una varianza non può assumere un valore negativo. Solitamente, quando la stima di una comunalità è maggiore di uno, il processo iterativo viene interrotto e il programma riporta che non può essere trovata una soluzione. Nell’esempio presente viene utilizzata la funzione factor.pa() contenuta nel pacchetto psych per trovare la soluzione dei fattori principali mediante il metodo iterativo: pa &lt;- fa(R, nfactors = 2, rotate = &quot;none&quot;, fm = &quot;pa&quot;) pa #&gt; Factor Analysis using method = pa #&gt; Call: fa(r = R, nfactors = 2, rotate = &quot;none&quot;, fm = &quot;pa&quot;) #&gt; Standardized loadings (pattern matrix) based upon correlation matrix #&gt; PA1 PA2 h2 u2 com #&gt; K 0.98 -0.21 1.01 -0.008 1.1 #&gt; I 0.48 0.74 0.77 0.230 1.7 #&gt; H 0.78 -0.56 0.92 0.085 1.8 #&gt; L 0.98 -0.19 0.99 0.010 1.1 #&gt; J 0.69 0.69 0.95 0.049 2.0 #&gt; #&gt; PA1 PA2 #&gt; SS loadings 3.22 1.41 #&gt; Proportion Var 0.64 0.28 #&gt; Cumulative Var 0.64 0.93 #&gt; Proportion Explained 0.70 0.30 #&gt; Cumulative Proportion 0.70 1.00 #&gt; #&gt; Mean item complexity = 1.5 #&gt; Test of the hypothesis that 2 factors are sufficient. #&gt; #&gt; The degrees of freedom for the null model are 10 and the objective function was 12 #&gt; The degrees of freedom for the model are 1 and the objective function was 5.6 #&gt; #&gt; The root mean square of the residuals (RMSR) is 0.01 #&gt; The df corrected root mean square of the residuals is 0.04 #&gt; #&gt; Fit based upon off diagonal values = 1 Si noti che, in questo caso, le unicità assumono valori negativi, il che suggerisce che la soluzione è impropria. "],["metodo-di-massima-verosimiglianza.html", "15.5 Metodo di massima verosimiglianza", " 15.5 Metodo di massima verosimiglianza L’applicazione del metodo di massima verosimiglianza è indicata quando si può assumere che le variabili manifeste seguono una distribuzione normale multivariata. Sotto tali condizioni, tale metodo produce le stime dei pesi fattoriali che più verosimilmente hanno prodotto le correlazioni osservate. Gli stimatori di massima verosimiglianza sono preferibili a quelli ottenuti con altri metodi, sempre che siano pienamente realizzate le premesse. La funzione \\(F\\) da minimizzare rappresenta una misura di “distanza” tra la matrice di covarianza osservata e quella predetta dal modello. Uguagliando a zero le derivate di \\(F\\) rispetto a \\(\\boldsymbol{\\Lambda}\\) e \\(\\boldsymbol{\\Psi}\\) si ottengono le equazioni per le stime di massima verosimiglianza di \\(\\hat{\\boldsymbol{\\Lambda}}\\) e \\(\\hat{\\boldsymbol{\\Psi}}\\). Risolvendo tali equazioni rispetto alle incognite \\(\\hat{\\boldsymbol{\\Lambda}}\\) e \\(\\hat{\\boldsymbol{\\Psi}}\\) si ricavano le stime di massima verosimiglianza. Non esistendo una soluzione analitica per queste equazioni, si ricorre a procedimenti numerici iterativi che talvolta presentano problemi di convergenza. La soluzione, pur presentando la possibilità di fornire delle stime di comunalità superiori a 1 (caso di Heywood), è equivariante rispetto a cambiamenti di scala: le stime di massima verosimiglianza sono indipendenti dall’unità di misura delle variabili manifeste. Pertanto, si ottiene la stessa soluzione sia che si analizzi la matrice delle varianze e covarianze, sia che si analizzi la matrice delle correlazioni. Consideriamo nuovamente i dati dell’esempio precedente. Le istruzioni sono le seguenti: factanal(covmat = R, factors = 2, rotation = &quot;none&quot;, n.obs = 225) #&gt; #&gt; Call: #&gt; factanal(factors = 2, covmat = R, n.obs = 225, rotation = &quot;none&quot;) #&gt; #&gt; Uniquenesses: #&gt; K I H L J #&gt; 0.005 0.268 0.055 0.008 0.005 #&gt; #&gt; Loadings: #&gt; Factor1 Factor2 #&gt; K 0.955 -0.289 #&gt; I 0.528 0.673 #&gt; H 0.720 -0.653 #&gt; L 0.954 -0.287 #&gt; J 0.764 0.642 #&gt; #&gt; Factor1 Factor2 #&gt; SS loadings 3.203 1.457 #&gt; Proportion Var 0.641 0.291 #&gt; Cumulative Var 0.641 0.932 #&gt; #&gt; Test of the hypothesis that 2 factors are sufficient. #&gt; The chi square statistic is 648.09 on 1 degree of freedom. #&gt; The p-value is 5.81e-143 "],["il-numero-dei-fattori.html", "Capitolo 16 Il numero dei fattori", " Capitolo 16 Il numero dei fattori Sono stati proposti quattro criteri per determinare il numero \\(m\\) di fattori da estrarre (Rencher, 2002). Tali criteri sono elencati di seguito. Scegliere \\(m\\) tale per cui la varianza spiegata dal modello fattoriale superi una soglia predeterminata, per esempio l’80% della varianza totale, \\(tr(\\textbf{S})\\) o \\(tr(\\textbf{R})\\). Scegliere \\(m\\) uguale al numero di autovalori aventi un valore maggiore del valore medio degli autovalori. Per R il valore medio degli autovalori è \\(1\\); per S è \\(\\sum_{j=1}^p \\theta_j/p\\). Usare lo scree test. Valutare l’ipotesi che \\(m\\) sia il numero corretto di fattori, \\(H_0: \\boldsymbol{\\Sigma} = \\boldsymbol{\\Lambda} \\boldsymbol{\\Lambda}^{\\ensuremath{\\mathsf{T}}} + \\boldsymbol{\\Psi}\\), dove \\(\\boldsymbol{\\Lambda}\\) è di ordine \\(p \\times m\\). "],["quota-di-varianza-spiegata.html", "16.1 Quota di varianza spiegata", " 16.1 Quota di varianza spiegata Il primo criterio si applica soprattutto al metodo delle componenti principali. La proporzione della varianza capionaria spiegata dal fattore \\(j\\)-esimo estratto da S è uguale a \\[\\sum_{i=i}^p \\hat{\\lambda}_{ij}^2 / tr(\\textbf{S}).\\] Nel caso in cui i fattori vengano estratti da R avremo \\[\\sum_{i=i}^p \\hat{\\lambda}_{ij}^2 / p.\\] Nel caso di fattori incorrelati, ciascun fattore contribuisce con una quota complessiva di varianza spiegata pari alla somma dei quadrati delle saturazioni fattoriali contenute nella matrice \\(\\hat{\\boldsymbol{\\Lambda}}\\): \\(\\sum_{i=1}^p\\sum_{j=1}^m\\hat{\\lambda}_{ij}^2\\). Nel caso del metodo delle componenti principali, tale somma è anche uguale alla somma dei primi \\(m\\) autovalori, o alla somma di tutte le \\(p\\) comunalità: \\[\\sum_{i=1}^p\\sum_{j=1}^m\\hat{\\lambda}_{ij}^2= \\sum_{i=1}^p \\hat{h}_i^2 = \\sum_{j=1}^m \\theta_j\\] Sulla base di queste considerazioni, il numero \\(m\\) di fattori viene scelto in modo da spiegare una quota sufficientemente grande di S o \\(p\\). Il numero dei fattori può essere determinato in questo modo anche nel caso in cui l’analisi fattoriale venga eseguita con il metodo dei fattori principali (ovvero, nel caso in cui vengano usate le stime delle comunalità per generare la matrice ridotta \\(\\textbf{S} - \\hat{\\boldsymbol{\\Psi}}\\) o \\(\\textbf{R} - \\hat{\\boldsymbol{\\Psi}}\\)). In questo caso, però, è possibile che alcuni autovalori della matrice \\(\\textbf{S} - \\hat{\\boldsymbol{\\Psi}}\\) o \\(\\textbf{R} - \\hat{\\boldsymbol{\\Psi}}\\) assumano valore negativo. In tali circostanze, è possibile che la proporzione cumulativa della varianza \\(\\sum_{j=1}^m \\theta_j / \\sum_{j=1}^p \\theta_j\\) assuma un valore maggiore di \\(1.0\\) per \\(j &lt; p\\). La proporzione cumulativa della varianza si riduce poi a \\(1.0\\) quando vengono considerati anche i successivi autovalori negativi. Di conseguenza, può succedere che, utilizzando la matrice \\(\\textbf{S} - \\hat{\\boldsymbol{\\Psi}}\\) o \\(\\textbf{R} - \\hat{\\boldsymbol{\\Psi}}\\), il criterio definito in base alla quota della varianza spiegata venga raggiunto per un valore \\(m\\) minore di quello che verrebbe trovato utilizzando la matrice S o R. Nel caso del metodo dei fattori principali iterato, \\(m\\) viene specificato precedentemente a ciascuna iterazione e \\(\\sum_{i} \\hat{h}^2_i\\) viene ottenuto dopo ciascuna iterazione calcolando \\(\\text{tr}(\\textbf{S} - \\hat{\\boldsymbol{\\Psi}})\\). Per scegliere \\(m\\), come per il metodo delle componenti principali, possono essere usati gli autovalori di S o R. "],["valore-medio-degli-autovalori.html", "16.2 Valore medio degli autovalori", " 16.2 Valore medio degli autovalori Il calcolo del valore medio degli autovalori è una procedura euristica implementata in molti software. In una variante di tale metodo, \\(m\\) viene scelto in modo tale da uguagliare il numero degli autovalori positivi della matrice ridotta \\(\\textbf{R} - \\hat{\\boldsymbol{\\Psi}}\\) (in tale matrice vi sono solitamente degli autovalori negativi). Tale variante ha però lo svantaggio di produrre solitamente un numero di fattori troppo grande. "],["scree-test.html", "16.3 Scree test", " 16.3 Scree test Lo scree test è basato su una rappresentazione grafica degli autovalori di S o R. Si costruisce un grafico che rappresenta gli autovalori ordinati in maniera decrescente in funzione del numero dei fattori. I punti che rappresentano gli autovalori vengono collegati con una spezzata. Il valore \\(m\\) viene determinato in corrispondenza di quel fattore oltre il quale il dislivello tra fattori successivi diventa esiguo e la spezzata tende a diventare orizzontale. "],["parallel-analysis.html", "16.4 Parallel analysis", " 16.4 Parallel analysis La Parallel Analysis è un metodo alternativo allo scree test[^1]. Nella Parallel Analysis, il criterio usato per decidere il numero di fattori da estrarre viene determinato dal confronto con la media degli autovalori generati da un campione casuale di variabili standardizzate. Tale confronto ha lo scopo di controllare le variazioni dovute agli errori di campionamento. Anche se, nel caso di variabili incorrelate, tutti gli autovalori di una matrice di correlazione dovrebbero avere un valore pari a uno, come conseguenza della variabilità campionaria in qualunque campione finito vi sono comunque uno o più autovalori empirici maggiori di uno. Tale fatto può essere illustrato mediante la seguente simulazione di Monte Carlo. Si consideri una matrice di correlazione calcolata su \\(p=10\\) variabili casuali mutuamente indipendenti, ciascuna costituita da \\(n=20\\) osservazioni. n &lt;- 20 nsim &lt;- 1000 e1 &lt;- rep(0, nsim) for (i in 1:nsim) { Y &lt;- cbind( rnorm(n), rnorm(n), rnorm(n), rnorm(n), rnorm(n), rnorm(n), rnorm(n), rnorm(n), rnorm(n), rnorm(n) ) e &lt;- eigen(cor(Y)) e1[i] &lt;- e$values[1] } max(e1) #&gt; [1] 3.332866 Per i dati di questa simulazione, l’autovalore maggiore ha un valore pari a \\(3.53\\), anche se i dati sono del tutto casuali. La Parallel Analysis tiene conto di questo fatto e determina \\(m\\) confrontando gli autovalori empirici con le loro “controparti casuali.” Vanno a determinare \\(m\\) solo gli autovalori empirici che hanno un valore superiore ai corrispondenti autovalori generati da una matrice di dati dello stesso ordine composta da colonne mutualmente incorrelate. Nel caso dell’esempio presente, per esempio, l’autovalore maggiore dovrà avere un valore maggiore di \\(3.53\\) (anziché di \\(1.00\\) o del punto di flesso della spezzata dello scree test). "],["test-di-bontà-di-adattamento.html", "16.5 Test di bontà di adattamento", " 16.5 Test di bontà di adattamento Se si assume la normalità distributiva dei dati è possibile valutare la bontà di adattamento attraverso il test del rapporto di verosimiglianze. L’ipotesi nulla postula che la matrice di covarianza delle \\(Y\\) abbia la forma specificata dal modello fattoriale, ossia \\[H_0: \\boldsymbol{\\Sigma} = \\boldsymbol{\\Lambda} \\boldsymbol{\\Lambda}^{\\ensuremath{\\mathsf{T}}} + \\boldsymbol{\\Psi},\\] ovvero che \\(m\\) fattori comuni siano sufficienti per spiegare la struttura di interdipendenza della variabile casuale \\(Y\\) oggetto di osservazione campionaria. L’alternativa è che \\(m\\) fattori comuni non siano sufficienti a tale spiegazione \\[H_1: \\boldsymbol{\\Sigma} \\neq \\boldsymbol{\\Lambda} \\boldsymbol{\\Lambda}^{\\ensuremath{\\mathsf{T}}} + \\boldsymbol{\\Psi},\\] dove \\(\\boldsymbol{\\Lambda}\\) è di ordine \\(p \\times m\\). Se l’ipotesi nulla non viene rifiutata vuol dire che il modello fornisce un buon adattamento ai dati. Sotto l’ipotesi nulla, il test ha una distribuzione asintotica, per \\(n \\rightarrow \\infty\\), di tipo chi quadrato con gradi di libertà pari a: \\[\\nu=\\frac{1}{2}\\left[ (p-m)^2 - (p - m) \\right].\\] Tale risultato di natura asintotica, valido per \\(n\\) grande, può essere migliorato, per ottenere una approssimazione migliore, sostituendo \\(\\nu\\) con: \\[\\nu^* = n - 2 - \\frac{2p-1}{6}-\\frac{2}{3}m.\\] Il rifiuto di \\(H_0\\) implica che \\(m\\) è troppo piccolo e un numero maggiore di fattori è necessario. Solitamente si inizia l’analisi considerando un numero di fattori molto piccolo: \\(m^*=1\\) e si prende come ipotesi per il test che il numero di fattori sia \\(m^*\\). Se l’ipotesi nulla è accettata il procedimento si arresta, altrimenti si passa a considerare \\(m^* + 1\\) fattori e si prosegue con lo stesso ragionamento. Il procedimento si arresta non appena si verifica una delle seguenti situazioni: è stata accettata l’ipotesi \\(H_0\\) per un certo valore di \\(m\\), oppure, \\(\\nu=\\frac{1}{2}\\left[ (p-m)^2 - (p - m) \\right]=0\\), ossia la variabile \\(\\chi^2\\) dovrebbe avere zero gradi di libertà, che non è possibile. Per poter applicare il test che determina il buon grado di adattamento del modello fattoriale occorre che i gradi di libertà della statistica del chi-quadrato siano positivi. Questo sta a significare che il numero di fattori comuni non può superare il più grande numero intero che soddisfa la seguente equazione: \\[m &lt; \\frac{1}{2} \\left( 2p+1-\\sqrt{8p+1} \\right)\\] per un numero fissato \\(p\\) di variabili manifeste. In pratica, quando \\(n\\) è grande, il test basato sul rapporto di verosimiglianze rivela un numero di fattori maggiore degli altri metodi descritti in precedenza. Alcuni considerano dunque il valore \\(m\\) indicato dal test quale limite superiore del numero dei fattori che rivestono una qualche importanza pratica. Per alcuni campioni di dati, la scelta di \\(m\\) non è ovvia. Questa indeterminazione costituisce un limite dell’analisi fattoriale. Solitamente, si procede con utilizzando un certo metodo per la scelta di \\(m\\) (diciamo lo scree test) e valuta la proporzione di varianza spiegata di ciascun item e, dopo un’appropriata rotazione, l’interpretabilità della soluzione ottenuta. Se le comunalità o l’interpretabilità dei fattori non sembrano adeguati, si procede con un numero maggiore di fattori. Tale procedura è certamente soggettiva e i limiti della soluzione che viene ottenuta sono evidenti. Per altri campioni di dati, la scelta di \\(m\\) consente una maggiore certezza. Questo avviene quando tutti i metodi che abbiamo descritto prima forniscono la stessa risposta. In questi casi, possiamo essere più certi della soluzione dell’analisi fattoriale. Esempio 16.1 Per confrontare i quattro metodi discussi per la scelta del numero \\(m\\) di fattori usiamo qui una matrice di correlazioni calcolata sulla WAIS. Le 11 sottoscale sono le seguenti: X1 = Information X2 = Comprehension X3 = Arithmetic X4 = Similarities X5 = Digit.span X6 = Vocabulary X7 = Digit.symbol X8 = Picture.completion X9 = Block.design X10 = Picture.arrangement X11 = Object.assembly varnames &lt;- c( &quot;IN&quot;, &quot;CO&quot;, &quot;AR&quot;, &quot;SI&quot;, &quot;DS&quot;, &quot;VO&quot;, &quot;SY&quot;, &quot;PC&quot;, &quot;BD&quot;, &quot;PA&quot;, &quot;OA&quot;, &quot;AG&quot;, &quot;ED&quot; ) temp &lt;- matrix(c( 1, 0.67, 0.62, 0.66, 0.47, 0.81, 0.47, 0.60, 0.49, 0.51, 0.41, -0.07, 0.66, .67, 1, 0.54, 0.60, 0.39, 0.72, 0.40, 0.54, 0.45, 0.49, 0.38, -0.08, 0.52, .62, .54, 1, 0.51, 0.51, 0.58, 0.41, 0.46, 0.48, 0.43, 0.37, -0.08, 0.49, .66, .60, .51, 1, 0.41, 0.68, 0.49, 0.56, 0.50, 0.50, 0.41, -0.19, 0.55, .47, .39, .51, .41, 1, 0.45, 0.45, 0.42, 0.39, 0.42, 0.31, -0.19, 0.43, .81, .72, .58, .68, .45, 1, 0.49, 0.57, 0.46, 0.52, 0.40, -0.02, 0.62, .47, .40, .41, .49, .45, .49, 1, 0.50, 0.50, 0.52, 0.46, -0.46, 0.57, .60, .54, .46, .56, .42, .57, .50, 1, 0.61, 0.59, 0.51, -0.28, 0.48, .49, .45, .48, .50, .39, .46, .50, .61, 1, 0.54, 0.59, -0.32, 0.44, .51, .49, .43, .50, .42, .52, .52, .59, .54, 1, 0.46, -0.37, 0.49, .41, .38, .37, .41, .31, .40, .46, .51, .59, .46, 1, -0.28, 0.40, -.07, -.08, -.08, -.19, -.19, -.02, -.46, -.28, -.32, -.37, -.28, 1, -0.29, .66, .52, .49, .55, .43, .62, .57, .48, .44, .49, .40, -.29, 1 ), nrow = 13, ncol = 13, byrow = TRUE) colnames(temp) &lt;- varnames rownames(temp) &lt;- varnames wais_cor &lt;- temp[1:11, 1:11] wais_cor #&gt; IN CO AR SI DS VO SY PC BD PA OA #&gt; IN 1.00 0.67 0.62 0.66 0.47 0.81 0.47 0.60 0.49 0.51 0.41 #&gt; CO 0.67 1.00 0.54 0.60 0.39 0.72 0.40 0.54 0.45 0.49 0.38 #&gt; AR 0.62 0.54 1.00 0.51 0.51 0.58 0.41 0.46 0.48 0.43 0.37 #&gt; SI 0.66 0.60 0.51 1.00 0.41 0.68 0.49 0.56 0.50 0.50 0.41 #&gt; DS 0.47 0.39 0.51 0.41 1.00 0.45 0.45 0.42 0.39 0.42 0.31 #&gt; VO 0.81 0.72 0.58 0.68 0.45 1.00 0.49 0.57 0.46 0.52 0.40 #&gt; SY 0.47 0.40 0.41 0.49 0.45 0.49 1.00 0.50 0.50 0.52 0.46 #&gt; PC 0.60 0.54 0.46 0.56 0.42 0.57 0.50 1.00 0.61 0.59 0.51 #&gt; BD 0.49 0.45 0.48 0.50 0.39 0.46 0.50 0.61 1.00 0.54 0.59 #&gt; PA 0.51 0.49 0.43 0.50 0.42 0.52 0.52 0.59 0.54 1.00 0.46 #&gt; OA 0.41 0.38 0.37 0.41 0.31 0.40 0.46 0.51 0.59 0.46 1.00 Il primo metodo per la determinazione di \\(m\\) richiede di estrarre tanti fattori quanti sono necessari per spiegare una quota predeterminata della varianza totale. Supponiamo di porre il criterio pari all’80% della varianza totale. La soluzione ottenuta in questo modo ci porterebbe a mantenere \\(m=5\\) fattori: out &lt;- eigen(wais_cor) sum(out$val[1:4]) / sum(out$val) #&gt; [1] 0.7656781 sum(out$val[1:5]) / sum(out$val) #&gt; [1] 0.8118853 Il secondo metodo suggerisce di mantenere tutti gli autovalori superiori al valore medio degli autovalori (che, nel caso di R è uguale a \\(1\\)). Nel caso presente, \\(m=2\\): round(out$values, 3) #&gt; [1] 6.074 1.015 0.746 0.587 0.508 0.431 0.423 0.377 0.351 0.310 0.177 Il terzo metodo, lo scree test, può essere eseguito usando la funzione VSS.scree() contenuta nel pacchetto psych. VSS.scree(wais_cor) Lo scree test suggerisce una soluzione a \\(m=1\\) fattori, come indicato nella figura precedente. Il terzo metodo, nella versione della Parallel Analysis, può essere eseguito usando la funzione paran() contenuta nel pacchetto paran. La Parallel Analysis indica una soluzione a \\(m=1\\) fattore. library(&quot;paran&quot;) paran(wais_cor, graph = TRUE) #&gt; #&gt; Using eigendecomposition of correlation matrix. #&gt; Computing: 10% 20% 30% 40% 50% 60% 70% 80% 90% 100% #&gt; #&gt; #&gt; Results of Horn&#39;s Parallel Analysis for component retention #&gt; 330 iterations, using the mean estimate #&gt; #&gt; -------------------------------------------------- #&gt; Component Adjusted Unadjusted Estimated #&gt; Eigenvalue Eigenvalue Bias #&gt; -------------------------------------------------- #&gt; 1 1.636878 3.765744 2.128865 #&gt; -------------------------------------------------- #&gt; #&gt; Adjusted eigenvalues &gt; 1 indicate dimensions to retain. #&gt; (1 components retained) Il quarto metodo consiste nell’applicazione di un test inferenziale relativo al numero di fattori. Anche questo metodo indica una soluzione a sei fattori: factanal(covmat = wais_cor, factors = 5, n.obs = 933) #&gt; #&gt; Call: #&gt; factanal(factors = 5, covmat = wais_cor, n.obs = 933) #&gt; #&gt; Uniquenesses: #&gt; IN CO AR SI DS VO SY PC BD PA OA #&gt; 0.235 0.389 0.117 0.419 0.600 0.109 0.277 0.308 0.334 0.472 0.456 #&gt; #&gt; Loadings: #&gt; Factor1 Factor2 Factor3 Factor4 Factor5 #&gt; IN 0.745 0.264 0.301 0.192 0.118 #&gt; CO 0.667 0.278 0.244 0.129 0.111 #&gt; AR 0.378 0.236 0.814 0.145 #&gt; SI 0.591 0.332 0.207 0.252 0.121 #&gt; DS 0.288 0.208 0.366 0.341 0.155 #&gt; VO 0.865 0.216 0.207 0.229 #&gt; SY 0.251 0.364 0.153 0.708 #&gt; PC 0.425 0.548 0.156 0.216 0.375 #&gt; BD 0.246 0.708 0.230 0.201 0.107 #&gt; PA 0.355 0.457 0.163 0.325 0.245 #&gt; OA 0.211 0.664 0.128 0.205 #&gt; #&gt; Factor1 Factor2 Factor3 Factor4 Factor5 #&gt; SS loadings 2.799 1.986 1.176 1.043 0.280 #&gt; Proportion Var 0.254 0.181 0.107 0.095 0.025 #&gt; Cumulative Var 0.254 0.435 0.542 0.637 0.662 #&gt; #&gt; Test of the hypothesis that 5 factors are sufficient. #&gt; The chi square statistic is 12.46 on 10 degrees of freedom. #&gt; The p-value is 0.256 Le differenze tra i risultati ottenuti con i quattro metodi descritti sopra suggeriscono la presenza di una componente di arbitrarietà nella scelta della soluzione da adottare. "],["la-rotazione-fattoriale.html", "Capitolo 17 La rotazione fattoriale", " Capitolo 17 La rotazione fattoriale Nel capitolo 15 abbiamo visto come sia possibile ottenere la soluzione fattoriale non ruotata per il numero di fattori comuni che meglio riassume l’informazione contenuta nella matrice di correlazioni (o covarianze). La soluzione non ruotata non garantisce l’identificazione di aggregati omogenei e interpretabili di variabili osservate. Si tende dunque a ricorrere alla rotazione degli assi fattoriali nella ricerca di una soluzione più facilmente interpretabile di quella ottenuta in prima istanza. "],["indeterminatezza-della-soluzione-fattoriale.html", "17.1 Indeterminatezza della soluzione fattoriale", " 17.1 Indeterminatezza della soluzione fattoriale Il problema della rotazione si pone perché la matrice delle saturazioni non presenta un’unica soluzione e, attraverso la sua trasformazione matematica, si possono ottenere infinite matrici dello stesso ordine. Tale fatto va sotto il nome di indeterminatezza della soluzione fattoriale. La matrice delle saturazioni fattoriali \\(\\boldsymbol{\\Lambda}\\) non risulta univocamente definita in quanto non esiste una soluzione unica alla determinazione delle saturazioni fattoriali. Una matrice di correlazioni \\(\\boldsymbol{R}\\) consente di determinare soluzioni fattoriali diverse, ovvero matrici aventi lo stesso numero di fattori comuni ma una diversa configurazione di saturazioni fattoriali, oppure matrici di saturazioni fattoriali corrispondenti ad un diverso numero di fattori comuni. Siano \\(\\boldsymbol{\\Lambda}_1\\) e \\(\\boldsymbol{\\Lambda}_2\\) due matrici aventi lo stesso numero di righe e colonne, ma contenenti saturazioni fattoriali diverse. \\(\\boldsymbol{\\Lambda}_1\\) è definita dai valori seguenti l1 &lt;- matrix( c( 0.766, -0.232, 0.670, -0.203, 0.574, -0.174, 0.454, 0.533, 0.389, 0.457, 0.324, 0.381 ), byrow = TRUE, ncol = 2 ) mentre per \\(\\boldsymbol{\\Lambda}_2\\) abbiamo l2 &lt;- matrix( c( 0.783, 0.163, 0.685, 0.143, 0.587, 0.123, 0.143, 0.685, 0.123, 0.587, 0.102, 0.489 ), byrow = TRUE, ncol = 2 ) Esaminiamo la matrice delle correlazioni riprodotte dalle due matrici di pesi fattoriali (con le comunalità sulla diagonale di \\(\\boldsymbol{R}\\)): l1 %*% t(l1) #&gt; [,1] [,2] [,3] [,4] [,5] [,6] #&gt; [1,] 0.640580 0.560316 0.480052 0.224108 0.191950 0.159792 #&gt; [2,] 0.560316 0.490109 0.419902 0.195981 0.167859 0.139737 #&gt; [3,] 0.480052 0.419902 0.359752 0.167854 0.143768 0.119682 #&gt; [4,] 0.224108 0.195981 0.167854 0.490205 0.420187 0.350169 #&gt; [5,] 0.191950 0.167859 0.143768 0.420187 0.360170 0.300153 #&gt; [6,] 0.159792 0.139737 0.119682 0.350169 0.300153 0.250137 l2 %*% t(l2) #&gt; [,1] [,2] [,3] [,4] [,5] [,6] #&gt; [1,] 0.639658 0.559664 0.479670 0.223624 0.191990 0.159573 #&gt; [2,] 0.559664 0.489674 0.419684 0.195910 0.168196 0.139797 #&gt; [3,] 0.479670 0.419684 0.359698 0.168196 0.144402 0.120021 #&gt; [4,] 0.223624 0.195910 0.168196 0.489674 0.419684 0.349551 #&gt; [5,] 0.191990 0.168196 0.144402 0.419684 0.359698 0.299589 #&gt; [6,] 0.159573 0.139797 0.120021 0.349551 0.299589 0.249525 Come si vede, viene ottenuto lo stesso risultato utilizzando matrici \\(\\boldsymbol{\\Lambda}\\) con lo stesso numero \\(m\\) di colonne ma saturazioni fattoriali diverse. Si consideri ora il caso di matrici \\(\\boldsymbol{\\Lambda}\\) corrispondenti a soluzioni fattoriali con un diverso numero di fattori comuni. Siano \\(\\boldsymbol{\\Lambda}_1\\) e \\(\\boldsymbol{\\Lambda}_2\\) due matrici aventi lo stesso numero di righe ma un numero diverso di colonne: l1 &lt;- matrix( c( 0.9, 0.7, 0.5, 0.3 ), byrow = TRUE, ncol = 1 ) l2 &lt;- matrix( c( 0.78, 0.45, 0.61, 0.35, 0.43, 0.25, 0.25, 0.15 ), byrow = TRUE, ncol = 2 ) Si noti che la stessa matrice di correlazioni riprodotte (con le comunalità sulla diagonale principale) viene generata dalle saturazioni fattoriali corrispondenti ad un numero diverso di fattori comuni: l1 %*% t(l1) #&gt; [,1] [,2] [,3] [,4] #&gt; [1,] 0.81 0.63 0.45 0.27 #&gt; [2,] 0.63 0.49 0.35 0.21 #&gt; [3,] 0.45 0.35 0.25 0.15 #&gt; [4,] 0.27 0.21 0.15 0.09 l2 %*% t(l2) #&gt; [,1] [,2] [,3] [,4] #&gt; [1,] 0.8109 0.6333 0.4479 0.2625 #&gt; [2,] 0.6333 0.4946 0.3498 0.2050 #&gt; [3,] 0.4479 0.3498 0.2474 0.1450 #&gt; [4,] 0.2625 0.2050 0.1450 0.0850 "],["parsimonia-e-semplicità.html", "17.2 Parsimonia e semplicità", " 17.2 Parsimonia e semplicità Come si raggiunge allora una qualche certezza sui risultati dell’analisi fattoriale? Il problema dell’indeterminazione fattoriale si affronta scegliendo la soluzione che soddisfa i seguenti due criteri: criterio della parsimonia: se sia un modello ad un fattore comune sia un modello a due fattori comuni possono spiegare la covariazione tra le variabili si deve accettare quello ad un fattore; criterio della semplicità: a parità di numero di fattori, sono da preferire le strutture più semplici della matrice \\(\\boldsymbol{\\Lambda}\\) (Thurstone, 1947). Il criterio della parsimonia è facilmente applicabile: se due soluzioni fattoriali aventi un numero diverso di fattori riproducono allo stesso modo la matrice S o R, si sceglie la soluzione con il numero minore di fattori. D’altra parte, se vi sono diverse soluzioni fattoriali con lo stesso numero \\(m\\) di fattori, il criterio della semplicità ci guida nella scelta della trasformazione più appropriata della matrice \\(\\hat{\\boldsymbol{\\Lambda}}\\). La trasformazione della matrice \\(\\hat{\\boldsymbol{\\Lambda}}\\) va sotto il nome di rotazione. A seconda che i fattori ruotati risultino o meno incorrelati, si distingue tra metodi di rotazione ortogonale o obliqua dei fattori. 17.2.1 Il criterio della “struttura semplice” Tramite la rotazione degli assi fattoriali miriamo alla “struttura semplice” della matrice delle saturazioni fattoriali: poche ma forti saturazioni diverse da zero e assenza di variabili saturate da più di un fattore. Il criterio della “struttura semplice” è stato originariamente proposto da Thurstone (1947) secondo il quale tale criterio viene raggiunto quando: nella matrice fattoriale ruotata, ogni variabile deve avere almeno un peso nullo; ogni fattore deve avere almeno \\(m\\) saturazioni nulle (\\(m\\): numero dei fattori comuni); per ciascuna coppia di fattori vi devono essere saturazioni basse su un fattore e saturazioni alte sull’altro; nel caso di molti fattori, per ciascuna coppia di fattori una grande proporzione di saturazioni dovrebbe essere nulla; per ciascuna coppia di fattori, vi dovrebbero essere solo poche saturazioni di entità non trascurabile su entrambi i fattori. Nella pratica, il requisito della struttura semplice viene perseguito, non tanto seguendo le indicazioni di Thursone, quanto bensì cercando di massimizzare il numero di saturazioni nulle o quasi nulle nella matrice \\(\\hat{\\boldsymbol{\\Lambda}}\\). Uno dei grandi vantaggi che derivano dall’ottenimento della struttura semplice è la facilitazione nell’interpretazione dei fattori (Cattell, 1978). L’esame delle saturazioni fattoriali contenute nella matrice \\(\\hat{\\boldsymbol{\\Lambda}}^*\\) ruotata consente infatti di fornire un’interpretazione ai fattori. Per poter interpretare un fattore, dobbiamo chiederci quali sono le variabili che risultano maggiormente associate con tale fattore e quanto forti siano tali legami. Se i coefficienti di impatto di un fattore sono positivi e piuttosto elevati su un sottoinsieme di variabili osservate, da ciò deduciamo che il fattore rappresenta ciò che hanno in comune le variabili che saturano sul fattore. Ovviamente, l’interpretazione si complica nel caso di variabili che saturano su più fattori. "],["rotazione-nello-spazio-geometrico.html", "17.3 Rotazione nello spazio geometrico", " 17.3 Rotazione nello spazio geometrico 17.3.1 Rotazione ortogonale Come è stato notato nella sezione precedente, la matrice \\(\\boldsymbol{\\Lambda}\\) non è identificabile poiché non esiste una soluzione unica alla determinazione delle saturazioni fattoriali: qualunque matrice \\(\\hat{\\boldsymbol{\\Lambda}}^* = \\hat{\\boldsymbol{\\Lambda}} \\textbf{T}\\), dove T è una matrice ortonormale di ordine \\(m\\), è in grado di riprodurre la matrice di varianze-covarianze allo stesso modo di \\(\\hat{\\boldsymbol{\\Lambda}}\\). La matrice \\(\\hat{\\boldsymbol{\\Lambda}}\\) è pertanto determinata a meno della moltiplicazione per una matrice ortonormale. Definizione 17.1 Geometricamente, i pesi fattoriali costituiscono le coordinate di un punto (ci sono tanti punti quante sono le \\(p\\) variabili manifeste) in uno spazio avente un numero di dimensioni pari al numero \\(m\\) dei fattori. Dal punto di vista geometrico, il problema dell’indeterminazione fattoriale si può descrivere facendo riferimento alla rotazione rigida dei punti che rappresentano le saturazioni fattoriali attorno l’origine del sistema di coordinate. Tale rotazione rigida lascia invariate le distanze tra i punti (ed è equivalente ad una rotazione (contraria) del sistema di assi cartesiani) e dà luogo ad un nuovo insieme di valori per i pesi fattoriali. Ciascuno di questi insiemi di pesi fattoriali così ottenuti produce la medesima matrice di correlazioni riprodotte dal modello fattoriale. L’indeterminazione fattoriale nasce dal fatto che sono possibili infinite rotazioni diverse degli assi. 17.3.2 Vincoli alla rotazione Il problema della non identificabilità di \\(\\hat{\\boldsymbol{\\Lambda}}\\) viene generalmente risolto imponendo dei vincoli alla rotazione. Il criterio che ci guida nella scelta di una delle possibili trasformazioni della matrice dei pesi fattoriali è quello della semplicità della matrice \\(\\hat{\\boldsymbol{\\Lambda}}\\) (Thurstone, 1947), ovvero la vicinanza dei suoi elementi ai valori 0 e 1. Quanto più ciò si verifica tanto più risulta semplice l’interpretazione dei fattori comuni nei termini delle variabili. L’identificazione dei fattori risulta infatti semplificata se ciascuno di essi è fortemente correlato con un numero limitato di variabili ed è poco correlato con le altre. Le rotazioni ortogonali lasciano immutate le comunalità nel caso di fattori incorrelati. Questo accade perché qualunque rotazione rigida rispetto all’origine preserva le distanze tra i punti identificati dai pesi fattoriali e, nel caso di fattori incorrelati, la comunalità non è nient’altro che la distanza dall’origine (al quadrato): \\[\\hat{h}^2_i = \\sum_{i=1}^m \\hat{\\lambda}_{ij}^2\\] Rotazioni non ortogonali, però, mutano la quota di varianza spiegata da ciascun fattore, essendo questa data da \\[\\frac{\\sum_{i=1}^p \\hat{\\lambda}_{ij}^2}{\\text{tr}(\\textbf{S})}\\] oppure da \\[\\frac{\\sum_{i=1}^p \\hat{\\lambda}_{ij}^2}{\\text{tr}(\\textbf{R})}\\] laddove \\(\\text{tr}(\\textbf{R})=p\\), con \\(i=1, \\dots, p\\) (numero di item) e \\(j=1, \\dots, m\\) (numero di fattori). Diversi algoritmi sono stati proposti per la rotazione ortogonale dei fattori. Inizieremo ad esaminare una possibile soluzione al problema dell’indeterminazione fattoriale mediante il metodo grafico. Esamineremo poi i metodi Quartimax e Varimax. 17.3.3 Metodo grafico Come si può ruotare il sitema degli assi? Se ci sono solo \\(m=2\\) fattori, per ottenere la loro rappresentazione geometrica utilizziamo un sistema di coordinate bidimensionale. L’ispezione visiva del diagramma delle saturazioni fattoriali ci può guidare alla scelta della rotazione più appropriata. Le righe di \\(\\hat{\\boldsymbol{\\Lambda}}\\) corrispondono a coppie di pesi fattoriali (\\(\\hat{\\lambda}_{i1}, \\hat{\\lambda}_{i2}\\), con \\(i=1, \\dots, p\\)) che possono essere interpretate come le coordinate di \\(p\\) punti (tanti quanti le variabili manifeste). Gli assi del diagramma vengono ruotati di un angolo \\(\\phi\\) in modo tale da portarli il più vicino possibile ai punti presenti nel grafico. Le nuove coordinate (\\(\\hat{\\lambda}_{i1}^*, \\hat{\\lambda}_{i2}^*\\)) vengono calcolate come \\(\\hat{\\boldsymbol{\\Lambda}}^* = \\hat{\\boldsymbol{\\Lambda}} \\textbf{T}\\), dove \\[ \\textbf{T} = \\left[ \\begin{array}{ c c } \\cos{\\phi} &amp; - \\sin{\\phi}\\\\ \\sin{\\phi} &amp; \\cos{\\phi} \\end{array} \\right] \\] è una matrice ortogonale \\(2 \\times 2\\). Esempio 17.1 Si considerino i dati di Brown, Williams e Barlow (1984) discussi da Rencher (2002). Ad una bambina di dodici anni è stato chiesto di valutare sette dei suoi conoscenti su cinque variabili: kind, intelligent, happy, likeable e just. Per queste cinque variabili, la matrice di correlazioni è R &lt;- matrix( c( 1.00, .296, .881, .995, .545, .296, 1.000, -.022, .326, .837, .881, -.022, 1.000, .867, .130, .995, .326, .867, 1.000, .544, .545, .837, .130, .544, 1.00 ), ncol = 5, byrow = TRUE, dimnames = list( c(&quot;K&quot;, &quot;I&quot;, &quot;H&quot;, &quot;L&quot;, &quot;J&quot;), c(&quot;K&quot;, &quot;I&quot;, &quot;H&quot;, &quot;L&quot;, &quot;J&quot;) ) ) Dalla matrice R estraiamo due fattori con il metodo delle componenti principali: library(&quot;psych&quot;) f.pc &lt;- principal(R, 2, rotate = FALSE) f.pc #&gt; Principal Components Analysis #&gt; Call: principal(r = R, nfactors = 2, rotate = FALSE) #&gt; Standardized loadings (pattern matrix) based upon correlation matrix #&gt; PC1 PC2 h2 u2 com #&gt; K 0.97 -0.23 0.99 0.0067 1.1 #&gt; I 0.52 0.81 0.92 0.0792 1.7 #&gt; H 0.78 -0.59 0.96 0.0391 1.9 #&gt; L 0.97 -0.21 0.99 0.0135 1.1 #&gt; J 0.70 0.67 0.94 0.0597 2.0 #&gt; #&gt; PC1 PC2 #&gt; SS loadings 3.26 1.54 #&gt; Proportion Var 0.65 0.31 #&gt; Cumulative Var 0.65 0.96 #&gt; Proportion Explained 0.68 0.32 #&gt; Cumulative Proportion 0.68 1.00 #&gt; #&gt; Mean item complexity = 1.6 #&gt; Test of the hypothesis that 2 components are sufficient. #&gt; #&gt; The root mean square of the residuals (RMSR) is 0.03 #&gt; #&gt; Fit based upon off diagonal values = 1 Nella seguente figura, i punti rappresentano le cinque coppie di pesi fattoriali non ruotati: plot( f.pc$load[, 1], f.pc$load[, 2], bty = &quot;n&quot;, xaxt = &quot;n&quot;, xlab = &quot;Primo Fattore&quot;, ylab = &quot;Secondo Fattore&quot;, ylim = c(-.6, 1), xlim = c(0, 1), pch = 19 ) axis(1, pos = c(0, 0)) abline(0, 0) Rencher (2002) nota che, per questi dati, una rotazione ortogonale di \\(-35^{\\circ}\\) ci porterebbe ad avvicinare gli assi ai punti nel diagramma. Per verificare questo, disegnamo sul diagramma i nuovi assi dopo una rotazione di \\(-35^{\\circ}\\). Le istruzioni R sono le seguenti: plot( f.pc$load[, 1], f.pc$load[, 2], bty = &quot;n&quot;, xaxt = &quot;n&quot;, xlab = &quot;Primo Fattore&quot;, ylab = &quot;Secondo Fattore&quot;, ylim = c(-.6, 1), xlim = c(0, 1), pch = 19 ) axis(1, pos = c(0, 0)) abline(0, 0) ar &lt;- matrix(c( 0, 0, 0, 1, 0, 0, 1, 0 ), ncol = 2, byrow = TRUE) angle &lt;- 35 rad &lt;- angle * pi / 180 T &lt;- matrix(c( cos(rad), -sin(rad), sin(rad), cos(rad) ), ncol = 2, byrow = TRUE) round(ar %*% T, 3) #&gt; [,1] [,2] #&gt; [1,] 0.000 0.000 #&gt; [2,] 0.574 0.819 #&gt; [3,] 0.000 0.000 #&gt; [4,] 0.819 -0.574 arrows(0, 0, 0.574, 0.819, lwd = 2) arrows(0, 0, 0.819, -0.574, lwd = 2) Nella figura precedente, le due frecce rappresentano gli assi ruotati. È chiaro come tale rotazione di \\(-35^{\\circ}\\) ha effettivamente l’effetto di avvicinare gli assi ai punti del diagramma. Se usiamo dunque il valore \\(\\phi = -35^{\\circ}\\) nella matrice di rotazione, possiamo calcolare le saturazioni fattoriali della soluzione ruotata \\(\\hat{\\boldsymbol{\\Lambda}}^* = \\hat{\\boldsymbol{\\Lambda}} \\textbf{T}\\). Le saturazioni fattoriali ruotate non sono altro che la proiezione ortogonale dei punti sugli assi ruotati: angle &lt;- -35 rad &lt;- angle * pi / 180 T &lt;- matrix(c( cos(rad), -sin(rad), sin(rad), cos(rad) ), ncol = 2, byrow = TRUE) round(f.pc$load %*% T, 3) #&gt; [,1] [,2] #&gt; K 0.927 0.367 #&gt; I -0.037 0.959 #&gt; H 0.980 -0.031 #&gt; L 0.916 0.385 #&gt; J 0.194 0.950 La soluzione ottenuta in questo modo riproduce quella riportata da Rencher (2002). 17.3.4 Medodi di rotazione ortogonale Un tipo di rotazione ortogonale molto utilizzato è la rotazione Varimax (Kaiser, 1958). La matrice \\(\\hat{\\boldsymbol{\\Lambda}}\\) è semplificata in modo tale che le varianze dei quadrati degli elementi \\(\\lambda_{ij}\\) appartenenti a colonne diverse di \\(\\hat{\\boldsymbol{\\Lambda}}\\) siano massime. Se le saturazioni fattoriali in una colonna di \\(\\hat{\\boldsymbol{\\Lambda}}\\) sono simili tra loro, la varianza sarà prossima a zero. Tale varianza è tanto più grande quanto più i quadrati degli elementi \\(\\lambda_{ij}\\) assumono valori prossimi a \\(0\\) e \\(1\\). Amplificando le correlazioni più alte e riducendo quelle più basse, la rotazione Varimax agevola l’interpretazione di ciascun fattore. Usando la funzione factanal() del modulo base, la rotazione Varimax può essere applicata alla soluzione ottenuta mediante il metodo di massima verosimiglianza. Usando le funzioni principal() e factor.pa() disponibili nel pacchetto psych, la rotazione Varimax può essere applicata alle soluzioni ottenute mediante il metodo delle componenti principali e il metodo del fattore principale. Ad esempio, otteniamo: f_pc &lt;- principal(R, 2, n.obs = 7, rotate = &quot;varimax&quot;) f_pc #&gt; Principal Components Analysis #&gt; Call: principal(r = R, nfactors = 2, rotate = &quot;varimax&quot;, n.obs = 7) #&gt; Standardized loadings (pattern matrix) based upon correlation matrix #&gt; RC1 RC2 h2 u2 com #&gt; K 0.95 0.30 0.99 0.0067 1.2 #&gt; I 0.03 0.96 0.92 0.0792 1.0 #&gt; H 0.97 -0.10 0.96 0.0391 1.0 #&gt; L 0.94 0.32 0.99 0.0135 1.2 #&gt; J 0.26 0.93 0.94 0.0597 1.2 #&gt; #&gt; RC1 RC2 #&gt; SS loadings 2.81 1.99 #&gt; Proportion Var 0.56 0.40 #&gt; Cumulative Var 0.56 0.96 #&gt; Proportion Explained 0.58 0.42 #&gt; Cumulative Proportion 0.58 1.00 #&gt; #&gt; Mean item complexity = 1.1 #&gt; Test of the hypothesis that 2 components are sufficient. #&gt; #&gt; The root mean square of the residuals (RMSR) is 0.03 #&gt; with the empirical chi square 0.12 with prob &lt; 0.73 #&gt; #&gt; Fit based upon off diagonal values = 1 Il metodo Quartimax (Neuhaus e Wringley, 1954) opera una semplificazione della matrice \\(\\hat{\\boldsymbol{\\Lambda}}\\) massimizzando le covarianze tra i quadrati degli elementi \\(\\lambda_{ij}\\) appartenenti a righe diverse, subordinatamente alla condizione che la varianza delle righe rimanga inalterata. 17.3.5 Metodi di rotazione obliqua Parlare di rotazione obliqua significa usare un termine improprio: per definizione, infatti, una rotazione implica una trasformazione ortogonale che preserva le distanze. Secondo Rencher (2002), un termine migliore sarebbe trasformazione obliqua. Il termine rotazione obliqua, comunque, fa parte dell’uso corrente. Nella rotazione obliqua, gli assi della soluzione ruotata non devono rimanere ortogonali e quindi possono più facilmente avvicinarsi ai raggruppamenti di punti nello spazio delle saturazioni fattoriali (assumendo che dei raggruppamenti esistano). Vari metodi analitici sono stati proposti per ottenere una rotazione obliqua. Qui esamineremo brevemente solo uno di essi, il metodo Direct Oblimin. Il criterio usato nel metodo Direct Oblimin (Jennrich e Sampson, 1966) è il seguente: \\[ \\sum_{ij} \\left(\\sum_v \\lambda_i^2 \\lambda_j^2 - w \\frac{1}{p} \\sum_v \\lambda_i^2 \\sum_v \\lambda_j^2\\right) \\] dove \\(\\sum_{ij}\\) si riferisce alla somma su tutte le coppie di fattori \\(ij\\). In questo caso si procede ad una minimizzazione piuttosto che a una masssimizzazione. "],["matrice-dei-pesi-fattoriali-e-matrice-di-struttura.html", "17.4 Matrice dei pesi fattoriali e matrice di struttura", " 17.4 Matrice dei pesi fattoriali e matrice di struttura Nella rotazione ortogonale i fattori sono incorrelati. Si consideri la situazione presentata nella figura 17.1, con due variabili latenti incorrelate (\\(\\xi_1\\) e \\(\\xi_2\\)) e quattro variabili manifeste (\\(y_1\\), \\(y_2\\), \\(y_3\\), \\(y_4\\)). Siano \\(\\lambda_{11}\\), \\(\\lambda_{12}\\), \\(\\lambda_{13}\\) e \\(\\lambda_{14}\\) le saturazioni fattoriali delle variabili nel primo fattore; siano \\(\\lambda_{21}\\), \\(\\lambda_{22}\\), \\(\\lambda_{23}\\) e \\(\\lambda_{24}\\) le saturazioni fattoriali delle variabili nel secondo fattore. FIGURA 17.1: Modello fattoriale con due fattori comuni ortogonali. In un diagramma di percorso, la correlazione tra due variabili contenute è uguale alla somma dei valori numerici di tutti i percorsi legittimi che collegano le variabili. Se i fattori comuni sono incorrelati (come nella figura 17.1, allora in un path diagram c’è un unico percorso legittimo che collega ciascuna variabile manifesta a ciascun fattore comune in base alle regole di Wright. Le correlazioni tra variabili manifeste e fattori comuni sono dunque uguali alle saturazioni fattoriali. Nel caso di fattori comuni sono incorrelati, dunque, la matrice delle saturazioni fattoriali descrive le correlazioni fra variabili e fattori. Si ricordi che le saturazioni fattoriali possono essere interpretate in maniera equivalente ai pesi beta del modello di regressione multipla, ovvero come la stima del contributo specifico di ciascun fattore comune nella determinazione della varianza spiegata degli item (Tabachnick &amp; Fidell, 2001). Nel caso della rotazione obliqua, invece, la soluzione fattoriale ruotata produce un insieme di fattori comuni fra loro correlati. Di conseguenza, la matrice delle saturazioni fattoriali non descrive le correlazioni fra variabili e fattori. Infatti, in un path diagram ci sono almeno due percorsi legittimi che collegano ciascuna variabile manifesta a ciascun fattore comune in base alle regole di Wright. Nel caso di una rotazione obliqua è quindi necessario specificare tre diverse matrici: la matrice delle saturazioni fattoriali, \\(\\hat{\\boldsymbol{\\Lambda}}\\), detta matrice pattern (factor pattern matrix, o “configurazione,” o “matrice dei modelli”); la matrice delle correlazioni tra variabili manifeste e fattori, detta matrice di struttura (factor structure matrix); la matrice che esprime le correlazioni tra i fattori, \\(\\hat{\\boldsymbol{\\Phi}}\\), detta matrice di intercorrelazione fattoriale. In questo caso, la matrice pattern rappresenta l’analogo dei coefficienti parziali di regressione della variabile sul fattore, al netto degli altri fattori. Nel caso della rotazione obliqua, è la matrice che viene usata per determinare in che grado è stata raggiunta la “struttura semplice”. Esaminiamo in dettaglio la soluzione fattoriale che viene prodotta da una rotazione obliqua. In tali circostanze, gli assi che rappresentano i fattori non sono ortogonali (ovvero, i fattori sono correlati) e, in un diagramma di percorso, le variabili manifeste sono collegate ai fattori attraverso due tipi distinti di percorsi. Tali percorsi rappresentano l’effetto “diretto” e “indiretto” dei fattori sulle variabili. Nel caso di una rotazione obliqua, come abbiamo detto sopra, le saturazioni fattoriali non coincidono con le correlazioni tra variabili e fattori. Si consideri la figura 17.2. Nel caso di una rotazione obliqua, la correlazione tra i due fattori comuni viene rappresentata mediante la freccia non direzionata \\(\\phi_{12}\\) che collega \\(\\xi_1\\) e \\(\\xi_2\\). Nel diagramma di percorso della figura 17.2 ci sono due percorsi legittimi che, in base alle regole di Wright, consentono di collegare ciascuna variabile manifesta ad un fattore comune. Ad esempio, nel caso della variabile \\(y_1\\) e il fattore \\(\\xi_1\\), i percorsi sono: la freccia causale \\(\\lambda_{11}\\) che rappresenta l’effetto diretto di \\(\\xi_1\\) su \\(y_1\\) e il percorso composto che rappresenta l’effetto indiretto di \\(\\xi_1\\) su \\(y_1\\). Il valore numerico di tale percorso composto è uguale al prodotto \\(\\lambda_{21}\\phi_{12}\\). Nei termini dell’analisi dei percorsi, dunque, la correlazione tra \\(\\xi_1\\) e \\(y_1\\) è uguale alla somma dei valori numerici dei percorsi legittimi che collegano \\(y_1\\) a \\(\\xi_1\\), ovvero \\(\\lambda_{11} + \\lambda_{21} \\phi_{12}\\). FIGURA 17.2: Modello fattoriale con due fattori comuni dopo una rotazione obliqua. Per illustrare la rotazione obliqua, utilizziamo i dati discussi da Rencher (2002). Si consideri la matrice di correlazione presentata qui sotto. R &lt;- matrix( c( 1.00, 0.735, 0.711, 0.704, 0.735, 1.00, 0.693, 0.709, 0.711, 0.693, 1.00, 0.839, 0.704, 0.709, 0.839, 1.00 ), ncol = 4, byrow = TRUE ) R #&gt; [,1] [,2] [,3] [,4] #&gt; [1,] 1.000 0.735 0.711 0.704 #&gt; [2,] 0.735 1.000 0.693 0.709 #&gt; [3,] 0.711 0.693 1.000 0.839 #&gt; [4,] 0.704 0.709 0.839 1.000 Iniziamo calcolando la soluzione a due fattori mediante il metodo delle componenti principali e una rotazione Varimax (ovvero, ortogonale). Otteniamo le seguenti saturazioni fattoriali. f1_pc &lt;- principal(R, 2, rotate = &quot;varimax&quot;) f1_pc #&gt; Principal Components Analysis #&gt; Call: principal(r = R, nfactors = 2, rotate = &quot;varimax&quot;) #&gt; Standardized loadings (pattern matrix) based upon correlation matrix #&gt; RC1 RC2 h2 u2 com #&gt; 1 0.50 0.78 0.86 0.140 1.7 #&gt; 2 0.47 0.81 0.88 0.124 1.6 #&gt; 3 0.90 0.33 0.92 0.078 1.3 #&gt; 4 0.89 0.35 0.92 0.083 1.3 #&gt; #&gt; RC1 RC2 #&gt; SS loadings 2.08 1.50 #&gt; Proportion Var 0.52 0.37 #&gt; Cumulative Var 0.52 0.89 #&gt; Proportion Explained 0.58 0.42 #&gt; Cumulative Proportion 0.58 1.00 #&gt; #&gt; Mean item complexity = 1.5 #&gt; Test of the hypothesis that 2 components are sufficient. #&gt; #&gt; The root mean square of the residuals (RMSR) is 0.06 #&gt; #&gt; Fit based upon off diagonal values = 0.99 Si noti che i due fattori non sono molto distinti. Consideriamo dunque la soluzione prodotta da una rotazione obliqua. Usiamo qui l’algoritmo Oblimin. pr_oblimin &lt;- principal(R, 2, rotate = &quot;oblimin&quot;) La matrice \\(\\hat{\\boldsymbol{\\Lambda}}\\) delle saturazioni fattoriali si ricava come indicato di seguito. cbind(pr_oblimin$load[, 1], pr_oblimin$load[, 2]) #&gt; [,1] [,2] #&gt; [1,] 0.03206780 0.90186261 #&gt; [2,] -0.02543116 0.95556536 #&gt; [3,] 0.96858605 -0.01096737 #&gt; [4,] 0.94726778 0.01327683 La matrice \\(\\hat{\\boldsymbol{\\Phi}}\\) di inter-correlazione fattoriale è la seguente. pr_oblimin$Phi #&gt; TC1 TC2 #&gt; TC1 1.0000000 0.7869776 #&gt; TC2 0.7869776 1.0000000 La matrice di struttura, che riporta le correlazioni tra indicatori e fattori comuni, si ottiene pre-moltiplicando la matrice \\(\\boldsymbol{\\Lambda}\\) delle saturazioni fattoriali alla matrice \\(\\boldsymbol{\\Phi}\\) di inter-correlazione fattoriale. \\[ \\text{matrice di struttura} = \\boldsymbol{\\Lambda}\\boldsymbol{\\Phi}. \\] Per esempio, la correlazione tra la prima variabile manifesta e il primo fattore si ottiene nel modo seguente. pr_oblimin$load[1, 1] + pr_oblimin$load[1, 2] * pr_oblimin$Phi[2, 1] #&gt; TC1 #&gt; 0.7418135 L’intera matrice di struttura si può trovare eseguendo la moltiplicazione \\(\\boldsymbol{\\Lambda}\\boldsymbol{\\Phi}\\). pr_oblimin$load %*% pr_oblimin$Phi %&gt;% round(3) #&gt; TC1 TC2 #&gt; [1,] 0.742 0.927 #&gt; [2,] 0.727 0.936 #&gt; [3,] 0.960 0.751 #&gt; [4,] 0.958 0.759 "],["esempio-con-semtools.html", "17.5 Esempio con semTools", " 17.5 Esempio con semTools Presento qui un esempio di uso di vari metodi di estrazione fattoriale. Tra tali metodi, la rotazione obliqua Geomin è molto popolare ed è il default di M-Plus. Iniziamo a caricare il pacchetto semTools. suppressPackageStartupMessages(library(&quot;semTools&quot;)) Eseguiamo l’analisi fattoriale esplorativa del classico set di dati di Holzinger e Swineford (1939) il quale è costituito dai punteggi dei test di abilità mentale di bambini di seconda e terza media di due scuole diverse (Pasteur e Grant-White). Nel set di dati originale (disponibile nel pacchetto MBESS), sono forniti i punteggi di 26 test. Tuttavia, un sottoinsieme più piccolo con 9 variabili è più ampiamente utilizzato in letteratura. Questi sono i dati qui usati. Nel presente esempio, verrà eseguita l’analisi fattoriale esplorativa con l’estrazione di tre fattori. Il metodo di estrazione è mlr: maximum likelihood estimation with robust (Huber-White) standard errors and a scaled test statistic that is (asymptotically) equal to the Yuan-Bentler test statistic. For both complete and incomplete data. La soluzione iniziale non è ruotata. unrotated &lt;- efaUnrotate(HolzingerSwineford1939, nf = 3, varList = paste0(&quot;x&quot;, 1:9), estimator = &quot;mlr&quot;) summary(unrotated) #&gt; lavaan 0.6.14 ended normally after 203 iterations #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of model parameters 36 #&gt; #&gt; Number of observations 301 #&gt; #&gt; Model Test User Model: #&gt; Standard Scaled #&gt; Test Statistic 22.897 23.864 #&gt; Degrees of freedom 12 12 #&gt; P-value (Chi-square) 0.029 0.021 #&gt; Scaling correction factor 0.959 #&gt; Yuan-Bentler correction (Mplus variant) #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Sandwich #&gt; Information bread Observed #&gt; Observed information based on Hessian #&gt; #&gt; Latent Variables: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; factor1 =~ #&gt; x1 (l1_1) 0.653 0.083 7.909 0.000 #&gt; x2 (l2_1) 0.353 0.079 4.481 0.000 #&gt; x3 (l3_1) 0.415 0.086 4.832 0.000 #&gt; x4 (l4_1) 0.926 0.067 13.762 0.000 #&gt; x5 (l5_1) 1.014 0.067 15.176 0.000 #&gt; x6 (l6_1) 0.868 0.062 13.886 0.000 #&gt; x7 (l7_1) 0.283 0.091 3.113 0.002 #&gt; x8 (l8_1) 0.340 0.083 4.096 0.000 #&gt; x9 (l9_1) 0.460 0.078 5.881 0.000 #&gt; factor2 =~ #&gt; x1 (l1_2) 0.349 0.124 2.814 0.005 #&gt; x2 (l2_2) 0.242 0.159 1.523 0.128 #&gt; x3 (l3_2) 0.497 0.132 3.767 0.000 #&gt; x4 (l4_2) -0.337 0.067 -5.058 0.000 #&gt; x5 (l5_2) -0.461 0.077 -6.009 0.000 #&gt; x6 (l6_2) -0.280 0.057 -4.908 0.000 #&gt; x7 (l7_2) 0.372 0.188 1.976 0.048 #&gt; x8 (l8_2) 0.510 0.133 3.830 0.000 #&gt; x9 (l9_2) 0.489 0.066 7.416 0.000 #&gt; factor3 =~ #&gt; x1 (l1_3) -0.338 0.103 -3.275 0.001 #&gt; x2 (l2_3) -0.405 0.092 -4.401 0.000 #&gt; x3 (l3_3) -0.404 0.120 -3.355 0.001 #&gt; x4 (l4_3) 0.049 0.098 0.503 0.615 #&gt; x5 (l5_3) 0.122 0.105 1.154 0.248 #&gt; x6 (l6_3) -0.000 0.076 -0.003 0.998 #&gt; x7 (l7_3) 0.609 0.125 4.863 0.000 #&gt; x8 (l8_3) 0.409 0.143 2.853 0.004 #&gt; x9 (l9_3) 0.112 0.123 0.915 0.360 #&gt; #&gt; Covariances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; factor1 ~~ #&gt; factor2 0.000 #&gt; factor3 0.000 #&gt; factor2 ~~ #&gt; factor3 0.000 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; factor1 1.000 #&gt; factor2 1.000 #&gt; factor3 1.000 #&gt; .x1 0.696 0.113 6.184 0.000 #&gt; .x2 1.035 0.106 9.803 0.000 #&gt; .x3 0.692 0.097 7.133 0.000 #&gt; .x4 0.377 0.053 7.170 0.000 #&gt; .x5 0.403 0.064 6.303 0.000 #&gt; .x6 0.365 0.046 7.984 0.000 #&gt; .x7 0.594 0.148 4.014 0.000 #&gt; .x8 0.479 0.099 4.842 0.000 #&gt; .x9 0.551 0.065 8.518 0.000 #&gt; #&gt; Constraints: #&gt; |Slack| #&gt; 0-(1_2*1_1+2_2*2_1+3_2*3_1+4_2*4_1+5_2*5_ 0.000 #&gt; 0-(1_3*1_1+2_3*2_1+3_3*3_1+4_3*4_1+5_3*5_ 0.000 #&gt; 0-(1_3*1_2+2_3*2_2+3_3*3_2+4_3*4_2+5_3*5_ 0.000 Si noti che, in assenza di rotazione, è impossibile assegnare un significato ai fattori comuni. 17.5.1 Orthogonal varimax Utilizziamo ora la rotazione ortogonale Varimax. out_varimax &lt;- orthRotate(unrotated, method = &quot;varimax&quot;) summary(out_varimax, sort = FALSE, suppress = 0.3) #&gt; Standardized Rotated Factor Loadings #&gt; factor1 factor2 factor3 #&gt; x1 0.320* 0.607* #&gt; x2 0.481* #&gt; x3 0.662* #&gt; x4 0.838* #&gt; x5 0.867* #&gt; x6 0.815* #&gt; x7 0.695* #&gt; x8 0.704* #&gt; x9 0.409* 0.511* #&gt; #&gt; Factor Correlation #&gt; factor1 factor2 factor3 #&gt; factor1 1 0 0 #&gt; factor2 0 1 0 #&gt; factor3 0 0 1 #&gt; #&gt; Method of rotation: varimax #&gt; #&gt; Test Statistics for Standardized Rotated Factor Loadings #&gt; lhs op rhs std.loading se z p ci.lower ci.upper #&gt; 1 factor1 =~ x1 0.320 0.055 5.799 0.000 0.212 0.428 #&gt; 2 factor1 =~ x2 0.135 0.063 2.151 0.031 0.012 0.259 #&gt; 3 factor1 =~ x3 0.080 0.049 1.622 0.105 -0.017 0.176 #&gt; 4 factor1 =~ x4 0.838 0.028 30.193 0.000 0.784 0.892 #&gt; 5 factor1 =~ x5 0.867 0.024 36.188 0.000 0.820 0.914 #&gt; 6 factor1 =~ x6 0.815 0.024 33.939 0.000 0.768 0.862 #&gt; 7 factor1 =~ x7 0.102 0.049 2.059 0.040 0.005 0.199 #&gt; 8 factor1 =~ x8 0.078 0.048 1.618 0.106 -0.016 0.172 #&gt; 9 factor1 =~ x9 0.170 0.053 3.222 0.001 0.067 0.273 #&gt; 10 factor2 =~ x1 0.607 0.075 8.138 0.000 0.461 0.753 #&gt; 11 factor2 =~ x2 0.481 0.067 7.184 0.000 0.350 0.612 #&gt; 12 factor2 =~ x3 0.662 0.058 11.499 0.000 0.549 0.775 #&gt; 13 factor2 =~ x4 0.113 0.043 2.615 0.009 0.028 0.198 #&gt; 14 factor2 =~ x5 0.032 0.040 0.802 0.422 -0.047 0.111 #&gt; 15 factor2 =~ x6 0.162 0.042 3.855 0.000 0.079 0.244 #&gt; 16 factor2 =~ x7 -0.062 0.047 -1.341 0.180 -0.154 0.029 #&gt; 17 factor2 =~ x8 0.174 0.082 2.117 0.034 0.013 0.336 #&gt; 18 factor2 =~ x9 0.409 0.079 5.173 0.000 0.254 0.564 #&gt; 19 factor3 =~ x1 0.130 0.066 1.978 0.048 0.001 0.259 #&gt; 20 factor3 =~ x2 -0.041 0.071 -0.578 0.563 -0.179 0.098 #&gt; 21 factor3 =~ x3 0.113 0.049 2.324 0.020 0.018 0.209 #&gt; 22 factor3 =~ x4 0.077 0.040 1.916 0.055 -0.002 0.155 #&gt; 23 factor3 =~ x5 0.070 0.042 1.669 0.095 -0.012 0.153 #&gt; 24 factor3 =~ x6 0.066 0.038 1.715 0.086 -0.009 0.141 #&gt; 25 factor3 =~ x7 0.695 0.092 7.591 0.000 0.516 0.875 #&gt; 26 factor3 =~ x8 0.704 0.083 8.520 0.000 0.542 0.865 #&gt; 27 factor3 =~ x9 0.511 0.065 7.884 0.000 0.384 0.638 17.5.2 Orthogonal Quartimin Un metodo alternativo per la rotazione ortogonale è Quartimin. out_quartimin &lt;- orthRotate(unrotated, method = &quot;quartimin&quot;) summary(out_quartimin, sort = FALSE, suppress = 0.3) #&gt; Standardized Rotated Factor Loadings #&gt; factor1 factor2 factor3 #&gt; x1 0.353* 0.590* #&gt; x2 0.474* #&gt; x3 0.657* #&gt; x4 0.844* #&gt; x5 0.869* #&gt; x6 0.823* #&gt; x7 0.692* #&gt; x8 0.702* #&gt; x9 0.397* 0.508* #&gt; #&gt; Factor Correlation #&gt; factor1 factor2 factor3 #&gt; factor1 1 0 0 #&gt; factor2 0 1 0 #&gt; factor3 0 0 1 #&gt; #&gt; Method of rotation: Quartimin #&gt; #&gt; Test Statistics for Standardized Rotated Factor Loadings #&gt; lhs op rhs std.loading se z p ci.lower ci.upper #&gt; 1 factor1 =~ x1 0.353 0.062 5.720 0.000 0.232 0.473 #&gt; 2 factor1 =~ x2 0.158 0.066 2.375 0.018 0.028 0.288 #&gt; 3 factor1 =~ x3 0.115 0.057 2.015 0.044 0.003 0.226 #&gt; 4 factor1 =~ x4 0.844 0.027 30.814 0.000 0.790 0.898 #&gt; 5 factor1 =~ x5 0.869 0.023 37.224 0.000 0.823 0.914 #&gt; 6 factor1 =~ x6 0.823 0.024 35.026 0.000 0.777 0.869 #&gt; 7 factor1 =~ x7 0.116 0.054 2.161 0.031 0.011 0.222 #&gt; 8 factor1 =~ x8 0.104 0.054 1.914 0.056 -0.003 0.210 #&gt; 9 factor1 =~ x9 0.202 0.059 3.403 0.001 0.086 0.319 #&gt; 10 factor2 =~ x1 0.590 0.078 7.523 0.000 0.436 0.743 #&gt; 11 factor2 =~ x2 0.474 0.068 6.935 0.000 0.340 0.608 #&gt; 12 factor2 =~ x3 0.657 0.059 11.204 0.000 0.542 0.771 #&gt; 13 factor2 =~ x4 0.072 0.041 1.748 0.080 -0.009 0.152 #&gt; 14 factor2 =~ x5 -0.010 0.039 -0.263 0.793 -0.087 0.066 #&gt; 15 factor2 =~ x6 0.122 0.040 3.008 0.003 0.042 0.201 #&gt; 16 factor2 =~ x7 -0.071 0.048 -1.465 0.143 -0.166 0.024 #&gt; 17 factor2 =~ x8 0.167 0.090 1.849 0.064 -0.010 0.343 #&gt; 18 factor2 =~ x9 0.397 0.087 4.581 0.000 0.227 0.567 #&gt; 19 factor3 =~ x1 0.124 0.071 1.740 0.082 -0.016 0.264 #&gt; 20 factor3 =~ x2 -0.042 0.074 -0.574 0.566 -0.187 0.102 #&gt; 21 factor3 =~ x3 0.114 0.054 2.093 0.036 0.007 0.221 #&gt; 22 factor3 =~ x4 0.056 0.037 1.503 0.133 -0.017 0.128 #&gt; 23 factor3 =~ x5 0.048 0.038 1.263 0.206 -0.027 0.123 #&gt; 24 factor3 =~ x6 0.046 0.034 1.347 0.178 -0.021 0.112 #&gt; 25 factor3 =~ x7 0.692 0.093 7.477 0.000 0.511 0.874 #&gt; 26 factor3 =~ x8 0.702 0.084 8.331 0.000 0.537 0.867 #&gt; 27 factor3 =~ x9 0.508 0.070 7.298 0.000 0.371 0.644 17.5.3 Oblique Quartimin L’algoritmo Quartimin può anche essere usato per una soluzione obliqua. out_oblq &lt;- oblqRotate(unrotated, method = &quot;quartimin&quot;) summary(out_oblq, sort = FALSE, suppress = 0.3) #&gt; Standardized Rotated Factor Loadings #&gt; factor1 factor2 factor3 #&gt; x1 0.602* #&gt; x2 0.505* #&gt; x3 0.689* #&gt; x4 0.840* #&gt; x5 0.888* #&gt; x6 0.808* #&gt; x7 0.723* #&gt; x8 0.701* #&gt; x9 0.366* 0.463* #&gt; #&gt; Factor Correlation #&gt; factor1 factor2 factor3 #&gt; factor1 1.0000000 0.3257784 0.2164388 #&gt; factor2 0.3257784 1.0000000 0.2704753 #&gt; factor3 0.2164388 0.2704753 1.0000000 #&gt; #&gt; Method of rotation: Quartimin #&gt; #&gt; Test Statistics for Standardized Rotated Factor Loadings #&gt; lhs op rhs std.loading se z p ci.lower ci.upper #&gt; 1 factor1 =~ x1 0.191 0.064 2.965 0.003 0.065 0.317 #&gt; 2 factor1 =~ x2 0.044 0.066 0.665 0.506 -0.085 0.172 #&gt; 3 factor1 =~ x3 -0.069 0.034 -2.031 0.042 -0.137 -0.002 #&gt; 4 factor1 =~ x4 0.840 0.033 25.622 0.000 0.776 0.905 #&gt; 5 factor1 =~ x5 0.888 0.027 32.583 0.000 0.835 0.942 #&gt; 6 factor1 =~ x6 0.808 0.028 28.441 0.000 0.752 0.863 #&gt; 7 factor1 =~ x7 0.044 0.037 1.179 0.238 -0.029 0.116 #&gt; 8 factor1 =~ x8 -0.033 0.036 -0.916 0.360 -0.103 0.037 #&gt; 9 factor1 =~ x9 0.035 0.048 0.728 0.467 -0.059 0.129 #&gt; 10 factor2 =~ x1 0.602 0.086 7.003 0.000 0.434 0.771 #&gt; 11 factor2 =~ x2 0.505 0.071 7.163 0.000 0.367 0.644 #&gt; 12 factor2 =~ x3 0.689 0.056 12.344 0.000 0.580 0.799 #&gt; 13 factor2 =~ x4 0.022 0.045 0.483 0.629 -0.067 0.110 #&gt; 14 factor2 =~ x5 -0.067 0.036 -1.890 0.059 -0.137 0.002 #&gt; 15 factor2 =~ x6 0.078 0.041 1.887 0.059 -0.003 0.158 #&gt; 16 factor2 =~ x7 -0.152 0.037 -4.058 0.000 -0.225 -0.078 #&gt; 17 factor2 =~ x8 0.104 0.109 0.960 0.337 -0.109 0.317 #&gt; 18 factor2 =~ x9 0.366 0.097 3.780 0.000 0.176 0.556 #&gt; 19 factor3 =~ x1 0.031 0.062 0.500 0.617 -0.090 0.152 #&gt; 20 factor3 =~ x2 -0.117 0.066 -1.776 0.076 -0.245 0.012 #&gt; 21 factor3 =~ x3 0.023 0.039 0.587 0.557 -0.054 0.100 #&gt; 22 factor3 =~ x4 0.005 0.042 0.128 0.898 -0.076 0.087 #&gt; 23 factor3 =~ x5 0.008 0.035 0.216 0.829 -0.061 0.076 #&gt; 24 factor3 =~ x6 -0.011 0.030 -0.362 0.717 -0.070 0.048 #&gt; 25 factor3 =~ x7 0.723 0.087 8.328 0.000 0.553 0.893 #&gt; 26 factor3 =~ x8 0.701 0.098 7.137 0.000 0.509 0.894 #&gt; 27 factor3 =~ x9 0.463 0.075 6.211 0.000 0.317 0.609 17.5.4 Orthogonal Geomin Consideriamo ora la rotazione Geomin. L’algoritmo Geomin fornisce un metodo di rotazione che riduce al minimo la media geometrica delle saturazioni fattoriali innalzate al quadrato. Qui è usato per ottenere una soluzione ortogonale. out_geomin_orh &lt;- orthRotate(unrotated, method = &quot;geomin&quot;) summary(out_geomin_orh, sort = FALSE, suppress = 0.3) #&gt; Standardized Rotated Factor Loadings #&gt; factor1 factor2 factor3 #&gt; x1 0.315 -0.621 #&gt; x2 -0.474* #&gt; x3 -0.671* #&gt; x4 0.838* #&gt; x5 0.867* #&gt; x6 0.814* #&gt; x7 0.696* #&gt; x8 0.677* #&gt; x9 0.456* -0.468 #&gt; #&gt; Factor Correlation #&gt; factor1 factor2 factor3 #&gt; factor1 1 0 0 #&gt; factor2 0 1 0 #&gt; factor3 0 0 1 #&gt; #&gt; Method of rotation: Geomin #&gt; #&gt; Test Statistics for Standardized Rotated Factor Loadings #&gt; lhs op rhs std.loading se z p ci.lower ci.upper #&gt; 1 factor1 =~ x1 0.315 0.633 0.499 0.618 -0.925 1.555 #&gt; 2 factor1 =~ x2 0.130 0.509 0.255 0.799 -0.868 1.128 #&gt; 3 factor1 =~ x3 0.074 0.672 0.110 0.912 -1.244 1.392 #&gt; 4 factor1 =~ x4 0.838 0.126 6.644 0.000 0.591 1.085 #&gt; 5 factor1 =~ x5 0.867 0.047 18.395 0.000 0.775 0.960 #&gt; 6 factor1 =~ x6 0.814 0.176 4.623 0.000 0.469 1.159 #&gt; 7 factor1 =~ x7 0.112 0.112 0.993 0.321 -0.109 0.332 #&gt; 8 factor1 =~ x8 0.085 0.157 0.542 0.588 -0.222 0.392 #&gt; 9 factor1 =~ x9 0.172 0.409 0.421 0.674 -0.629 0.973 #&gt; 10 factor2 =~ x1 0.053 0.112 0.475 0.635 -0.166 0.272 #&gt; 11 factor2 =~ x2 -0.099 0.087 -1.142 0.254 -0.269 0.071 #&gt; 12 factor2 =~ x3 0.033 0.069 0.482 0.630 -0.103 0.169 #&gt; 13 factor2 =~ x4 0.051 0.136 0.374 0.708 -0.215 0.317 #&gt; 14 factor2 =~ x5 0.054 0.158 0.340 0.734 -0.256 0.363 #&gt; 15 factor2 =~ x6 0.035 0.133 0.260 0.795 -0.226 0.296 #&gt; 16 factor2 =~ x7 0.696 0.089 7.863 0.000 0.523 0.870 #&gt; 17 factor2 =~ x8 0.677 0.098 6.897 0.000 0.485 0.869 #&gt; 18 factor2 =~ x9 0.456 0.109 4.175 0.000 0.242 0.671 #&gt; 19 factor3 =~ x1 -0.621 0.345 -1.797 0.072 -1.298 0.056 #&gt; 20 factor3 =~ x2 -0.474 0.151 -3.144 0.002 -0.769 -0.179 #&gt; 21 factor3 =~ x3 -0.671 0.090 -7.499 0.000 -0.847 -0.496 #&gt; 22 factor3 =~ x4 -0.129 0.861 -0.150 0.881 -1.816 1.558 #&gt; 23 factor3 =~ x5 -0.048 0.905 -0.053 0.958 -1.822 1.725 #&gt; 24 factor3 =~ x6 -0.176 0.840 -0.209 0.834 -1.823 1.471 #&gt; 25 factor3 =~ x7 -0.021 0.170 -0.123 0.902 -0.354 0.312 #&gt; 26 factor3 =~ x8 -0.257 0.173 -1.481 0.139 -0.597 0.083 #&gt; 27 factor3 =~ x9 -0.468 0.263 -1.776 0.076 -0.984 0.048 17.5.5 Oblique Geomin La rotazione Geomin può anche essere usata per ottenere una soluzione obliqua. out_geomin_obl &lt;- oblqRotate(unrotated, method = &quot;geomin&quot;) summary(out_geomin_obl, sort = FALSE, suppress = 0.3) #&gt; Standardized Rotated Factor Loadings #&gt; factor1 factor2 factor3 #&gt; x1 -0.604* #&gt; x2 -0.507* #&gt; x3 -0.691* #&gt; x4 0.839* #&gt; x5 0.887* #&gt; x6 0.806* #&gt; x7 0.726* #&gt; x8 0.703* #&gt; x9 0.463* -0.368* #&gt; #&gt; Factor Correlation #&gt; factor1 factor2 factor3 #&gt; factor1 1.0000000 0.2296197 -0.3271561 #&gt; factor2 0.2296197 1.0000000 -0.2776935 #&gt; factor3 -0.3271561 -0.2776935 1.0000000 #&gt; #&gt; Method of rotation: Geomin #&gt; #&gt; Test Statistics for Standardized Rotated Factor Loadings #&gt; lhs op rhs std.loading se z p ci.lower ci.upper #&gt; 1 factor1 =~ x1 0.188 0.070 2.670 0.008 0.050 0.326 #&gt; 2 factor1 =~ x2 0.044 0.054 0.806 0.420 -0.062 0.150 #&gt; 3 factor1 =~ x3 -0.073 0.050 -1.466 0.143 -0.170 0.024 #&gt; 4 factor1 =~ x4 0.839 0.032 26.467 0.000 0.777 0.901 #&gt; 5 factor1 =~ x5 0.887 0.029 30.078 0.000 0.829 0.945 #&gt; 6 factor1 =~ x6 0.806 0.030 26.717 0.000 0.747 0.865 #&gt; 7 factor1 =~ x7 0.031 0.034 0.914 0.361 -0.036 0.099 #&gt; 8 factor1 =~ x8 -0.045 0.048 -0.949 0.343 -0.139 0.048 #&gt; 9 factor1 =~ x9 0.025 0.034 0.746 0.455 -0.041 0.091 #&gt; 10 factor2 =~ x1 0.029 0.051 0.566 0.571 -0.071 0.129 #&gt; 11 factor2 =~ x2 -0.119 0.072 -1.663 0.096 -0.260 0.021 #&gt; 12 factor2 =~ x3 0.020 0.037 0.538 0.590 -0.052 0.092 #&gt; 13 factor2 =~ x4 0.007 0.043 0.174 0.862 -0.076 0.091 #&gt; 14 factor2 =~ x5 0.010 0.036 0.285 0.775 -0.060 0.080 #&gt; 15 factor2 =~ x6 -0.009 0.030 -0.309 0.758 -0.068 0.049 #&gt; 16 factor2 =~ x7 0.726 0.072 10.089 0.000 0.585 0.867 #&gt; 17 factor2 =~ x8 0.703 0.118 5.966 0.000 0.472 0.934 #&gt; 18 factor2 =~ x9 0.463 0.080 5.820 0.000 0.307 0.619 #&gt; 19 factor3 =~ x1 -0.604 0.081 -7.442 0.000 -0.763 -0.445 #&gt; 20 factor3 =~ x2 -0.507 0.073 -6.972 0.000 -0.649 -0.364 #&gt; 21 factor3 =~ x3 -0.691 0.061 -11.384 0.000 -0.810 -0.572 #&gt; 22 factor3 =~ x4 -0.024 0.034 -0.702 0.483 -0.091 0.043 #&gt; 23 factor3 =~ x5 0.065 0.045 1.459 0.145 -0.022 0.153 #&gt; 24 factor3 =~ x6 -0.080 0.048 -1.679 0.093 -0.173 0.013 #&gt; 25 factor3 =~ x7 0.150 0.108 1.396 0.163 -0.061 0.361 #&gt; 26 factor3 =~ x8 -0.106 0.165 -0.645 0.519 -0.428 0.216 #&gt; 27 factor3 =~ x9 -0.368 0.133 -2.772 0.006 -0.628 -0.108 "],["interpretazione-1.html", "17.6 Interpretazione", " 17.6 Interpretazione Possiamo chiederci se, per fornire un’interpretazione ai fattori comuni latenti, sia più opportuno usare la matrice pattern o la matrice struttura. Teoricamente, il fattore individuato dall’analisi fattoriale è una caratteristica latente univariata (una sorta di qualità che esprime l’“essenza” di un fenomeno psicologico). Poiché il fattore è una sorta di “essenza” univariata, dovrebbe essere interpretato come il significato (relativamente semplice) che giace sopra (o “dietro”) l’intersezione dei significati/contenuti delle variabili che saturano nel fattore. Nella rotazione obliqua i fattori sono correlati. Vogliamo comunque interpretarli come dimensioni psicologiche distinte. L’etichetta che assegniamo al fattore \\(F_1\\) dovrebbe contribuire a dissociare, in termini teorici, il fenomeno psicologico corrispondente a \\(F_1\\) dal fenomeno denotato dall’etichetta del fattore \\(F_2\\), anche in presenza di una correlazione tra i due, per sottolineare l’individualità di entrambi i fattori, pur riconoscendo il fatto che “nella realtà esterna” i due corrispondenti fenomeni psicologici tendono a covariare. Se è questa la strategia interpretativa, allora lo strumento principale per l’interpretazione corrisponde alla matrice pattern. Infatti, i coefficienti della matrice pattern, in quanto interpretabili come coefficienti parziali di regressione, rivelano l’influenza “causale” del fattore comune nella determinazione delle variabili manifeste. La matrice struttura, invece, descrive le correlazioni tra variabili e fattori. Abbiamo visto che, all’interno di un diagramma di percorso, la correlazione dipende sia dai percorsi diretti (“relazioni causali”) sia dai percorsi indiretti (che dipendono dalle correlazioni tra i fattori). Dunque la matrice struttura non descrive gli “effetti diretti”, cioè “causali” dei fattori comuni latenti sulle variabili manifeste ma solo, appunto, la covariazione tra i fattori comuni e le variabili manifeste. Il punto debole della matrice pattern è che è meno stabile da un campione all’altro, come lo sono di solito i coefficienti di regressione rispetto ai coefficienti di correlazione. Di conseguenza, fare affidamento sulla matrice pattern per l’interpretazione richiede uno studio ben pianificato e un’adeguata dimensione campionaria. Per uno studio pilota e un’interpretazione provvisoria, invece, la matrice struttura potrebbe essere la scelta migliore. "],["come-valutare-e-rifinire-la-soluzione-fattoriale.html", "Capitolo 18 Come valutare e rifinire la soluzione fattoriale ", " Capitolo 18 Come valutare e rifinire la soluzione fattoriale "],["valutazione-della-matrice-pattern.html", "18.1 Valutazione della matrice pattern", " 18.1 Valutazione della matrice pattern La maggior parte di strumenti usati nell’assessment psicologico e neuropsicologico non valuta una singola dimensione psicologica, ma piuttosto misura molteplici aspetti di un costrutto. Di conseguenza, l’analisi fattoriale produce solitamente una soluzione a più fattori. Idealmente, dopo la rotazione, ciascun item saturerà fortemente su un singolo fattore e debolmente sugli altri. In realtà, anche dopo la rotazione degli assi fattoriali, spesso si presentano item che saturano debolmente su tutti i fattori, oppure item che saturano fortemente su più di un fattore. Uno dei primi passi da compiere per rifinire la soluzione fattoriale è quello di valutare la matrice struttura e intervenire utilizzando il criterio della “struttura semplice”, per poi valutare gli effetti delle azioni intraprese (es., eliminazione di alcuni item) nella matrice pattern. Ricordiamo che la matrice struttura contiene le correlazioni tra item e fattori, mentre la matrice pattern contiene le saturazioni fattoriali. 18.1.1 Item con basse saturazioni su tutti i fattori Prima di procedere con l’analisi fattoriale è auspicabile esaminare la matrice di correlazioni tra gli item ed eliminare quegli item che sono insufficientemente correlati con gli altri item della matrice. Tuttavia, anche dopo questo screening iniziale, è possibile che vi siano item caratterizzati da saturazioni basse su tutti i fattori. Dal punto di vista pratico, si considerano “basse” le saturazioni il cui valore assoluto è minore di 0.30 (Hair et al., 1995). Hair e collaboratori suggeriscono due soluzioni nel caso di item con saturazioni basse su tutti i fattori: eliminare gli item con basse saturazioni, valutare le comunalità degli item problematici e il contributo specifico che forniscono allo strumento. Se un item ha una bassa comunalità, o se il contributo di un item nei confronti del significato generale dello strumento è di poca importanza, allora l’item dovrebbe essere eliminato. Dopo l’eliminazione degli item critici, si procede calcolando una nuova soluzione fattoriale e si esaminano i risultati ottenuti. Se vi sono degli item con basse saturazioni su tutti i fattori che però contribuiscono in maniera importante a determinare il significato della scala nel suo complesso, allora questi item dovrebbero essere mantenuti. Alle volte, per tali item è possibile creare delle sottoscale separate dalle altre. 18.1.2 Item con saturazioni evevate su più di un fattore È comune anche il caso opposto, ovvero quello nel quale ci sono item che saturano su fattori multipli (con saturazioni fattoriali \\(&gt;\\) .30), specialmente nel caso di soluzioni fattoriali ottenutie dopo una rotazione obliqua. Kline (2000) suggerisce di eliminare tali item in quanto rendono difficile da interpretare il significato della scala che così si ottiene. Hair e collaboratori (1995) ritengono invece che tali item dovrebbero essere mantenuti, dato possono chiarire il significato dei fattori che la scala identifica. "],["valutazione-dellattendibilità.html", "18.2 Valutazione dell’attendibilità", " 18.2 Valutazione dell’attendibilità All’interno del problema della costruzione di uno strumento vengono esaminati tre aspetti dell’attendibilità: la consistenza interna, la stabilità e l’equivalenza. 18.2.1 Consistenza interna 18.2.1.1 La procedura split-half La consistenza interna misura il grado di coerenza tra gli item che costituiscono lo strumento o le sottoscale dello strumento. Se tutti gli item che costituiscono uno strumento o una sua sottoscala misurano la stessa cosa, allora saranno fortemente associati tra loro. È possibile misurare la consistenza interna con il metodo dello split-half, ovvero mediante la correlazione di Pearson tra i punteggi ottenuti utilizzando ciascuna delle due metà degli item dello strumento. Usando un software, è meglio trovare la media delle correlazioni inter-item ricavabili a partire da tutte le possibili divisioni a metà dell’insieme di item che costituiscono lo strumento. La correlazione trovata in questo modo viene poi corretta utilizzando la formula “profetica” di Spearman-Brown per tenere in considerazione il fatto che l’attendibilità è stata calcolata utilizzando soltanto metà degli item dello strumento. Si noti che la formula di Spearman-Brown è basata sull’assunzione che le due metà dello strumento siano parallele, ovvero che abbiano identici punteggi veri e uguali varianze d’errore (questa assunzione comporta la conseguenza per cui le due metà degli item devono producono punteggi aventi la stessa media e la stessa varianza). Se queste assunzioni molto stringenti non vengono soddisfatte, allora la procedura descritta sopra conduce ad una sovrastima dell’attendibilità quale consisenza interna della scala. 18.2.1.2 L’analisi della varianza Se tutti gli item di uno strumento o di una sottoscala sono espressione dello stesso costrutto, allora ci dobbiamo aspettare che anche le medie dei punteggi sugli item siano uguali. Come è stato detto sopra, questa è infatti una delle assunzioni delle forme strettamente parallele di un test. È dunque possibile verificare questa assunzione mediante un’ANOVA che sottopone a test l’ipotesi nulla dell’uguaglianza delle medie di gruppi. Nel caso degli item di un test, dato che ciascun soggetto completa tutti gli item che costituiscono lo strumento, è appropriato usare un’ANOVA per misure ripetute che, nella sua declinazione più moderna, corrisponde ad un modello multi-livello (mixed-effect model). 18.2.1.3 L’indice \\(\\alpha\\) di Cronbach L’indice \\(\\alpha\\) di Cronbach è comunque la misura più utilizzata per valutare l’attendibilità quale consistenza interna di uno strumento. L’\\(\\alpha\\) di Cronbach è stato interpretato come la proporzione di varianza della scala che può essere attribuita al fattore comune (DeVellis, 1991). Può anche essere interpretato come la correlazione stimata tra i punteggi della scala e un’altro strumento della stessa lunghezza tratto dall’universo degli item possibili che costituiscono il dominio del costrutto (Kline, 1986). La radice quadrata del coefficiente \\(\\alpha\\) di Cronbach rappresenta la correlazione stimata tra i punteggi ottenuti tramite lo strumento e i punteggi veri (Nunnally &amp; Bernstein, 1994). In precedenza abbiamo descritto una serie di limiti del coefficiente \\(\\alpha\\) di Cronbach. In generale, molti ricercatori suggeriscono di usare al suo posto l’indice \\(\\omega\\) di McDonald. 18.2.2 Stabilità temporale La stabilità temporale viene valutata attraverso la procedura di test-retest. La correlazione tra le misure ottenute in due momenti negli stessi rispondenti ci fornisce l’attendibilità di test-retest. Kline (2000) ha messo in evidenza come l’attendibilità di test-retest sia influenzata da molteplici fattori, tra cui le caratteristiche del campione, la maturità dei rispondenti, i cambiamenti nello stato emozionale, le differenze nelle condizioni di somministrazione del test, la possibilità di ricordare le risposte date in precedenza, la difficoltà degli item, la grandezza del campione e le caratteristiche del costrutto (ad esempio, stato vs. tratto). Particolare attenzione deve essere rivolta all’intervallo temporale usato nella procedura di test-retest. Se il periodo di tempo che intercorre tra le due somministrazioni è troppo corto, i risultati possono risultare distorti a causa del fatto che i soggetti si ricordano le risposte date in precedenza. Questo può condurre ad una sovrastima dell’attendibilità test-retest (Pedhazur &amp; Schmelkin, 1991). Un intervallo temporale troppo lungo tra le due somministrazioni ha invece come limite il fatto che, in questo caso, vi è un’alta possibilità che intervengano dei cambiamenti nei rispondenti rispetto al costrutto in esame. Alla luce di queste considerazioni è stato suggerito di utilizzare un intervallo temporale abbastanza breve, ovvero di una o due settimane (Nunnally &amp; Bernstein, 1994; Pedhazur &amp; Schmelkin, 1991). Se è necessario valutare la stabilità temporale nel corso di un lungo arco temporale, Nunnally e Bernstein (1994) suggeriscono di utilizzare un intervallo di sei mesi o maggiore. 18.2.3 Equivalenza Per cercare di evitare i problemi associati all’attendibilità quale stabilità temporale, alcuni autori si sono posti il problema di esaminare la correlazione tra forme parallele (o equivalenti) dello strumento. La correlazione tra forme parallele di uno strumento va sotto il nome di coefficiente di equivalenza e fornisce una misura alternativa dell’attendibilità dello strumento (Burns &amp; Grove, 2001; Pedhazur &amp; Schmelkin, 1991; Polit &amp; Hungler, 1999). Nunnally e Bernstein (1994) suggeriscono di confrontare i risultati ottenuti con la somministrazione delle forme parallele lo stesso giorno con quelli ottenuti nel caso di un intervallo temporale di due settimane. Kline (2000) ritiene che l’attendibilità tra due forme parallele debba essere di almeno 0.9 perché, per valori inferiori, sarebbe difficile sostenere che le forme sono veramente parallele. È tuttavia molto oneroso predisporre due forme parallele di uno strumento. Per questa ragione, il coefficiente di equivalenza viene raramente usato. "],["selezione-di-un-sottoinsieme-di-item.html", "18.3 Selezione di un sottoinsieme di item", " 18.3 Selezione di un sottoinsieme di item Tipicamente, la costruzione di un test viene realizzata somministrando un grande numero di item per poi selezionare gli item “migliori” che andranno a fare parte del test vero e proprio. Si supponga di somministrare inizialmente \\(m\\) item, quando si desidera che il test finale sia costituito da \\(p &lt; m\\) item. Un modo di affrontare questo problema potrebbe essere quello di calcolare l’attendibilità del test (coefficiente \\(\\omega\\)) per tutti i possibili sottoinsiemi di \\(p\\) item, così da individuare il sottoinsieme migliore. Questo modo di procedere, però, è problematico perché richiede la valutazione di un elevatissimo numero di possibilità. Per esempio, da un insieme iniziale neanche troppo numeroso di 100 item, il numero di sottoinsiemi di 20 item è uguale a \\[ \\binom{100}{20} = 5.36 \\times 10^{20}. \\] È dunque necessario trovare metodi alternativi che evitino una tale esplosione combinatoria. A questo fine, ovvero per procedere alla selezione del sottoinsieme dei “migliori” item, McDonald (2013) suggerisce di calcolare la quantità di informazione di ciascun item. La quantità di informazione di un item è definita come rapporto tra segnale/rumore, in relazione alla scomposizione della varianza dell’item: \\[ \\frac{\\lambda_i^2}{\\psi_{ii}}. \\] McDonald (2013) mostra come l’omissione di uno o più item produce sempre una riduzione dell’attendibilità del test (ovvero, una riduzione nel valore del coefficiente \\(\\omega\\)). Tuttavia, tale riduzione è tanto più piccola quanto più piccola è la quantità di informazione degli item omessi. Il processo di selezione degli item può dunque essere guidato da un semplice principio: si selezionano gli item aventi la quantità di informazione maggiore. Ovvero, in altre parole, si rimuovono gli item aventi la quantità di informazione più bassa. Esempio 18.1 Per fare un esempio, consideriamo nuovamente la matrice di varianze e di covarianze della scala SWLS. varnames &lt;- c(&quot;Y1&quot;, &quot;Y2&quot;, &quot;Y3&quot;, &quot;Y4&quot;, &quot;Y5&quot;) SWLS &lt;- matrix( c( 2.565, 1.424, 1.481, 1.328, 1.529, 1.424, 2.493, 1.267, 1.051, 1.308, 1.481, 1.267, 2.462, 1.093, 1.360, 1.328, 1.051, 1.093, 2.769, 1.128, 1.529, 1.308, 1.360, 1.128, 3.355 ), ncol = 5, byrow = TRUE, dimnames = list(varnames, varnames) ) SWLS #&gt; Y1 Y2 Y3 Y4 Y5 #&gt; Y1 2.565 1.424 1.481 1.328 1.529 #&gt; Y2 1.424 2.493 1.267 1.051 1.308 #&gt; Y3 1.481 1.267 2.462 1.093 1.360 #&gt; Y4 1.328 1.051 1.093 2.769 1.128 #&gt; Y5 1.529 1.308 1.360 1.128 3.355 Utilizzando la funzione cfa() contenuta nel pacchetto lavaan, il modello ad un fattore viene definito nel modo seguente. mod_1 &lt;- &quot; F =~ Y1 + Y2 + Y3 + Y4 + Y5 &quot; Otteniamo così una stima dei pesi fattoriali e delle unicità. fit &lt;- lavaan::cfa( mod_1, sample.cov = SWLS, sample.nobs = 215, std.lv = TRUE ) Calcoliamo la quantità di informazione fornita da ciascun item. Iniziamo a estrarre dall’oggetto fit la matrice delle saturazioni fattoriali. lambda &lt;- inspect(fit, what = &quot;std&quot;)$lambda lambda #&gt; F #&gt; Y1 0.817 #&gt; Y2 0.694 #&gt; Y3 0.726 #&gt; Y4 0.591 #&gt; Y5 0.643 Estraiamo da fit le specificità. theta &lt;- diag(inspect(fit, what = &quot;std&quot;)$theta) theta #&gt; Y1 Y2 Y3 Y4 Y5 #&gt; 0.3330083 0.5181701 0.4732395 0.6512159 0.5866646 Possiamo ora calcolare quantità di informazione degli item facendo il rapporto tra ciascuna saturazione fattoriale innalzata al quadrato e la corrispondente specificità. for (i in 1:5) { print(lambda[i]^2 / theta[i]) } #&gt; Y1 #&gt; 2.002928 #&gt; Y2 #&gt; 0.9298683 #&gt; Y3 #&gt; 1.113095 #&gt; Y4 #&gt; 0.5355891 #&gt; Y5 #&gt; 0.7045515 Il risultato ottenuto indica che il quarto item è il meno informativo e che il quinto item è il secondo meno informativo. Se un solo item deve essere eliminato, dunque, elimineremo il quarto item. Se devono essere eliminati due item, andranno eliminati il quarto e il quinto item. 18.3.1 Attendibilità e numero di item Di quanto cambia l’attendibilità di uno strumento se viene variato il numero di item? Una risposta a questa domanda può essere fornita dalla formula profetica di Spearman-Brown. Supponiamo che nella formula di Spearman-Brown, \\[\\begin{equation} \\rho_p = \\frac{p \\rho_1}{(p-1)\\rho_1 + 1}, \\tag{18.1} \\end{equation}\\] \\(\\rho_1\\) rappresenti l’attendibilità di un test costituito da un certo numero di item. Se poniamo \\(p=2\\), la (18.1) ci fornisce una stima dell’attendibilità che si otterrebbe raddoppiando il numero di item nel test. Valori di \\(p\\) minori di \\(1\\), invece, vengono usati per predire la diminuizione dell’attendibilità conseguente ad una diminuzione nel numero degli item del test. Ricordiamo però che le predizioni della formula di Spearman-Brown sono accurate solo se la forma allungata o accorciata del test è parallela rispetto al test considerato. Per esempio, se ad un test con un coefficiente di attendibilità molto alto vengono aggiunti item aventi una bassa attendibilità, allora l’attendibilità del test allungato sarà minore di quella predetta dalla formula di Spearman-Brown. Anche se la formula di Spearman-Brown ha un ruolo centrale nella teoria classica dei test, si tenga conto che non rappresenta l’unico strumento che può essere utilizzato per valutare la relazione tra attendibilità e numero degli item del test. La quantità detta informazione dell’item (item information), formulata dai modelli IRT, consente di predire i cambiamenti nella qualità della misura a seguito dell’aggiunta o della cancellazione di un sottoinsieme di item. Esempio 18.2 Si consideri la scala SWLS. Chiediamoci come varia l’attendibilità della scala se il numero di item aumenta da 5 a 20. Poniamo che l’attendibilità della scala SWLS costituita da 5 item sia uguale a 0.824. Applicando la formula di Spearman-Brown otteniamo la stima seguente. (4 * 0.824) / ((4 - 1) * 0.824 + 1) #&gt; [1] 0.9493088 Esempio 18.3 Possiamo giungere al risultato precedente in un altro modo. Supponiamo che i 15 item aggiuntivi abbiano le stesse saturazioni fattoriali medie (\\(\\bar{\\lambda}\\)) e le stesse varianze specifiche medie (\\(\\bar{\\psi}\\)) rispetto agli item originali. Mediante gli item di cui disponiamo, stimiamo l’attendibilità di un “item medio” nel modo seguente \\[ \\rho_1 = \\frac{\\bar{\\lambda}^2}{\\bar{\\lambda}^2 + \\bar{\\psi}}, \\] ovvero otteniamo la stima di 0.48: rho_1 &lt;- mean(lambda)^2 / (mean(lambda)^2 + mean(theta)) rho_1 #&gt; [1] 0.4845124 L’attendibilità predetta di un test costituito da 20 item sarà dunque uguale a (20 * rho_1) / ((20 - 1) * rho_1 + 1) #&gt; [1] 0.9494904 il che replica il risultato ottenuto precedentemente. Esempio 18.4 Un altro modo ancora per ottenere lo stesso risultato è quello di utilizzare un modello mono-fattoriale per item paralleli. mod_2 &lt;- &quot; F =~ a*Y1 + a*Y2 + a*Y3 + a*Y4 + a*Y5 Y1 ~~ b*Y1 Y2 ~~ b*Y2 Y3 ~~ b*Y3 Y4 ~~ b*Y4 Y5 ~~ b*Y5 &quot; Adattiamo il modello ai dati. fit2 &lt;- lavaan::cfa( mod_2, sample.cov = SWLS, sample.nobs = 215, std.lv = TRUE ) Estraiamo dall’oggetto fit2 le saturazioni fattoriali. lambda &lt;- inspect(fit2, what = &quot;std&quot;)$lambda lambda #&gt; F #&gt; Y1 0.689 #&gt; Y2 0.689 #&gt; Y3 0.689 #&gt; Y4 0.689 #&gt; Y5 0.689 Estraiamo da fit2 le specificità. theta &lt;- diag(inspect(fit2, what = &quot;std&quot;)$theta) theta #&gt; Y1 Y2 Y3 Y4 Y5 #&gt; 0.5247361 0.5247361 0.5247361 0.5247361 0.5247361 Calcoliamo l’attendibilità dell’item “medio” usando \\(\\lambda\\) e \\(\\psi\\) (chiamato theta da lavaan). rho_1 &lt;- lambda[1]^2 / (lambda[1]^2 + theta[2]) rho_1 #&gt; Y2 #&gt; 0.4752639 Posso ora applicare la formula di Spearman-Brown. (20 * rho_1) / ((20 - 1) * rho_1 + 1) #&gt; Y2 #&gt; 0.9476834 Il risultato è praticamente identico a quelli trovati in precedenza. 18.3.2 Numero di item e affidabilità La formula di Spearman-Brown può anche essere riarrangiata in maniera tale da consentirci di predire il numero degli item necessari per raggiungere un determinato livello di affidabilità: \\[\\begin{equation} p = \\frac{\\rho_p (1-\\rho_1)}{\\rho_1(1-\\rho_p)}, \\tag{18.2} \\end{equation}\\] dove \\(\\rho_1\\) è l’attendibilità stimata di un “item medio,” \\(\\rho_p\\) è il livello desiderato di attendibilità del test allungato e \\(p\\) è il numero di item del test allungato. Esempio 18.5 L’attendibilità della scala SWLS costituita da 5 item è \\(\\omega = 0.824\\). Quanti item devono essere aggiunti se si vuole raggiungere un livello di attendibilità pari a \\(0.95\\)? Ponendo \\(\\rho_p = 0.95\\) e \\(\\rho_1= 0.479\\), in base alla (18.2) si ottiene che (.95 * (1 - rho_1)) / (rho_1 * (1 - .95)) #&gt; Y2 #&gt; 20.97779 il test dovrà essere costituito da 21 item. References "],["analisi-degli-item.html", "18.4 Analisi degli item", " 18.4 Analisi degli item L’analisi degli item esamina le risposte fornite ai singoli item del questionario allo scopo di valutare la qualità degli item e del questionario nel suo complesso. Sotto al rubrica di analisi degli item possiamo raggruppare le procedure che possono essere utilizzate per descrivere la difficoltà degli item, le relazioni tra coppie di item, il punteggio totale del test, le relazioni tra gli item e il punteggio totale del test. Tali analisi statistiche vengono usate per la selezione degli item al fine di costruire un questionario omogeneo, attendibile e dotato di validità predittiva. La selezione degli item di un test, però, non può essere svolta in maniera automatica usando soltanto criteri statistici quali quelli elencati sopra. La selezione degli item, invece, deve anche tenere includere considerazioni di ordine teorico basate sulla centralità degli item rispetto alla definizione del costrutto e considerazioni relative agli scopi della misurazione e al modo in cui l’item è stato formulato e costruito. Se alcuni aspetti di un costrutto non vengono rappresentanti da item che soddisfano i criteri statistici descritti sopra, o se c’è un numero insufficiente di item per produrre uno strumento attendibile, allora alcuni item dovranno essere riscritti. Nella riformulazione degli item, risultano utili le intuizioni che si sono guadagnate dalle analisi statistiche degli item che si sono dovuti scartare. 18.4.1 Difficoltà degli item Se consideriamo un test di prestazione massima, la caratteristica psicometrica più ovvia che deve essere valutata negli item è la proporzione di soggetti che rispondono correttamente agli item. La proporzione \\(p_j\\) di partecipanti che rispondono correttamente all’item \\(j\\)-esimo, o proporzione di partecipanti che si dichiarano in accordo con l’affermazione espressa dall’item, se il test non è di prestazione, fornisce una stima del livello di difficoltà \\(\\pi_j\\) dell’item. In realtà, \\(p_j\\) dovrebbe essere chiamato “facilità dell’item” in quanto assume il suo valore maggiore (ovvero \\(1\\)) quando tutti i rispondenti rispondono correttamente all’item e il suo valore minimo (ovvero \\(0\\)) quando le risposte sono tutte sbagliate. I valori \\(p_j\\) giocano un ruolo importante nelle procedure di selezione degli item. La difficoltà degli item deve essere interpretata in riferimento alla probabilità di indovinare la risposta corretta. Si suppone, infatti, che i rispondenti tirino ad indovinare quando non conoscono la risposta alla domanda di un questionario. Nel caso di item dicotomici, per esempio, ci possiamo aspettare un valore \\(p_j\\) pari a \\(0.50\\) sulla base del caso soltanto; nel caso di item a risposta multipla con quattro opzioni di scelta, invece, \\(p_j\\) assume un valore pari a \\(0.25\\) quando i rispondenti tirano ad indovinare. Se il test è composto per la maggior parte da item “facili”, allora il test non sarà in grado di discriminare tra rispondenti con diversi livelli di abilità, in quanto quasi tutti i rispondenti saranno in grado di fornire una risposta corretta alla maggioranza degli item. Lo stesso si può dire per un test composto da item “difficili”. Se il test è composto unicamente da item di difficoltà media, non potrà differenziare i rispondenti che hanno un grado di abilità media da quelli con abilità superiori alla media, dato che non ci sono item “difficili”, e neppure da quelli con abilità inferiori alla media, dato che non ci sono item “facili”. In generale, dunque, è buona pratica costruire test composti da item che coprano tutti i livelli di difficoltà. La scelta che viene usualmente fatta è quella di una dispersione moderata e simmetrica del livello di difficoltà attorno ad un valore leggermente superiore al valore che sta a metà tra il livello del caso (\\(1.0\\) diviso per il numero di alternative) e il punteggio pieno (\\(1.0\\)). Per item che presentano cinque alternative di risposta, ad esempio, il livello del caso è pari a \\(1.0 / 5 = 0.20\\). Il livello ottimale di difficoltà è uguale a \\[ 0.20 + (1.0 - 0.20) / 2 = 0.60. \\] Per item dicotomici, il livello del caso è \\(1.0 / 2 = 0.50\\) e il livello ottimale di difficoltà è uguale a \\[ 0.50 + (1.00 - 0.50) / 2 = 0.75. \\] In generale, item con livelli di difficoltà superiore a \\(0.90\\) o inferiore a \\(0.20\\) dovrebbero essere utilizzati con cautela. Esempio 18.6 Riporto qui sotto le proporzioni di risposte corrette (usando la correzione per il guessing) di 192 studenti di Psicometria nel primo parziale dell’AA 2021/2022. Il test aveva 16 item con 5 alternative di risposta ciascuno. Dunque la difficoltà media ottimale è pari a 0.6. item_par_1 &lt;- c( 0.54255319, 0.76063830, 0.64361702, 0.65957447, 0.67021277, 0.12234043, 0.14361702, 0.18085106, 0.76063830, 0.82978723, 0.81914894, 0.84042553, 0.07978723, 0.07978723, 0.76063830, 0.79255319 ) Nel compito, la difficoltà media è risultata essere un po’ inferiore. mean(item_par_1) %&gt;% round(2) #&gt; [1] 0.54 La distribuzione dei livelli di difficoltà degli item suggerisce che forse alcuni item “difficili” si sarebbero potuti sostituire con item di difficoltà media. plot(density(item_par_1)) 18.4.2 Correzione per guessing Alle volte i valori \\(p_j\\) sono calcolati introducendo una correzione per le risposte fornite casualmente dai soggetti (guessing). Si consideri un test a scelta multipla composto da item aventi ciascuno \\(C\\) alternative di risposta ed una sola risposta corretta. Si supponga che un rispondente risponda correttamente a \\(R\\) item e risponda in maniera sbagliata a \\(W\\) item. La correzione per guessing si ottiene applicando una formula basata sul seguente ragionamento. Se assumiamo che un rispondente si limita a tirare ad indovinare allora, ogni \\(C\\) risposte, ci aspettiamo 1 risposta giusta e \\(C-1\\) risposte sbagliate. Per calcolare il punteggio totale del test in modo da eliminare il numero di risposte corrette ottenute tirando ad indovinare è necessario sottrarre 1 punto per ogni \\(C-1\\) item a cui è stata fornita una risposta corretta. Questo ragionamento conduce alla seguente formula: \\[\\begin{equation} FS = R - \\frac{W}{C - 1}, \\tag{18.3} \\end{equation}\\] con \\(R\\) = # risposte corrette, \\(W\\) = # risposte sbagliate, \\(C\\) = # alternative di risposta. Per esempio, se \\(C=5\\), allora è necessario sottrarre un punto ogni 4, il che è proprio quello che fa la (18.3). La (18.3) produce un punteggio totale corretto per il guessing identico a quello che si otterrebbe assegnando 1 punto a ciascuna risposta corretta e assegnando \\(- \\frac{1}{C-1}\\) punti alle risposte sbagliate; le risposte non date non vengono considerate. La correzione per guessing rappresenta il tentativo di scomporre il numero totale di risposte corrette in due componenti: le risposte corrette dovute alle conoscenze del soggetto, le risposte che risultano corrette come effetto del caso. La stessa formula può anche essere utilizzata per calcolare la difficoltà degli item corretta per il guessing (come è stato fatto nell’esempio del parziale di Psicometria). 18.4.3 Discriminatività La discriminatività è una misura di quanto ogni item è in grado di distinguere i soggetti con elevati livelli nel costrutto da quelli con un livello basso. L’indice di discriminatività \\(D\\) per i test di prestazione massima si trova nel modo seguente. Dopo avere calcolato il punteggio totale al test, si dividono i soggetti in due gruppi: soggetti con basso punteggio e soggetti con alto punteggio. Una volta definiti i due gruppi, l’indice di discriminatività \\(D\\) sarà dato da: \\[D = P(\\text{alto}) - P(\\text{basso}),\\] dove \\(P(\\text{alto}\\) è la proporzione di soggetti che ha risposto correttamente all’item nel gruppo con punteggi alti e \\(P(\\text{basso}\\) è la proporzione di soggetti che ha risposto correttamente all’item nel gruppo con punteggi bassi. Il valore di \\(D\\) può variare da -1 a +1. Nella tabella seguente sono fornite le linee guida per l’interpretazione di questo indice (Ebel, 1965). Linee guida per l’interpretazione dell’indice di discriminatività \\(D\\). Valore di \\(D\\) Commento \\(D \\geq 0.40\\) Ottima, nessuna revisione \\(0.30 \\leq D &lt; 0.40\\) Buona, revisioni minime \\(0.20 \\leq D &lt; 0.30\\) Sufficiente, revisioni parziali \\(D &lt; 0.20\\) Insufficiente, riformulazione o eliminazione La discriminatività degli item di tipo Likert viene valutata con la medesima procedura degli item dei testi di prestazione massima, anche se cambiano le procedure statistiche da utilizzare. Si può dividere la distribuzione dei punteggi totali (o punteggi medi) in quartili e confrontare il punteggio medio o mediano del quartile superiore con quello del quartile inferiore, oppure, se il test è orientato al criterio e lo scopo è selezionare gli item che discriminano meglio due gruppi precostituiti di soggetto, eseguire i medesimi confronti tra il gruppo target (ad esempio, pazienti) e quello “di controllo” (per esempio, popolazione generale). È consigliabile valutare la dimensione dell’effetto, ad esempio attraverso l’indice \\(d\\) di Cohen. La dimensione dell’effetto dovrebbe essere almeno moderata (\\(d &gt; |0.50|\\)). Esempio 18.7 Per il primo parziale di Psicometria AA 2021/2022, l’indice \\(d\\) di Cohen calcolato sulla proporzione di risposte corrette per il gruppo di studenti con i punteggi più bassi (primo quartile) e il gruppo di studenti con i punteggi più alti (ultimo quartile) è stato di 4.76, 95% CI [4.0, 5.51]. L’indice complessivo di discriminatività sembra dunque adeguato. Sarebbe però necessario calcolare questo indice item per item. 18.4.4 Potere discriminante dell’item e analisi fattoriale Secondo McDondald (1999), la nozione di potere discriminante dell’item può essere trattata in maniera più precisa nell’ambito del modello monofattoriale. Se l’insieme di item a disposizione non è eccessivamente grande (200 o meno), infatti, è possibile procedere alla selezione degli item migliori tramite l’analisi fattoriale – ovvero, scegliendo gli item con le saturazioni maggiori. Esempio 18.8 Per il primo parziale di Psicometria AA 2021/2022 si ottiene la seguente soluzione fattoriale a due fattori. Questa soluzione sembra suggerire che gli item 1 e 5 forse andrebbero sostituiti, mentre gli altri item sembrano adeguati. faT1 &lt;- fa(r=cormat, nfactors=2, n.obs=192, rotate=&quot;oblimin&quot;) faT1$loadings Loadings: MR1 MR2 i1 0.132 i2 0.270 0.107 i3 0.489 i4 0.343 0.365 i5 0.130 0.105 i6 0.565 -0.497 i7 0.527 i8 0.792 i9 0.363 i10 0.467 0.250 i11 0.459 0.190 i12 0.111 0.497 i13 0.401 i14 0.511 0.173 i15 0.206 0.252 i16 0.247 0.365 18.4.5 Punteggio sull’item e punteggio totale Il grado di associazione tra il punteggio sull’item e il punteggio totale viene considerato dalla teoria classica dei test come un indice che descrive il potere discriminante dell’item. Se il test fornisce una misura attendibile di un unico attributo, e se un item è fortemente associato al punteggio del test, allora l’item sarà in grado di distinguere tra rispondenti che ottengono un punteggio basso nel test e rispondenti che ottengono un punteggio alto nel test. Nel caso di una forte associazione positiva tra il punteggio sull’item e il punteggio totale, la probabilità di risposta corretta sull’item è alta per rispondenti che ottengono un punteggio totale alto, e bassa per i rispondenti che ottengono un punteggio totale basso. Nel caso di una debole associazione tra il punteggio sull’item e il punteggio totale, invece, la probabilità di risposta corretta all’item non è predittiva del punteggio totale. Gli item con un basso potere discriminante dovrebbero dunque essere rimossi dal reattivo. È necessario distinguere i casi in cui gli item sono dicotomici dal caso di item continui. Nel caso di item dicotomici e di un test unidimensionale, il potere discriminante viene calcolato mediante la correlazione biseriale o punto-biseriale. 18.4.6 Relazioni tra coppie di item Le relazioni tra coppie di item sono importanti sia per la costruzione sia per la validazione dei test psicometrici. La teoria classica dei test definisce l’attendibilità di un test (o di un item) come il rapporto tra la varianza del punteggio vero e la varianza del punteggio osservato. Il coefficiente di attendibilità può però essere calcolato anche trovando la correlazione tra due forme parallele di un test (o tra due item). Inoltre, è possibile interpretare la correlazione tra due forme parallele di un test (o tra due item) come il quadrato del coefficiente di correlazione tra i punteggi osservati e i punteggi veri di un test (o di un item). Molti indici sono disponibili per misurare il grado di associazione tra item. Per item quantitativi, possiamo usare la correlazione di Pearson o la covarianza. Per item qualitativi politomici ordinali, usiamo la correlazione policorica. Per item ordinali dicotomici, usiamo la correlazione tetracorica. Per item dicotomici usiamo, ad esempio, l’indice \\(\\phi\\). 18.4.7 Ridondanza Nel processo di raffinamento del test occorre anche tenere conto degli item ridondanti, ossia degli item che sono troppo associati tra loro. La ridondanza può essere valutata con indici statistici quali la correlazione: se due o più item hanno tra loro una correlazione maggiore di \\(|0.70|\\) viene mantenuto nell’item pool solo uno di essi, dato che gli altri item forniscono la stessa informazione. 18.4.8 Massimizzazione della varianza del punteggio totale Uno dei criteri che possono essere utilizzati per la selezionare degli item che andranno a costituire la versione finale di un test è la massimizzazione della varianza del punteggio totale. Più in particolare, si vuole massimizzare il rapporto tra la varianza del punteggio totale e la somma delle varianze dei punteggi dei \\(p\\) item. Dato che il coefficiente \\(\\alpha\\) di Cronbach ha la seguente forma: \\[\\alpha = \\frac{p}{p-1}\\left[1- \\frac{\\sum \\sigma^2_{Y_i}}{\\sigma^2_T} \\right],\\] la scelta di massimizzare il rapporto definito in precedenza avrà anche la conseguenza di massimizzare \\(\\alpha\\). McDonald (2013) fa notare che una procedura di selezione degli item basata sul principio della massimizzazione di \\(\\alpha\\) ha però dei limiti. In primo luogo, tale procedura è appropriata solo quando l’insieme di item è troppo grande per selezionare gli item in base all’esame delle saturazioni fattoriali ottenute applicando il modello mono-fattoriale. In secondo luogo, McDonald (2013) nota che la procedura di selezione basata sulla massimizzazione di \\(\\alpha\\) è adeguata solo nel caso di una struttura mono-fattoriale. La selezione degli item basata sulla massimizzazione di \\(\\alpha\\) deve dunque essere accompagnata da considerazione relative al contenuto e alla struttura del costrutto. References "],["ch-factorial-invariance.html", "Capitolo 19 Invarianza di misura", " Capitolo 19 Invarianza di misura I precedenti esempi di CFA presentati in questa dispensa sono stati stimati all’interno di un singolo gruppo, hanno utilizzato come input un’unica matrice covarianza e hanno portato alla stima dei parametri del modello sui quali non è stata imposta alcuna restrizione. In questo capitolo, le analisi precedenti verranno estese considerando il problema dell’invarianza di misura. Quello che ci chiediamo è se sia sensato considerare la medesima struttura fattoriale in gruppi diversi. In altre parole, ci chiediamo se viene misurata la stessa variabile latente tra gruppi diversi. Questa proprietà è chiamata invarianza di misura (Meredith 1993). L’approccio che viene utilizzato per valutare l’invarianza di misura è quello dell’analisi fattoriale confermativa a gruppi multipli (multiple-group confirmatory factor analysis, MG-CFA). Questa verifica è importante perché i confronti tra le medie dei gruppi sono possibili solo se viene dimostrata l’equivalenza di misura: se lo stesso reattivo misura dimensioni diverse in gruppi diversi, i confronti tra gruppi nei termini di quella misura non sono ovviamente possibili. Nel presente Capitolo, verrà affrontato il problema dell’invarianza di misura considerando prima il caso degli indicatori continui e poi il caso ddeli indicatori categoriali. References "],["indicatori-continui.html", "19.1 Indicatori continui", " 19.1 Indicatori continui 19.1.1 Intercette degli item In generale, i modelli di equazioni strutturali vengono utilizzati per modellare unicamente la matrice di covarianza delle variabili osservate in un set di dati. Ricordiamo che, quando abbiamo introdotto il modello dell’analisi fattoriale, \\[ y_i = \\mu + \\lambda_j \\xi_k + \\delta_i, \\] per semplicità abbiamo ignorato la media \\(\\mu\\) degli indicatori esprimendo i dati osservati nei termini degli scarti dalla media, \\(y_i -\\mu\\), in quanto ciò lascia immutate le covarianze. Tuttavia, in alcune applicazioni (quali, appunto, l’invarianza di misura), è utile considerare anche le medie delle variabili osservate. Per includere nel modello fattoriale le informazioni sulle medie facciamo esplicito riferimento all’intercetta della precedente equazione. Usando la sintassi lavaan, la media di una variabile manifesta viene inserita nel modello specificando l’intercetta dell’equazione precedente come segue my_item ~ 1 La parte sinistra dell’espressione precedente contiene il nome della variabile manifesta a cui si fa riferimento; la parte destra dell’espressione precedente specifica la presenza dell’intercetta. Per esempio, nella specificazione di un modello a due fattori comuni, è possibile aggiungere al modello le medie delle variabili manifeste nel modo seguente: mod1 &lt;- &quot; # two-factor model f1 =~ x1 + x2 + x3 f2 =~ x4 + x5 + x6 # intercepts x1 ~ 1 x2 ~ 1 x3 ~ 1 x4 ~ 1 x5 ~ 1 x6 ~ 1 &quot; Tuttavia, è più conveniente omettere le intercette nella specificazione del modello e aggiungere l’argomento meanstructure = TRUE nella funzione cfa(). mod2 &lt;- &quot; f1 =~ x1 + x2 + x3 f2 =~ x4 + x5 + x6 &quot; fit &lt;- cfa( mod2, data = d, meanstructure = TRUE ) Si noti che modelli con o senza meanstructure avranno la stessa statistica chi-quadrato e lo stesso numero di gradi di libertà. Il motivo è che, nel caso di un modello con meanstructure, vengono introdotti \\(p\\) nuovi dati (ovvero, il valore della media per ciascuno dei \\(p\\) indicatori) ma vengono anche stimati ulteriori \\(p\\) parametri (ovvero, un’intercetta per ciascuno dei \\(p\\) indicatori). Il risultato finale è che la bontà dell’adattamento resta immutata. In pratica, l’unico motivo per aggiungere le intercette nella sintassi del modello è quello di introdurre dei vincoli nella stima di tali parametri. 19.1.2 Terminologia La discussione dell’invarianza di misura nel contesto della CFA fa uso della seguente terminologia. L’invarianza configurale (configural invariance) verifica se la struttura dei fattori sia la stessa tra i gruppi, ovvero verifica la presenza dello stesso numero di fattori e della stessa struttura fattoriale (nella CFA) tra i gruppi. L’invarianza metrica (metric invariance) o invarianza fattoriale debole (weak factorial invariance) verifica inoltre se le saturazioni fattoriali rimangono invariante tra i gruppi. L’invarianza scalare (scalar invariance) o invarianza fattoriale forte verifica inoltre se le intercette degli item rimangono invariate tra i gruppi. L’invarianza fattoriale rigorosa (strict factorial invariance) verifica inoltre se i residui degli indicatori rimangono invarianti tra i gruppi. 19.1.3 Un esempio concreto Consideriamo qui un esempio discusso da Brown (2015). Il modello CFA riguarda un modello di misurazione per la depressione maggiore così come è definita nel DSM-IV. Il campione include 9 indicatori: MDD1, depressed mood; MDD2, loss of interest in usual activities; MDD3, weight/appetite change; MDD4, sleep disturbance; MDD5, psychomotor agitation/retardation; MDD6, fatigue/loss of energy; MDD7, feelings of worthlessness/guilt; MDD8, concentration difficulties; MDD9, thoughts of death/suicidality. Leggiamo i dati in \\(\\mathsf{R}\\): d &lt;- readRDS( here::here(&quot;data&quot;, &quot;mdd_sex.RDS&quot;) ) I due gruppi considerati corrispondono al genere. Il problema riguarda l’invarianza fattoriale in funzione del genere. Consideriamo il seguente modello: model_mdd &lt;- &quot; MDD =~ mdd1 + mdd2 + mdd3 + mdd4 + mdd5 + mdd6 + mdd7 + mdd8 + mdd9 mdd1 ~~ mdd2 &quot; Si noti la presenza di una correlazione residua tra gli indicatori mdd1 e mdd2. Esaminiamo dunque di seguito le varie forme di invarianza fattoriale. Si notino i vincoli che vengono via via introdotti quando vengono specificati modelli via via più restrittivi. Nella sintassi lavaan i vincoli vengono specificati dall’argomento group.equal. Le forme di invarianza fattoriale qui verificate sono leggermente diverse da quelle elencate sopra. # configural invariance fit_ef &lt;- cfa( model_mdd, data = d, group = &quot;sex&quot;, meanstructure = TRUE ) # plus equal factor loadings- metric invariance fit_efl &lt;- update( fit_ef, group.equal = c(&quot;loadings&quot;) ) # plus equal indicator intercepts fit_eii &lt;- update( fit_efl, group.equal = c(&quot;loadings&quot;, &quot;intercepts&quot;) ) # plus equal indicator error variances fit_eir &lt;- update( fit_eii, group.equal = c(&quot;loadings&quot;, &quot;intercepts&quot;, &quot;residuals&quot;) ) # plus equal factor variances fit_fv &lt;- update( fit_eir, group.equal = c( &quot;loadings&quot;, &quot;intercepts&quot;, &quot;residuals&quot;, &quot;lv.variances&quot; ) ) # plus equal latent means fit_fm &lt;- update( fit_fv, group.equal = c( &quot;loadings&quot;, &quot;intercepts&quot;, &quot;residuals&quot;, &quot;lv.variances&quot;, &quot;means&quot; ) ) Confrontiamo i modelli: lavTestLRT(fit_ef, fit_efl, fit_eii, fit_eir, fit_fv, fit_fm) #&gt; #&gt; Chi-Squared Difference Test #&gt; #&gt; Df AIC BIC Chisq Chisq diff RMSEA Df diff Pr(&gt;Chisq) #&gt; fit_ef 52 27526 27784 98.911 #&gt; fit_efl 60 27514 27736 102.839 3.9286 0.000000 8 0.8635 #&gt; fit_eii 68 27510 27695 115.309 12.4699 0.038600 8 0.1314 #&gt; fit_eir 77 27502 27645 125.021 9.7115 0.014520 9 0.3743 #&gt; fit_fv 78 27501 27639 125.814 0.7931 0.000000 1 0.3732 #&gt; fit_fm 79 27501 27635 127.734 1.9201 0.049533 1 0.1659 Il confronto tra i precedenti modelli nidificati che introducono vincoli sempre più stringenti sui parametri indica che non vi è una “significativa” perdita di bontà dell’adattamento passando dal modello congenerico al modello che assume l’uguaglianza delle saturazioni fattoriali, delle intercette, delle varianze residue, delle varianze delle variabili latenti e delle medie dei due gruppi. Per i dati discussi da Brown (2015), dunque, possiamo concludere che vi sono forti evidenze di invarianza fattoriale tra maschi e femmine in relazione al costrutto di depressione maggiore. L’invarianza fattoriali giustifica, per questi dati, un confronto tra le medie dei punteggi totali del test calcolate nei due gruppi. References "],["indicatori-a-livello-di-scala-ordinale.html", "19.2 Indicatori a livello di scala ordinale", " 19.2 Indicatori a livello di scala ordinale I test di invarianza fattoriale per i dati ordinali sono diversi da quelli utilizzati con le variabili continue per due aspetti: differiscono sia per lo stimatore che viene utilizzato per la stima delle saturazioni fattoriali, sia per il tipo di analisi statistiche che vengono svolte. Le variabili ordinali sono costituite da una serie di modalità (opzioni di risposta) caratterizzate da un ordine logico; ad esempio, le modalità “fortemente in disaccordo” fino a “fortemente d’accordo”; oppure le modalità “mai”, “a volte”, “spesso”, “sempre”. Queste opzioni di risposta sono logicamente ordinate e, per convenzione, ad esse vengono assegnati valori numerici interi. Tuttavia, poiché le risposte ordinali non descrivono l’intensità della presenza di un attributo, l’assegnazione di numeri alle risposte ordinali è arbitraria. Ad esempio, alle stesse cinque opzioni di risposta ordinate possiamo assegnare valori da 0 a 4, da 1 a 5, o da 5 a 1. Pertanto, i dati ordinali non possono essere analizzati come se fossero continui: nel caso di dati ordinali, le medie, le varianze e le covarianze delle variabili non hanno significato. Un primo problema da affrontare è quello di come si possono calcolare le correlazioni per variabili di questo tipo. La risposta a questa domanda viene fornita dalle correlazioni policoriche. Le correlazioni policoriche si calcolano ipotizzando che vi sia una variabile continua latente normalmente distribuita che è responsabile delle frequenze osservate delle varie modalità di ciascuna variabile ordinali. Secondo questa ipotesi, ogni valore di risposta ordinale (es, “spesso”) corrisponde ai valori della variabile continua latente sottostante compresi in un determinato intervallo di valori. Tali soglie, o cutoff, (\\(\\tau_1, \\tau_2, \\dots, \\tau_k\\)) sono concepite come dei margini verticali che suddividono l’area sottesa alla funzione di densità della distribuzione normale sottostante in \\(k\\) sezioni, ciascuna delle quali corrisponde alla frequenza del punteggio ordinale che è stato osservato in quella categoria di risposta. Se le correlazioni tra variabili ordinali sono stimate mediante le correlazioni policoriche, allora, nel contesto dell’invarianza fattoriale, un primo problema è quello dell’invarianza delle soglie (treshold invariance), la quale assume che le soglie necessarie per definire le correlazioni policoriche siano invarianti tra i gruppi. Un secondo aspetto specifico che riguarda lo studio dell’invarianza fattoriale nel caso di variabili ordinali riguarda lo stimatore da usare per la stima delle saturazioni fattoriali. Lo stimatore attualmente consigliato per i dati ordinali è quello dei minimi quadrati ponderati (Weighted least squares, WLS). 19.2.1 Un esempio concreto Wu and Estabrook (2016) ritengono che la procedura per la valutazione dell’invarianza fattoriale che è stata descritta in precedenza (per dati continui) debba essere modificata se vogliamo applicarla a indicatori categoriali. La procedura usuale consiste nel definire prima un modello di riferimento e successivamente di imporre restrizioni crescenti ai parametri. Secondo Wu and Estabrook (2016), tale approccio non è ottimale nel caso di dati categoriali perché dipende fortemente dal modo in cui vengono definite le soglie necessarie per definire le correlazioni policoriche assegnate alle variabili continue latenti nel modello dell’invarianza configurale. Secondo Wu and Estabrook (2016), dunque, è prima necessario valutare l’equivalenza delle soglie tra gruppi (threshold model) e poi valutare il modello che ipotizza l’equivalenza delle saturazioni fattoriali tra i gruppi. Per illustrare tale procedura, replichiamo qui il tutorial messo a punto da Svetina, Rutkowski, and Rutkowski (2020). Questi autori utilizzano quattro item di una scala del bullismo ed esaminano i dati raccolti in tre paesi (31 = Azerbaigian; 40 = Austria; 246 = Finlandia). Tutti gli item sono misurati su una scala di tipo Likert a 4 punti, che va da 0 (mai) a 3 (almeno una volta alla settimana). Gli item chiedono al partecipante di valutare delle affermazioni relative ad episodi di bullismo. Per esempio, “mi prendevano in giro o mi insultavano”. Per l’Azerbaigian, l’Austria e la Finlandia, le dimensioni del campione sono rispettivamente pari a 3,808, 4,457 e 4,520. Leggiamo in dati in \\(\\textsf{R}\\): dat &lt;- read.table(&quot;data/BULLY.dat&quot;, header = FALSE) names(dat) &lt;- c(&quot;IDCNTRY&quot;, &quot;R09A&quot;, &quot;R09B&quot;, &quot;R09C&quot;, &quot;R09D&quot;) head(dat) #&gt; IDCNTRY R09A R09B R09C R09D #&gt; 1 31 3 3 0 0 #&gt; 2 31 0 0 0 0 #&gt; 3 31 3 2 1 3 #&gt; 4 31 0 0 3 0 #&gt; 5 31 0 0 0 0 #&gt; 6 31 0 0 0 0 Viene creata la matrice all.results per immagazzinare i risultati dei diversi modelli che verranno confrontati, chiamati baseline (nessun vincolo tra i gruppi), proposition 4 (equivalenza delle soglie tra i gruppi), e proposition 7 (equivalenza delle soglie e delle saturazioni fattoriali tra i gruppi). Gli indici di bontà dell’adattamento che verranno considerati sono: chi-square, df, p, RMSEA, CFI, e TLI. all.results &lt;- matrix(NA, ncol = 6, nrow = 3) 19.2.2 Baseline model Nel baseline model non viene posto alcun vincolo tra i gruppi. È quello dell’invarianza configurale. mod.cat &lt;- &quot;F1 =~ R09A + R09B + R09C + R09D&quot; baseline &lt;- measEq.syntax( configural.model = mod.cat, data = dat, ordered = c(&quot;R09A&quot;, &quot;R09B&quot;, &quot;R09C&quot;, &quot;R09D&quot;), parameterization = &quot;delta&quot;, ID.fac = &quot;std.lv&quot;, ID.cat = &quot;Wu.Estabrook.2016&quot;, group = &quot;IDCNTRY&quot;, group.equal = &quot;configural&quot; ) Informazioni sul modello baseline si ottengono nel modo seguente: summary(baseline) Le proprietà del modello possono essere esplicitate con la seguente istruzione: cat(as.character(baseline)) Per potere essere passato a lavaan, l’oggetto baseline deve essere in formato char: model.baseline &lt;- as.character(baseline) Adattiamo il modello ai dati: fit.baseline &lt;- cfa( model.baseline, data = dat, group = &quot;IDCNTRY&quot;, ordered = c(&quot;R09A&quot;, &quot;R09B&quot;, &quot;R09C&quot;, &quot;R09D&quot;) ) Salviamo i risultati: all.results[1, ] &lt;- round( data.matrix( fitmeasures(fit.baseline, fit.measures = c( &quot;chisq.scaled&quot;, &quot;df.scaled&quot;, &quot;pvalue.scaled&quot;, &quot;rmsea.scaled&quot;, &quot;cfi.scaled&quot;, &quot;tli.scaled&quot; )) ), digits = 3 ) 19.2.3 Invarianza delle soglie Consideriamo ora il modello threshold invariance (chiamato Proposition 4 da Wu and Estabrook 2016). prop4 &lt;- measEq.syntax( configural.model = mod.cat, data = dat, ordered = c(&quot;R09A&quot;, &quot;R09B&quot;, &quot;R09C&quot;, &quot;R09D&quot;), parameterization = &quot;delta&quot;, ID.fac = &quot;std.lv&quot;, ID.cat = &quot;Wu.Estabrook.2016&quot;, group = &quot;IDCNTRY&quot;, group.equal = c(&quot;thresholds&quot;) ) Adattiamo il modello ai dati: model.prop4 &lt;- as.character(prop4) fit.prop4 &lt;- cfa( model.prop4, data = dat, group = &quot;IDCNTRY&quot;, ordered = c(&quot;R09A&quot;, &quot;R09B&quot;, &quot;R09C&quot;, &quot;R09D&quot;) ) Salviamo i risulati # store model fit information for proposition 4 all.results[2, ] &lt;- round( data.matrix( fitmeasures(fit.prop4, fit.measures = c( &quot;chisq.scaled&quot;, &quot;df.scaled&quot;, &quot;pvalue.scaled&quot;, &quot;rmsea.scaled&quot;, &quot;cfi.scaled&quot;, &quot;tli.scaled&quot; )) ), digits = 3 ) Eseguiamo il confronto tra il modello threshold invariance e il modello baseline: lavTestLRT(fit.baseline, fit.prop4) #&gt; #&gt; Scaled Chi-Squared Difference Test (method = &quot;satorra.2000&quot;) #&gt; #&gt; lavaan NOTE: #&gt; The &quot;Chisq&quot; column contains standard test statistics, not the #&gt; robust test that should be reported per model. A robust difference #&gt; test is a function of two standard (not robust) statistics. #&gt; #&gt; Df AIC BIC Chisq Chisq diff Df diff Pr(&gt;Chisq) #&gt; fit.baseline 6 26.942 #&gt; fit.prop4 14 42.170 61.011 8 2.951e-10 *** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 19.2.4 Invarianza delle soglie e delle saturazioni fattoriali Consideriamo ora il modello threshold and loading invariance (chiamato Proposition 7 da Wu and Estabrook 2016). prop7 &lt;- measEq.syntax( configural.model = mod.cat, data = dat, ordered = c(&quot;R09A&quot;, &quot;R09B&quot;, &quot;R09C&quot;, &quot;R09D&quot;), parameterization = &quot;delta&quot;, ID.fac = &quot;std.lv&quot;, ID.cat = &quot;Wu.Estabrook.2016&quot;, group = &quot;IDCNTRY&quot;, group.equal = c(&quot;thresholds&quot;, &quot;loadings&quot;) ) Adattiamo il modello ai dati: model.prop7 &lt;- as.character(prop7) fit.prop7 &lt;- cfa( model.prop7, data = dat, group = &quot;IDCNTRY&quot;, ordered = c(&quot;R09A&quot;, &quot;R09B&quot;, &quot;R09C&quot;, &quot;R09D&quot;) ) Salviamo i risultati: all.results[3, ] &lt;- round(data.matrix( fitmeasures(fit.prop7, fit.measures = c( &quot;chisq.scaled&quot;, &quot;df.scaled&quot;, &quot;pvalue.scaled&quot;, &quot;rmsea.scaled&quot;, &quot;cfi.scaled&quot;, &quot;tli.scaled&quot; )) ), digits = 3) column.names &lt;- c( &quot;chisq.scaled&quot;, &quot;df.scaled&quot;, &quot;pvalue.scaled&quot;, &quot;rmsea.scaled&quot;, &quot;cfi.scaled&quot;, &quot;tli.scaled&quot; ) row.names &lt;- c(&quot;baseline&quot;, &quot;prop4&quot;, &quot;prop7&quot;) colnames(all.results) &lt;- column.names rownames(all.results) &lt;- row.names Eseguiamo i confronti tra modelli: lavTestLRT(fit.prop4, fit.prop7) #&gt; #&gt; Scaled Chi-Squared Difference Test (method = &quot;satorra.2000&quot;) #&gt; #&gt; lavaan NOTE: #&gt; The &quot;Chisq&quot; column contains standard test statistics, not the #&gt; robust test that should be reported per model. A robust difference #&gt; test is a function of two standard (not robust) statistics. #&gt; #&gt; Df AIC BIC Chisq Chisq diff Df diff Pr(&gt;Chisq) #&gt; fit.prop4 14 42.170 #&gt; fit.prop7 20 93.115 73.708 6 7.08e-14 *** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 lavTestLRT(fit.prop7, fit.baseline) #&gt; #&gt; Scaled Chi-Squared Difference Test (method = &quot;satorra.2000&quot;) #&gt; #&gt; lavaan NOTE: #&gt; The &quot;Chisq&quot; column contains standard test statistics, not the #&gt; robust test that should be reported per model. A robust difference #&gt; test is a function of two standard (not robust) statistics. #&gt; #&gt; Df AIC BIC Chisq Chisq diff Df diff Pr(&gt;Chisq) #&gt; fit.baseline 6 26.942 #&gt; fit.prop7 20 93.115 136.14 14 &lt; 2.2e-16 *** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Un confronto tra gli indici di bontà di adattamento dei tre modelli è fornito di seguito: all.results #&gt; chisq.scaled df.scaled pvalue.scaled rmsea.scaled cfi.scaled #&gt; baseline 50.944 6 0 0.042 0.997 #&gt; prop4 107.839 14 0 0.040 0.994 #&gt; prop7 186.542 20 0 0.044 0.989 #&gt; tli.scaled #&gt; baseline 0.991 #&gt; prop4 0.992 #&gt; prop7 0.990 In conclusione, nel caso presente, il test del rapporto di verosimiglianza indica che non viene rispettata neppure l’invarianza delle soglie tra gruppi. Gli altri confronti, dunque, sono superflui e sono stati qui presentati solo allo scopo di illustrare la procedura, References "],["ch-goodness-of-fit.html", "Capitolo 20 Indici di bontà dell’adattamento", " Capitolo 20 Indici di bontà dell’adattamento I passi principali nella CFA e nei modelli SEM comprendono la specificazione del modello, la stima dei parametri, la valutazione del modello e dei parametri e la modificazione del modello. Questa sequenza può essere ripetuta molte volte fino a quando non si trovi un modello considerato accettabile. La valutazione del modello viene eseguita calcolando vari indici di bontà dell’adattamento. In questo Capitolo considereremo i principali indici di bontà dell’adattamento utilizzati nella letteratura. "],["stima-del-modello.html", "20.1 Stima del modello", " 20.1 Stima del modello L’obiettivo della CFA è ottenere stime per i parametro del modello (vale a dire, saturazioni fattoriali, varianze e covarianze fattoriali, varianze residue ed eventualmente covarianze degli errori) che sono in grado di produrre una matrice di covarianza prevista (denotata da \\(\\boldsymbol{\\Sigma}\\)) la quale è il più possibile simile alla matrice di covarianze campionarie (denotata da \\(\\boldsymbol{S}\\)). Questo processo di stima è basato sulla minimizzazione di una funzione che descrive la differenza tra \\(\\boldsymbol{\\Sigma}\\) e \\(\\boldsymbol{S}\\). Il metodo di stima più utilizzato nella CFA (e, in generale, nei modelli SEM) è la massima verosimiglianza (ML). "],["massima-verosimiglianza.html", "20.2 Massima verosimiglianza", " 20.2 Massima verosimiglianza L’equazione fondamentale dell’analisi fattoriale è \\[ \\boldsymbol y = \\boldsymbol \\Lambda \\boldsymbol x + \\boldsymbol z, \\] dove \\(\\boldsymbol{y}\\) è un vettore di \\(p\\) componenti (i punteggi osservati nel del test), \\(\\boldsymbol{x}\\) è un vettore di \\(k &lt; p\\) componenti (i punteggi fattoriali), \\(\\boldsymbol{\\Lambda}\\) è una \\(p \\cdot k\\) matrice (di saturazioni fattoriali), e \\(\\boldsymbol{z}\\) è un vettore di \\(p\\) componenti (la componenti dei punteggi del test non dovute all’effetto causale delle variabili comuni latenti). Per l’item \\(i\\)-esimo, in precedenza abbiamo scritto l’equazione precedente come \\[ y_i = \\lambda_{i1} \\xi_1 + \\dots + \\lambda_{ik} \\xi_k + \\delta_i. \\] Dalle assunzioni del modello fattoriale deriva che \\[ \\boldsymbol{\\Sigma} = \\boldsymbol{\\Lambda}\\boldsymbol{\\Phi}\\boldsymbol{\\Lambda}^\\prime + \\Psi, \\] dove \\(\\boldsymbol{\\Phi}\\) è la matrice delle inter-correlazioni fattoriali. Si assume che il vettore casuale \\(\\boldsymbol{y}\\) abbia una distribuzione normale multivariata con matrice di covarianza \\(\\boldsymbol{\\Sigma}\\) e che da tale distribuzione sia stato estratto un campione casuale di \\(n\\) osservazioni \\(y_l, y_2, \\dots, y_n\\). Il logaritmo della funzione di verosimiglianza per il campione è dato da \\[ \\log L = \\frac{1}{2}n [\\log | \\boldsymbol{\\Sigma}| + \\mbox{tr}(\\boldsymbol{\\boldsymbol{S} \\Sigma}^{-1})]. \\] L’equazione precedente viene vista come funzione di \\(\\Lambda\\) e \\(\\Psi\\). Anziché massimizzare \\(\\log L\\), è equivalente e più conveniente minimizzare \\[ F_{k}(\\Lambda, \\Psi) = \\log |\\boldsymbol{\\Sigma}| + \\mbox{tr}[\\boldsymbol{S}\\boldsymbol{\\Sigma}^{-1}] - \\log|\\boldsymbol{S}| – p, \\] dove \\(|\\boldsymbol{S}|\\) è il determinante della matrice di covarianza tra le variabili osservate, \\(|\\boldsymbol{\\Sigma}|\\) è il determinante della matrice di covarianza prevista e \\(p\\) è il numero di indicatori. L’obiettivo della stima di massima verosimiglianza della CFA è trovare le stime dei parametri che rendono più verosimili i dati osservati (o, al contrario, massimizzano la verosimiglianza dei parametri dati i dati). Le stime dei parametri in un modello CFA si ottengono con una procedura iterativa. Cioè, l’algoritmo inizia con una serie iniziale di stime dei parametri (denominate valori iniziali o stime iniziali, che possono essere generate automaticamente dal software o specificate dall’utente) e raffina ripetutamente queste stime nel tentativo di minimizzare la differenza tra \\(\\boldsymbol{\\Sigma}\\) e \\(\\boldsymbol{S}\\). Il programma effettua controlli interni per valutare i suoi progressi nell’ottenere stime dei parametri che al meglio riproducono \\(\\boldsymbol{S}\\). Si raggiunge la convergenza quando l’algoritmo produce una serie di stime dei parametri che non possono essere ulteriormente migliorate per ridurre la differenza tra \\(\\boldsymbol{\\Sigma}\\) e \\(\\boldsymbol{S}\\). "],["identificabilità-del-modello.html", "20.3 Identificabilità del modello", " 20.3 Identificabilità del modello Un modello CFA deve essere formulato in modo tale da garantire la risolvibilità matematica dello stesso, ovvero deve essere tale da consentire una stima univoca dei parametri del modello. Detto in altre parole, la specificazione del modello ne deve garantire l’dentificabilità. Il problema dell’identificazione richiede, innanzitutto, di chiarire il concetto di gradi di libertà (degrees of freedom). Nel presente contesto, per gradi di libertà (\\(\\mbox{df}\\)) intendiamo \\[ \\mbox{df} = \\# (\\text{unità di informazione}) - \\# (\\text{parametri da stimare}). \\] I dati che vengono analizzati da un modello CFA sono contenuti in una matrice di covarianza. Per una matrice di covarianza di ordine \\(p\\), il numero di unità di informazione è \\[ \\frac{p (p+1)}{2}. \\] Affinché il modello sia identificabile, devono essere soddisfatte le seguenti condizioni. Indipendentemente dalla complessità del modello (ad es. modelli ad un fattore rispetto a più fattori), l’unità di misura delle variabili latenti deve essere specificata (di solito fissandola a un valore di 1); Indipendentemente dalla complessità del modello, il numero di unità di informazione (es. la matrice di covarianza degli indicatori) deve essere uguale o superiore al numero di parametri da stimare (es. saturazioni fattoriali, specificità, covarianze degli errori dell’indicatore, covarianze tra i fattori); Nel caso di modelli ad un fattore è richiesto un minimo di tre indicatori. Quando vengono utilizzati tre indicatori, la soluzione a un fattore si dice “appena identificata” (just-identified); in tali condizioni non è possibile valutare la bontà dell’adattamento. Nel caso di modelli a due o più fattori e due indicatori per costrutto latente, la soluzione è sovraidentificata, a condizione che ogni variabile latente sia correlata con almeno un’altra variabile latente e gli errori tra gli indicatori siano tra loro incorrelati. Tuttavia, poiché tali soluzioni sono suscettibili di scarsa identificazione empirica, viene raccomandato un minimo di tre indicatori per variabile latente. In conclusione, una semplice e necessaria condizione per l’identificazione di un modello CFA è che vi siano più unità di informazione che parametri da stimare. Dunque, abbiamo che: se \\(\\mbox{df} &lt; 0\\), il modello non è identificato e, in questo caso, non è possibile stimare i parametri; se \\(\\mbox{df} = 0\\), il modello è appena identificato o “saturo”; in questo caso, la matrice di covarianza riprodotta coincide con la matrice di covarianza delle variabili osservate e, di conseguenza, non esiste un residuo attraverso cui valutare la bontà dell’adattamento del modello; se \\(\\mbox{df} &gt; 0\\), il modello è sovra-identificato ed esistono le condizioni per valutare la bontà dell’adattamento. Le considerazioni precedenti ci fanno capire perché non si può fare un’analisi fattoriale con solo due indicatori e un fattore; in tali circostanze, infatti, ci sono \\((2 \\cdot 3)/2 = 3\\) gradi di libertà, ma 4 parametri da stimare (due saturazioni fattoriali e due specificità). Il caso di tre item e un fattore definisce un modello “appena identificato”, ovvero, il caso in cui ci sono zero gradi di libertà. In tali circostanze è possibile stimare i parametri (ricordiamo il metodo dell’annullamento della tetrade), ma non è possibile un test di bontà dell’adattamento. Questo vuol dire, in pratica, che per un modello ad un solo fattore comune latente è necessario disporre di almeno quattro indicatori. "],["bontà-delladattamento.html", "20.4 Bontà dell’adattamento", " 20.4 Bontà dell’adattamento 20.4.1 Chi quadrato L’indice classico di bontà dell’adattamento dei modelli CFA è il \\(\\chi^2\\). Sotto determinate condizioni, la funzione di discrepanza \\(F_{k}(\\boldsymbol{\\Sigma}, \\boldsymbol{S})\\) moltiplicata per \\(n\\) o \\(n-1\\) (a seconda dei software) \\[ n F_{k}(\\Lambda, \\Psi) \\quad \\text{oppure}\\quad (n-1) F_{k}(\\Lambda, \\Psi) \\] con \\(n\\) uguale alla numerosità campionaria, si distribuisce come una \\(\\chi^2\\) con gradi di libertà pari a \\[\\begin{equation} \\mbox{df} = \\frac{p (p+1)}{2}-t, \\tag{20.1} \\end{equation}\\] dove \\(p\\) è il numero di item (variabili osservate) e \\(t\\) è il numero di parametri da stimare. Sebbene l’indice \\(\\chi^2\\) sia stato il primo indice di adattamento ad essere sviluppato, esso è raramente usato nella ricerca applicata quale unico indice di adattamento del modello. Infatti, in molti casi (es. \\(n\\) piccolo, oppure dati non normali) la distribuzione sottostante non è \\(\\chi^2\\) (il che compromette i test di significatività statistica del modello basati su \\(\\chi^2\\)); \\(\\chi^2\\) dipende fortemente dalla dimensione del campione; soluzioni fattoriali per grandi campioni vengono regolarmente rifiutate sulla base di \\(\\chi^2\\) anche quando le differenze tra \\(\\boldsymbol{\\Sigma}\\) e \\(\\boldsymbol{S}\\) sono trascurabili; \\(\\chi^2\\) si basa sull’ipotesi molto stringente \\(\\boldsymbol{\\Sigma} = \\boldsymbol{S}\\). Come discusso di seguito, molti indici di adattamento alternativi si basano su standard meno stringenti come l’adattamento “ragionevole” e l’adattamento relativo a un modello di indipendenza. Nonostante questi limiti, la statistica \\(\\chi^2\\) viene comunque utilizzata per altri scopi, come il confronto di modelli nidificati, il calcolo di altri indici di adattamento (ad es. l’indice di Tucker–Lewis) e il calcolo del rapporto tra \\(\\chi^2\\) e gradi di libertà. Sebbene la statistica \\(\\chi^2\\) sia riportata di routine nell’output dei software che svolgono la CFA, nella valutazione dell’adattamento del modello si fa solitamente affidamento su altri indici di adattamento. Tali indici possono essere suddivisi in tre categorie: misure di adeguamento per il confronto – permettono di confrontare fra loro due o più modelli al fine di potere scegliere il modello (statisticamente) migliore; misure di adeguamento parsimonioso – indici “aggiustati” in base ai gradi di libertà. misure di adeguamento assoluto – indicano l’abilità del modello di riprodurre i dati osservati; "],["misure-di-adeguamento-per-il-confronto.html", "20.5 Misure di adeguamento per il confronto", " 20.5 Misure di adeguamento per il confronto 20.5.1 CFI Gli indici di adattamento comparativo [detti anche indici di adattamento incrementale; ad es. Hu and Bentler (1998)] valutano l’adattamento di una soluzione specificata dall’utente in relazione a un modello di base nidificato più ristretto. Tipicamente, il modello base è un modello “nullo” o “di indipendenza” in cui le covarianze tra tutti gli indicatori di input sono fissate a zero, ma nessun vincolo viene posto sulle varianze degli indicatori. Uno di questi indici, l’indice di adattamento comparativo (comparative fit index, CFI; Bentler, 1990), è calcolato come segue. Sia \\(\\delta = \\chi^2 - \\mbox{df}\\), dove \\(\\mbox{df}\\) sono i gradi di libertà di un particolare modello. Tanto più \\(\\delta\\) è prossimo allo zero tanto maggiore è la bontà dell’adattamento. La formula di CFI è \\[\\begin{equation} \\mbox{CFI} = \\frac{\\delta_B - \\delta_T}{\\delta_B}, \\end{equation}\\] dove il pedice \\(T\\) denota il modello target (cioè il modello in valutazione) e il pedice \\(B\\) denota il modello baseline (cioè il modello “nullo”). References "],["misure-di-adeguamento-parsimonioso.html", "20.6 Misure di adeguamento parsimonioso", " 20.6 Misure di adeguamento parsimonioso 20.6.1 TLI Un indice che rientra nella degli indici di adeguamento parsimonioso è l’indice Tucker-Lewis (Tucker–Lewis index, TLI, anche chiamato indice di adattamento non normato). Il TLI si pone il problema di penalizzare la complessità del modello, ovvero include una funzione di penalizzazione per l’addizione di parametri che non migliorano in maniera sostanziale l’adattamento del modello. Il TLI è calcolato con la seguente formula: \\[\\begin{equation} \\mbox{TLI} = \\frac{(\\chi^2_B / \\mbox{df}_B)–(\\chi^2_T / \\mbox{df}_T)}{(\\chi^2_B / \\mbox{df}_B) – 1}, \\end{equation}\\] dove \\(\\chi^2_T\\) è il valore \\(\\chi^2\\) del modello target, \\(\\mbox{df}_T\\) sono i gradi di libertà del modello target, \\(\\chi^2_B\\) è il valore \\(\\chi^2\\) del modello baseline e \\(\\mbox{df}_B\\) sono i gradi di libertà del modello base. "],["misure-di-adeguamento-assoluto.html", "20.7 Misure di adeguamento assoluto", " 20.7 Misure di adeguamento assoluto 20.7.1 RMSEA L’errore quadratico medio di approssimazione è una misura assoluta dell’adattamento perché non confronta la discrepanza del modello target rispetto a un modello di base, come CFI o TLI. Invece, RMSEA utilizza \\(\\delta\\) come parametro che misura il grado di errata specificazione del modello. Ricordiamo dalla discussione sull’indice CFI che \\(\\delta = \\chi^2 - df\\), dove \\(df\\) sono i gradi di libertà del modello. Tanto maggiore è \\(\\delta\\) tanto più grande è la mancanza di adattamento del modello ai dati. L’indice RMSEA si ottiene nel modo seguente: \\[\\begin{equation} \\mbox{RMSEA} = \\sqrt{\\frac{\\delta}{\\mbox{df} \\cdot (n-1)}}, \\end{equation}\\] dove \\(n\\) corrisponde alla numerosità campionaria. L’indice RMSEA fornisce una stima dell’errore di approssimazione che si commette quando la matrice delle correlazioni (o covarianze) osservate viene riprodotta tramite la matrice ricavata dalle saturazioni fattoriali. Questo indice rappresenta una stima della bontà di adattamento del modello nella popolazione, ponderata per i gradi di liberà e quindi è una misura che tiene in considerazione la parsimonia del modello. 20.7.2 RMRS L’indice RMRS viene definito come la radice quadrata della media dei residui al quadrato. L’indice RMRS rappresenta la correlazione residua media, cioè non spiegata dal modello, ed è ricavabile con la seguente formula: \\[\\begin{equation} \\mbox{RMRS} = \\sqrt{ \\frac{2 \\sum_i\\sum_j(r_{ij} - \\hat{r}_{ij})^2}{p(p+1)}}, \\end{equation}\\] dove \\(p\\) è il numero di item, e \\(r_{ij}\\) e \\(\\hat{r}_{ij}\\) sono rispettivamente la correlazione osservata e la correlazione riprodotta tra le variabili \\(i\\) e \\(j\\). 20.7.3 Interpretazione Un valore RMSEA &lt; .05 indica un “close fit” e quello &lt; .08 suggerisce un ragionevole adattamento modello-dati. Bentler e Bonett (1980) raccomandano TLI &gt; .90 per un adattamento accettabile. L’interpretazione degli indici di bontà di adattamento trovati nella CFA o nella modellazione di equazioni strutturali può essere ottenuta usando le funzioni del pacchetto effectsize. Ad esempio (dal manuale): structure &lt;- &quot; ind60 =~ x1 + x2 + x3 dem60 =~ y1 + y2 + y3 dem60 ~~ ind60 &quot; fit &lt;- lavaan::sem(structure, data = lavaan::PoliticalDemocracy) effectsize::interpret(fit) #&gt; Name Value Threshold Interpretation #&gt; 1 GFI 0.96664121 0.95 satisfactory #&gt; 2 AGFI 0.91243318 0.90 satisfactory #&gt; 3 NFI 0.97486324 0.90 satisfactory #&gt; 4 NNFI 1.00010307 0.90 satisfactory #&gt; 5 CFI 1.00000000 0.90 satisfactory #&gt; 6 RMSEA 0.00000000 0.05 satisfactory #&gt; 7 SRMR 0.02726216 0.08 satisfactory #&gt; 8 RFI 0.95286858 0.90 satisfactory #&gt; 9 PNFI 0.51992706 0.50 satisfactory #&gt; 10 IFI 1.00005373 0.90 satisfactory "],["un-esempio-concreto-5.html", "20.8 Un esempio concreto", " 20.8 Un esempio concreto Consideriamo nuovamente i dati discussi da Brown (2015) relativi al modello di misurazione per la depressione maggiore così come è definita nel DSM-IV. Ignoriamo qui le differenze di genere – si veda il Capitolo 19. Leggiamo i dati in \\(\\mathsf{R}\\): d &lt;- readRDS( here::here(&quot;data&quot;, &quot;mdd_sex.RDS&quot;) ) Consideriamo il seguente modello: model_mdd &lt;- &quot; MDD =~ mdd1 + mdd2 + mdd3 + mdd4 + mdd5 + mdd6 + mdd7 + mdd8 + mdd9 &quot; Adattiamo il modello ai dati. fit &lt;- cfa( model_mdd, data = d ) Esaminiamo gli indici di bontà di adattamento. effectsize::interpret(fit) #&gt; Name Value Threshold Interpretation #&gt; 1 GFI 0.96402909 0.95 satisfactory #&gt; 2 AGFI 0.94004848 0.90 satisfactory #&gt; 3 NFI 0.91501936 0.90 satisfactory #&gt; 4 NNFI 0.91199406 0.90 satisfactory #&gt; 5 CFI 0.93399554 0.90 satisfactory #&gt; 6 RMSEA 0.06412658 0.05 poor #&gt; 7 SRMR 0.04448302 0.08 satisfactory #&gt; 8 RFI 0.88669248 0.90 poor #&gt; 9 PNFI 0.68626452 0.50 satisfactory #&gt; 10 IFI 0.93446306 0.90 satisfactory Il rapporto \\(\\chi^2 / df\\) è adeguato. 110.272 / 27 #&gt; [1] 4.084148 Gli indici Comparative Fit Index (CFI) = 0.934 e Tucker-Lewis Index (TLI) = 0.912 sono superiori a 0.9, dunque sono almeno sufficienti per gli standard correnti. L’indice RMSEA = 0.064 è appena superiore alla soglia di 0.06. L’indice SRMR = 0.044 è inferiore alla soglia 0.05. Dunque, complessivamente, il modello sembra adeguato. Adattiamo ora il modello con la modifica proposta da Brown (2015), ovvero model2_mdd &lt;- &quot; MDD =~ mdd1 + mdd2 + mdd3 + mdd4 + mdd5 + mdd6 + mdd7 + mdd8 + mdd9 mdd1 ~~ mdd2 &quot; fit2 &lt;- cfa( model2_mdd, data = d ) Esaminiamo gli indici di bontà di adattamento. effectsize::interpret(fit2) #&gt; Name Value Threshold Interpretation #&gt; 1 GFI 0.97807123 0.95 satisfactory #&gt; 2 AGFI 0.96204635 0.90 satisfactory #&gt; 3 NFI 0.94793648 0.90 satisfactory #&gt; 4 NNFI 0.95438982 0.90 satisfactory #&gt; 5 CFI 0.96705932 0.90 satisfactory #&gt; 6 RMSEA 0.04616501 0.05 satisfactory #&gt; 7 SRMR 0.03675390 0.08 satisfactory #&gt; 8 RFI 0.92791205 0.90 satisfactory #&gt; 9 PNFI 0.68462079 0.50 satisfactory #&gt; 10 IFI 0.96731836 0.90 satisfactory In questa seconda versione, l’adattamento del modello è molto migliorato. Il rapporto \\(\\chi^2 / df\\) è pari a 67.559 / 26 #&gt; [1] 2.598423 Gli indici Comparative Fit Index (CFI) = 0.967 e Tucker-Lewis Index (TLI) = 0.954 sono superiori a 0.95. L’indice RMSEA = 0.046. L’indice SRMR = 0.037. Il “costo” che si paga per questo miglioramento dell’adattamento è che indici di adattamento così buoni, probabilmente, non si replicheranno in un altro campione di dati, a meno che venga introdotto un qualche altro aggiustamento che, sicuramente, sarà diverso da quello usato nel campione corrente. Personalmente, non avrei introdotto il “miglioramento” proposto da Brown (2015) in quanto, anche senza un tale aggiustamento post-hoc, il modello produce un adattamento accettabile. References "],["commenti-e-considerazioni-finali.html", "Commenti e considerazioni finali", " Commenti e considerazioni finali Nella letteratura SEM sono state sollevate forti argomentazioni contro l’applicazione di RMSEA, CFI e TLI e i loro valori di cutoff convenzionali (si veda, ad esempio, Barrett 2007). Tuttavia, prima che i ricercatori propongano e accettino alternative migliori, questi indici di bontà dell’adattamento continueranno ad essere applicati nella maggior parte degli studi SEM. Xia and Yang (2019) fanno notare come, in base alla consuetudine corrente, valori RMSEA più grandi e valori CFI e TLI più piccoli indicano un adattamento peggiore. Ciò spinge i ricercatori a modificare i loro modelli per cercare di ottenere indici migliori. Tuttavia, la pratica attuale si è evoluta a tal punto da raggiungere la fase per cui gli indici di adattamento servono come gli unici criteri (in molte situazioni) per determinare se accettare o rifiutare un modello ipotizzato: se i valori degli indici di adattamento raggiungono la soglia “di pubblicabilità” (ad es. RMSEA &lt; .06), allora non si ritiene più necessario migliorare il modello. In realtà, un’affermazione come la seguente non è sufficiente: “poiché i valori RMSEA, CFI e TLI suggeriscono un buon adattamento, questo modello è stato scelto come modello finale”. Il raggiungimento di una serie di soglie desiderate di RMSEA, CFI e TLI è solo uno dei possibili indicatori che devono essere considerati nel processo di selezione di modelli. I ricercatori dovrebbero anche spiegare se esistono altre opzioni per migliorare il modello, perché tali opzioni sono o non sono adottate, e quali sono le conseguenze scientifiche e cliniche che derivano dalla scelta del modello in questione come quello finale. References "],["ch-model-revision.html", "Capitolo 21 La revisione del modello", " Capitolo 21 La revisione del modello Brown (2015) discute alcune possibili cause che possono essere responsabili della mancanza di adattamento del modello EFA o CFA ai dati. In particolare, vengono esaminate le seguenti possibili cause: il ricercatore ha ipotizzato il numero sbagliato di fattori comuni latenti, un item viene ipotizzato saturare su un solo fattore comune mentre satura su diversi fattori, un item viene ipotizzato saturare sul fattore comune sbagliato, è possibile che vi siano correlazioni residue che il modello non ha considerato. Brown (2015) mostra come il ricercatore possa usare i Modification Indices per valutare le cause del mancato adattamento del modello ai dati. References "],["un-numero-di-fattori-troppo-piccolo.html", "21.1 Un numero di fattori troppo piccolo", " 21.1 Un numero di fattori troppo piccolo Una delle possibili fonti di mancanza di adattamento del modello può dipendere dal fatto che è stato ipotizzato un numero insufficiente di fattori latenti comuni. Brown (2015) discute il caso nel quale si confrontano gli indici di bontà di adattamento di un modello ad un solo fattore comune e un modello a due fattori comuni. L’esempio riguarda i dati già in precedenza discussi e relativi relativi a otto misure di personalità raccolte su un campione di 250 pazienti che hanno concluso un programma di psicoterapia. Le scale sono le seguenti: anxiety (N1), hostility (N2), depression (N3), self-consciousness (N4), warmth (E1), gregariousness (E2), assertiveness (E3), positive emotions (E4). Leggiamo i dati in \\(\\mathsf{R}\\). varnames &lt;- c(&quot;N1&quot;, &quot;N2&quot;, &quot;N3&quot;, &quot;N4&quot;, &quot;E1&quot;, &quot;E2&quot;, &quot;E3&quot;, &quot;E4&quot;) sds &lt;- c(5.7, 5.6, 6.4, 5.7, 6.0, 6.2, 5.7, 5.6) cors &lt;- &quot; 1.000 0.767 1.000 0.731 0.709 1.000 0.778 0.738 0.762 1.000 -0.351 -0.302 -0.356 -0.318 1.000 -0.316 -0.280 -0.300 -0.267 0.675 1.000 -0.296 -0.289 -0.297 -0.296 0.634 0.651 1.000 -0.282 -0.254 -0.292 -0.245 0.534 0.593 0.566 1.000&quot; psychot_cor_mat &lt;- getCov(cors, names = varnames) n &lt;- 250 Supponiamo di adattare ai dati il modello “sbagliato” che include un unico fattore comune. Svolgiamo qui l’analisi fattoriale esplorativa usando la funzione sperimentale efa() di lavaan. # 1-factor model f1 &lt;- &#39; efa(&quot;efa&quot;)*f1 =~ N1 + N2 + N3 + N4 + E1 + E2 + E3 + E4 &#39; Adattiamo il modello ai dati. efa_f1 &lt;- cfa( model = f1, sample.cov = psychot_cor_mat, sample.nobs = 250, rotation = &quot;oblimin&quot; ) Consideriamo ora un modello a due fattori. f2 &lt;- &#39; efa(&quot;efa&quot;)*f1 + efa(&quot;efa&quot;)*f2 =~ N1 + N2 + N3 + N4 + E1 + E2 + E3 + E4 &#39; Adattiamo il modello ai dati. efa_f2 &lt;- cfa( model = f2, sample.cov = psychot_cor_mat, sample.nobs = 250, rotation = &quot;oblimin&quot; ) Esaminiamo gli indici di bontà di adattamento. # define the fit measures fit_measures_robust &lt;- c(&quot;chisq&quot;, &quot;df&quot;, &quot;pvalue&quot;, &quot;cfi&quot;, &quot;tli&quot;, &quot;rmsea&quot;, &quot;srmr&quot;) # collect them for each model rbind( fitmeasures(efa_f1, fit_measures_robust), fitmeasures(efa_f2, fit_measures_robust) ) %&gt;% # wrangle data.frame() %&gt;% mutate( chisq = round(chisq, digits = 0), df = as.integer(df), pvalue = ifelse(pvalue == 0, &quot;&lt; .001&quot;, pvalue) ) %&gt;% mutate_at(vars(cfi:srmr), ~ round(., digits = 3)) #&gt; chisq df pvalue cfi tli rmsea srmr #&gt; 1 375 20 &lt; .001 0.71 0.594 0.267 0.187 #&gt; 2 10 13 0.709310449320062 1.00 1.006 0.000 0.010 effectsize::interpret(efa_f1) #&gt; Name Value Threshold Interpretation #&gt; 1 GFI 0.6713421 0.95 poor #&gt; 2 AGFI 0.4084158 0.90 poor #&gt; 3 NFI 0.7006460 0.90 poor #&gt; 4 NNFI 0.5941736 0.90 poor #&gt; 5 CFI 0.7101240 0.90 poor #&gt; 6 RMSEA 0.2665811 0.05 poor #&gt; 7 SRMR 0.1873289 0.08 poor #&gt; 8 RFI 0.5809044 0.90 poor #&gt; 9 PNFI 0.5004614 0.50 satisfactory #&gt; 10 IFI 0.7120036 0.90 poor effectsize::interpret(efa_f2) #&gt; Name Value Threshold Interpretation #&gt; 1 GFI 0.990554109 0.95 satisfactory #&gt; 2 AGFI 0.973842148 0.90 satisfactory #&gt; 3 NFI 0.992174918 0.90 satisfactory #&gt; 4 NNFI 1.005603388 0.90 satisfactory #&gt; 5 CFI 1.000000000 0.90 satisfactory #&gt; 6 RMSEA 0.000000000 0.05 satisfactory #&gt; 7 SRMR 0.009907613 0.08 satisfactory #&gt; 8 RFI 0.983145977 0.90 satisfactory #&gt; 9 PNFI 0.460652640 0.50 poor #&gt; 10 IFI 1.002570123 0.90 satisfactory I risultati mostrano come, in un modello EFA, una soluzione a due fattori produca un adattamento adeguato, mentre ciò non si verifica con un modello ad un solo fattore. References "],["specificazione-errata-delle-relazioni-tra-indicatori-e-fattori-latenti.html", "21.2 Specificazione errata delle relazioni tra indicatori e fattori latenti", " 21.2 Specificazione errata delle relazioni tra indicatori e fattori latenti Un’altra potenziale fonte di errata specificazione del modello CFA è una designazione errata delle relazioni tra indicatori e fattori latenti. In questo esempio, un ricercatore ha sviluppato un questionario di 12 item (gli item sono valutati su scale da 0 a 8) progettato per valutare le motivazioni dei giovani adulti a consumare bevande alcoliche (Cooper, 1994). La misura aveva lo scopo di valutare tre aspetti di questo costrutto (4 item ciascuno): (1) motivazioni di coping (item 1–4), (2) motivazioni sociali (item 5–8) e (3) motivazioni di miglioramento (item 9 –12). I dati sono i seguenti. sds &lt;- c(2.06, 1.52, 1.92, 1.41, 1.73, 1.77, 2.49, 2.27, 2.68, 1.75, 2.57, 2.66) cors &lt;- &quot; 1.000 0.300 1.000 0.229 0.261 1.000 0.411 0.406 0.429 1.000 0.172 0.252 0.218 0.481 1.000 0.214 0.268 0.267 0.579 0.484 1.000 0.200 0.214 0.241 0.543 0.426 0.492 1.000 0.185 0.230 0.185 0.545 0.463 0.548 0.522 1.000 0.134 0.146 0.108 0.186 0.122 0.131 0.108 0.151 1.000 0.134 0.099 0.061 0.223 0.133 0.188 0.105 0.170 0.448 1.000 0.160 0.131 0.158 0.161 0.044 0.124 0.066 0.061 0.370 0.350 1.000 0.087 0.088 0.101 0.198 0.077 0.177 0.128 0.112 0.356 0.359 0.507 1.000&quot; covs &lt;- getCov(cors, sds = sds, names = paste(&quot;x&quot;, 1:12, sep = &quot;&quot;)) Iniziamo con un modello che ipotizza tre fattori comuni latenti correlati, coerentemente con la motivazione che stava alla base della costruzione dello strumento. model1 &lt;- &quot; copingm =~ x1 + x2 + x3 + x4 socialm =~ x5 + x6 + x7 + x8 enhancem =~ x9 + x10 + x11 + x12 &quot; Adattiamo il modello ai dati. fit1 &lt;- cfa( model1, sample.cov = covs, sample.nobs = 500, mimic = &quot;mplus&quot; ) Esaminando le misure di adattamento potremmo concludere che il modello è adeguato. effectsize::interpret(fit1) #&gt; Name Value Threshold Interpretation #&gt; 1 GFI 0.97009178 0.95 satisfactory #&gt; 2 AGFI 0.94722078 0.90 satisfactory #&gt; 3 NFI 0.94785001 0.90 satisfactory #&gt; 4 NNFI 0.97102541 0.90 satisfactory #&gt; 5 CFI 0.97761054 0.90 satisfactory #&gt; 6 RMSEA 0.03745791 0.05 satisfactory #&gt; 7 SRMR 0.03438699 0.08 satisfactory #&gt; 8 RFI 0.93251177 0.90 satisfactory #&gt; 9 PNFI 0.73242955 0.50 satisfactory #&gt; 10 IFI 0.97781875 0.90 satisfactory Tuttavia, un esame più attento mette in evidenza un comportamento anomalo dell’item x4 e alcune caratteristiche anomale del modello in generale. standardizedSolution(fit1) #&gt; lhs op rhs est.std se z pvalue ci.lower ci.upper #&gt; 1 copingm =~ x1 0.432 0.039 11.030 0.00 0.355 0.508 #&gt; 2 copingm =~ x2 0.436 0.039 11.174 0.00 0.359 0.512 #&gt; 3 copingm =~ x3 0.451 0.038 11.730 0.00 0.376 0.527 #&gt; 4 copingm =~ x4 0.953 0.024 38.967 0.00 0.905 1.001 #&gt; 5 socialm =~ x5 0.633 0.032 20.064 0.00 0.571 0.695 #&gt; 6 socialm =~ x6 0.748 0.025 29.363 0.00 0.698 0.798 #&gt; 7 socialm =~ x7 0.690 0.029 24.154 0.00 0.634 0.746 #&gt; 8 socialm =~ x8 0.729 0.026 27.519 0.00 0.677 0.781 #&gt; 9 enhancem =~ x9 0.602 0.039 15.581 0.00 0.526 0.678 #&gt; 10 enhancem =~ x10 0.597 0.039 15.397 0.00 0.521 0.673 #&gt; 11 enhancem =~ x11 0.661 0.037 17.982 0.00 0.589 0.733 #&gt; 12 enhancem =~ x12 0.665 0.037 18.167 0.00 0.593 0.737 #&gt; 13 x1 ~~ x1 0.814 0.034 24.085 0.00 0.747 0.880 #&gt; 14 x2 ~~ x2 0.810 0.034 23.837 0.00 0.744 0.877 #&gt; 15 x3 ~~ x3 0.796 0.035 22.938 0.00 0.728 0.864 #&gt; 16 x4 ~~ x4 0.091 0.047 1.959 0.05 0.000 0.183 #&gt; 17 x5 ~~ x5 0.599 0.040 14.985 0.00 0.521 0.677 #&gt; 18 x6 ~~ x6 0.441 0.038 11.573 0.00 0.366 0.515 #&gt; 19 x7 ~~ x7 0.524 0.039 13.293 0.00 0.447 0.601 #&gt; 20 x8 ~~ x8 0.469 0.039 12.151 0.00 0.393 0.545 #&gt; 21 x9 ~~ x9 0.638 0.047 13.707 0.00 0.546 0.729 #&gt; 22 x10 ~~ x10 0.643 0.046 13.875 0.00 0.552 0.734 #&gt; 23 x11 ~~ x11 0.563 0.049 11.605 0.00 0.468 0.659 #&gt; 24 x12 ~~ x12 0.558 0.049 11.447 0.00 0.462 0.653 #&gt; 25 copingm ~~ copingm 1.000 0.000 NA NA 1.000 1.000 #&gt; 26 socialm ~~ socialm 1.000 0.000 NA NA 1.000 1.000 #&gt; 27 enhancem ~~ enhancem 1.000 0.000 NA NA 1.000 1.000 #&gt; 28 copingm ~~ socialm 0.799 0.031 26.150 0.00 0.739 0.859 #&gt; 29 copingm ~~ enhancem 0.322 0.051 6.336 0.00 0.222 0.422 #&gt; 30 socialm ~~ enhancem 0.268 0.056 4.817 0.00 0.159 0.377 #&gt; 31 x1 ~1 0.000 0.045 0.000 1.00 -0.088 0.088 #&gt; 32 x2 ~1 0.000 0.045 0.000 1.00 -0.088 0.088 #&gt; 33 x3 ~1 0.000 0.045 0.000 1.00 -0.088 0.088 #&gt; 34 x4 ~1 0.000 0.045 0.000 1.00 -0.088 0.088 #&gt; 35 x5 ~1 0.000 0.045 0.000 1.00 -0.088 0.088 #&gt; 36 x6 ~1 0.000 0.045 0.000 1.00 -0.088 0.088 #&gt; 37 x7 ~1 0.000 0.045 0.000 1.00 -0.088 0.088 #&gt; 38 x8 ~1 0.000 0.045 0.000 1.00 -0.088 0.088 #&gt; 39 x9 ~1 0.000 0.045 0.000 1.00 -0.088 0.088 #&gt; 40 x10 ~1 0.000 0.045 0.000 1.00 -0.088 0.088 #&gt; 41 x11 ~1 0.000 0.045 0.000 1.00 -0.088 0.088 #&gt; 42 x12 ~1 0.000 0.045 0.000 1.00 -0.088 0.088 #&gt; 43 copingm ~1 0.000 0.000 NA NA 0.000 0.000 #&gt; 44 socialm ~1 0.000 0.000 NA NA 0.000 0.000 #&gt; 45 enhancem ~1 0.000 0.000 NA NA 0.000 0.000 In particolare, l’item x4 mostra una saturazione molto forte sul fattore Motivi di coping (.955) ed emerge una correlazione molto alta tra i fattori Motivi di coping e Motivi sociali (.798). Brown (2015) suggerisce di esaminare i Modification Indices. Tale esame mostra che il MI associato a x4 è molto alto, 18.916. modindices(fit1) #&gt; lhs op rhs mi epc sepc.lv sepc.all sepc.nox #&gt; 46 copingm =~ x5 0.030 -0.030 -0.027 -0.015 -0.015 #&gt; 47 copingm =~ x6 0.484 0.127 0.113 0.064 0.064 #&gt; 48 copingm =~ x7 0.780 0.220 0.196 0.079 0.079 #&gt; 49 copingm =~ x8 1.962 -0.323 -0.287 -0.127 -0.127 #&gt; 50 copingm =~ x9 0.101 0.044 0.039 0.015 0.015 #&gt; 51 copingm =~ x10 2.016 0.129 0.114 0.065 0.065 #&gt; 52 copingm =~ x11 1.870 -0.181 -0.161 -0.063 -0.063 #&gt; 53 copingm =~ x12 0.040 -0.027 -0.024 -0.009 -0.009 #&gt; 54 socialm =~ x1 6.927 -0.520 -0.569 -0.277 -0.277 #&gt; 55 socialm =~ x2 0.052 -0.033 -0.036 -0.024 -0.024 #&gt; 56 socialm =~ x3 2.058 -0.267 -0.292 -0.152 -0.152 #&gt; 57 socialm =~ x4 18.916 1.300 1.423 1.010 1.010 #&gt; 58 socialm =~ x9 0.338 0.067 0.073 0.027 0.027 #&gt; 59 socialm =~ x10 2.884 0.128 0.140 0.080 0.080 #&gt; 60 socialm =~ x11 4.357 -0.229 -0.251 -0.098 -0.098 #&gt; 61 socialm =~ x12 0.001 0.004 0.004 0.002 0.002 #&gt; 62 enhancem =~ x1 1.954 0.093 0.149 0.072 0.072 #&gt; 63 enhancem =~ x2 0.863 0.045 0.073 0.048 0.048 #&gt; 64 enhancem =~ x3 0.380 0.038 0.061 0.032 0.032 #&gt; 65 enhancem =~ x4 3.102 -0.104 -0.168 -0.119 -0.119 #&gt; 66 enhancem =~ x5 0.596 -0.039 -0.063 -0.036 -0.036 #&gt; 67 enhancem =~ x6 2.495 0.078 0.125 0.071 0.071 #&gt; 68 enhancem =~ x7 0.539 -0.052 -0.084 -0.034 -0.034 #&gt; 69 enhancem =~ x8 0.093 -0.019 -0.031 -0.014 -0.014 #&gt; 70 x1 ~~ x2 10.299 0.379 0.379 0.149 0.149 #&gt; 71 x1 ~~ x3 0.986 0.147 0.147 0.046 0.046 #&gt; 72 x1 ~~ x4 0.016 -0.015 -0.015 -0.019 -0.019 #&gt; 73 x1 ~~ x5 0.452 -0.080 -0.080 -0.032 -0.032 #&gt; 74 x1 ~~ x6 0.484 -0.078 -0.078 -0.036 -0.036 #&gt; 75 x1 ~~ x7 0.290 -0.089 -0.089 -0.027 -0.027 #&gt; 76 x1 ~~ x8 1.535 -0.181 -0.181 -0.063 -0.063 #&gt; 77 x1 ~~ x9 0.468 0.133 0.133 0.034 0.034 #&gt; 78 x1 ~~ x10 0.067 0.033 0.033 0.013 0.013 #&gt; 79 x1 ~~ x11 4.030 0.364 0.364 0.102 0.102 #&gt; 80 x1 ~~ x12 1.504 -0.229 -0.229 -0.062 -0.062 #&gt; 81 x2 ~~ x3 3.508 0.205 0.205 0.088 0.088 #&gt; 82 x2 ~~ x4 6.780 -0.229 -0.229 -0.393 -0.393 #&gt; 83 x2 ~~ x5 1.449 0.106 0.106 0.058 0.058 #&gt; 84 x2 ~~ x6 0.102 0.026 0.026 0.016 0.016 #&gt; 85 x2 ~~ x7 1.144 -0.130 -0.130 -0.053 -0.053 #&gt; 86 x2 ~~ x8 0.366 -0.065 -0.065 -0.031 -0.031 #&gt; 87 x2 ~~ x9 1.877 0.196 0.196 0.067 0.067 #&gt; 88 x2 ~~ x10 0.434 -0.062 -0.062 -0.032 -0.032 #&gt; 89 x2 ~~ x11 1.599 0.169 0.169 0.064 0.064 #&gt; 90 x2 ~~ x12 0.726 -0.117 -0.117 -0.043 -0.043 #&gt; 91 x3 ~~ x4 0.107 -0.037 -0.037 -0.051 -0.051 #&gt; 92 x3 ~~ x5 0.024 0.017 0.017 0.008 0.008 #&gt; 93 x3 ~~ x6 0.211 0.048 0.048 0.024 0.024 #&gt; 94 x3 ~~ x7 0.009 0.015 0.015 0.005 0.005 #&gt; 95 x3 ~~ x8 5.281 -0.310 -0.310 -0.117 -0.117 #&gt; 96 x3 ~~ x9 0.031 0.031 0.031 0.009 0.009 #&gt; 97 x3 ~~ x10 3.545 -0.221 -0.221 -0.092 -0.092 #&gt; 98 x3 ~~ x11 5.967 0.408 0.408 0.124 0.124 #&gt; 99 x3 ~~ x12 0.055 -0.040 -0.040 -0.012 -0.012 #&gt; 100 x4 ~~ x5 0.063 -0.016 -0.016 -0.028 -0.028 #&gt; 101 x4 ~~ x6 0.052 0.015 0.015 0.029 0.029 #&gt; 102 x4 ~~ x7 2.114 0.131 0.131 0.170 0.170 #&gt; 103 x4 ~~ x8 0.208 0.037 0.037 0.057 0.057 #&gt; 104 x4 ~~ x9 0.887 -0.091 -0.091 -0.100 -0.100 #&gt; 105 x4 ~~ x10 1.063 0.065 0.065 0.109 0.109 #&gt; 106 x4 ~~ x11 2.637 -0.149 -0.149 -0.181 -0.181 #&gt; 107 x4 ~~ x12 0.169 0.039 0.039 0.046 0.046 #&gt; 108 x5 ~~ x6 0.370 0.057 0.057 0.036 0.036 #&gt; 109 x5 ~~ x7 0.292 -0.072 -0.072 -0.030 -0.030 #&gt; 110 x5 ~~ x8 0.007 0.010 0.010 0.005 0.005 #&gt; 111 x5 ~~ x9 0.822 0.133 0.133 0.047 0.047 #&gt; 112 x5 ~~ x10 0.339 0.056 0.056 0.030 0.030 #&gt; 113 x5 ~~ x11 1.126 -0.145 -0.145 -0.056 -0.056 #&gt; 114 x5 ~~ x12 1.143 -0.151 -0.151 -0.057 -0.057 #&gt; 115 x6 ~~ x7 2.528 -0.215 -0.215 -0.101 -0.101 #&gt; 116 x6 ~~ x8 0.053 0.029 0.029 0.016 0.016 #&gt; 117 x6 ~~ x9 1.056 -0.141 -0.141 -0.056 -0.056 #&gt; 118 x6 ~~ x10 0.598 0.069 0.069 0.042 0.042 #&gt; 119 x6 ~~ x11 0.248 0.064 0.064 0.028 0.028 #&gt; 120 x6 ~~ x12 1.667 0.170 0.170 0.073 0.073 #&gt; 121 x7 ~~ x8 1.431 0.206 0.206 0.074 0.074 #&gt; 122 x7 ~~ x9 0.032 -0.036 -0.036 -0.009 -0.009 #&gt; 123 x7 ~~ x10 1.521 -0.163 -0.163 -0.065 -0.065 #&gt; 124 x7 ~~ x11 0.263 -0.097 -0.097 -0.028 -0.028 #&gt; 125 x7 ~~ x12 0.637 0.156 0.156 0.044 0.044 #&gt; 126 x8 ~~ x9 1.621 0.227 0.227 0.068 0.068 #&gt; 127 x8 ~~ x10 1.311 0.134 0.134 0.061 0.061 #&gt; 128 x8 ~~ x11 2.144 -0.244 -0.244 -0.081 -0.081 #&gt; 129 x8 ~~ x12 0.591 -0.132 -0.132 -0.043 -0.043 #&gt; 130 x9 ~~ x10 19.846 0.862 0.862 0.288 0.288 #&gt; 131 x9 ~~ x11 2.908 -0.518 -0.518 -0.126 -0.126 #&gt; 132 x9 ~~ x12 7.696 -0.876 -0.876 -0.207 -0.207 #&gt; 133 x10 ~~ x11 7.331 -0.534 -0.534 -0.197 -0.197 #&gt; 134 x10 ~~ x12 5.572 -0.484 -0.484 -0.174 -0.174 #&gt; 135 x11 ~~ x12 26.947 1.711 1.711 0.447 0.447 Le considerazioni precedenti, dunque, suggeriscono che il modello potrebbe non avere descritto in maniera adeguata le relazioni tra x4 e i fattori comuni latenti. In base a considerazioni teoriche, supponiamo che abbia senso pensare che x4 saturi non solo sul fattore Motivi di coping ma anche sul fattore di Motivi Sociali. Specifichiamo dunque un nuovo modello nel modo seguente. model2 &lt;- &quot; copingm =~ x1 + x2 + x3 + x4 socialm =~ x4 + x5 + x6 + x7 + x8 enhancem =~ x9 + x10 + x11 + x12 &quot; Adattiamo il modello. fit2 &lt;- cfa( model2, sample.cov = covs, sample.nobs = 500, mimic = &quot;mplus&quot; ) Esaminiamo gli indici di bontà di adattamento. effectsize::interpret(fit2) #&gt; Name Value Threshold Interpretation #&gt; 1 GFI 0.97684139 0.95 satisfactory #&gt; 2 AGFI 0.95831451 0.90 satisfactory #&gt; 3 NFI 0.95826773 0.90 satisfactory #&gt; 4 NNFI 0.98393923 0.90 satisfactory #&gt; 5 CFI 0.98783275 0.90 satisfactory #&gt; 6 RMSEA 0.02788804 0.05 satisfactory #&gt; 7 SRMR 0.02887855 0.08 satisfactory #&gt; 8 RFI 0.94491340 0.90 satisfactory #&gt; 9 PNFI 0.72596040 0.50 satisfactory #&gt; 10 IFI 0.98795337 0.90 satisfactory La bontà di adattamento è migliorata. Esaminiamo la soluzione standardizzata. Vediamo ora che sono scomparse le due anomalie trovate in precedenza. standardizedSolution(fit2) #&gt; lhs op rhs est.std se z pvalue ci.lower ci.upper #&gt; 1 copingm =~ x1 0.514 0.043 12.034 0 0.430 0.597 #&gt; 2 copingm =~ x2 0.515 0.043 12.072 0 0.431 0.599 #&gt; 3 copingm =~ x3 0.516 0.043 12.106 0 0.432 0.600 #&gt; 4 copingm =~ x4 0.538 0.062 8.660 0 0.416 0.660 #&gt; 5 socialm =~ x4 0.439 0.061 7.204 0 0.320 0.558 #&gt; 6 socialm =~ x5 0.632 0.032 19.995 0 0.570 0.694 #&gt; 7 socialm =~ x6 0.746 0.025 29.279 0 0.696 0.796 #&gt; 8 socialm =~ x7 0.691 0.028 24.235 0 0.635 0.746 #&gt; 9 socialm =~ x8 0.731 0.026 27.762 0 0.679 0.782 #&gt; 10 enhancem =~ x9 0.603 0.039 15.625 0 0.527 0.678 #&gt; 11 enhancem =~ x10 0.595 0.039 15.308 0 0.519 0.671 #&gt; 12 enhancem =~ x11 0.665 0.037 18.188 0 0.593 0.737 #&gt; 13 enhancem =~ x12 0.663 0.037 18.103 0 0.591 0.735 #&gt; 14 x1 ~~ x1 0.736 0.044 16.786 0 0.650 0.822 #&gt; 15 x2 ~~ x2 0.735 0.044 16.729 0 0.649 0.821 #&gt; 16 x3 ~~ x3 0.734 0.044 16.678 0 0.647 0.820 #&gt; 17 x4 ~~ x4 0.230 0.037 6.292 0 0.158 0.301 #&gt; 18 x5 ~~ x5 0.601 0.040 15.043 0 0.522 0.679 #&gt; 19 x6 ~~ x6 0.443 0.038 11.634 0 0.368 0.517 #&gt; 20 x7 ~~ x7 0.523 0.039 13.292 0 0.446 0.600 #&gt; 21 x8 ~~ x8 0.466 0.038 12.106 0 0.390 0.541 #&gt; 22 x9 ~~ x9 0.637 0.046 13.701 0 0.546 0.728 #&gt; 23 x10 ~~ x10 0.646 0.046 13.990 0 0.556 0.737 #&gt; 24 x11 ~~ x11 0.558 0.049 11.474 0 0.463 0.653 #&gt; 25 x12 ~~ x12 0.561 0.049 11.546 0 0.465 0.656 #&gt; 26 copingm ~~ copingm 1.000 0.000 NA NA 1.000 1.000 #&gt; 27 socialm ~~ socialm 1.000 0.000 NA NA 1.000 1.000 #&gt; 28 enhancem ~~ enhancem 1.000 0.000 NA NA 1.000 1.000 #&gt; 29 copingm ~~ socialm 0.610 0.057 10.744 0 0.498 0.721 #&gt; 30 copingm ~~ enhancem 0.350 0.059 5.964 0 0.235 0.465 #&gt; 31 socialm ~~ enhancem 0.265 0.055 4.794 0 0.156 0.373 #&gt; 32 x1 ~1 0.000 0.045 0.000 1 -0.088 0.088 #&gt; 33 x2 ~1 0.000 0.045 0.000 1 -0.088 0.088 #&gt; 34 x3 ~1 0.000 0.045 0.000 1 -0.088 0.088 #&gt; 35 x4 ~1 0.000 0.045 0.000 1 -0.088 0.088 #&gt; 36 x5 ~1 0.000 0.045 0.000 1 -0.088 0.088 #&gt; 37 x6 ~1 0.000 0.045 0.000 1 -0.088 0.088 #&gt; 38 x7 ~1 0.000 0.045 0.000 1 -0.088 0.088 #&gt; 39 x8 ~1 0.000 0.045 0.000 1 -0.088 0.088 #&gt; 40 x9 ~1 0.000 0.045 0.000 1 -0.088 0.088 #&gt; 41 x10 ~1 0.000 0.045 0.000 1 -0.088 0.088 #&gt; 42 x11 ~1 0.000 0.045 0.000 1 -0.088 0.088 #&gt; 43 x12 ~1 0.000 0.045 0.000 1 -0.088 0.088 #&gt; 44 copingm ~1 0.000 0.000 NA NA 0.000 0.000 #&gt; 45 socialm ~1 0.000 0.000 NA NA 0.000 0.000 #&gt; 46 enhancem ~1 0.000 0.000 NA NA 0.000 0.000 Esaminando i MI, notiamo che il modello potrebbe migliorare se introduciamo una correlazione tra le specificità x11 e x12. modindices(fit2) #&gt; lhs op rhs mi epc sepc.lv sepc.all sepc.nox #&gt; 47 copingm =~ x5 0.076 0.032 0.034 0.020 0.020 #&gt; 48 copingm =~ x6 1.413 0.143 0.151 0.086 0.086 #&gt; 49 copingm =~ x7 0.245 0.083 0.088 0.035 0.035 #&gt; 50 copingm =~ x8 3.668 -0.295 -0.311 -0.137 -0.137 #&gt; 51 copingm =~ x9 0.243 0.066 0.069 0.026 0.026 #&gt; 52 copingm =~ x10 0.566 0.065 0.069 0.040 0.040 #&gt; 53 copingm =~ x11 0.119 -0.044 -0.046 -0.018 -0.018 #&gt; 54 copingm =~ x12 0.598 -0.102 -0.108 -0.041 -0.041 #&gt; 55 socialm =~ x1 1.948 -0.396 -0.245 -0.119 -0.119 #&gt; 56 socialm =~ x2 0.718 0.177 0.110 0.072 0.072 #&gt; 57 socialm =~ x3 0.298 0.144 0.089 0.047 0.047 #&gt; 58 socialm =~ x9 0.316 0.114 0.071 0.026 0.026 #&gt; 59 socialm =~ x10 3.169 0.236 0.146 0.084 0.084 #&gt; 60 socialm =~ x11 4.927 -0.430 -0.266 -0.104 -0.104 #&gt; 61 socialm =~ x12 0.017 0.026 0.016 0.006 0.006 #&gt; 62 enhancem =~ x1 0.314 0.040 0.064 0.031 0.031 #&gt; 63 enhancem =~ x2 0.003 0.003 0.004 0.003 0.003 #&gt; 64 enhancem =~ x3 0.037 -0.013 -0.020 -0.011 -0.011 #&gt; 65 enhancem =~ x4 0.106 -0.013 -0.021 -0.015 -0.015 #&gt; 66 enhancem =~ x5 0.464 -0.034 -0.055 -0.032 -0.032 #&gt; 67 enhancem =~ x6 2.703 0.079 0.128 0.072 0.072 #&gt; 68 enhancem =~ x7 0.467 -0.048 -0.077 -0.031 -0.031 #&gt; 69 enhancem =~ x8 0.095 -0.019 -0.031 -0.014 -0.014 #&gt; 70 x1 ~~ x2 1.966 0.187 0.187 0.081 0.081 #&gt; 71 x1 ~~ x3 2.042 -0.241 -0.241 -0.083 -0.083 #&gt; 72 x1 ~~ x4 0.775 0.098 0.098 0.082 0.082 #&gt; 73 x1 ~~ x5 0.238 -0.058 -0.058 -0.024 -0.024 #&gt; 74 x1 ~~ x6 0.187 -0.048 -0.048 -0.023 -0.023 #&gt; 75 x1 ~~ x7 0.019 -0.022 -0.022 -0.007 -0.007 #&gt; 76 x1 ~~ x8 0.366 -0.087 -0.087 -0.032 -0.032 #&gt; 77 x1 ~~ x9 0.155 0.076 0.076 0.020 0.020 #&gt; 78 x1 ~~ x10 0.104 0.041 0.041 0.016 0.016 #&gt; 79 x1 ~~ x11 2.019 0.255 0.255 0.075 0.075 #&gt; 80 x1 ~~ x12 1.911 -0.257 -0.257 -0.073 -0.073 #&gt; 81 x2 ~~ x3 0.035 -0.023 -0.023 -0.011 -0.011 #&gt; 82 x2 ~~ x4 3.029 -0.144 -0.144 -0.163 -0.163 #&gt; 83 x2 ~~ x5 2.503 0.138 0.138 0.079 0.079 #&gt; 84 x2 ~~ x6 0.509 0.058 0.058 0.038 0.038 #&gt; 85 x2 ~~ x7 0.471 -0.082 -0.082 -0.035 -0.035 #&gt; 86 x2 ~~ x8 0.015 0.013 0.013 0.006 0.006 #&gt; 87 x2 ~~ x9 1.289 0.161 0.161 0.058 0.058 #&gt; 88 x2 ~~ x10 0.467 -0.064 -0.064 -0.035 -0.035 #&gt; 89 x2 ~~ x11 0.338 0.077 0.077 0.031 0.031 #&gt; 90 x2 ~~ x12 0.970 -0.135 -0.135 -0.052 -0.052 #&gt; 91 x3 ~~ x4 1.095 0.109 0.109 0.098 0.098 #&gt; 92 x3 ~~ x5 0.169 0.045 0.045 0.021 0.021 #&gt; 93 x3 ~~ x6 0.681 0.085 0.085 0.044 0.044 #&gt; 94 x3 ~~ x7 0.315 0.085 0.085 0.029 0.029 #&gt; 95 x3 ~~ x8 3.075 -0.235 -0.235 -0.092 -0.092 #&gt; 96 x3 ~~ x9 0.022 -0.026 -0.026 -0.008 -0.008 #&gt; 97 x3 ~~ x10 3.825 -0.230 -0.230 -0.100 -0.100 #&gt; 98 x3 ~~ x11 3.498 0.313 0.313 0.099 0.099 #&gt; 99 x3 ~~ x12 0.079 -0.049 -0.049 -0.015 -0.015 #&gt; 100 x4 ~~ x5 0.337 -0.037 -0.037 -0.041 -0.041 #&gt; 101 x4 ~~ x6 0.033 -0.012 -0.012 -0.015 -0.015 #&gt; 102 x4 ~~ x7 1.053 0.094 0.094 0.077 0.077 #&gt; 103 x4 ~~ x8 0.071 -0.022 -0.022 -0.021 -0.021 #&gt; 104 x4 ~~ x9 0.541 -0.070 -0.070 -0.048 -0.048 #&gt; 105 x4 ~~ x10 1.128 0.066 0.066 0.070 0.070 #&gt; 106 x4 ~~ x11 1.313 -0.102 -0.102 -0.079 -0.079 #&gt; 107 x4 ~~ x12 0.322 0.052 0.052 0.039 0.039 #&gt; 108 x5 ~~ x6 0.504 0.066 0.066 0.042 0.042 #&gt; 109 x5 ~~ x7 0.262 -0.068 -0.068 -0.028 -0.028 #&gt; 110 x5 ~~ x8 0.004 0.008 0.008 0.004 0.004 #&gt; 111 x5 ~~ x9 0.850 0.135 0.135 0.047 0.047 #&gt; 112 x5 ~~ x10 0.288 0.052 0.052 0.027 0.027 #&gt; 113 x5 ~~ x11 1.019 -0.138 -0.138 -0.054 -0.054 #&gt; 114 x5 ~~ x12 1.224 -0.157 -0.157 -0.059 -0.059 #&gt; 115 x6 ~~ x7 2.404 -0.209 -0.209 -0.099 -0.099 #&gt; 116 x6 ~~ x8 0.034 0.023 0.023 0.012 0.012 #&gt; 117 x6 ~~ x9 0.978 -0.135 -0.135 -0.054 -0.054 #&gt; 118 x6 ~~ x10 0.524 0.065 0.065 0.039 0.039 #&gt; 119 x6 ~~ x11 0.341 0.074 0.074 0.033 0.033 #&gt; 120 x6 ~~ x12 1.520 0.163 0.163 0.069 0.069 #&gt; 121 x7 ~~ x8 1.171 0.186 0.186 0.067 0.067 #&gt; 122 x7 ~~ x9 0.020 -0.028 -0.028 -0.007 -0.007 #&gt; 123 x7 ~~ x10 1.593 -0.167 -0.167 -0.066 -0.066 #&gt; 124 x7 ~~ x11 0.175 -0.079 -0.079 -0.023 -0.023 #&gt; 125 x7 ~~ x12 0.586 0.149 0.149 0.042 0.042 #&gt; 126 x8 ~~ x9 1.808 0.239 0.239 0.072 0.072 #&gt; 127 x8 ~~ x10 1.267 0.131 0.131 0.060 0.060 #&gt; 128 x8 ~~ x11 1.791 -0.222 -0.222 -0.075 -0.075 #&gt; 129 x8 ~~ x12 0.595 -0.132 -0.132 -0.043 -0.043 #&gt; 130 x9 ~~ x10 20.103 0.864 0.864 0.288 0.288 #&gt; 131 x9 ~~ x11 3.658 -0.582 -0.582 -0.142 -0.142 #&gt; 132 x9 ~~ x12 7.229 -0.845 -0.845 -0.199 -0.199 #&gt; 133 x10 ~~ x11 7.617 -0.543 -0.543 -0.201 -0.201 #&gt; 134 x10 ~~ x12 4.512 -0.431 -0.431 -0.154 -0.154 #&gt; 135 x11 ~~ x12 26.071 1.680 1.680 0.440 0.440 Il nuovo modello diventa dunque il seguente. model3 &lt;- &quot; copingm =~ x1 + x2 + x3 + x4 socialm =~ x4 + x5 + x6 + x7 + x8 enhancem =~ x9 + x10 + x11 + x12 x11 ~~ x12 &quot; Adattiamo il modello. fit3 &lt;- cfa( model3, sample.cov = covs, sample.nobs = 500, mimic = &quot;mplus&quot; ) Un test basato sul rapporto di verosimiglianze conferma che il miglioramento di adattamento è sostanziale. lavTestLRT(fit2, fit3) #&gt; #&gt; Chi-Squared Difference Test #&gt; #&gt; Df AIC BIC Chisq Chisq diff RMSEA Df diff Pr(&gt;Chisq) #&gt; fit3 49 23934 24107 44.955 #&gt; fit2 50 23957 24125 69.444 24.488 0.21674 1 7.477e-07 *** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Esaminiamo gli indici di bontà di adattamento. summary(fit3, fit.measures = TRUE) #&gt; lavaan 0.6.14 ended normally after 61 iterations #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of model parameters 41 #&gt; #&gt; Number of observations 500 #&gt; #&gt; Model Test User Model: #&gt; #&gt; Test statistic 44.955 #&gt; Degrees of freedom 49 #&gt; P-value (Chi-square) 0.638 #&gt; #&gt; Model Test Baseline Model: #&gt; #&gt; Test statistic 1664.026 #&gt; Degrees of freedom 66 #&gt; P-value 0.000 #&gt; #&gt; User Model versus Baseline Model: #&gt; #&gt; Comparative Fit Index (CFI) 1.000 #&gt; Tucker-Lewis Index (TLI) 1.003 #&gt; #&gt; Loglikelihood and Information Criteria: #&gt; #&gt; Loglikelihood user model (H0) -11926.170 #&gt; Loglikelihood unrestricted model (H1) -11903.692 #&gt; #&gt; Akaike (AIC) 23934.339 #&gt; Bayesian (BIC) 24107.138 #&gt; Sample-size adjusted Bayesian (SABIC) 23977.002 #&gt; #&gt; Root Mean Square Error of Approximation: #&gt; #&gt; RMSEA 0.000 #&gt; 90 Percent confidence interval - lower 0.000 #&gt; 90 Percent confidence interval - upper 0.025 #&gt; P-value H_0: RMSEA &lt;= 0.050 1.000 #&gt; P-value H_0: RMSEA &gt;= 0.080 0.000 #&gt; #&gt; Standardized Root Mean Square Residual: #&gt; #&gt; SRMR 0.023 #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Standard #&gt; Information Expected #&gt; Information saturated (h1) model Structured #&gt; #&gt; Latent Variables: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; copingm =~ #&gt; x1 1.000 #&gt; x2 0.740 0.094 7.909 0.000 #&gt; x3 0.933 0.118 7.903 0.000 #&gt; x4 0.719 0.118 6.070 0.000 #&gt; socialm =~ #&gt; x4 1.000 #&gt; x5 1.771 0.273 6.485 0.000 #&gt; x6 2.141 0.319 6.703 0.000 #&gt; x7 2.784 0.421 6.611 0.000 #&gt; x8 2.689 0.402 6.681 0.000 #&gt; enhancem =~ #&gt; x9 1.000 #&gt; x10 0.648 0.070 9.293 0.000 #&gt; x11 0.776 0.093 8.340 0.000 #&gt; x12 0.802 0.096 8.327 0.000 #&gt; #&gt; Covariances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x11 ~~ #&gt; .x12 1.460 0.300 4.873 0.000 #&gt; copingm ~~ #&gt; socialm 0.398 0.071 5.603 0.000 #&gt; enhancem 0.669 0.145 4.613 0.000 #&gt; socialm ~~ #&gt; enhancem 0.320 0.084 3.783 0.000 #&gt; #&gt; Intercepts: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 0.000 0.092 0.000 1.000 #&gt; .x2 0.000 0.068 0.000 1.000 #&gt; .x3 0.000 0.086 0.000 1.000 #&gt; .x4 0.000 0.063 0.000 1.000 #&gt; .x5 0.000 0.077 0.000 1.000 #&gt; .x6 0.000 0.079 0.000 1.000 #&gt; .x7 0.000 0.111 0.000 1.000 #&gt; .x8 0.000 0.101 0.000 1.000 #&gt; .x9 0.000 0.120 0.000 1.000 #&gt; .x10 0.000 0.078 0.000 1.000 #&gt; .x11 0.000 0.115 0.000 1.000 #&gt; .x12 0.000 0.119 0.000 1.000 #&gt; copingm 0.000 #&gt; socialm 0.000 #&gt; enhancem 0.000 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 3.117 0.230 13.546 0.000 #&gt; .x2 1.694 0.125 13.527 0.000 #&gt; .x3 2.705 0.200 13.536 0.000 #&gt; .x4 0.454 0.070 6.502 0.000 #&gt; .x5 1.794 0.130 13.835 0.000 #&gt; .x6 1.384 0.115 12.015 0.000 #&gt; .x7 3.240 0.248 13.089 0.000 #&gt; .x8 2.393 0.194 12.352 0.000 #&gt; .x9 3.958 0.400 9.895 0.000 #&gt; .x10 1.710 0.170 10.063 0.000 #&gt; .x11 4.657 0.371 12.545 0.000 #&gt; .x12 4.997 0.398 12.561 0.000 #&gt; copingm 1.118 0.217 5.158 0.000 #&gt; socialm 0.380 0.110 3.469 0.001 #&gt; enhancem 3.210 0.490 6.550 0.000 Gli indici di fit sono migliorati. Esaminiamo la soluzione standardizzata. standardizedSolution(fit3) #&gt; lhs op rhs est.std se z pvalue ci.lower ci.upper #&gt; 1 copingm =~ x1 0.514 0.043 12.016 0 0.430 0.598 #&gt; 2 copingm =~ x2 0.515 0.043 12.055 0 0.431 0.599 #&gt; 3 copingm =~ x3 0.514 0.043 12.037 0 0.431 0.598 #&gt; 4 copingm =~ x4 0.540 0.063 8.609 0 0.417 0.663 #&gt; 5 socialm =~ x4 0.438 0.061 7.129 0 0.317 0.558 #&gt; 6 socialm =~ x5 0.632 0.032 20.004 0 0.570 0.694 #&gt; 7 socialm =~ x6 0.746 0.025 29.291 0 0.697 0.796 #&gt; 8 socialm =~ x7 0.690 0.029 24.206 0 0.634 0.746 #&gt; 9 socialm =~ x8 0.731 0.026 27.800 0 0.680 0.783 #&gt; 10 enhancem =~ x9 0.669 0.041 16.388 0 0.589 0.749 #&gt; 11 enhancem =~ x10 0.664 0.041 16.243 0 0.584 0.744 #&gt; 12 enhancem =~ x11 0.542 0.045 12.120 0 0.454 0.629 #&gt; 13 enhancem =~ x12 0.541 0.045 12.083 0 0.453 0.628 #&gt; 14 x11 ~~ x12 0.303 0.050 6.097 0 0.205 0.400 #&gt; 15 x1 ~~ x1 0.736 0.044 16.757 0 0.650 0.822 #&gt; 16 x2 ~~ x2 0.735 0.044 16.697 0 0.649 0.821 #&gt; 17 x3 ~~ x3 0.735 0.044 16.726 0 0.649 0.822 #&gt; 18 x4 ~~ x4 0.229 0.037 6.223 0 0.157 0.301 #&gt; 19 x5 ~~ x5 0.601 0.040 15.043 0 0.522 0.679 #&gt; 20 x6 ~~ x6 0.443 0.038 11.636 0 0.368 0.517 #&gt; 21 x7 ~~ x7 0.524 0.039 13.307 0 0.447 0.601 #&gt; 22 x8 ~~ x8 0.465 0.038 12.099 0 0.390 0.541 #&gt; 23 x9 ~~ x9 0.552 0.055 10.104 0 0.445 0.659 #&gt; 24 x10 ~~ x10 0.559 0.054 10.314 0 0.453 0.666 #&gt; 25 x11 ~~ x11 0.706 0.048 14.582 0 0.611 0.801 #&gt; 26 x12 ~~ x12 0.708 0.048 14.622 0 0.613 0.802 #&gt; 27 copingm ~~ copingm 1.000 0.000 NA NA 1.000 1.000 #&gt; 28 socialm ~~ socialm 1.000 0.000 NA NA 1.000 1.000 #&gt; 29 enhancem ~~ enhancem 1.000 0.000 NA NA 1.000 1.000 #&gt; 30 copingm ~~ socialm 0.610 0.057 10.735 0 0.499 0.721 #&gt; 31 copingm ~~ enhancem 0.353 0.060 5.844 0 0.235 0.472 #&gt; 32 socialm ~~ enhancem 0.289 0.056 5.141 0 0.179 0.399 #&gt; 33 x1 ~1 0.000 0.045 0.000 1 -0.088 0.088 #&gt; 34 x2 ~1 0.000 0.045 0.000 1 -0.088 0.088 #&gt; 35 x3 ~1 0.000 0.045 0.000 1 -0.088 0.088 #&gt; 36 x4 ~1 0.000 0.045 0.000 1 -0.088 0.088 #&gt; 37 x5 ~1 0.000 0.045 0.000 1 -0.088 0.088 #&gt; 38 x6 ~1 0.000 0.045 0.000 1 -0.088 0.088 #&gt; 39 x7 ~1 0.000 0.045 0.000 1 -0.088 0.088 #&gt; 40 x8 ~1 0.000 0.045 0.000 1 -0.088 0.088 #&gt; 41 x9 ~1 0.000 0.045 0.000 1 -0.088 0.088 #&gt; 42 x10 ~1 0.000 0.045 0.000 1 -0.088 0.088 #&gt; 43 x11 ~1 0.000 0.045 0.000 1 -0.088 0.088 #&gt; 44 x12 ~1 0.000 0.045 0.000 1 -0.088 0.088 #&gt; 45 copingm ~1 0.000 0.000 NA NA 0.000 0.000 #&gt; 46 socialm ~1 0.000 0.000 NA NA 0.000 0.000 #&gt; 47 enhancem ~1 0.000 0.000 NA NA 0.000 0.000 Non ci sono ulteriori motivi di preoccupazione. Brown (2015) conclude che il modello più adeguato sia model3. Nel caso presente, a mio parare, l’introduzione della correlazione residua tra x11 e x12 si sarebbe anche potuta evitare, dato che il modello model3 (con meno idiosincrasie legate al campione) si era già dimostrato adeguato. References "],["saturazione-sul-fattore-sbagliato.html", "21.3 Saturazione sul fattore sbagliato", " 21.3 Saturazione sul fattore sbagliato Brown (2015) considera anche il caso opposto, ovvero quello nel quale il ricercatore ipotizza una saturazione spuria. Per i dati in discussione, si può avere la situazione presente. model4 &lt;- &quot; copingm =~ x1 + x2 + x3 + x4 socialm =~ x4 +x5 + x6 + x7 + x8 + x12 enhancem =~ x9 + x10 + x11 &quot; Adattiamo il modello ai dati. fit4 &lt;- cfa( model4, sample.cov = covs, sample.nobs = 500, mimic = &quot;mplus&quot; ) Esaminiamo la soluzione ottenuta. summary(fit4, fit.measures = TRUE) #&gt; lavaan 0.6.14 ended normally after 59 iterations #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of model parameters 40 #&gt; #&gt; Number of observations 500 #&gt; #&gt; Model Test User Model: #&gt; #&gt; Test statistic 212.717 #&gt; Degrees of freedom 50 #&gt; P-value (Chi-square) 0.000 #&gt; #&gt; Model Test Baseline Model: #&gt; #&gt; Test statistic 1664.026 #&gt; Degrees of freedom 66 #&gt; P-value 0.000 #&gt; #&gt; User Model versus Baseline Model: #&gt; #&gt; Comparative Fit Index (CFI) 0.898 #&gt; Tucker-Lewis Index (TLI) 0.866 #&gt; #&gt; Loglikelihood and Information Criteria: #&gt; #&gt; Loglikelihood user model (H0) -12010.051 #&gt; Loglikelihood unrestricted model (H1) -11903.692 #&gt; #&gt; Akaike (AIC) 24100.101 #&gt; Bayesian (BIC) 24268.685 #&gt; Sample-size adjusted Bayesian (SABIC) 24141.723 #&gt; #&gt; Root Mean Square Error of Approximation: #&gt; #&gt; RMSEA 0.081 #&gt; 90 Percent confidence interval - lower 0.070 #&gt; 90 Percent confidence interval - upper 0.092 #&gt; P-value H_0: RMSEA &lt;= 0.050 0.000 #&gt; P-value H_0: RMSEA &gt;= 0.080 0.554 #&gt; #&gt; Standardized Root Mean Square Residual: #&gt; #&gt; SRMR 0.073 #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Standard #&gt; Information Expected #&gt; Information saturated (h1) model Structured #&gt; #&gt; Latent Variables: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; copingm =~ #&gt; x1 1.000 #&gt; x2 0.741 0.093 7.925 0.000 #&gt; x3 0.932 0.118 7.906 0.000 #&gt; x4 0.699 0.117 5.995 0.000 #&gt; socialm =~ #&gt; x4 1.000 #&gt; x5 1.725 0.260 6.634 0.000 #&gt; x6 2.098 0.305 6.879 0.000 #&gt; x7 2.717 0.401 6.775 0.000 #&gt; x8 2.619 0.382 6.848 0.000 #&gt; x12 0.900 0.236 3.818 0.000 #&gt; enhancem =~ #&gt; x9 1.000 #&gt; x10 0.638 0.076 8.408 0.000 #&gt; x11 0.767 0.094 8.153 0.000 #&gt; #&gt; Covariances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; copingm ~~ #&gt; socialm 0.410 0.072 5.663 0.000 #&gt; enhancem 0.661 0.148 4.456 0.000 #&gt; socialm ~~ #&gt; enhancem 0.347 0.089 3.902 0.000 #&gt; #&gt; Intercepts: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 0.000 0.092 0.000 1.000 #&gt; .x2 0.000 0.068 0.000 1.000 #&gt; .x3 0.000 0.086 0.000 1.000 #&gt; .x4 0.000 0.063 0.000 1.000 #&gt; .x5 0.000 0.077 0.000 1.000 #&gt; .x6 0.000 0.079 0.000 1.000 #&gt; .x7 0.000 0.111 0.000 1.000 #&gt; .x8 0.000 0.101 0.000 1.000 #&gt; .x12 0.000 0.119 0.000 1.000 #&gt; .x9 0.000 0.120 0.000 1.000 #&gt; .x10 0.000 0.078 0.000 1.000 #&gt; .x11 0.000 0.115 0.000 1.000 #&gt; copingm 0.000 #&gt; socialm 0.000 #&gt; enhancem 0.000 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 3.106 0.230 13.478 0.000 #&gt; .x2 1.686 0.125 13.449 0.000 #&gt; .x3 2.698 0.200 13.477 0.000 #&gt; .x4 0.463 0.069 6.719 0.000 #&gt; .x5 1.805 0.130 13.886 0.000 #&gt; .x6 1.378 0.115 12.022 0.000 #&gt; .x7 3.255 0.248 13.143 0.000 #&gt; .x8 2.418 0.194 12.455 0.000 #&gt; .x12 6.740 0.430 15.673 0.000 #&gt; .x9 3.891 0.436 8.933 0.000 #&gt; .x10 1.724 0.183 9.435 0.000 #&gt; .x11 4.662 0.371 12.579 0.000 #&gt; copingm 1.129 0.218 5.170 0.000 #&gt; socialm 0.397 0.111 3.566 0.000 #&gt; enhancem 3.277 0.524 6.258 0.000 È chiaro che il modello model4 è inadeguato. Il problema emerge chiaramente anche esaminando i MI. modindices(fit4) #&gt; lhs op rhs mi epc sepc.lv sepc.all sepc.nox #&gt; 47 copingm =~ x5 0.090 0.036 0.038 0.022 0.022 #&gt; 48 copingm =~ x6 0.554 0.090 0.096 0.054 0.054 #&gt; 49 copingm =~ x7 0.107 0.055 0.059 0.024 0.024 #&gt; 50 copingm =~ x8 3.919 -0.306 -0.325 -0.143 -0.143 #&gt; 51 copingm =~ x12 6.109 0.499 0.530 0.199 0.199 #&gt; 52 copingm =~ x9 0.390 -0.096 -0.102 -0.038 -0.038 #&gt; 53 copingm =~ x10 0.027 -0.016 -0.017 -0.010 -0.010 #&gt; 54 copingm =~ x11 0.823 0.123 0.131 0.051 0.051 #&gt; 55 socialm =~ x1 1.990 -0.398 -0.251 -0.122 -0.122 #&gt; 56 socialm =~ x2 0.638 0.166 0.105 0.069 0.069 #&gt; 57 socialm =~ x3 0.372 0.160 0.101 0.053 0.053 #&gt; 58 socialm =~ x9 0.315 -0.130 -0.082 -0.031 -0.031 #&gt; 59 socialm =~ x10 1.423 0.179 0.113 0.064 0.064 #&gt; 60 socialm =~ x11 0.520 -0.150 -0.094 -0.037 -0.037 #&gt; 61 enhancem =~ x1 1.029 0.067 0.121 0.059 0.059 #&gt; 62 enhancem =~ x2 0.232 0.023 0.042 0.028 0.028 #&gt; 63 enhancem =~ x3 0.153 -0.024 -0.043 -0.023 -0.023 #&gt; 64 enhancem =~ x4 0.745 -0.031 -0.056 -0.040 -0.040 #&gt; 65 enhancem =~ x5 0.343 -0.028 -0.050 -0.029 -0.029 #&gt; 66 enhancem =~ x6 0.103 0.015 0.027 0.015 0.015 #&gt; 67 enhancem =~ x7 2.752 -0.110 -0.198 -0.080 -0.080 #&gt; 68 enhancem =~ x8 0.129 -0.021 -0.038 -0.017 -0.017 #&gt; 69 enhancem =~ x12 116.781 0.916 1.658 0.624 0.624 #&gt; 70 x1 ~~ x2 1.709 0.177 0.177 0.077 0.077 #&gt; 71 x1 ~~ x3 2.273 -0.257 -0.257 -0.089 -0.089 #&gt; 72 x1 ~~ x4 0.850 0.103 0.103 0.086 0.086 #&gt; 73 x1 ~~ x5 0.292 -0.064 -0.064 -0.027 -0.027 #&gt; 74 x1 ~~ x6 0.188 -0.048 -0.048 -0.023 -0.023 #&gt; 75 x1 ~~ x7 0.023 -0.025 -0.025 -0.008 -0.008 #&gt; 76 x1 ~~ x8 0.419 -0.093 -0.093 -0.034 -0.034 #&gt; 77 x1 ~~ x12 0.025 -0.034 -0.034 -0.007 -0.007 #&gt; 78 x1 ~~ x9 0.011 0.020 0.020 0.006 0.006 #&gt; 79 x1 ~~ x10 0.004 0.008 0.008 0.003 0.003 #&gt; 80 x1 ~~ x11 1.804 0.259 0.259 0.068 0.068 #&gt; 81 x2 ~~ x3 0.071 -0.034 -0.034 -0.016 -0.016 #&gt; 82 x2 ~~ x4 2.979 -0.143 -0.143 -0.162 -0.162 #&gt; 83 x2 ~~ x5 2.403 0.135 0.135 0.077 0.077 #&gt; 84 x2 ~~ x6 0.551 0.060 0.060 0.040 0.040 #&gt; 85 x2 ~~ x7 0.457 -0.081 -0.081 -0.035 -0.035 #&gt; 86 x2 ~~ x8 0.012 0.011 0.011 0.006 0.006 #&gt; 87 x2 ~~ x12 0.134 -0.058 -0.058 -0.017 -0.017 #&gt; 88 x2 ~~ x9 1.033 0.145 0.145 0.056 0.056 #&gt; 89 x2 ~~ x10 1.140 -0.100 -0.100 -0.058 -0.058 #&gt; 90 x2 ~~ x11 0.323 0.081 0.081 0.029 0.029 #&gt; 91 x3 ~~ x4 1.472 0.127 0.127 0.113 0.113 #&gt; 92 x3 ~~ x5 0.140 0.041 0.041 0.019 0.019 #&gt; 93 x3 ~~ x6 0.717 0.087 0.087 0.045 0.045 #&gt; 94 x3 ~~ x7 0.317 0.086 0.086 0.029 0.029 #&gt; 95 x3 ~~ x8 3.121 -0.237 -0.237 -0.093 -0.093 #&gt; 96 x3 ~~ x12 0.001 0.006 0.006 0.001 0.001 #&gt; 97 x3 ~~ x9 0.000 0.003 0.003 0.001 0.001 #&gt; 98 x3 ~~ x10 4.165 -0.241 -0.241 -0.111 -0.111 #&gt; 99 x3 ~~ x11 3.806 0.350 0.350 0.099 0.099 #&gt; 100 x4 ~~ x5 0.316 -0.036 -0.036 -0.039 -0.039 #&gt; 101 x4 ~~ x6 0.052 -0.015 -0.015 -0.019 -0.019 #&gt; 102 x4 ~~ x7 1.182 0.099 0.099 0.081 0.081 #&gt; 103 x4 ~~ x8 0.062 -0.021 -0.021 -0.020 -0.020 #&gt; 104 x4 ~~ x12 0.033 0.020 0.020 0.011 0.011 #&gt; 105 x4 ~~ x9 1.418 -0.115 -0.115 -0.086 -0.086 #&gt; 106 x4 ~~ x10 0.914 0.061 0.061 0.068 0.068 #&gt; 107 x4 ~~ x11 0.517 -0.068 -0.068 -0.047 -0.047 #&gt; 108 x5 ~~ x6 0.611 0.073 0.073 0.046 0.046 #&gt; 109 x5 ~~ x7 0.115 -0.045 -0.045 -0.019 -0.019 #&gt; 110 x5 ~~ x8 0.079 0.034 0.034 0.016 0.016 #&gt; 111 x5 ~~ x12 3.265 -0.302 -0.302 -0.087 -0.087 #&gt; 112 x5 ~~ x9 0.203 0.066 0.066 0.025 0.025 #&gt; 113 x5 ~~ x10 0.000 0.002 0.002 0.001 0.001 #&gt; 114 x5 ~~ x11 2.312 -0.224 -0.224 -0.077 -0.077 #&gt; 115 x6 ~~ x7 2.239 -0.200 -0.200 -0.094 -0.094 #&gt; 116 x6 ~~ x8 0.073 0.033 0.033 0.018 0.018 #&gt; 117 x6 ~~ x12 0.478 0.109 0.109 0.036 0.036 #&gt; 118 x6 ~~ x9 1.251 -0.153 -0.153 -0.066 -0.066 #&gt; 119 x6 ~~ x10 0.784 0.079 0.079 0.051 0.051 #&gt; 120 x6 ~~ x11 0.370 0.083 0.083 0.033 0.033 #&gt; 121 x7 ~~ x8 1.644 0.219 0.219 0.078 0.078 #&gt; 122 x7 ~~ x12 0.433 -0.152 -0.152 -0.032 -0.032 #&gt; 123 x7 ~~ x9 0.005 -0.015 -0.015 -0.004 -0.004 #&gt; 124 x7 ~~ x10 1.836 -0.179 -0.179 -0.076 -0.076 #&gt; 125 x7 ~~ x11 0.348 -0.119 -0.119 -0.031 -0.031 #&gt; 126 x8 ~~ x12 2.680 -0.335 -0.335 -0.083 -0.083 #&gt; 127 x8 ~~ x9 0.676 0.147 0.147 0.048 0.048 #&gt; 128 x8 ~~ x10 0.337 0.068 0.068 0.033 0.033 #&gt; 129 x8 ~~ x11 3.437 -0.330 -0.330 -0.098 -0.098 #&gt; 130 x12 ~~ x9 7.051 0.713 0.713 0.139 0.139 #&gt; 131 x12 ~~ x10 6.960 0.465 0.465 0.136 0.136 #&gt; 132 x12 ~~ x11 68.717 2.238 2.238 0.399 0.399 #&gt; 133 x9 ~~ x10 0.081 0.138 0.138 0.053 0.053 #&gt; 134 x9 ~~ x11 0.166 0.209 0.209 0.049 0.049 #&gt; 135 x10 ~~ x11 0.423 -0.211 -0.211 -0.075 -0.075 Il MI relativo alla saturazione di x12 su enhancem è uguale a 116.781. Chiaramente, in una revisione del modello, questo problema dovrebbe deve essere affrontato. References "],["commenti-e-considerazioni-finali-1.html", "Commenti e considerazioni finali", " Commenti e considerazioni finali Gli esempi discussi da Brown (2015) mostrano come l’uso dei MI, insieme all’esame della soluzione fattoriale, possano essere usati dallo psicologo per migliorare il modello che viene proposto. References "],["ch-mmm.html", "Capitolo 22 CFA per matrici multi-tratto multi-metodo", " Capitolo 22 CFA per matrici multi-tratto multi-metodo La validità rappresenta la capacità di una procedura di misurazione di misurare ciò che si intende misurare. È possibile distinguere diversi tipi di validità cui corrispondono metodi diversi di verifica. validità di facciata: “il grado in con cui gli item di un test appaiono ragionevoli o sensibili, rispetto al costrutto, sia alle persone a cui è diretto il test sia a coloro che lo usano” (Anastasi, 1969); è dunque determinata dalla significatività apparente ed esteriore che una misura presenta; per valutarla si richiedono giudizi di esperti relativamente alla validità che sembrano avere le misure; validità di contenuto: una misura ha validità di contenuto quando i suoi indicatori rappresentano in modo accurato l’universo di contenuto misurato; anche questo tipo di validità richiede il giudizio di esperti; validità di costrutto: richiama la definizione generica di validità: “il grado in cui uno strumento misura il costrutto che intende misurare”; si riferisce all’inferenza della misurazione delle variabili latenti (o costrutti), non direttamente osservabili ma dedotte, attraverso un modello statistico, da variabili osservate; è data dal livello in cui gli indicatori misurano accuratamente i costrutti teorici che interessa misurare; essa è verificata praticamente attraverso la misura dell’associazione tra un costrutto ed altri costrutti secondo particolari modelli teorici (poniamo, per esempio, di voler costruire uno strumento che misuri la depressione di un particolare gruppo di individui; secondo l’ipotesi, lo strumento fornirà una buona misura di depressione, ovvero avrà validità di costrutto, se risulterà essere inversamente correlato con il benessere, ad esempio; per poter procedere in questo modo è necessario assumere che la teoria sia corretta, ovvero che esista la relazione ipotizzata tra depressione e benessere); validità di criterio: rappresenta la capacità di uno strumento di fare previsioni accurate; la verifica di tale validità è fatta a partire dalla sua adeguatezza nel predire un criterio esterno; validità concorrente: è determinata osservando quanto lo strumento correla con altri strumenti che il ricercatore ritiene validi nel misurare la stessa caratteristica; l’osservazione di una forte relazione statisticamente è considerata verifica della validità; validità convergente: è determinata confrontando e correlando i punteggi ottenuti con la misura da validare con quelli ottenuti con la misura di un altro costrutto, teoricamente legato al primo. La possibilità di verificare la validità convergente dipende quindi dall’esistenza di costrutti, e relative misure, legati con quello misurato; validità discriminante: è speculare alla validità convergente; essa è alta quando la misura da validare non correla con le misure di altri costrutti, teoricamente distinti dal primo. "],["mtmm-e-cfa.html", "22.1 MTMM e CFA", " 22.1 MTMM e CFA La Matrice Multi-Tratto Multi-Metodo (MTMM; Campbell and Fiske, 1959) è un metodo per valutare la validità di costrutto. La MTMM valuta la correlazione tra costrutti differenti misurati sia con metodi uguali, sia con metodi differenti. La ratio è che la validità di costrutto è alta quando lo strumento misura il costrutto in modo tale che lo strumento utilizzato non è essenziale alla misurazione. 22.1.1 Un esempio concreto Nell’esempio discusso da Brown (2015), il ricercatore desidera esaminare la validità del costrutto dei disturbi di personalità del Cluster A del DSM-IV, che sono pattern persistenti di sintomi caratterizzati da comportamenti strani o eccentrici (American Psychiatric Association, 1994). Il cluster A comprende tre costrutti di disturbo della personalità: paranoico (un pattern duraturo di sfiducia e sospetto tale che le motivazioni degli altri sono interpretate come malevole); schizoide (un pattern duraturo di distacco dalle relazioni sociali e una gamma ristretta di espressioni emotive); schizotipico (un pattern duraturo di disagio acuto nelle relazioni sociali, distorsioni cognitive e percettive ed eccentricità comportamentali). In un campione di 500 pazienti, ciascuno di questi tre tratti è misurato mediante tre metodi di valutazione: un inventario di autovalutazione dei disturbi di personalità; valutazioni dimensionali da un colloquio clinico* strutturato sui disturbi della personalità; valutazioni osservazionali effettuate da psicologi. I dati sono contenuti in una matrice 3 (T) × 3 (M), organizzata in modo tale che le correlazioni tra i diversi tratti (disturbi della personalità: paranoico, schizotipico, schizoide) siano annidate all’interno di ciascun metodo (tipo di valutazione: inventario, colloquio clinico, valutazioni degli osservatori). I dati sono riportati qui sotto. sds &lt;- c(3.61, 3.66, 3.59, 2.94, 3.03, 2.85, 2.22, 2.42, 2.04) cors &lt;- &quot; 1.000 0.290 1.000 0.372 0.478 1.000 0.587 0.238 0.209 1.000 0.201 0.586 0.126 0.213 1.000 0.218 0.281 0.681 0.195 0.096 1.000 0.557 0.228 0.195 0.664 0.242 0.232 1.000 0.196 0.644 0.146 0.261 0.641 0.248 0.383 1.000 0.219 0.241 0.676 0.290 0.168 0.749 0.361 0.342 1.000&quot; covs &lt;- getCov( cors, sds = sds, names = c(&quot;pari&quot;, &quot;szti&quot;, &quot;szdi&quot;, &quot;parc&quot;, &quot;sztc&quot;, &quot;szdc&quot;, &quot;paro&quot;, &quot;szto&quot;, &quot;szdo&quot;) ) La matrice MTMM è costituita da due tipi di blocchi di coefficienti. Blocchi di mono-metodo, che contengono correlazioni tra indicatori derivati dallo stesso metodo di valutazione. Blocchi etero-metodo, che contengono correlazioni tra indicatori valutati con metodi differenti. Di centrale interesse è la diagonale di validità, che corrisponde alla diagonale all’interno di ciascun blocco etero-metodo. Le correlazioni sulla diagonale di validità rappresentano stime di validità convergente: diverse misure di costrutti teoricamente simili o sovrapposti dovrebbero essere fortemente interconnesse. Nella matrice MTMM, la validità convergente è evidenziata da forti correlazioni tra metodi che misurano lo stesso tratto (cioè, coefficienti mono-tratto/etero-metodo). Ad esempio, i risultati dell’esempio indicano che le tre diverse misure della personalità schizotipica sono fortemente correlate (valori \\(r\\) da .676 a .749). Gli elementi al di fuori della diagonale dei blocchi etero-metodo rivelano la validità discriminante: le misure di costrutti teoricamente distinti non dovrebbero essere altamente inter-correlate. La validità discriminante nella matrice MTMM è evidenziata da correlazioni deboli tra diversi tratti misurati con metodi diversi (cioè, coefficienti etero-tratto/etero-metodo) in relazione alle correlazioni sulla diagonale di validità (coefficienti mono-tratto/etero-metodo). Nei dati dell’esempio, il supporto per la validità discriminante è ottenuto dalla constatazione che le correlazioni negli elementi al di fuori della diagonale dei blocchi etero-metodo sono uniformemente inferiori (valori \\(r\\) = .126 a .290) rispetto ai coefficienti di validità (valori \\(r\\) = .557 a .749). Infine, l’evidenza degli effetti del metodo è ottenuta dall’esame degli elementi fuori dalla diagonale dei blocchi del mono-metodo. L’entità degli effetti del metodo è riflessa dall’entità differenziale delle correlazioni tra i diversi tratti misurati con lo stesso metodo (coefficienti etero-tratto/mono-metodo) rispetto alle correlazioni tra gli stessi due tratti misurati con metodi diversi. Come mostrato nei dati dell’esempio, sebbene non estrema, è evidente una certa varianza di metodo, in particolare per le misure di valutazione dell’inventario e dell’osservatore. Ad esempio, le valutazioni dell’osservatore dei tratti della personalità paranoica e schizotipica sono più altamente correlate (r = .383) rispetto alle misure etero-metodo di questi tratti (ad esempio, la correlazione tra i tratti della personalità paranoide e schizotipica misurata rispettivamente dall’inventario e dalla valutazione dell’osservatore, è .196). Come nel presente esempio, quando i risultati complessivi indicano che la validità convergente e discriminante sono elevate e gli effetti del metodo sono trascurabili, la validità del costrutto è supportata. Brown (2015) mostra come sia possibile analizzare la matrice MTMM con un modello CFA nel quale si ipotizza che vi siano correlazioni residue tra le specificità di ciascun metodo. Il modello è dunque formulato nel modo seguente: ogni fattore comune (paranoid, schizotypal, schizoid) è identificato dagli item corrispondenti definiti da metodi diversi; le specificità di ciascun metodo, inoltre, sono tra loro correlate. model &lt;- &quot; paranoid =~ pari + parc + paro schizotypal =~ szti + sztc + szto schizoid =~ szdi + szdc + szdo pari ~~ szti + szdi szti ~~ szdi parc ~~ sztc + szdc sztc ~~ szdc paro ~~ szto + szdo szto ~~ szdo &quot; Adattiamo il modello ai dati. fit &lt;- cfa( model, sample.cov = covs, sample.nobs = 500, std.lv = TRUE ) Esaminiamo la soluzione ottenuta. summary(fit, fit.measures = TRUE, standardized = TRUE) #&gt; lavaan 0.6.14 ended normally after 59 iterations #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of model parameters 30 #&gt; #&gt; Number of observations 500 #&gt; #&gt; Model Test User Model: #&gt; #&gt; Test statistic 14.371 #&gt; Degrees of freedom 15 #&gt; P-value (Chi-square) 0.498 #&gt; #&gt; Model Test Baseline Model: #&gt; #&gt; Test statistic 2503.656 #&gt; Degrees of freedom 36 #&gt; P-value 0.000 #&gt; #&gt; User Model versus Baseline Model: #&gt; #&gt; Comparative Fit Index (CFI) 1.000 #&gt; Tucker-Lewis Index (TLI) 1.001 #&gt; #&gt; Loglikelihood and Information Criteria: #&gt; #&gt; Loglikelihood user model (H0) -9879.996 #&gt; Loglikelihood unrestricted model (H1) -9872.811 #&gt; #&gt; Akaike (AIC) 19819.992 #&gt; Bayesian (BIC) 19946.430 #&gt; Sample-size adjusted Bayesian (SABIC) 19851.209 #&gt; #&gt; Root Mean Square Error of Approximation: #&gt; #&gt; RMSEA 0.000 #&gt; 90 Percent confidence interval - lower 0.000 #&gt; 90 Percent confidence interval - upper 0.041 #&gt; P-value H_0: RMSEA &lt;= 0.050 0.989 #&gt; P-value H_0: RMSEA &gt;= 0.080 0.000 #&gt; #&gt; Standardized Root Mean Square Residual: #&gt; #&gt; SRMR 0.025 #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Standard #&gt; Information Expected #&gt; Information saturated (h1) model Structured #&gt; #&gt; Latent Variables: #&gt; Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all #&gt; paranoid =~ #&gt; pari 2.588 0.145 17.833 0.000 2.588 0.712 #&gt; parc 2.472 0.121 20.350 0.000 2.472 0.841 #&gt; paro 1.747 0.088 19.946 0.000 1.747 0.788 #&gt; schizotypal =~ #&gt; szti 2.950 0.132 22.367 0.000 2.950 0.788 #&gt; sztc 2.348 0.123 19.047 0.000 2.348 0.768 #&gt; szto 2.047 0.089 22.905 0.000 2.047 0.843 #&gt; schizoid =~ #&gt; szdi 2.713 0.120 22.526 0.000 2.713 0.769 #&gt; szdc 2.438 0.107 22.826 0.000 2.438 0.860 #&gt; szdo 1.782 0.073 24.323 0.000 1.782 0.872 #&gt; #&gt; Covariances: #&gt; Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all #&gt; .pari ~~ #&gt; .szti 1.274 0.338 3.774 0.000 1.274 0.217 #&gt; .szdi 2.537 0.329 7.703 0.000 2.537 0.441 #&gt; .szti ~~ #&gt; .szdi 3.872 0.342 11.329 0.000 3.872 0.746 #&gt; .parc ~~ #&gt; .sztc -0.335 0.210 -1.597 0.110 -0.335 -0.107 #&gt; .szdc -0.608 0.176 -3.461 0.001 -0.608 -0.265 #&gt; .sztc ~~ #&gt; .szdc -0.933 0.188 -4.967 0.000 -0.933 -0.330 #&gt; .paro ~~ #&gt; .szto 0.737 0.118 6.240 0.000 0.737 0.413 #&gt; .szdo 0.505 0.096 5.274 0.000 0.505 0.368 #&gt; .szto ~~ #&gt; .szdo 0.625 0.102 6.158 0.000 0.625 0.478 #&gt; paranoid ~~ #&gt; schizotypal 0.381 0.046 8.341 0.000 0.381 0.381 #&gt; schizoid 0.359 0.046 7.856 0.000 0.359 0.359 #&gt; schizotypal ~~ #&gt; schizoid 0.310 0.047 6.666 0.000 0.310 0.310 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all #&gt; .pari 6.514 0.513 12.695 0.000 6.514 0.493 #&gt; .parc 2.529 0.334 7.562 0.000 2.529 0.293 #&gt; .paro 1.867 0.179 10.434 0.000 1.867 0.380 #&gt; .szti 5.309 0.460 11.529 0.000 5.309 0.379 #&gt; .sztc 3.846 0.330 11.654 0.000 3.846 0.411 #&gt; .szto 1.704 0.175 9.742 0.000 1.704 0.289 #&gt; .szdi 5.080 0.386 13.158 0.000 5.080 0.408 #&gt; .szdc 2.085 0.230 9.047 0.000 2.085 0.260 #&gt; .szdo 1.005 0.107 9.351 0.000 1.005 0.240 #&gt; paranoid 1.000 1.000 1.000 #&gt; schizotypal 1.000 1.000 1.000 #&gt; schizoid 1.000 1.000 1.000 effectsize::interpret(fit) #&gt; Name Value Threshold Interpretation #&gt; 1 GFI 0.99376810 0.95 satisfactory #&gt; 2 AGFI 0.98130431 0.90 satisfactory #&gt; 3 NFI 0.99425997 0.90 satisfactory #&gt; 4 NNFI 1.00061169 0.90 satisfactory #&gt; 5 CFI 1.00000000 0.90 satisfactory #&gt; 6 RMSEA 0.00000000 0.05 satisfactory #&gt; 7 SRMR 0.02482894 0.08 satisfactory #&gt; 8 RFI 0.98622392 0.90 satisfactory #&gt; 9 PNFI 0.41427499 0.50 poor #&gt; 10 IFI 1.00025272 0.90 satisfactory Per i dati considerati da Brown (2015), l’adattamento del modello MTMM è eccellente. Ciò fornisce forti evidenze di validità di costrutto per i fattori Paranoico, Schizoide e Schizotipico che sono stati ipotizzati. References "],["simbologia-di-base.html", "Appendice A Simbologia di base", " Appendice A Simbologia di base Per una scrittura più sintetica possono essere utilizzati alcuni simboli matematici. \\(\\log(x)\\): il logaritmo naturale di \\(x\\). L’operatore logico booleano \\(\\land\\) significa “e” (congiunzione forte) mentre il connettivo di disgiunzione \\(\\lor\\) significa “o” (oppure) (congiunzione debole). Il quantificatore esistenziale \\(\\exists\\) vuol dire “esiste almeno un” e indica l’esistenza di almeno una istanza del concetto/oggetto indicato. Il quantificatore esistenziale di unicità \\(\\exists!\\) (“esiste soltanto un”) indica l’esistenza di esattamente una istanza del concetto/oggetto indicato. Il quantificatore esistenziale \\(\\nexists\\) nega l’esistenza del concetto/oggetto indicato. Il quantificatore universale \\(\\forall\\) vuol dire “per ogni.” \\(\\mathcal{A, S}\\): insiemi. \\(x \\in A\\): \\(x\\) è un elemento dell’insieme \\(A\\). L’implicazione logica “\\(\\Rightarrow\\)” significa “implica” (se …allora). \\(P \\Rightarrow Q\\) vuol dire che \\(P\\) è condizione sufficiente per la verità di \\(Q\\) e che \\(Q\\) è condizione necessaria per la verità di \\(P\\). L’equivalenza matematica “\\(\\iff\\)” significa “se e solo se” e indica una condizione necessaria e sufficiente, o corrispondenza biunivoca. Il simbolo \\(\\vert\\) si legge “tale che.” Il simbolo \\(\\triangleq\\) (o \\(:=\\)) si legge “uguale per definizione.” Il simbolo \\(\\Delta\\) indica la differenza fra due valori della variabile scritta a destra del simbolo. Il simbolo \\(\\propto\\) si legge “proporzionale a.” Il simbolo \\(\\approx\\) si legge “circa.” Il simbolo \\(\\in\\) della teoria degli insiemi vuol dire “appartiene” e indica l’appartenenza di un elemento ad un insieme. Il simbolo \\(\\notin\\) vuol dire “non appartiene.” Il simbolo \\(\\subseteq\\) si legge “è un sottoinsieme di” (può coincidere con l’insieme stesso). Il simbolo \\(\\subset\\) si legge “è un sottoinsieme proprio di.” Il simbolo \\(\\#\\) indica la cardinalità di un insieme. Il simbolo \\(\\cap\\) indica l’intersezione di due insiemi. Il simbolo \\(\\cup\\) indica l’unione di due insiemi. Il simbolo \\(\\emptyset\\) indica l’insieme vuoto o evento impossibile. In matematica, \\(\\mbox{argmax}\\) identifica l’insieme dei punti per i quali una data funzione raggiunge il suo massimo. In altre parole, \\(\\mbox{argmax}_x f(x)\\) è l’insieme dei valori di \\(x\\) per i quali \\(f(x)\\) raggiunge il valore più alto. \\(a, c, \\alpha, \\gamma\\): scalari. \\(\\boldsymbol{x}, \\boldsymbol{y}\\): vettori. \\(\\boldsymbol{X}, \\boldsymbol{Y}\\): matrici. \\(X \\sim p\\): la variabile casuale \\(X\\) si distribuisce come \\(p\\). \\(p(\\cdot)\\): distribuzione di massa o di densità di probabilità. \\(p(y \\mid \\boldsymbol{x})\\): la probabilità o densità di \\(y\\) dato \\(\\boldsymbol{x}\\), ovvero \\(p(y = \\boldsymbol{Y} \\mid x = \\boldsymbol{X})\\). \\(f(x)\\): una funzione arbitraria di \\(x\\). \\(f(\\boldsymbol{X}; \\theta, \\gamma)\\): \\(f\\) è una funzione di \\(\\boldsymbol{X}\\) con parametri \\(\\theta, \\gamma\\). Questa notazione indica che \\(\\boldsymbol{X}\\) sono i dati che vengono passati ad un modello di parametri \\(\\theta, \\gamma\\). \\(\\mathcal{N}(\\mu, \\sigma^2)\\): distribuzione gaussiana di media \\(\\mu\\) e varianza \\(sigma^2\\). \\(\\mbox{Beta}(\\alpha, \\beta)\\): distribuzione Beta di parametri \\(\\alpha\\) e \\(\\beta\\). \\(\\mathcal{U}(a, b)\\): distribuzione uniforme con limite inferiore \\(a\\) e limite superiore \\(b\\). \\(\\mbox{Cauchy}(\\alpha, \\beta)\\): distribuzione di Cauchy di parametri \\(\\alpha\\) (posizione: media) e \\(\\beta\\) (scala: radice quadrata della varianza). \\(\\mathcal{B}(p)\\): distribuzione di Bernoulli di parametro \\(p\\) (probabilità di successo). \\(\\mbox{Bin}(n, p)\\): distribuzione binomiale di parametri \\(n\\) (numero di prove) e \\(p\\) (probabilità di successo). \\(\\mathbb{KL} (p \\mid\\mid q)\\): la divergenza di Kullback-Leibler da \\(p\\) a \\(q\\). "],["elementi-di-algebra-lineare.html", "Appendice B Elementi di algebra lineare", " Appendice B Elementi di algebra lineare L’analisi fattoriale è una tecnica di analisi multivariata e, perciò, richiede la comprensione di almeno alcuni concetti di base dell’algebra lineare. A livello minimale è necessario capire che cosa sono i vettori e le matrici, che cosa è il determinante di una matrice, e in che modo possano essere eseguite le operazioni algebriche su vettori e matrici. Questo Capitolo si pone l’obiettivo di chiarire le nozioni elencate sopra. "],["vettori.html", "B.1 Vettori", " B.1 Vettori B.1.1 Vettori nello spazio euclideo Un vettore geometrico è un segmento orientato dotato di una lunghezza, una direzione e un verso. Spesso viene rappresentato con una freccia. Dato che i vettori non hanno posizione (ma solo direzione, verso e intensità), sono possibili rappresentazioni multiple dello stesso vettore. Nella discussione seguente, considereremo soltanto vettori che hanno origine nel punto (0, 0). Questo verrà chiarito dall’esempio seguente. La posizione di un punto nel piano può essere espressa nei termini di una coppia ordinata di numeri (\\(x, y\\)), le coordinate di quel punto. Tale coppia di valori rappresenta la distanza verticale dal punto a ciascuno degli assi coordinati. Possiamo anche definire il punto \\(P\\) specificando la distanza e la direzione di \\(P\\) dall’origine, ovvero nei termini del vettore \\(\\overrightarrow{OP}\\). A sua volta, questo vettore può essere espresso nei termini delle sue componenti nelle direzioni orizzontali e verticali: \\[ \\overrightarrow{OP} = \\left[ \\begin{array}{c} 2\\\\ 3 \\end{array} \\right] \\] Se volessimo specificare un punto in uno spazio a 3 dimensioni, avremmo: \\[ \\overrightarrow{OP} = \\left[ \\begin{array}{c} x\\\\ y\\\\ z \\end{array} \\right] \\] In generale, un punto \\(P\\) in uno spazio a \\(n\\)-dimensioni sarà specificato da: \\[ \\overrightarrow{OP} = \\left[ \\begin{array}{c} v_1\\\\ v_2\\\\ \\dots\\\\ v_n \\end{array} \\right] \\] Dal punto di vista geometrico, dunque, un vettore rappresenta un punto in uno spazio \\(n\\)-dimensionale. In \\(\\mathsf{R}\\), un vettore è definito come a &lt;- c(1, 3, 2) a #&gt; [1] 1 3 2 B.1.2 Somma e differenza di vettori La somma di due vettori è definita come \\[ (a_1, a_2) + (b_1, b_2) = (a_1 + b_1, a_2 + b_2). \\] In \\(\\mathsf{R}\\) abbiamo a &lt;- c(1, 3, 2) b &lt;- c(2, 8, 9) a + b #&gt; [1] 3 11 11 La differenza di due vettori è \\[ (a_1, a_2) - (b_1, b_2) = (a_1 - b_1, b_2 - b_2). \\] In \\(\\mathsf{R}\\) abbiamo a &lt;- c(1, 3, 2) b &lt;- c(2, 8, 9) a - b #&gt; [1] -1 -5 -7 B.1.3 Moltiplicazione scalare La moltiplicazione scalare di un vettore per un numero reale (o scalare) è data da \\[ \\rho (a_1, a_2) = (\\rho a_1, \\rho a_2) \\] Dal punto di vista geometrico, la moltiplicazione scalare effettua una estensione o contrazione del vettore \\(\\boldsymbol{a}\\), preservandone la direzione. In \\(\\mathsf{R}\\) abbiamo a &lt;- 2 x &lt;- c(2, 8, 9) a * x #&gt; [1] 4 16 18 B.1.4 Combinazione lineare Se \\(\\mathbf{v}_{1}, \\dots, \\mathbf{v}_{n}\\) sono vettori e \\(a_1, \\dots, a_n\\) sono scalari, allora la combinazione lineare di questi vettori con questi coefficienti scalari è data da \\[ {\\displaystyle a_{1}\\mathbf {v} _{1}+a_{2}\\mathbf {v} _{2}+a_{3}\\mathbf {v} _{3}+\\cdots +a_{n}\\mathbf {v} _{n}.} \\] Per esempio, in \\(\\mathsf{R}\\) possiamo aver a &lt;- c(2, 3, 4) v1 &lt;- c(2, 8, 3) v2 &lt;- c(4, 5, 1) v3 &lt;- c(1, 3, 2) y &lt;- a[1] * v1 + a[2] * v2 + a[3] * v3 y #&gt; [1] 20 43 17 B.1.5 Vettore 0 e vettore 1 Il vettore 0 è costituito da \\(n\\) elementi, tutti uguali a 0. Il vettore 1 è costituito da \\(n\\) elementi, tutti uguali a 1. In \\(\\mathsf{R}\\) abbiamo x &lt;- rep(0, 5) x #&gt; [1] 0 0 0 0 0 y &lt;- rep(1, 5) y #&gt; [1] 1 1 1 1 1 B.1.6 Ortogonalità tra vettori Due vettori si dicono ortogonali, e si scrive \\(\\boldsymbol{a} \\bot \\boldsymbol{b}\\), se e solo se il loro prodotto scalare è nullo: \\[ \\boldsymbol{a}&#39;\\boldsymbol{b} = 0. \\] In \\(\\mathsf{R}\\) abbiamo v1 &lt;- c(1, 1) v2 &lt;- c(-1, 1) sum(v1 * v2) #&gt; [1] 0 B.1.7 Trasposta di un vettore In un vettore trasposto gli indici delle righe prendono il posto degli indici delle colonne, e viceversa. In \\(\\mathsf{R}\\) abbiamo v1 &lt;- c(1, 3, 7) %&gt;% as.matrix() v1 #&gt; [,1] #&gt; [1,] 1 #&gt; [2,] 3 #&gt; [3,] 7 Le dimensioni di v1 sono dim(v1) #&gt; [1] 3 1 La trasposta di v1 è v2 &lt;- t(v1) v2 #&gt; [,1] [,2] [,3] #&gt; [1,] 1 3 7 e ha dimensioni dim(v2) #&gt; [1] 1 3 B.1.8 Norma o lunghezza di un vettore Per il teorema di Pitagora, la norma di un vettore \\((a_1, a_2)\\) è \\(\\sqrt{a_1^2 + a_2^2}\\) ed è denotata da \\(\\| (a_1, a_2) \\|\\). Infatti, se un vettore \\(\\boldsymbol{a}\\) (l’ipotenusa) è la somma di due vettori ortogonali \\(\\boldsymbol{a}_1\\) e \\(\\boldsymbol{a}_2\\) (i cateti), allora la lunghezza al quadrato di \\(\\boldsymbol{a}\\) è uguale alla somma dei quadrati delle lunghezze di \\(\\boldsymbol{a}_1\\) e \\(\\boldsymbol{a}_2\\). Viene detta norma di \\(\\boldsymbol{a}\\) la radice del prodotto scalare di un vettore per se stesso: \\[ \\| \\boldsymbol{a} \\| = \\sqrt{\\boldsymbol{a}&#39;\\boldsymbol{a}}. \\] In \\(\\mathsf{R}\\) abbiamo sqrt(t(v1) %*% v1) #&gt; [,1] #&gt; [1,] 7.681146 "],["matrici.html", "B.2 Matrici", " B.2 Matrici Una matrice costituisce un insieme rettangolare di scalari ordinati per riga e colonna. Può anche essere vista come la raccolta di \\(m\\) vettori colonna di dimensione \\(n\\) o come la raccolta di \\(n\\) vettori riga di dimensione \\(m\\). Per esempio: \\[ \\boldsymbol{A} = \\left[ \\begin{array}{c c c} a_{11} &amp; a_{12} &amp; a_{13}\\\\ a_{21} &amp; a_{22} &amp; a_{23} \\end{array} \\right] \\] In \\(\\mathsf{R}\\) abbiamo M &lt;- matrix( c(1, 2, 3, 4, 5, 6), ncol = 3, byrow = TRUE ) M #&gt; [,1] [,2] [,3] #&gt; [1,] 1 2 3 #&gt; [2,] 4 5 6 B.2.1 Dimensioni della matrice I numeri interi \\(m\\) ed \\(n\\) si dicono dimensioni della matrice, ovvero \\(\\boldsymbol{A}\\) si dice matrice di dimensioni \\(m \\times n\\) o di ordine \\(m \\times n\\). Nel caso presente, la matrice \\(\\boldsymbol{A}\\) ha dimensioni \\(2 \\times 3\\). dim(M) #&gt; [1] 2 3 B.2.2 Matrice trasposta Si definisce matrice trasposta di \\(\\boldsymbol{A}\\), e si denota con \\(\\boldsymbol{A}&#39;\\) oppure \\(\\boldsymbol{A}&#39;\\), la matrice \\(\\boldsymbol{B} = \\boldsymbol{A}&#39;\\) di ordine \\(n \\times m\\) cui elementi sono: \\[ b_{ij} = a_{ji}, \\quad i = 1 \\dots m, j = 1 \\dots n \\] Per esempio, \\[ \\left[ \\begin{array}{c c} -2 &amp; 5\\\\ 3 &amp; 1\\\\ 7 &amp; -6 \\end{array} \\right]&#39;= \\left[ \\begin{array}{c c c} -2 &amp; 3 &amp; 7\\\\ 5 &amp; 1 &amp; -6 \\end{array} \\right] \\] B.2.3 Matrice simmetrica Se accade che \\(\\boldsymbol{A} = \\boldsymbol{A}&#39;\\) allora la matrice è detta simmetrica. \\[ \\boldsymbol{A} = \\left[ \\begin{array}{c c c} 7 &amp; 1 &amp; 2\\\\ 1 &amp; 8 &amp; 3\\\\ 2 &amp; 3 &amp; 9 \\end{array} \\right] \\] \\((\\boldsymbol{A} + \\boldsymbol{B})&#39; = (\\boldsymbol{A})&#39; + (\\boldsymbol{B})&#39;\\) \\((\\boldsymbol{A} - \\boldsymbol{B})&#39; = (\\boldsymbol{A})&#39; - (\\boldsymbol{B})&#39;\\) \\((\\boldsymbol{a} + \\boldsymbol{b})&#39; = (\\boldsymbol{a})&#39; + (\\boldsymbol{b})&#39;\\) \\((\\boldsymbol{a} - \\boldsymbol{b})&#39; = (\\boldsymbol{a})&#39; - (\\boldsymbol{b})&#39;\\) B.2.4 Matrice quadrata o rettangolare Se \\(m = n\\) allora la matrice \\(\\boldsymbol{A}\\) si dice quadrata di dimensione \\(n\\) o di ordine \\(n\\) altrimenti si dice rettangolare. Le righe di \\(\\boldsymbol{A}\\) sono \\([a_{11}\\ a_{12}\\ a_{13}]\\) e \\([a_{21}\\ a_{22}\\ a_{23}]\\). Le colonne di \\(\\boldsymbol{A}\\) sono \\(\\left[\\begin{array}{c} a_{11} \\\\ a_{21} \\end{array} \\right]\\), \\(\\left[ \\begin{array}{c} a_{12} \\\\ a_{22} \\end{array} \\right]\\) e \\(\\left[ \\begin{array}{c} a_{13} \\\\ a_{23} \\end{array} \\right]\\). B.2.5 Diagonale principale Se \\(i\\) e \\(j\\) sono numeri interi con \\(1 \\leq i \\leq m\\) e \\(1 \\leq j \\leq n\\) allora l’elemento della matrice \\(\\boldsymbol{A}\\) di dimensione \\(m \\times n\\) che si trova in posizione (\\(i, j\\)) viene indicato con \\(a_{ij}\\). Gli elementi \\(a_{ij}\\) di una matrice quadrata \\(\\boldsymbol{A}\\) di ordine \\(n\\) tali che \\(i = j\\) sono detti elementi principali o diagonali e formano la cosiddetta diagonale principale di \\(\\boldsymbol{A}\\). \\[ \\boldsymbol{A} = \\left[ \\begin{array}{c c c} a_{11} &amp; a_{12} &amp; a_{13}\\\\ a_{21} &amp; a_{22} &amp; a_{23}\\\\ a_{31} &amp; a_{32} &amp; a_{33} \\end{array} \\right] \\] B.2.6 Matrice diagonale Se gli elementi \\(a_{ij}\\) di una matrice quadrata \\(\\boldsymbol{A}\\) sono tali che \\(a_{ij} =0\\) e \\(a_{ii} \\neq 0\\), allora la matrice \\(\\boldsymbol{A}\\) viene detta matrice diagonale. \\[ \\boldsymbol{A} = \\left[ \\begin{array}{c c c} a_{11} &amp; 0 &amp; 0\\\\ 0 &amp; a_{22} &amp; 0\\\\ 0 &amp; 0 &amp; a_{33} \\end{array} \\right] \\] B.2.7 Matrice identità Si definisce matrice identità di ordine \\(n\\) la matrice quadrata diagonale \\(\\boldsymbol{I}_n\\) avente tutti gli elementi principali uguali a \\(1\\): \\[ \\boldsymbol{I}_3 = \\left[ \\begin{array}{c c c} 1 &amp; 0 &amp; 0\\\\ 0 &amp; 1 &amp; 0\\\\ 0 &amp; 0 &amp; 1 \\end{array} \\right] \\] La matrice identità ha la stessa funzione del numero “1” nel sistema dei numeri reali. B.2.8 Matrici diagonali e triangolari Gli elementi di una matrice che si trovano al di sopra della diagonale principale sono detti sopradiagonali, mentre quelli che si trovano al di sotto della stessa diagonale principale sono detti sottodiagonali. Se una matrice ha tutti gli elementi sopradiagonali e sottodiagonali uguali a zero viene detta matrice diagonale. Se invece ha solo gli elementi sopradiagonali nulli allora viene detta triangolare inferiore. Se ha gli elementi sottodiagonali nulli allora è detta triangolare superiore. B.2.9 Somma e sottrazione La somma e la sottrazione di due matrici sono operazioni definite elemento per elemento. Per sommare due matrici sommiamo gli elementi corrispondenti. Per sottrarre due matrici sottraiamo gli elementi corrispondenti. Si noti che queste operazioni hanno senso solo se le due matrici hanno le stesse dimensioni (altrimenti queste operazioni non sono definite). Per esempio, \\[ \\left[ \\begin{array}{c c} -2 &amp; 5\\\\ 3 &amp; 1\\\\ 7 &amp; -6 \\end{array} \\right]+ \\left[ \\begin{array}{c c} 3 &amp; -2\\\\ 4 &amp; 5\\\\ 10 &amp; -3 \\end{array} \\right]= \\left[ \\begin{array}{c c} 1 &amp; 3\\\\ 7 &amp; 6\\\\ 17 &amp; -9 \\end{array} \\right] \\] A &lt;- matrix( c(-2, 5, 3, 1, 7, -6), nrow = 3, byrow = TRUE ) A #&gt; [,1] [,2] #&gt; [1,] -2 5 #&gt; [2,] 3 1 #&gt; [3,] 7 -6 B &lt;- matrix( c(3, -2, 4, 5, 10, -3), nrow = 3, byrow = TRUE ) B #&gt; [,1] [,2] #&gt; [1,] 3 -2 #&gt; [2,] 4 5 #&gt; [3,] 10 -3 A + B #&gt; [,1] [,2] #&gt; [1,] 1 3 #&gt; [2,] 7 6 #&gt; [3,] 17 -9 \\[ \\left[ \\begin{array}{c c} -2 &amp; 5\\\\ 3 &amp; 1\\\\ 7 &amp; -6 \\end{array} \\right]- \\left[ \\begin{array}{c c} 3 &amp; -2\\\\ 4 &amp; 5\\\\ 10 &amp; -3 \\end{array} \\right]= \\left[ \\begin{array}{c c} -5 &amp; 7\\\\ -1 &amp; -4\\\\ -3 &amp; -3 \\end{array} \\right] \\] A - B #&gt; [,1] [,2] #&gt; [1,] -5 7 #&gt; [2,] -1 -4 #&gt; [3,] -3 -3 B.2.10 Moltiplicazione di scalari e matrici L’effetto della moltiplicazione di una matrice \\(\\boldsymbol{A}\\) di qualsiasi dimensione per un numero reale b (scalare) è quello di moltiplicare ciascun elemento in \\(\\boldsymbol{A}\\) per b. Questo è equivalente a sommare \\(\\boldsymbol{A}\\) a se stessa b volte. Per esempio, \\[ 3 \\left[ \\begin{array}{c c} -2 &amp; 5\\\\ 3 &amp; 1\\\\ 7 &amp; -6 \\end{array} \\right]= \\left[ \\begin{array}{c c} -6 &amp; 15\\\\ 9 &amp; 3\\\\ 21 &amp; -18 \\end{array} \\right] \\] 3 * A #&gt; [,1] [,2] #&gt; [1,] -6 15 #&gt; [2,] 9 3 #&gt; [3,] 21 -18 B.2.11 Proprietà della somma e differenza È facile verificare che la somma e la differenza cosı̀ definite godono delle proprietà commutativa e associativa. Siano \\(k\\) uno scalare e \\(A\\) e \\(B\\) due matrici aventi le stesse dimensioni. Allora \\(\\boldsymbol{A}+ \\boldsymbol{B} = \\boldsymbol{B} + \\boldsymbol{A}\\)(Proprietà commutativa) \\(\\boldsymbol{A} + (\\boldsymbol{B} + \\boldsymbol{C}) = (\\boldsymbol{A} + \\boldsymbol{B}) + \\boldsymbol{C}\\) (Proprietà associativa) \\(k(l\\boldsymbol{A}) = (kl)\\boldsymbol{A}\\) \\(k(\\boldsymbol{A} + \\boldsymbol{B}) = k\\boldsymbol{A} + k\\boldsymbol{B}\\)(Proprietà distributiva) \\((k+l)\\boldsymbol{A} = k\\boldsymbol{A} + l\\boldsymbol{A}\\) \\(1\\boldsymbol{A} = \\boldsymbol{A}\\) B.2.12 Prodotto di matrici La moltiplicazione di matrici non è un’operazione intuitiva come la somma e la differenza, ma fornisce uno strumento potente per eseguire una lunga serie di calcoli in un modo molto semplice. L’ordine è importante: il numero delle colonne della prima matrice deve essere uguale al numero di righe della seconda matrice. Quando ciò accade le matrici si dicono conformabili, altrimenti si dicono non conformabili. Sia \\(\\boldsymbol{A}\\) una matrice \\(m \\times p\\) e \\(\\boldsymbol{B}\\) una matrice \\(p \\times n\\). Il prodotto tra le due matrici \\(\\boldsymbol{C} = \\boldsymbol{AB}\\) è la matrice di ordine \\(m \\times n\\) il cui elemento generico è \\[ c_{ij} = \\sum_{k=1}^{p} a_{ik}a_{kj}, \\quad i = 1 \\dots m, j = 1 \\dots n \\] Pertanto, il prodotto si effettua riga per colonna. È facile verificare che il prodotto tra matrici gode della proprietà associativa ma in generale non di quella commutativa. Vale invece la seguente proprietà: \\[ (\\boldsymbol{AB})&#39; = \\boldsymbol{B}&#39;\\boldsymbol{A}&#39; \\] Ad esempio, siano \\(\\boldsymbol{A}\\) e \\(\\boldsymbol{B}\\) le seguenti matrici \\[ \\left[ \\begin{array}{c c c} -2 &amp; 1 &amp; 1\\\\ 1 &amp; 1 &amp; 4\\\\ 2 &amp; -3 &amp; 2 \\end{array} \\right] \\quad \\text{e} \\quad \\left[ \\begin{array}{c c c} 3 &amp; -2 &amp;1\\\\ 4 &amp; 5 &amp; 0\\\\ 1 &amp; -3 &amp; 1 \\end{array} \\right] \\] Calcoliamo la matrice \\(\\boldsymbol{C} = \\boldsymbol{AB}\\). L’elemento \\(c_{ij}\\) è uguale alla somma dei prodotti degli elementi della i-esima riga di \\(\\boldsymbol{A}\\) per la j-esima colonna di \\(\\boldsymbol{B}\\). \\(c_{11} = (-2) \\cdot 3 + 1 \\cdot 4 + 1 \\cdot 1 = -1\\) \\(c_{12} = (-2) \\cdot (-2) + 1 \\cdot 5 + 1 \\cdot (-3) = 6\\) \\(c_{13} = (-2) \\cdot 3 + 1 \\cdot 0 + 1 \\cdot 1 = -1\\) \\(c_{21} = 1 \\cdot 3 + 1 \\cdot 4 + 4 \\cdot 1 = 11\\) \\(c_{22} = 1 \\cdot (-2) + 1 \\cdot 5 + 4 \\cdot (-3) = -9\\) \\(c_{23} = 1 \\cdot 3 + 1 \\cdot 0 + 4 \\cdot 1 = 5\\) \\(c_{31} = 2 \\cdot 3 +(-3) \\cdot 4 + 2 \\cdot 1 = -4\\) \\(c_{32} = 2 \\cdot (-2) +(-3) \\cdot 5 + 2 \\cdot (-3) = -25\\) \\(c_{33} = 2 \\cdot 1 + (-3) \\cdot 0 + 2 \\cdot 1 = 4\\) In definitiva \\[ \\boldsymbol{C} = \\left[ \\begin{array}{c c c} -1 &amp; 6 &amp; -1\\\\ 11 &amp; -9 &amp; 5\\\\ -4 &amp; -25 &amp; 4 \\end{array} \\right] \\] A &lt;- matrix( c(-2, 1, 1, 1, 1, 4, 2, -3, 2), nrow = 3, byrow = TRUE ) A #&gt; [,1] [,2] [,3] #&gt; [1,] -2 1 1 #&gt; [2,] 1 1 4 #&gt; [3,] 2 -3 2 B &lt;- matrix( c(3, -2, 1, 4, 5, 0, 1, -3, 1), nrow = 3, byrow = TRUE ) B #&gt; [,1] [,2] [,3] #&gt; [1,] 3 -2 1 #&gt; [2,] 4 5 0 #&gt; [3,] 1 -3 1 A %*% B #&gt; [,1] [,2] [,3] #&gt; [1,] -1 6 -1 #&gt; [2,] 11 -9 5 #&gt; [3,] -4 -25 4 Calcolando il prodotto \\(\\boldsymbol{D} = \\boldsymbol{BA}\\) si trova invece: \\[ \\boldsymbol{D} = \\left[ \\begin{array}{c c c} -6 &amp; -2 &amp; -3\\\\ -3 &amp; 9 &amp; 24\\\\ -3 &amp; -5 &amp; -9 \\end{array} \\right] \\] da cui risulta evidente che \\(\\boldsymbol{AB} \\neq \\boldsymbol{BA}\\). B %*% A #&gt; [,1] [,2] [,3] #&gt; [1,] -6 -2 -3 #&gt; [2,] -3 9 24 #&gt; [3,] -3 -5 -9 B.2.13 Proprietà del prodotto di matrici \\(\\boldsymbol{A}(\\boldsymbol{B} + \\boldsymbol{C}) = \\boldsymbol{AB} + \\boldsymbol{AC}\\) \\((\\boldsymbol{A} + \\boldsymbol{B})\\boldsymbol{C} = \\boldsymbol{AC} + \\boldsymbol{BC}\\) Per qualunque matrice \\(\\boldsymbol{A}\\), \\(\\boldsymbol{A}&#39;\\boldsymbol{A}\\) sarà una matrice quadrata. \\((\\boldsymbol{AB})&#39; = \\boldsymbol{B}&#39;\\boldsymbol{A}&#39;\\) B.2.14 Casi particolari La matrice identità è l’elemento neutro per il prodotto, cioè se \\(\\boldsymbol{I}\\) è una matrice \\(n \\times n\\) si ha \\[ \\boldsymbol{A} \\boldsymbol{I}_n = \\boldsymbol{I}_n \\boldsymbol{A} = \\boldsymbol{A}. \\] Per esempio, \\[ \\boldsymbol{IA} = \\left(% \\begin{array}{cc} 1 &amp; 0 \\\\ 0 &amp; 1 \\\\ \\end{array}% \\right) \\left(% \\begin{array}{ccc} 2 &amp; 3 &amp; -1 \\\\ 1 &amp; 4 &amp; 7 \\\\ \\end{array}% \\right)= \\left(% \\begin{array}{ccc} 2 &amp; 3 &amp; -1 \\\\ 1 &amp; 4 &amp; 7 \\\\ \\end{array}% \\right) \\] In R la matrice identità si crea nel modo seguente. diag(2) #&gt; [,1] [,2] #&gt; [1,] 1 0 #&gt; [2,] 0 1 Dunque A &lt;- matrix( c(2, 3, -1, 1, 4, 7), nrow = 2, byrow = TRUE ) A #&gt; [,1] [,2] [,3] #&gt; [1,] 2 3 -1 #&gt; [2,] 1 4 7 diag(2) %*% A #&gt; [,1] [,2] [,3] #&gt; [1,] 2 3 -1 #&gt; [2,] 1 4 7 A %*% diag(3) #&gt; [,1] [,2] [,3] #&gt; [1,] 2 3 -1 #&gt; [2,] 1 4 7 Un secondo caso particolare si verifica quando una matrice è costituita da un’unica colonna o un’unica riga. Se la matrice \\(\\boldsymbol{A}\\) si riduce ad una sola colonna (o una sola riga) e viene detta vettore colonna (o riga) ad \\(m\\) elementi o componenti. Un vettore colonna è una matrice \\(n \\times 1\\); un vettore riga è una matrice \\(1 \\times m\\). Se \\(\\boldsymbol{a}\\) è un vettore colonna di \\(m\\) elementi allora \\(\\boldsymbol{a}&#39;\\) è un vettore riga sempre di \\(m\\) elementi. Per le operazioni tra vettori valgono le stesse regole viste per le matrici, cioè la somma e la differenza sono possibili tra vettori dello stesso tipo e con lo stesso numero di componenti. La moltiplicazione è possibile tra una matrice e un vettore di dimensioni appropriate, e tra due vettori di dimensioni appropriate. In questo secondo caso, distinguiamo tra prodotto interno e prodotto esterno. B.2.15 Operazioni tra vettori Il prodotto interno (o scalare) di un vettore \\(\\boldsymbol{a}&#39;\\) \\(1 \\times n\\) che premoltiplica un vettore \\(\\boldsymbol{b}\\) \\(n \\times 1\\) produce uno scalare: \\[ \\boldsymbol{a}&#39;\\boldsymbol{b} = \\sum_{i=1}^{n}a_i b_i \\] Dati due vettori \\(\\boldsymbol{a}\\), \\(\\boldsymbol{b}\\) di ordini \\(n \\times 1\\) e \\(m \\times 1\\), il prodotto esterno \\(\\boldsymbol{C} = \\boldsymbol{ab}&#39;\\) è una matrice \\(n \\times m\\) di elementi \\(c_{ij} = a_i b_j\\). B.2.16 Prodotto interno Siano \\(\\boldsymbol{a}\\) e \\(\\boldsymbol{b}\\) i seguenti vettori: \\[ \\left[ \\begin{array}{c} 1 \\\\ 2 \\\\ 3 \\end{array} \\right] \\quad e \\quad \\left[ \\begin{array}{c} -1 \\\\ -2 \\\\ 4 \\end{array} \\right] \\] Il prodotto interno è: \\[ \\boldsymbol{a}&#39;\\boldsymbol{b}= 1 \\cdot (-1) + 2 \\cdot (-2) + 3 \\cdot 4 = 7 \\] Osserviamo che tale operazione gode della proprietà commutativa, poichè \\(\\boldsymbol{b}&#39;\\boldsymbol{a}=7\\). a &lt;- matrix( c(1, 2, 3), nrow = 3, byrow = TRUE ) a #&gt; [,1] #&gt; [1,] 1 #&gt; [2,] 2 #&gt; [3,] 3 b &lt;- matrix( c(-1, -2, 4), nrow = 3, byrow = TRUE ) b #&gt; [,1] #&gt; [1,] -1 #&gt; [2,] -2 #&gt; [3,] 4 t(a) %*% b #&gt; [,1] #&gt; [1,] 7 B.2.17 Prodotto esterno Il prodotto esterno è la matrice \\[ \\boldsymbol{C} = \\boldsymbol{a}\\boldsymbol{b}&#39;= \\left[ \\begin{array}{c c c} -1 &amp; -2 &amp; 4\\\\ -2 &amp; -4 &amp; 8\\\\ -3 &amp; -6 &amp; 12 \\end{array} \\right] \\] a %*% t(b) #&gt; [,1] [,2] [,3] #&gt; [1,] -1 -2 4 #&gt; [2,] -2 -4 8 #&gt; [3,] -3 -6 12 Tale prodotto non gode della proprietà commutativa, infatti: \\[ \\boldsymbol{D} = \\boldsymbol{b}\\boldsymbol{a}&#39;= \\left[ \\begin{array}{c c c} -1 &amp; -2 &amp; -3\\\\ -2 &amp; -4 &amp; -6\\\\ 4 &amp; 8 &amp; 12 \\end{array} \\right] \\] b %*% t(a) #&gt; [,1] [,2] [,3] #&gt; [1,] -1 -2 -3 #&gt; [2,] -2 -4 -6 #&gt; [3,] 4 8 12 B.2.18 Traccia di una matrice Si definisce traccia di una matrice quadrata \\(\\boldsymbol{A}\\) \\(n \\times n\\), e si denota con \\(tr(\\boldsymbol{A})\\) la somma degli elementi sulla diagonale principale di \\(\\boldsymbol{A}\\): \\[ tr(\\boldsymbol{A}) = \\sum_{i=1}^{n} a_{ii} \\] La traccia gode delle seguenti proprietà: \\[ \\begin{aligned} &amp;tr(\\rho \\boldsymbol{A}) = \\rho tr( \\boldsymbol{A}) \\notag \\\\ &amp;tr(\\boldsymbol{A} + \\boldsymbol{B}) = tr( \\boldsymbol{A})+tr( \\boldsymbol{B}) \\notag \\\\ &amp;tr(\\boldsymbol{A}&#39;) = tr( \\boldsymbol{A}) \\notag \\\\ &amp;tr(\\boldsymbol{AB}) = tr( \\boldsymbol{BA}) \\notag\\end{aligned} \\] Per esempio, sia \\[ \\boldsymbol{A} = \\left[ \\begin{array}{c c c} 7 &amp; 1 &amp; 2\\\\ 1 &amp; 8 &amp; 3\\\\ 2 &amp; 3 &amp; 9 \\end{array} \\right] \\] allora \\[ tr(\\boldsymbol{A}) = 7 + 8 + 9 = 24. \\] A &lt;- matrix( c(7, 1, 2, 1, 8, 3, 2, 3, 9), nrow = 3, byrow = TRUE ) A #&gt; [,1] [,2] [,3] #&gt; [1,] 7 1 2 #&gt; [2,] 1 8 3 #&gt; [3,] 2 3 9 sum(diag(A)) #&gt; [1] 24 B.2.18.0.1 Dipendenza lineare Si consideri la matrice \\[ \\boldsymbol{A}= \\left(% \\begin{array}{ccc} 1 &amp; 1 &amp; 1 \\\\ 3 &amp; 1 &amp; 5 \\\\ 2 &amp; 3 &amp; 1 \\\\ \\end{array}% \\right) \\] Siano \\(\\boldsymbol{c}_1\\), \\(\\boldsymbol{c}_2\\), \\(\\boldsymbol{c}_3\\) le colonne di \\(\\boldsymbol{A}\\). Si noti che \\[ 2\\boldsymbol{c}_1 + -\\boldsymbol{c}_2 + - \\boldsymbol{c}_3 = \\boldsymbol{0} \\] dove \\(\\boldsymbol{0}\\) è un vettore (\\(3 \\times 1\\)) di zeri. Dato che le 3 colonne di \\(\\boldsymbol{A}\\) possono essere combinate linearmente in modo da produrre un vettore \\(\\boldsymbol{0}\\) vi è chiaramente una qualche forma di relazione, o dipendenza, tra le informazioni nelle colonne. Detto in un altro modo, sembra esserci una qualche duplicazione delle informazione nelle colonne. In generale, si dice che \\(k\\) colonne \\(\\boldsymbol{c}_1, \\boldsymbol{c}_2, \\dots \\boldsymbol{c}_k\\) di una matrice sono linearmente dipendenti se esiste un insieme di valori scalari \\(\\lambda_1, \\dots, \\lambda_k\\) tale per cui \\[ \\lambda_1 \\boldsymbol{c}_1 + \\dots + \\lambda_k \\boldsymbol{c}_k=\\boldsymbol{0} \\] e almeno uno dei valori \\(\\lambda_i\\) non è uguale a 0. La dipendenza lineare implica che ciascun vettore colonna è una combinazione degli altri. Per esempio \\[ \\boldsymbol{c}_k= -(\\lambda_1 \\boldsymbol{c}_1 + \\dots + \\lambda_{k-1} \\boldsymbol{c}_{k-1})/\\lambda_k \\] Questo implica che tutta “l’informazione” della matrice è contenuta in un sottoinsieme delle colonne – se \\(k-1\\) colonne sono conosciute, l’ultima resta determinata. È in questo senso che abbiamo detto che l’informazione della matrice veniva “duplicata”. Se l’unico insieme di valori scalari \\(\\lambda_i\\) che soddisfa l’equazione \\[ \\lambda_1 \\boldsymbol{c}_1 + \\dots + \\lambda_k \\boldsymbol{c}_k=\\boldsymbol{0} \\] è un vettore di zeri, allora questo significa che non vi è alcuna relazione tra le colonne della matrice. Le colonne si dicono linearmente indipendenti, nel senso che non contengono alcuna “duplicazione” di informazione. B.2.19 Rango di una matrice Il rango della matrice è il massimo numero di vettori colonna linearmente indipendenti che possono essere selezionati dalla matrice. In maniera equivalente, il rango di una matrice può essere definito come il massimo numero di vettori riga linermente indipendenti. Il rango minimo di una matrice è 1, il che significa che vi è una colonna tale per cui le altre colonne sono dei multipli di questa. Per l’esempio precedente, il rango della matrice \\(\\boldsymbol{A}\\) è 2. Se la matrice è quadrata, \\(\\boldsymbol{A}_{n \\times n}\\), ed è costituita da vettori tutti indipendenti tra di loro, allora il suo rango è \\(n\\). Se, invece, la matrice è rettangolare, \\(\\boldsymbol{A}_{m \\times n}\\), allora il suo rango può essere al massimo il più piccolo tra i due valori m ed n, cioè: \\[ r(\\boldsymbol{A}_{m \\times n}) \\leq min(m,n) \\] B.2.20 Matrice inversa L’inversa di una matrice quadrata è l’analogo del reciproco per gli scalari. Se \\(b\\) è uno scalare e \\(b=0\\), allora il reciproco di \\(b\\), \\(1/b\\) non esiste – non è definito. Allo stesso modo, vi sono delle matrici che “si comportano come lo 0” e per le quali l’inversa non è definita. Tali matrici si dicono singolari. Sia \\(\\boldsymbol{A}\\) una matrice quadrata di dimensione \\(n\\). Si definisce matrice inversa la matrice, denotata con \\(\\boldsymbol{A}^{-1}\\), che premoltiplicata o postmoltiplicata per \\(\\boldsymbol{A}\\) fornisce la matrice identità: \\[ \\boldsymbol{A}\\boldsymbol{A}^{-1}=\\boldsymbol{A}^{-1}\\boldsymbol{A}=\\boldsymbol{I} \\] La condizione per l’esistenza e l’unicità di \\(\\boldsymbol{A}^{-1}\\) è che le colonne di \\(\\boldsymbol{A}\\) siano linearmente indipendenti. Nel caso di una matrice diagonale la determinazione della matrice inversa risulta immediata: \\(\\boldsymbol{D}^{-1}= diag(1/d_1, \\dots, 1/d_n)\\). Nel caso di una matrice non diagonale, la matrice inversa si trova usando il computer dove complicate formule per matrici di qualunque dimensione sono implementate in vari software. Solo per matrici di piccole dimensioni sono disponibili semplici espressioni analitiche per il calcolo della matrice inversa. Per esempio, sia \\[ \\boldsymbol{A} = \\left[ \\begin{array}{c c} 3 &amp; 4 \\\\ 2 &amp; 6 \\end{array} \\right] \\] allora \\[ \\boldsymbol{A}^{-1} = \\left[ \\begin{array}{c c} .6 &amp; -.4 \\\\ -.2 &amp; .3 \\end{array} \\right] \\] e \\[ \\boldsymbol{A}\\boldsymbol{A}^{-1} =\\left[ \\begin{array}{c c} 3 &amp; 4 \\\\ 2 &amp; 6 \\end{array} \\right] \\left[ \\begin{array}{c c} .6 &amp; -.4 \\\\ -.2 &amp; .3 \\end{array} \\right] = \\left[ \\begin{array}{c c} 1 &amp; 0 \\\\ 0 &amp; 1 \\end{array} \\right] \\] A &lt;- matrix( c(3, 4, 2, 6), nrow = 2, byrow = TRUE ) A #&gt; [,1] [,2] #&gt; [1,] 3 4 #&gt; [2,] 2 6 solve(A) #&gt; [,1] [,2] #&gt; [1,] 0.6 -0.4 #&gt; [2,] -0.2 0.3 A %*% solve(A) #&gt; [,1] [,2] #&gt; [1,] 1 0 #&gt; [2,] 0 1 solve(A) %*% A #&gt; [,1] [,2] #&gt; [1,] 1 0 #&gt; [2,] 0 1 Se \\(\\boldsymbol{A}\\) e \\(\\boldsymbol{B}\\) sono due matrici non singolari aventi le stesse dimensioni, allora l’inversa del loro prodotto è uguale al prodotto delle loro inverse nella sequenza opposta: \\[ (\\boldsymbol{AB})^{-1}=\\boldsymbol{B}^{-1}\\boldsymbol{A}^{-1} \\] B &lt;- matrix( c(1, 2, 9, 7), nrow = 2, byrow = TRUE ) B #&gt; [,1] [,2] #&gt; [1,] 1 2 #&gt; [2,] 9 7 solve(A %*% B) #&gt; [,1] [,2] #&gt; [1,] -0.4181818 0.3090909 #&gt; [2,] 0.5090909 -0.3545455 solve(B) %*% solve(A) #&gt; [,1] [,2] #&gt; [1,] -0.4181818 0.3090909 #&gt; [2,] 0.5090909 -0.3545455 L’inversa della trasposta di una matrice non singolare è uguale alla trasposta dell’inversa: \\[ (\\boldsymbol{A}&#39;)^{-1}=(\\boldsymbol{A}^{-1})&#39; \\] solve(t(A)) #&gt; [,1] [,2] #&gt; [1,] 0.6 -0.2 #&gt; [2,] -0.4 0.3 t(solve(A)) #&gt; [,1] [,2] #&gt; [1,] 0.6 -0.2 #&gt; [2,] -0.4 0.3 B.2.21 Determinante di una matrice Sia \\(\\boldsymbol{A}\\) una matrice quadrata. Il determinante di \\(\\boldsymbol{A}\\) è uno scalare, \\(|\\boldsymbol{A}|\\), il cui valore assoluto misura il volume del parallelepipedo delimitato dalle colonne di \\(\\boldsymbol{A}\\). Nel caso della matrice identità il volume è pari a 1, per cui \\(|\\boldsymbol{I}| =1\\). Per una matrice diagonale \\(\\boldsymbol{D} = diag(d_1, \\dots, d_n)\\) si ha \\[ |\\boldsymbol{D}| = d_1 \\cdot d_2, \\dots, d_n = \\prod_{i=1}^{n}d_i \\] Per una matrice \\(2 \\times 2\\) \\[ \\boldsymbol{A} = \\left[ \\begin{array}{c c} a_{11}&amp; a_{12} \\\\ a_{21} &amp; a_{22} \\end{array} \\right] \\] il determinante di \\(\\boldsymbol{A}\\) vale: \\[ |\\boldsymbol{A}| = a_{11}a_{22}-a_{12}a_{21} \\] Per esempio: \\[ \\boldsymbol{A} = \\left[ \\begin{array}{c c} 1 &amp; -2 \\\\ 3 &amp; 9 \\end{array} \\right] \\quad |\\boldsymbol{A}| = 1\\cdot 9 - (-2) \\cdot 3 = 15 \\] Il determinante è definito anche per matrici di dimensioni superiori anche se, in quel caso, i calcoli sono molto più complessi (una volta ancora, si usi il computer!). A &lt;- matrix( c(1, -2, 3, 9), nrow = 2, byrow = TRUE ) A #&gt; [,1] [,2] #&gt; [1,] 1 -2 #&gt; [2,] 3 9 det(A) #&gt; [1] 15 B.2.22 Determinante e inversa Vi è una relazione tra il determinante e l’inversa di una matrice. Se la matrice \\(\\boldsymbol{A}\\) ha dimensioni \\(2 \\times 2\\) l’inversa di \\(\\boldsymbol{A}\\) si trova nel modo seguente \\[ \\boldsymbol{A}^{-1} = \\frac{1}{|\\boldsymbol{A}|} \\left[ \\begin{array}{c c} a_{22} &amp; -a_{12} \\\\ -a_{21} &amp; a_{11} \\end{array} \\right] \\] Anche per le matrici di dimensioni maggiori la matrice inversa è definita nei termini del determinante, ma le formule di calcolo sono molto più complesse. Per esempio, sia \\[ \\boldsymbol{A} = \\left[ \\begin{array}{c c} 3 &amp; 4 \\\\ 2 &amp; 6 \\end{array} \\right] \\] allora \\[ \\boldsymbol{A}^{-1} = \\frac{1}{10} \\left[ \\begin{array}{c c} 6 &amp; -4 \\\\ -2 &amp; 3 \\end{array} \\right]= \\left[ \\begin{array}{c c} .6 &amp; -.4 \\\\ -.2 &amp; .3 \\end{array} \\right] \\] In precedenza abbiamo detto che, in alcuni casi, una matrice “si comporta come lo 0.” Il determinante di una matrice è ci dice quando una matrice “si comporta come lo 0.” \\(|\\boldsymbol{A}| = 0\\), infatti, se una riga (o una colonna) è una combinazione lineare di due (o più) righe (o colonne) di \\(\\boldsymbol{A}\\). Per esempio, nel caso di una matrice (\\(2 \\times 2\\)) \\[ \\boldsymbol{A} = \\left( \\begin{array}{c c} a_{11}&amp; a_{12} \\\\ a_{21} &amp; a_{22} \\end{array} \\right) \\] supponiamo che \\[ \\left(% \\begin{array}{c} a_{11} \\\\ a_{21} \\\\ \\end{array}% \\right)=2 \\left(% \\begin{array}{c} a_{12} \\\\ a_{22} \\\\ \\end{array}% \\right)\\] Allora \\[ \\boldsymbol{A} = \\left( \\begin{array}{c c} 2a_{12}&amp; a_{12} \\\\ 2a_{22} &amp; a_{22} \\end{array} \\right) \\] e \\[ |\\boldsymbol{A}| = 2a_{12}a_{22}-2a_{12}a_{22}=0 \\] In conclusione, se il determinante è uguale a zero, allora la matrice inversa non esiste. Nel caso di una matrice (\\(2 \\times 2\\)), infatti, la formula dell’inversa richiede la divisione per \\(a_{11}a_{22}-a_{12}a_{21}\\) che, nel caso di una matrice singolare, è uguale a zero. A &lt;- matrix( c(2, 4, 3, 6), nrow = 2, byrow = TRUE ) A #&gt; [,1] [,2] #&gt; [1,] 2 4 #&gt; [2,] 3 6 det(A) #&gt; [1] 0 # solve(A) B.2.23 Proprietà del determinante \\(|\\boldsymbol{A}&#39;| = |\\boldsymbol{A}|\\). Se \\(\\boldsymbol{A}\\) contiene una colonna o una riga i cui elementi sono tutti 0, allora \\(|\\boldsymbol{A}|=0\\). Se \\(\\boldsymbol{A}\\) contiene due colonne (o righe) identiche, allora \\(|\\boldsymbol{A}|=0\\). \\(|\\boldsymbol{A}| = 0\\) se una riga (o una colonna) è combinazione lineare di due (o più) righe (o colonne) di \\(\\boldsymbol{A}\\). \\(|\\boldsymbol{A}| = 1/|\\boldsymbol{A}^{-1}|\\). \\(|\\boldsymbol{I}| = 1\\). \\(|\\boldsymbol{A} \\boldsymbol{B}| = |\\boldsymbol{A}| |\\boldsymbol{B}|\\). Per una matrice quadrata \\(\\boldsymbol{A}\\), le seguenti affermazioni sono equivalenti: \\(\\boldsymbol{A}\\) è non singolare, \\(|\\boldsymbol{A}|\\neq 0\\), \\(\\boldsymbol{A}^{-1}\\) esiste. B.2.24 Radici e vettori latenti Dal determinante di una matrice si possono ricavare le radici latenti o autovalori (denotati da \\(\\lambda_i\\)) e i vettori latenti o autovettori della matrice. Alle nozioni di autovalore e autovettore verrà qui fornita un’interpretazione geometrica. Simuliamo di dati di due variabili associate tra loro: library(&quot;car&quot;) set.seed(123456) npoints &lt;- 20 x &lt;- as.numeric(scale(rnorm(npoints, 0, 1))) y &lt;- as.numeric(scale(3 * x + rnorm(npoints, 0, 2))) mean(x) #&gt; [1] 1.076511e-17 mean(y) #&gt; [1] -1.872959e-17 cor(x, y) #&gt; [1] 0.8291033 Disegnamo il diagramma di dispersione con un ellisse che contiene la nube di punti: Y &lt;- cbind(x, y) car::dataEllipse( Y[, 1], Y[, 2], levels = 0.95, lty = 2, ylim = c(-3, 3), xlim = c(-3, 3) ) Se racchiudiamo le osservazioni (\\(v_1, v_2\\)) con un’ellisse, allora la lunghezza dei semiassi maggiori e minori dell’ellisse sarà proporzionale a \\(\\sqrt{\\lambda_1}\\) e \\(\\sqrt{\\lambda_2}\\). L’asse maggiore è la linea passante per il punto (\\(\\bar{v_1}, \\bar{v_2}\\)) nella direzione determinata dal primo autovettore \\(\\boldsymbol{a}_1&#39;\\) con pendenza uguale a \\(a_{12}/a_{11}\\). L’asse minore è la linea passante per il punto (\\(\\bar{v_1}, \\bar{v_2}\\)) nella direzione determinata dal secondo autovettore \\(\\boldsymbol{a}_2\\). Calcoliamo ora gli autovettori e gli autovalori: s &lt;- cov(Y) ee &lt;- eigen(s) Disegniamo gli assi dell’ellisse: car::dataEllipse( Y[, 1], Y[, 2], levels = 0.95, lty = 2, ylim = c(-3, 3), xlim = c(-3, 3) ) k &lt;- 2.65 arrows( 0, 0, k * sqrt(ee$values[1]) * ee$vectors[1], k * sqrt(ee$values[1]) * ee$vectors[2], code = 2, col = &quot;red&quot;, lwd = 2 ) arrows( 0, 0, k * sqrt(ee$values[2]) * ee$vectors[1], k * sqrt(ee$values[2]) * -ee$vectors[2], code = 2, col = &quot;red&quot;, lwd = 2 ) Tale analisi si può estendere a qualunque numero di variabili. Per esempio, nel caso di tre variabili, possiamo pensare di disegnare un ellisoide attorno ad una nube di punti nello spazio tridimensionale. Anche in questo caso, gli autovalori e gli associati autovettori corrisponderanno agli assi dell’elissoide. B.2.25 Scomposizione spettrale di una matrice Data una matrice quadrata e simmetrica di dimensione \\(n\\), \\(\\boldsymbol{A}\\), esistono una matrice diagonale \\(\\boldsymbol{\\Lambda}\\) e una matrice ortogonale \\(\\boldsymbol{V}\\) tali che \\[\\boldsymbol{A} =\\boldsymbol{V} \\boldsymbol{\\Lambda} \\boldsymbol{V}&#39;,\\] dove \\(\\boldsymbol{\\Lambda}\\) è una matrice diagonale i cui elementi sono gli autovalori di \\(\\boldsymbol{A}\\): \\(\\boldsymbol{\\Lambda} = diag(\\lambda_1, \\lambda_2, \\dots, \\lambda_n)\\); \\(\\boldsymbol{V}\\) è una matrice ortogonale le cui colonne \\((v_1, v_2, \\dots, v_p)\\) sono gli autovettori di \\(\\boldsymbol{A}\\) associati ai rispettivi autovalori. In maniera equivalente \\[\\boldsymbol{A} \\boldsymbol{V} = \\boldsymbol{\\Lambda} \\boldsymbol{V}&#39;.\\] Premoltiplicando entrambi i membri per \\(\\boldsymbol{V}&#39;\\) si ottiene \\[\\boldsymbol{V}&#39;\\boldsymbol{A} \\boldsymbol{V} = \\boldsymbol{\\Lambda},\\] da cui l’affermazione che la matrice degli autovettori diagonalizza \\(\\boldsymbol{A}\\). Per esempio, sigma &lt;- matrix( data = c(1, 0.5, 0.5, 1.25), nrow = 2, ncol = 2 ) sigma #&gt; [,1] [,2] #&gt; [1,] 1.0 0.50 #&gt; [2,] 0.5 1.25 out &lt;- eigen(sigma) out #&gt; eigen() decomposition #&gt; $values #&gt; [1] 1.6403882 0.6096118 #&gt; #&gt; $vectors #&gt; [,1] [,2] #&gt; [1,] 0.6154122 -0.7882054 #&gt; [2,] 0.7882054 0.6154122 Lambda &lt;- diag(out$values) Lambda #&gt; [,1] [,2] #&gt; [1,] 1.640388 0.0000000 #&gt; [2,] 0.000000 0.6096118 U &lt;- out$vectors U #&gt; [,1] [,2] #&gt; [1,] 0.6154122 -0.7882054 #&gt; [2,] 0.7882054 0.6154122 U %*% Lambda %*% t(U) #&gt; [,1] [,2] #&gt; [1,] 1.0 0.50 #&gt; [2,] 0.5 1.25 B.2.26 Autovalori e determinante Il determinante di una matrice è il prodotto degli autovalori: \\[\\begin{aligned} |\\boldsymbol{A}| &amp;= \\prod_{i=1}^{p} \\lambda_i. \\notag \\end{aligned}\\] La traccia di una matrice è uguale alla somma degli autovalori: \\[\\begin{aligned} tr(\\boldsymbol{A}) &amp;= \\sum_{i=1}^{p} \\lambda_i. \\notag \\end{aligned}\\] sigma &lt;- matrix(data = c(1, 0.5, 0.5, 2), nrow = 2, ncol = 2) sigma #&gt; [,1] [,2] #&gt; [1,] 1.0 0.5 #&gt; [2,] 0.5 2.0 out &lt;- eigen(sigma) out #&gt; eigen() decomposition #&gt; $values #&gt; [1] 2.2071068 0.7928932 #&gt; #&gt; $vectors #&gt; [,1] [,2] #&gt; [1,] 0.3826834 -0.9238795 #&gt; [2,] 0.9238795 0.3826834 La traccia di una matrice è uguale alla somma degli autovalori: sum(out$values) #&gt; [1] 3 Il determinante di una matrice è il prodotto degli autovalori: det(sigma) #&gt; [1] 1.75 out$values[1] * out$values[2] #&gt; [1] 1.75 Gli autovalori di \\(\\boldsymbol{A}^{-1}\\) sono i reciproci degli autovalori di \\(\\boldsymbol{A}\\); gli autovettori sono coincidenti. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
