[["curve-di-crescita-latente.html", "Capitolo 21 Curve di crescita latente", " Capitolo 21 Curve di crescita latente Un importante classe di modelli a variabili latenti è quella dei modelli delle curve di crescita latente (latent growth models, LGM). I modelli delle curve di crescita latente vengono spesso utilizzati per analizzare dati longitudinali. In questo tipo di dati, una misura di esito viene ottenuta in diversi momenti del tempo e si vuole studiare il cambiamento nel tempo. In molti casi, la traiettoria nel tempo può essere modellata come una semplice funzione lineare o quadratica. Le differenze individuali vengono catturate dagli effetti random che sono convenientemente rappresentati da variabili latenti (continue), spesso chiamate fattori di crescita (growth factors). "],["dati-longitudinali.html", "21.1 Dati longitudinali", " 21.1 Dati longitudinali Possiamo pensare ai modelli LGM come ad un’estensione del modello CFA dotato di meanstructure. L’inclusione della meanstructure significa che non possiamo usare in input la matrice di covarianza campionaria, ma dobbiamo invece utilizzare i dati grezzi (ovvero, le singole osservazioni per ciascun partecipante). Un altro requisito degli LGM è che i dati devono essere forniti del formato wide, il che significa che ogni colonna rappresenta la variabile di esito in un diverso momento nel tempo. Si presume che ogni osservazione o riga sia indipendente dalle altre; le colonne mostrano invece una dipendenza temporale. I modelli LGM sono dunque un caso speciale di CFA e, nello specifico, corrispondono un modello CFA a due fattori in cui le saturazioni fattoriali sono fissate a valori predefiniti. 21.1.1 Un esempio concreto L’esempio che discuteremo utilizza un campione di dati artificiali chiamato Demo.growth in cui si ipotizza che un determinato punteggio venga misurato su quattro punti temporali. I dati sono i seguenti: data(Demo.growth) glimpse(Demo.growth) #&gt; Rows: 400 #&gt; Columns: 10 #&gt; $ t1 &lt;dbl&gt; 1.7256454, -1.9841595, 0.3195183, 0.7769485, 0.4489440, -1.7469951,… #&gt; $ t2 &lt;dbl&gt; 2.1424005, -4.4006027, -1.2691171, 3.5313707, -0.7727747, -0.996340… #&gt; $ t3 &lt;dbl&gt; 2.77317167, -6.01655626, 1.56001603, 3.13821140, -1.50351504, -0.82… #&gt; $ t4 &lt;dbl&gt; 2.51595586, -7.02961801, 2.86852958, 5.36374139, 0.07846742, 0.5669… #&gt; $ x1 &lt;dbl&gt; -1.1641026, -1.7454025, 0.9202112, 2.3595236, -1.0887077, -0.513516… #&gt; $ x2 &lt;dbl&gt; 0.17422932, -1.57686022, -0.14181802, 0.70796813, -1.00999772, -0.1… #&gt; $ c1 &lt;dbl&gt; -0.02767765, -2.03196724, 0.05237496, 0.01911429, 0.65243274, -0.04… #&gt; $ c2 &lt;dbl&gt; 0.55492337, 0.12533477, -1.25774075, 0.64738300, 0.73091476, -0.416… #&gt; $ c3 &lt;dbl&gt; 0.254478433, -1.564232274, -1.803390895, -0.432379510, -0.753781573… #&gt; $ c4 &lt;dbl&gt; -1.00639541, 1.22926875, -0.32725761, -1.03239779, -0.02745598, 0.5… La variabile dipendente è rappresentata dalle quattro colonne chiamate t1, t2, t3 e t4 che corrispondono alla serie temporale con quattro misurazioni per ciascun soggetto. Trasformiamo i dati in formato long: demo_growth_long &lt;- Demo.growth %&gt;% dplyr::select(t1, t2, t3, t4) %&gt;% pivot_longer( cols = starts_with(&quot;t&quot;), names_to = &quot;t&quot;, values_to = &quot;y&quot; ) %&gt;% as.data.frame() demo_growth_long$time &lt;- rep(0:3, 400) demo_growth_long$id &lt;- rep(1:400, each = 4) Esaminiamo un campione casuale di 9 soggetti. È presente una notevole variazione da soggetto a soggetto: id_sel &lt;- sample(1:400, 9) d &lt;- demo_growth_long[demo_growth_long$id %in% id_sel, ] d %&gt;% ggplot(aes(x = time, y = y)) + geom_line() + facet_wrap(~id) Notiamo che una funzione lineare è appropriata per rendere conto della variazione temporale della variabile risposta: d %&gt;% ggplot(aes(x = time, y = y)) + geom_point() + stat_smooth(method = &quot;lm&quot;, se = FALSE) + facet_wrap(~id) Complessivamente, i dati suggeriscono un andamento crescente della variabile risposta in funzione del tempo: demo_growth_long %&gt;% ggplot(aes(time, y, group = id)) + geom_line(alpha = 0.1) + # add individual line with transparency stat_summary( # add average line aes(group = 1), fun = mean, geom = &quot;line&quot;, size = 1.5, color = &quot;black&quot; ) + labs(x = &quot;Time&quot;, y = &quot;y&quot;) Per adattare a questi dati un modello lineare di crescita, specifichiamo il seguente modello a variabili latenti \\[ y_j = \\alpha_0 + \\alpha_1 \\lambda_j + \\zeta_{00} + \\zeta_{11} \\lambda_j + \\epsilon_j, \\] dove \\(y_j\\) è la variabile di interesse che cambia nel tempo, con \\(j = 0, \\dots, 3\\). \\(\\alpha_0\\) rappresenta l’intercetta della retta di regressione al tempo \\(t = 0\\) (il punto di partenza della linea nera sopra). \\(\\alpha_1 \\lambda_j\\) è il tasso medio di crescita nel tempo (la pendenza della linea nera nel grafico sopra). Qui \\(\\lambda_j\\) è solo l’indice dei punti temporali considerati (0, 1, 2, 3). \\(\\zeta_{00}\\) è la varianza tra i soggetti nel punto \\(t = 0\\). \\(\\zeta_{11} \\lambda_j\\) è la varianza del tasso di crescita tra i soggetti. \\(\\epsilon_j\\) è la varianza di ciascun soggetto attorno alla sua retta di regressione. Tali relazioni statistiche vengono rappresentate dal modello di equazioni strutturali della figura 21.1. FIGURA 21.1: Modello di crescita latente. Un modello lineare di crescita latente corrisponde dunque ad un modello fattoriale con due variabili latenti: un fattore (\\(\\eta_0\\)) corrisponde al “punteggio vero” delle intercette individuali, mentre l’altro fattore (\\(\\eta_1\\)) che corrisponde al “punteggio vero” delle pendenze delle rette di regressione per i singoli individui. Nella sintassi lavaan il modello LGM diventa: model &lt;- &quot; i =~ 1*t1 + 1*t2 + 1*t3 + 1*t4 s =~ 0*t1 + 1*t2 + 2*t3 + 3*t4 &quot; Si noti che, per il fattore \\(\\eta_0\\) (che rappresenta le intercette), i valori delle saturazioni fattoriali sono fissate a 1 – questo è il motivo per cui \\(\\alpha_0\\) e \\(\\zeta_{00}\\) compaiono da soli nell’equazione precedente: in maniera esplicita sono \\(1 \\cdot \\alpha_0\\) e \\(1 \\cdot \\zeta_{00}\\). Le saturazioni per il fattore \\(\\eta_1\\) (che specifica le pendenze delle funzioni lineari) sono fissate ai valori che descrivono la variazione temporale: qui i valori \\(\\lambda_j\\) da 0 a 3. Il modello include anche la correlazione tra \\(\\eta_0\\) e \\(\\eta_1\\), rappresentata dalla doppia freccia \\(\\zeta_{01}\\). Se \\(\\zeta_{01} &gt; 0\\), questo significa che, con il passare del tempo, i partecipanti tendono a diventare sempre più diversi tra loro; un’interpretazione opposta si ha se \\(\\zeta_{01}&lt; 0\\). Adattiamo il modello ai dati: fit &lt;- growth(model, data = Demo.growth) summary(fit) #&gt; lavaan 0.6-11 ended normally after 29 iterations #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of model parameters 9 #&gt; #&gt; Number of observations 400 #&gt; #&gt; Model Test User Model: #&gt; #&gt; Test statistic 8.069 #&gt; Degrees of freedom 5 #&gt; P-value (Chi-square) 0.152 #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Standard #&gt; Information Expected #&gt; Information saturated (h1) model Structured #&gt; #&gt; Latent Variables: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; i =~ #&gt; t1 1.000 #&gt; t2 1.000 #&gt; t3 1.000 #&gt; t4 1.000 #&gt; s =~ #&gt; t1 0.000 #&gt; t2 1.000 #&gt; t3 2.000 #&gt; t4 3.000 #&gt; #&gt; Covariances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; i ~~ #&gt; s 0.618 0.071 8.686 0.000 #&gt; #&gt; Intercepts: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .t1 0.000 #&gt; .t2 0.000 #&gt; .t3 0.000 #&gt; .t4 0.000 #&gt; i 0.615 0.077 8.007 0.000 #&gt; s 1.006 0.042 24.076 0.000 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .t1 0.595 0.086 6.944 0.000 #&gt; .t2 0.676 0.061 11.061 0.000 #&gt; .t3 0.635 0.072 8.761 0.000 #&gt; .t4 0.508 0.124 4.090 0.000 #&gt; i 1.932 0.173 11.194 0.000 #&gt; s 0.587 0.052 11.336 0.000 Esaminiamo il path diagram. semPaths( fit, layout = &quot;tree&quot;, intercepts = FALSE, posCol = c(&quot;black&quot;), edge.label.cex = 0.00001, sizeMan = 7, what = &quot;path&quot;, optimizeLatRes = TRUE, residuals = TRUE, style = &quot;lisrel&quot; ) Ci sono 6 tipi di parametri di interesse: kable(coef(fit), booktabs = TRUE, format = &quot;markdown&quot;) x t1~~t1 0.5952890 t2~~t2 0.6760337 t3~~t3 0.6348906 t4~~t4 0.5076449 i~~i 1.9319804 s~~s 0.5869142 i~~s 0.6178630 i~1 0.6146957 s~1 1.0062943 l’intercetta \\(i\\) = 0.615 è il valore atteso della variabile risposta al momento \\(t_0\\); la pendenza \\(s\\) = 1.006 è il tasso di cambiamento medio della variabile risposta nel tempo. Ad ogni successivo momento temporale, il valore medio della variabile risposta aumenta in media di 1.006 punti; varianza \\(i\\) = 1.932 misura la variazione tra i soggetti al momento \\(t_0\\) (ci dice quanto sono diverse le intercette delle rette di regressione tra i soggetti); varianza \\(s\\) = 0.587 misura la variazione del tasso di crescita tra i soggetti (ci dice quanto sono diverse le pendenze delle rette di regressione tra i soggetti); varianze t1, …, t4: i valori da 0.595 a 0.508 descrivono la variazione tra i soggetti in ciascun momento del tempo; la covarianza tra i e s = 0.618 ci dice che i valori della variabile risposta diventano via via più diversi nel tempo tra i rispondenti (un valore negativo avrebbe l’interpretazione opposta). Le stime dell’intercetta e della pendenza della funzione di crescita per ciascun partecipante si ottengono nel modo seguente: rand_eff &lt;- as.data.frame(lavPredict(fit)) head(rand_eff) #&gt; i s #&gt; 1 1.2275557 0.60278312 #&gt; 2 -2.6795847 -1.38498215 #&gt; 3 -0.2955058 0.88828376 #&gt; 4 1.1576419 1.34051395 #&gt; 5 -0.4355522 0.03193498 #&gt; 6 -1.3121802 0.50258530 Istogrammi delle stime individuali dell’intercetta e della pendenza della curva di crescita si ottengono nel modo seguente: gi &lt;- rand_eff %&gt;% ggplot(aes(x = i)) + geom_histogram() gh &lt;- rand_eff %&gt;% ggplot(aes(x = s)) + geom_histogram() gi + gh 21.1.2 Visualizzare il cambiamento È utile visualizzare i punteggi previsti dal modello. A tal fine, useremo qui la funzione predict() per creare un nuovo oggetto \\(\\mathsf{R}\\) che contiene i punteggi previsti a livello individuale per l’intercetta e la pendenza. pred_lgm &lt;- predict(fit) head(pred_lgm) #&gt; i s #&gt; [1,] 1.2275557 0.60278312 #&gt; [2,] -2.6795847 -1.38498215 #&gt; [3,] -0.2955058 0.88828376 #&gt; [4,] 1.1576419 1.34051395 #&gt; [5,] -0.4355522 0.03193498 #&gt; [6,] -1.3121802 0.50258530 Questi sono i valori previsti dal modello per ciascun partecipante. Se calcoliamo la media di queste variabili otteniamo gli stessi risultati che sono stati riportati sopra: # average of the intercepts (first column) mean(pred_lgm[, 1]) #&gt; [1] 0.6146957 # average of the slope (second column) mean(pred_lgm[, 2]) #&gt; [1] 1.006294 Il cambiamento nel tempo previsto dal modello per il soggetto \\(j\\)-esimo è \\[ y_j = \\eta_0 + \\lambda_j \\eta_1. \\] Il cambiamento previsto per tutti i soggetti può essere visualizzato nel modo seguente: # create long data for each individual pred_lgm_long &lt;- map( 0:3, # loop over time function(x) pred_lgm[, 1] + x * pred_lgm[, 2] ) %&gt;% reduce(cbind) %&gt;% # bring together the wave predictions as.data.frame() %&gt;% # make data frame setNames(str_c(&quot;time&quot;, 0:3)) %&gt;% # give names to variables mutate(id = row_number()) %&gt;% # make unique id gather(-id, key = time, value = pred) # make long format # make graph pred_lgm_long %&gt;% ggplot(aes(time, pred, group = id)) + # what variables to plot? geom_line(alpha = 0.1) + # add a transparent line for each person stat_summary( # add average line aes(group = 1), fun = mean, geom = &quot;line&quot;, size = 1.5, color = &quot;black&quot; ) + labs(y = &quot;y&quot;, x = &quot;time&quot;) La linea nera più spessa rappresenta l’intercetta media e la pendenza media della curva di crescita del modello LGM. Ogni individuo ha una sua specifica intercetta e uno specifico tasso di cambiamento e questa diversità è catturata nelle componenti di varianza del modello. 21.1.3 Dati ordinali vs. intervalli temporali La specificazione s =~ 0*t1 + 1*t2 + 2*t3 + 3*t4 assume che il tempo sia misurato per intervalli costanti. Questa sintassi può essere usata quando il tempo è misurato su una scala a livello ordinale, quando supponiamo diverse rilevazioni temporali e chi chiediamo cosa succeda passando da una alla successiva, senza specificare precisamente qual è la distanza temporale tra le varie rilevazioni. In alternativa è possibile specificare in termini assoluti il tempo trascorso tra le diverse rilevazioni temporali – questo è possibile solo se tali distanze temporali sono costanti tra i soggetti. Ad esempio, se passano 2, 3 e 9 mesi dalla prima rilevazione, avremo il seguente modello. model_a &lt;- &quot; i =~ 1*t1 + 1*t2 + 1*t3 + 1*t4 s =~ 0*t1 + 2*t2 + 6*t3 + 9*t4 &quot; La scelta di utilizzare il tempo ordinale rispetto a quello assoluto non cambia il numero di parametri del modello o i gradi di libertà. Tuttavia la media dei punteggi fattoriali che rappresentano l’intercetta e la pendenza può cambiare e l’interpretazione di questi termini cambierà di conseguenza. fit_a &lt;- growth(model_a, data = Demo.growth) kable(coef(fit_a), booktabs = TRUE, format = &quot;markdown&quot;) x t1~~t1 0.75840584 t2~~t2 0.80990552 t3~~t3 0.63209463 t4~~t4 0.49864811 i~~i 2.04046924 s~~s 0.05802979 i~~s 0.23300623 i~1 0.76120704 s~1 0.31906615 Mentre in precedenza l’interpretazione era che la media della variabile risposta aumenta in media 1.006 punti passando da una rilevazione temporale alla successiva, nel caso della presente specificazione temporale in mesi possiamo dire che media della variabile risposta aumenta in media 0.319 punti dopo l’incremento temporale di un mese. 21.1.4 Verifica di ipotesi È anche possibile utilizzare le funzionalità di lavaan per verificare specifiche ipotesi di interesse relative ai dati longitudinali. Ad esempio, una possibile domanda riguarda l’uguaglianza degli errori nel tempo. Tale domanda può essere affrontata introducendo dei vincoli nella specificazione del modello LGM e, successivamente, confrontando la bontà dell’adattamento del modello vincolato e del modello generale. Il modello vincolato è model_eqerr &lt;- &quot; i =~ 1*t1 + 1*t2 + 1*t3 + 1*t4 s =~ 0*t1 + 1*t2 + 2*t3 + 3*t4 t1 ~~ a*t1 t2 ~~ a*t2 t3 ~~ a*t3 t4 ~~ a*t4 &quot; Adattiamo il modello vincolato: fit_eqerr &lt;- growth(model_eqerr, data = Demo.growth) Confrontiamo il modello vincolato con il modello libero: anova(fit, fit_eqerr) #&gt; Chi-Squared Difference Test #&gt; #&gt; Df AIC BIC Chisq Chisq diff Df diff Pr(&gt;Chisq) #&gt; fit 5 5528.1 5564.0 8.0687 #&gt; fit_eqerr 8 5523.7 5547.7 9.6779 1.6091 3 0.6573 Il test del rapporto di verosimiglianza (likelihood ratio) eseguito dalla funzione anova() produce un \\(p\\)-valore di 0.6573. Ciò significa che, nei dati esaminati, non si rileva una decremento della bontà dell’adattamento degna di nota nel passare dal modello libero al modello vincolato. Dunque, l’ipotesi dell’equaglianza della varianza degli errori nel tempo sembra ragionevole. 21.1.5 Un secondo esempio Un modello leggermente più complesso aggiunge due regressori (x1 e x2) che influenzano i fattori di crescita latenti. Inoltre, è stata aggiunta al modello una covariata c variabile nel tempo che influenza la misura del risultato nei quattro punti temporali. model2 &lt;- &quot; # intercept and slope with fixed coefficients i =~ 1*t1 + 1*t2 + 1*t3 + 1*t4 s =~ 0*t1 + 1*t2 + 2*t3 + 3*t4 # regressions i ~ x1 + x2 s ~ x1 + x2 # time-varying covariates t1 ~ c1 t2 ~ c2 t3 ~ c3 t4 ~ c4 &quot; fit2 &lt;- growth(model2, data = Demo.growth) summary(fit2) #&gt; lavaan 0.6-11 ended normally after 31 iterations #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of model parameters 17 #&gt; #&gt; Number of observations 400 #&gt; #&gt; Model Test User Model: #&gt; #&gt; Test statistic 26.059 #&gt; Degrees of freedom 21 #&gt; P-value (Chi-square) 0.204 #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Standard #&gt; Information Expected #&gt; Information saturated (h1) model Structured #&gt; #&gt; Latent Variables: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; i =~ #&gt; t1 1.000 #&gt; t2 1.000 #&gt; t3 1.000 #&gt; t4 1.000 #&gt; s =~ #&gt; t1 0.000 #&gt; t2 1.000 #&gt; t3 2.000 #&gt; t4 3.000 #&gt; #&gt; Regressions: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; i ~ #&gt; x1 0.608 0.060 10.134 0.000 #&gt; x2 0.604 0.064 9.412 0.000 #&gt; s ~ #&gt; x1 0.262 0.029 9.198 0.000 #&gt; x2 0.522 0.031 17.083 0.000 #&gt; t1 ~ #&gt; c1 0.143 0.050 2.883 0.004 #&gt; t2 ~ #&gt; c2 0.289 0.046 6.295 0.000 #&gt; t3 ~ #&gt; c3 0.328 0.044 7.361 0.000 #&gt; t4 ~ #&gt; c4 0.330 0.058 5.655 0.000 #&gt; #&gt; Covariances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .i ~~ #&gt; .s 0.075 0.040 1.855 0.064 #&gt; #&gt; Intercepts: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .t1 0.000 #&gt; .t2 0.000 #&gt; .t3 0.000 #&gt; .t4 0.000 #&gt; .i 0.580 0.062 9.368 0.000 #&gt; .s 0.958 0.029 32.552 0.000 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .t1 0.580 0.080 7.230 0.000 #&gt; .t2 0.596 0.054 10.969 0.000 #&gt; .t3 0.481 0.055 8.745 0.000 #&gt; .t4 0.535 0.098 5.466 0.000 #&gt; .i 1.079 0.112 9.609 0.000 #&gt; .s 0.224 0.027 8.429 0.000 kable(coef(fit2), booktabs = TRUE, format = &quot;markdown&quot;) x i~x1 0.60838657 i~x2 0.60410683 s~x1 0.26223932 s~x2 0.52173009 t1~c1 0.14335610 t2~c2 0.28900400 t3~c3 0.32753750 t4~c4 0.33049483 t1~~t1 0.57982241 t2~~t2 0.59559342 t3~~t3 0.48141221 t4~~t4 0.53520654 i~~i 1.07945768 s~~s 0.22376291 i~~s 0.07475324 i~1 0.58023837 s~1 0.95757971 I risultati mostrano che le due covariate \\(x\\) influenzano sia l’intercetta sia la pendenza della curva di crescita. Inoltre, vi sono evidenze di un effetto della covariata c. "],["crescita-non-lineare.html", "21.2 Crescita non lineare", " 21.2 Crescita non lineare Ripetiamo la procedura di analisi descritta sopra introducendo però un cambiamento: verrà considerato un modello nel quale la crescita non è lineare. Nelle analisi seguenti useremo i seguenti indici di bontà di adattamento. selected_fit_stats &lt;- c( &quot;chisq.scaled&quot;, &quot;df.scaled&quot;, ## must be &gt;0 to test G.O.F. &quot;pvalue.scaled&quot;, ## ideally n.s. &quot;cfi.scaled&quot;, ## ideally ≥ 0.95 &quot;rmsea.scaled&quot;, ## ideally ≤ 0.05 &quot;rmsea.pvalue.scaled&quot;, ## ideally n.s. &quot;srmr&quot; ## ideally &lt; 0.08 ) Simulo i dati secondo questo modello. growth_mod &lt;- &quot; ## intercept &amp; slope growth terms for X iX =~ 1*x1 + 1*x2 + 1*x3 + 1*x4 sX =~ 0*x1 + 1*x2 + 2*x3 + 3*x4 ## intercept, slope, &amp; quadratic terms for Y iY =~ 1*y1 + 1*y2 + 1*y3 + 1*y4 sY =~ 0*y1 + 1*y2 + 2*y3 + 3*y4 qY =~ 0*y1 + 1*y2 + 4*y3 + 9*y4 ## set variances y4 ~~ 2*y4 x4 ~~ 1*x4 ## set latent means/intercepts iX ~ 2*1 sX ~ 1*1 sY ~ -1*1 qY ~ -1.5*1 sY ~ 2*predictor outcome ~ 2*iX + 3*sY &quot; A questo fine uso la funzione simulateData() di lavaan. La simulazione include due variabili misurate in quattro punti temporali. sim_growth_dat &lt;- simulateData( model = growth_mod, model.type = &quot;growth&quot;, seed = 82020, orthogonal = F, auto.cov.y = T, auto.var = T ) Le variabili sono chiamate x1, x2, x3, x4, per la misurazione di x ai tempi 1, 2, 3, 4. Lo stesso per la y. head(sim_growth_dat) #&gt; x1 x2 x3 x4 y1 y2 y3 #&gt; 1 1.033229 2.746064 4.9423623 8.41058044 3.36324415 -1.196550 -11.103494 #&gt; 2 3.192802 3.057675 0.7965786 0.84592869 -1.60039704 -5.970381 -10.399366 #&gt; 3 3.758457 4.712351 5.6308218 4.76577291 2.58001675 -3.272134 -11.312994 #&gt; 4 2.700514 4.921257 6.7116263 10.13354061 0.03886676 0.510869 -5.937016 #&gt; 5 1.259807 1.526301 1.6663799 -0.09959486 0.53939838 -4.274106 -12.968362 #&gt; 6 2.547125 5.426192 4.9463195 8.48790397 2.18069542 1.590009 -2.253218 #&gt; y4 outcome predictor #&gt; 1 -31.509255 2.161186 -0.4893276 #&gt; 2 -19.908088 5.089750 0.5199749 #&gt; 3 -26.681111 3.173129 -0.5938816 #&gt; 4 -7.836099 1.035215 -0.7813707 #&gt; 5 -22.595311 -4.352557 -0.7067630 #&gt; 6 -8.892786 3.277985 -1.2978592 Aggiungo qui il numero del partecipante. sim_growth_dat$participant_n &lt;- 1:nrow(sim_growth_dat) # add participant number Nei dati simulati, la variabile x cambia linearmente nel tempo e la variabile y cambia seguendo un andamento quadratico. Esaminiamo i dati graficamente. x_plot &lt;- pivot_longer(sim_growth_dat, cols = x1:x4, names_to = &quot;x&quot;, names_prefix = &quot;x&quot; ) individual_x_trajectories &lt;- ggplot( x_plot, aes( x = as.numeric(x), y = value, group = participant_n, color = participant_n ) ) + geom_line(alpha = 0.2) + labs( title = &quot;Observed Trajectories of x&quot;, x = &quot;Timepoint&quot;, y = &quot;x&quot; ) + xlim(1, 4) + theme(legend.position = &quot;none&quot;) individual_x_trajectories Su può vedere che la variabile x segue una crescita lineare, ma un modello quadratico molto “debole” potrebbe adattarsi meglio ai dati, quindi sarà necessario controllare se in effetti questo è vero. Se entrambi i modelli si adattano bene, li confronteremo con il test del rapporto di verosimiglianza (LRT). Faccio lo stesso per la variabile y. y_plot &lt;- pivot_longer(sim_growth_dat, cols = y1:y4, names_to = &quot;y&quot;, names_prefix = &quot;y&quot; ) individual_y_trajectories &lt;- ggplot( y_plot, aes( x = as.numeric(y), y = value, group = participant_n, color = participant_n ) ) + geom_line(alpha = 0.2) + labs( title = &quot;Observed trajectories of y&quot;, x = &quot;Timepoint&quot;, y = &quot;y&quot; ) + xlim(1, 4) + theme(legend.position = &quot;none&quot;) individual_y_trajectories È chiaro che la y diminuisce in media con il tempo, ma c’è eterogeneità (o variabilità) in ciò che accade nei singoli caso. Anche in questo caso, sia un modello lineare sia un modello quadratico sembrano appropriati per descrivere il cambiamento nei dati. 21.2.1 Stimatore Tutti i dati utilizzati sono continui, quindi useremo la stima della massima verosimiglianza (stimatore = ML). Tuttavia è preferibile usare la variante “robusta” (stimatore = MLR) quando possibile per tenere conto dei possibili non normalità nei dati. 21.2.2 Assenza di crescita Iniziamo con un modello per la x che assume che non vi sia variazione in funzione del tempo. int_x_mod &lt;- &quot; iX =~ 1*x1 + 1*x2 + 1*x3 + 1*x4 &quot; Eseguiamo il fit e esaminiamo i risultati. int_x_fit &lt;- growth( model = int_x_mod, estimator = &quot;MLR&quot;, data = sim_growth_dat ) int_x_fit_stats &lt;- fitmeasures( int_x_fit, selected_fit_stats ) %&gt;% data.frame() round(int_x_fit_stats, 2) #&gt; . #&gt; chisq.scaled 1192.66 #&gt; df.scaled 8.00 #&gt; pvalue.scaled 0.00 #&gt; cfi.scaled 0.02 #&gt; rmsea.scaled 0.54 #&gt; rmsea.pvalue.scaled 0.00 #&gt; srmr 0.63 È chiaro che il modello di assenza di crescita non spiega i dati x. Consideriamo y. int_y_mod &lt;- &quot; iY =~ 1*y1 + 1*y2 + 1*y3 + 1*y4 &quot; int_y_fit &lt;- growth( model = int_y_mod, estimator = &quot;MLR&quot;, data = sim_growth_dat ) int_y_fit_stats &lt;- fitmeasures( int_y_fit, selected_fit_stats ) %&gt;% data.frame() round(int_y_fit_stats, 2) #&gt; . #&gt; chisq.scaled 3136.54 #&gt; df.scaled 8.00 #&gt; pvalue.scaled 0.00 #&gt; cfi.scaled 0.00 #&gt; rmsea.scaled 0.88 #&gt; rmsea.pvalue.scaled 0.00 #&gt; srmr 0.98 Il modello di assenza di crescita non è adeguato neppure per la variabile y. 21.2.3 Crescita lineare Esaminiamo un modello di crescita lineare per la x. linear_x_mod &lt;- &quot; iX =~ 1*x1 + 1*x2 + 1*x3 + 1*x4 sX =~ 0*x1 + 1*x2 + 2*x3 + 3*x4 &quot; linear_x_fit &lt;- growth( model = linear_x_mod, estimator = &quot;MLR&quot;, data = sim_growth_dat ) linear_x_fit_stats &lt;- fitmeasures( linear_x_fit, selected_fit_stats ) %&gt;% data.frame() round(linear_x_fit_stats, 2) #&gt; . #&gt; chisq.scaled 4.03 #&gt; df.scaled 5.00 #&gt; pvalue.scaled 0.54 #&gt; cfi.scaled 1.00 #&gt; rmsea.scaled 0.00 #&gt; rmsea.pvalue.scaled 0.92 #&gt; srmr 0.02 Il modello di crescita lineare per la x si adatta bene rispetto a tutti gli indici. Questo è ciò che ci aspettavamo in base al grafico dei dati osservati. Esaminiamo un modello di crescita lineare per la y. linear_y_mod &lt;- &quot; iY =~ 1*y1 + 1*y2 + 1*y3 + 1*y4 sY =~ 0*y1 + 1*y2 + 2*y3 + 3*y4 &quot; linear_y_fit &lt;- growth( model = linear_y_mod, estimator = &quot;MLR&quot;, data = sim_growth_dat ) linear_y_fit_stats &lt;- fitmeasures( linear_y_fit, selected_fit_stats ) %&gt;% data.frame() round(linear_y_fit_stats, 2) #&gt; . #&gt; chisq.scaled 842.85 #&gt; df.scaled 5.00 #&gt; pvalue.scaled 0.00 #&gt; cfi.scaled 0.61 #&gt; rmsea.scaled 0.58 #&gt; rmsea.pvalue.scaled 0.00 #&gt; srmr 0.55 Il modello lineare è inadeguato per la y rispetto a tutti gli indici considerati. 21.2.4 Crescita quadratica I termini quadratici rappresentano il tasso medio di variazione della pendenza nelle diverse rilevazioni temporali. Per descrivere una tale caratteristica si parla di “crescita quadratica” nei modelli SEM. Consideriamo un modello di crescita quadratica per la x. quad_x_mod &lt;- &quot; iX =~ 1*x1 + 1*x2 + 1*x3 + 1*x4 sX =~ 0*x1 + 1*x2 + 2*x3 + 3*x4 qX =~ 0*x1 + 1*x2 + 4*x3 + 9*x4 &quot; quad_x_fit &lt;- growth( model = quad_x_mod, estimator = &quot;MLR&quot;, data = sim_growth_dat ) quad_x_fit_stats &lt;- fitmeasures( quad_x_fit, selected_fit_stats ) round(quad_x_fit_stats, 2) #&gt; chisq.scaled df.scaled pvalue.scaled cfi.scaled #&gt; 0.02 1.00 0.89 1.00 #&gt; rmsea.scaled rmsea.pvalue.scaled srmr #&gt; 0.00 0.94 0.00 Qui abbiamo un problema interessante, poiché la x si adatta abbastanza bene sia a un modello lineare che a uno quadratico, ma abbiamo un caso di Heywood, in particolare la varianza della variabile osservata stimata è negativa. lavInspect(quad_x_fit, &quot;est&quot;)$theta #&gt; x1 x2 x3 x4 #&gt; x1 1.171 #&gt; x2 0.000 0.718 #&gt; x3 0.000 0.000 1.213 #&gt; x4 0.000 0.000 0.000 -0.064 Si ottiene una stima negativa per la varianza della variabile osservata x4. Questo è un problema e indica che il modello potrebbe non rappresentare bene i dati. È possibile introdurre dei vincoli nei parametri per vedere se l’adattamento rimane buono se “forziamo” una modifica a questo parametro, ma questo va oltre gli scopi presenti. Per i fini di questo tutorial ignoreremo questo caso di Heywood e proseguiremo nell’analisi. Quando si hanno due modelli nidificati adatti (nel nostro caso, modelli lineari e quadratici), possiamo confrontare formalmente l’adattamento con i test del rapporto di verosimiglianza (LRT). L’ipotesi nulla è che non vi sia alcuna differenza nella varianza spiegata dai due modelli. La parsimonia è preferita in una situazione in cui la varianza spiegata è equivalente. lavTestLRT(linear_x_fit, quad_x_fit) #&gt; Scaled Chi-Squared Difference Test (method = &quot;satorra.bentler.2001&quot;) #&gt; #&gt; lavaan NOTE: #&gt; The &quot;Chisq&quot; column contains standard test statistics, not the #&gt; robust test that should be reported per model. A robust difference #&gt; test is a function of two standard (not robust) statistics. #&gt; #&gt; Df AIC BIC Chisq Chisq diff Df diff Pr(&gt;Chisq) #&gt; quad_x_fit 1 7570.4 7625.2 0.0200 #&gt; linear_x_fit 5 7566.4 7604.3 4.0675 4.0026 4 0.4056 Qui, un p-value \\(&gt; 0.05\\) ci dice che il modello lineare è da preferire. Esaminiamo la y. quad_y_mod &lt;- &quot; iY =~ 1*y1 + 1*y2 + 1*y3 + 1*y4 sY =~ 0*y1 + 1*y2 + 2*y3 + 3*y4 qY =~ 0*y1 + 1*y2 + 4*y3 + 9*y4 &quot; quad_y_fit &lt;- growth( model = quad_y_mod, estimator = &quot;MLR&quot;, data = sim_growth_dat ) quad_y_fit_stats &lt;- fitmeasures( quad_y_fit, selected_fit_stats ) quad_y_fit_stats #&gt; chisq.scaled df.scaled pvalue.scaled cfi.scaled #&gt; 0.190 1.000 0.663 1.000 #&gt; rmsea.scaled rmsea.pvalue.scaled srmr #&gt; 0.000 0.813 0.001 Qui il modello quadratico si adatta molto bene ai dati ed è sicuramente da preferire al modello lineare per la y. lavTestLRT(linear_y_fit, quad_y_fit) #&gt; Scaled Chi-Squared Difference Test (method = &quot;satorra.bentler.2001&quot;) #&gt; #&gt; lavaan NOTE: #&gt; The &quot;Chisq&quot; column contains standard test statistics, not the #&gt; robust test that should be reported per model. A robust difference #&gt; test is a function of two standard (not robust) statistics. #&gt; #&gt; Df AIC BIC Chisq Chisq diff Df diff Pr(&gt;Chisq) #&gt; quad_y_fit 1 9301.7 9356.5 0.1901 #&gt; linear_y_fit 5 10194.9 10232.9 901.4270 829.59 4 &lt; 2.2e-16 *** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 "],["parallel-process-model.html", "21.3 Parallel Process Model", " 21.3 Parallel Process Model Esaminiamo ora un modello che include sia i termini lineari che quadratici (quando richiesti) delle variabili x e y. full_model &lt;- &quot; ## intercept &amp; slope growth terms for X iX =~ 1*x1 + 1*x2 + 1*x3 + 1*x4 sX =~ 0*x1 + 1*x2 + 2*x3 + 3*x4 ## intercept, slope, &amp; quadratic terms for Y iY =~ 1*y1 + 1*y2 + 1*y3 + 1*y4 sY =~ 0*y1 + 1*y2 + 2*y3 + 3*y4 qY =~ 0*y1 + 1*y2 + 4*y3 + 9*y4 ## regress growth terms on predictor qY + iY + sX + iX ~ predictor sY ~ a1*predictor ## regress outcome on growth terms outcome ~ iX + sX + iY + b1*sY + qY ## testing indirect effect ## predictor --&gt; sY --&gt; outcome predictor_sY_outcome := a1*b1 &quot; Adattiamo il modello ai dati. full_fit &lt;- growth( model = full_model, estimator = &quot;MLR&quot;, data = sim_growth_dat ) Esaminiamo il path diagram. semPaths( full_fit, layout = &quot;tree&quot;, intercepts = FALSE, posCol = c(&quot;black&quot;), edge.label.cex = 0.00001, sizeMan = 7, what = &quot;path&quot;, optimizeLatRes = TRUE, residuals = TRUE, style = &quot;lisrel&quot; ) Valutiamo l’adattamento. full_fit_stats &lt;- fitmeasures( full_fit, selected_fit_stats ) round(full_fit_stats, 2) #&gt; chisq.scaled df.scaled pvalue.scaled cfi.scaled #&gt; 28.23 34.00 0.75 1.00 #&gt; rmsea.scaled rmsea.pvalue.scaled srmr #&gt; 0.00 1.00 0.03 Possiamo vedere che questo modello si adatta bene a tutte le statistiche di adattamento scelte. Questo modello viene ritenuto accettabile e ora possiamo passare all’interpretazione dei risultati del modello. summary(full_fit) #&gt; lavaan 0.6-11 ended normally after 65 iterations #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of model parameters 29 #&gt; #&gt; Number of observations 500 #&gt; #&gt; Model Test User Model: #&gt; Standard Robust #&gt; Test Statistic 28.456 28.233 #&gt; Degrees of freedom 34 34 #&gt; P-value (Chi-square) 0.736 0.746 #&gt; Scaling correction factor 1.008 #&gt; Yuan-Bentler correction (Mplus variant) #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Sandwich #&gt; Information bread Observed #&gt; Observed information based on Hessian #&gt; #&gt; Latent Variables: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; iX =~ #&gt; x1 1.000 #&gt; x2 1.000 #&gt; x3 1.000 #&gt; x4 1.000 #&gt; sX =~ #&gt; x1 0.000 #&gt; x2 1.000 #&gt; x3 2.000 #&gt; x4 3.000 #&gt; iY =~ #&gt; y1 1.000 #&gt; y2 1.000 #&gt; y3 1.000 #&gt; y4 1.000 #&gt; sY =~ #&gt; y1 0.000 #&gt; y2 1.000 #&gt; y3 2.000 #&gt; y4 3.000 #&gt; qY =~ #&gt; y1 0.000 #&gt; y2 1.000 #&gt; y3 4.000 #&gt; y4 9.000 #&gt; #&gt; Regressions: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; qY ~ #&gt; predictor 0.041 0.048 0.850 0.395 #&gt; iY ~ #&gt; predictor 0.034 0.060 0.564 0.573 #&gt; sX ~ #&gt; predictor 0.008 0.051 0.161 0.872 #&gt; iX ~ #&gt; predictor 0.067 0.060 1.119 0.263 #&gt; sY ~ #&gt; predictor (a1) 2.022 0.079 25.545 0.000 #&gt; outcome ~ #&gt; iX 1.994 0.145 13.755 0.000 #&gt; sX -0.017 0.146 -0.115 0.908 #&gt; iY -0.028 0.186 -0.149 0.881 #&gt; sY (b1) 2.973 0.104 28.596 0.000 #&gt; qY -0.242 0.161 -1.510 0.131 #&gt; #&gt; Intercepts: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 0.000 #&gt; .x2 0.000 #&gt; .x3 0.000 #&gt; .x4 0.000 #&gt; .y1 0.000 #&gt; .y2 0.000 #&gt; .y3 0.000 #&gt; .y4 0.000 #&gt; .outcome 0.000 #&gt; .iX 1.976 0.059 33.700 0.000 #&gt; .sX 0.991 0.051 19.350 0.000 #&gt; .iY 0.031 0.061 0.508 0.611 #&gt; .sY -1.153 0.082 -14.019 0.000 #&gt; .qY -1.548 0.048 -32.151 0.000 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 1.067 0.099 10.777 0.000 #&gt; .x2 0.885 0.069 12.924 0.000 #&gt; .x3 0.983 0.104 9.492 0.000 #&gt; .x4 1.113 0.197 5.646 0.000 #&gt; .y1 0.961 0.107 8.991 0.000 #&gt; .y2 0.868 0.083 10.470 0.000 #&gt; .y3 0.996 0.179 5.557 0.000 #&gt; .y4 2.467 0.949 2.601 0.009 #&gt; .outcome 0.814 0.927 0.878 0.380 #&gt; .iX 1.043 0.100 10.444 0.000 #&gt; .sX 1.094 0.076 14.393 0.000 #&gt; .iY 1.040 0.108 9.595 0.000 #&gt; .sY 1.131 0.125 9.078 0.000 #&gt; .qY 0.927 0.068 13.684 0.000 #&gt; #&gt; Defined Parameters: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; predctr_sY_tcm 6.011 0.159 37.874 0.000 Il risultato importante è che iX e sY prevedono in modo significativo la variabile di esito, e quest’ultima ha un’importanza molto maggiore rispetto alla prima. Ciò significa che i livelli di base di x predicono il risultato, così come il tasso lineare di cambiamento della y, entrambi in modo positivo in modo tale che livelli più elevati di x iniziale o tassi di cambiamento più rapidi in y portino a livelli più elevati della variabile di esito. L’esempio include una covariata predictor invariante nel tempo. Poiché predictor ha previsto in modo significativo sY e sY ha previsto la variabile di esito, possiamo esaminare con più attenzione l’effetto di mediazione. È possibile riportare semplicemente la stima fornita dal prodotto calcolato in precedenza, ma è meglio fare affidamento su altri metodi per testare gli effetti indiretti. Una tecnica molto usata a questo fine è il bootstrapping. Il bootstrapping è un metodo di ricampionamento (con sostituzione) apprezzato per la costruzione di intervalli di confidenza attorno alle stime dei parametri degli effetti indiretti, perché non richiede ipotesi distributive sull’effetto indiretto. Questo crea un test più affidabile rispetto ai test di significatività standard. La usiamo qui per testare gli effetti indiretti utilizzando 5000 simulazioni – per velocizzare, nell’esempio vengono richieste solo 100 simulazioni. final_fit_boot &lt;- growth(full_fit, data = sim_growth_dat, estimator = &quot;ML&quot;, meanstructure = T, se = &quot;bootstrap&quot;, bootstrap = 100, # ~5000 better parallel = &quot;multicore&quot; ) parameterEstimates( final_fit_boot, level = .95, boot.ci.type = &quot;bca.simple&quot;, stand = TRUE )[61, c(4, 5, 9, 10)] #&gt; label est ci.lower ci.upper #&gt; 61 predictor_sY_outcome 6.011 5.707 6.355 In questo tutorial, dunque, abbiamo visto come valutare se un predittore influenza la crescita in un costrutto. In seguito abbiamo verificato se c’è un effetto indiretto e abbiamo quantificato l’entità di tale effetto indiretto. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
