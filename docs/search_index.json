[["curve-di-crescita-latente.html", "Capitolo 29 Curve di crescita latente", " Capitolo 29 Curve di crescita latente Un importante classe di modelli a variabili latenti è quella dei modelli delle curve di crescita latente (latent growth models, LGM). I modelli delle curve di crescita latente vengono spesso utilizzati per analizzare dati longitudinali. In questo tipo di dati, una misura di esito viene ottenuta in diversi momenti del tempo e si vuole studiare il cambiamento nel tempo. In molti casi, la traiettoria nel tempo può essere modellata come una semplice funzione lineare o quadratica. Le differenze individuali vengono catturate dagli effetti random che sono convenientemente rappresentati da variabili latenti (continue), spesso chiamate fattori di crescita (growth factors). Supponiamo che la variabile misurata rappresenti una qualche dimensione psicologica \\(y\\). Ci possiamo chiedere domande come le seguenti: la \\(y\\) tende ad aumentare nei termini di una relazione lineare? se la \\(y\\) tende ad aumentare nei termini di una relazione lineare, qual è in media la pendenza di questa retta? in che misura questa pendenza varia tra i partecipanti? in che misura questa pendenza dipende dall’effetto di qualche altra variabile \\(x\\)? in che misura questa pendenza differisce tra gruppi di partecipanti? in che misura la \\(y\\) durante nella prima rilevazione temporale varia tra i partecipanti? in che misura la \\(y\\) nella prima rilevazione temporale dipende dall’effetto di qualche altra variabile \\(x\\)? Queste sono alcune delle domande a cui si può rispondere usando i modelli LGM. In questo capitolo verranno introdotti i modelli misti e verrà fatto un confronto tra modelli misti e modelli LGM. "],["modelli-a-crescita-latente-e-modelli-misti.html", "29.1 Modelli a crescita latente e modelli misti", " 29.1 Modelli a crescita latente e modelli misti I modelli di crescita latente (LGM) sono un caso speciale di analisi fattoriale confermativa (CFA) e corrispondono a un modello CFA a due fattori in cui le saturazioni fattoriali sono fissate a valori predefiniti. Nella loro forma più semplice, i modelli LGM sono equivalenti ai modelli a effetti misti nell’analisi di regressione. Pertanto, descrivere i modelli misti ci aiuterà a comprendere meglio i modelli LGM. 29.1.1 Modelli misti Il modello lineare standard presuppone l’indipendenza delle osservazioni. Tuttavia, i modelli misti considerano la presenza di cluster di osservazioni, come ad esempio misure ripetute per lo stesso individuo nel tempo. Per gestire la correlazione tra le osservazioni raggruppate, si possono utilizzare i modelli a effetti misti. Questi modelli sono impiegati quando si hanno dati raccolti da più cluster, ognuno con caratteristiche uniche ma anche condivise. Un esempio comune di modello misto è quello utilizzato per analizzare dati longitudinali. In questo caso, il modello può includere un effetto fisso per il tempo e un effetto casuale per ogni unità. I modelli misti rappresentano un compromesso tra la modellizzazione pooled e quella separata. La modellizzazione pooled combina tutti i dati in un unico dataset, ma può portare a una perdita di informazioni sulle differenze tra i gruppi di osservazioni. La modellizzazione separata adatta un modello per ogni gruppo di osservazioni, ma può portare a problemi di sovrapparametrizzazione e scarsa generalizzazione ai nuovi dati. I modelli misti risolvono questi problemi combinando la modellizzazione pooled e quella separata. In questo modo, il modello tiene conto delle differenze tra i gruppi di dati e sfrutta l’informazione comune per migliorare la precisione delle stime dei parametri. Il caso seguente descrive un modello misto una struttura di raggruppamento annidata. I cluster che producono gli effetti casuali non devono necessariamente essere gerarchici, tuttavia utilizziamo qui una tale rappresentazione per semplicità. \\[ \\begin{equation} y_{k} = \\alpha + \\beta \\cdot x_{k} + \\varepsilon_{k}, \\quad k = 1, \\dots, K, \\tag{29.1} \\end{equation} \\] dove gli \\(\\{\\varepsilon_k\\}\\) sono variabili casuali indipendenti e identicamente distribuite con varianza costante \\(\\sigma^2\\). Nel caso delle misure ripetute viene violata l’assunzione che i dati siano variabili casuali indipendenti. Un modo per modellizzare una variabile casuale organizzata in maniera gerarchica è quello di assumere che ciascun ragruppamento sia dotato di una sua specifica intercetta. \\[ \\begin{equation} y_{ij} = \\alpha_i + \\beta \\cdot x_{ij} + \\varepsilon_{ij}, \\quad i = 1, \\dots, N, j = 1, \\dots, n_i. \\tag{29.2} \\end{equation} \\] Si noti che abbiamo usato due indici: \\(i\\) corrisponde all’\\(i\\)-esimo ragruppamento, \\(j\\) corrisponde alla osservazione \\(j\\)-esima nell’\\(i\\)-esimo ragruppamento, \\(n_i\\) è il numero di osservazioni nell’\\(i\\)-esimo ragruppamento e \\(\\alpha_i\\) è l’intercetta specifica al ragruppamento \\(i\\)-esimo. Il numero totale di osservazioni è \\(K = \\sum_{i=1}^N n_i\\). Per quel che riguarda gli errori \\(\\{\\varepsilon_{ij}\\}\\) assumiamo come in precedenza che siano iid con varianza \\(\\sigma^2\\). Il modello per dati ragruppati è più complesso del modello tradizionale e si riduce ad esso nel caso speciale nel quale \\(\\alpha_i = \\alpha\\). L’assunzione centrale dei modelli misti è che le intercette \\(\\{\\alpha_i, i = 1, \\dots, N\\}\\) siano variabili casuali che appartengono ad una popolazione che può essere descritta dalla seguente equazione: \\[ \\begin{equation} \\alpha_i = \\alpha + b_i, \\tag{29.3} \\end{equation} \\] dove \\(\\alpha\\) è l’intercetta della popolazione e \\(b_i\\) è l’effetto casuale, ovvero la deviazione di ciascun ragruppamento dal valore medio della popolazione. Sostituendo l’eq. (29.3) nella (29.2) otteniamo il modello ad effetti misti: \\[ \\begin{equation} y_{ij} = \\alpha + b_i + \\beta \\cdot x_{ij} + \\varepsilon_{ij}, \\quad i = 1, \\dots, N, j = 1, \\dots, n_i, \\tag{29.4} \\end{equation} \\] ovvero \\[ \\begin{equation} y_{ij} = \\alpha + \\beta \\cdot x_{ij} + \\eta_{ij}, \\quad i = 1, \\dots, N, j = 1, \\dots, n_i, \\tag{29.5} \\end{equation} \\] dove \\(\\eta_{ij} = \\varepsilon_{ij} + b_i\\). Questo è un modello gerarchico, ovvero un modello ad intercetta casuale. In pratica, ciò che abbiamo ottenuto è un modello di regressione standard con una fonte aggiuntiva di varianza. In un modello misto ci sono dunque due fonti della varianza: la variazione all’interno di ciascun ragruppamento, \\(\\sigma^2\\) e la variazione tra ragruppamenti, \\(\\sigma_b^2\\). Ricordiamo che, invece, nel modello classico abbiamo un’unica fonte della varianza. Nel modello misto, le osservazioni all’interno di ciascun ragruppamento sono tra loro correlate con una correlazione uguale a \\[ \\begin{equation} \\rho = \\frac{\\mathbb{V}(b_i)}{\\mathbb{V}(b_i + \\varepsilon_{ij})} = \\frac{\\sigma_b^2}{\\sigma^2 + \\sigma_b^2}. \\tag{29.6} \\end{equation} \\] Dalla (29.6) risulta che maggiore è la variazione tra i ragruppamenti, maggiore è la correlazione tra le osservazioni all’interno di ciascun ragruppamento. Se \\(\\sigma_b^2 = 0\\), la correlazione è 0, \\(\\alpha_i = \\alpha\\) e il modello si riduce a quello della regressione classica. Questa è solo una rappresentazione possibile dei modelli misti, in quanto è anche possibile consentire alla pendenza di variare, avere effetti casuali da più fonti di raggruppamento, aggiungere covariate a livello di ragruppamento, consentire alle intercette casuali e alle pendenze di correlare tra loro, ecc. Come abbiamo visto in precedenza, le variabili latenti sono assunte come distribuite normalmente, di solito con media zero e con una varianza stimata. Anche gli effetti casuali nei modelli misti lo sono e attraverso questo parallelo possiamo pensare agli effetti casuali come a delle variabili latenti (e viceversa). 29.1.2 Simulare effetti casuali Possiamo fornire una dimostrazione del funzionamento dei modelli misti con una simulazione. Ciò ci permetterà di meglio comprendere i modelli a crescita latente. Simuleremo dei dati bilanciati, con punteggi su quattro rilevazioni temporali per 500 individui (soggetti). Esamineremo il tasso di crescita (‘growth’) e consentiremo la presenza di intercette e pendenze specifiche per i diversi soggetti. Le istruzioni seguenti generano i dati (per i nostri scopi, non è importante capire i dettagli di questa porzione di codice). set.seed(12345) n &lt;- 500 timepoints &lt;- 4 time &lt;- rep(0:3, times = n) subject &lt;- rep(1:n, each = 4) intercept &lt;- .5 slope &lt;- .25 randomEffectsCorr &lt;- matrix(c(1, .2, .2, 1), ncol = 2) randomEffects &lt;- MASS::mvrnorm( n, mu = c(0, 0), Sigma = randomEffectsCorr, empirical = T ) %&gt;% data.frame() colnames(randomEffects) &lt;- c(&quot;Int&quot;, &quot;Slope&quot;) La simulazione comprende gli effetti ‘fissi’, ovvero l’intercetta e la pendenza della regressione standard, impostati rispettivamente a 0.5 e 0.25. Verrà simulata una correlazione di 0.2 tra intercetta e pendenza specifiche per ciascun soggetto. Per questa ragione, i dati verranno estratti da una distribuzione normale multivariata. Porremo uguale a 1 la varianza per entrambi gli effetti. Esaminiamo i dati ottenuti. Subject time Int Slope 1 0 -1.3323 -0.9548 1 1 -1.3323 -0.9548 1 2 -1.3323 -0.9548 1 3 -1.3323 -0.9548 2 0 -2.1262 -1.7814 2 1 -2.1262 -1.7814 2 2 -2.1262 -1.7814 2 3 -2.1262 -1.7814 3 0 0.4606 0.3040 3 1 0.4606 0.3040 Per ottenere una variabile target, sommiamo semplicemente gli effetti casuali così ottenuti all’intercetta complessiva e facciamo lo stesso per le pendenze. Sommeremo ai dati un rumore gaussiano con deviazione standard uguale a \\(\\sigma\\) = 0.5. set.seed(12345) sigma &lt;- .5 y1 &lt;- (intercept + randomEffects$Int[subject]) + # random intercepts (slope + randomEffects$Slope[subject]) * time + # random slopes rnorm(n * timepoints, mean = 0, sd = sigma) d &lt;- data.frame(subject, time, y1) subject time y1 1 0 -0.5395 1 1 -1.1824 1 2 -2.2966 1 3 -3.1735 2 0 -1.3232 2 1 -4.0665 2 2 -4.3738 2 3 -6.3583 3 0 0.8185 3 1 1.0549 Il grafico seguente mostra le rette di regressione per ciascuno dei 500 soggetti. Adattiamo ai dati un modello misto utilizzando la funzione lmer del pacchetto lme4. mix_mod &lt;- lmer(y1 ~ time + (1 + time | subject), data = d) summary(mix_mod) #&gt; Linear mixed model fit by REML [&#39;lmerMod&#39;] #&gt; Formula: y1 ~ time + (1 + time | subject) #&gt; Data: d #&gt; #&gt; REML criterion at convergence: 5881.3 #&gt; #&gt; Scaled residuals: #&gt; Min 1Q Median 3Q Max #&gt; -3.03499 -0.46249 0.00414 0.48241 2.74992 #&gt; #&gt; Random effects: #&gt; Groups Name Variance Std.Dev. Corr #&gt; subject (Intercept) 1.0245 1.0122 #&gt; time 1.0301 1.0149 0.15 #&gt; Residual 0.2412 0.4911 #&gt; Number of obs: 2000, groups: subject, 500 #&gt; #&gt; Fixed effects: #&gt; Estimate Std. Error t value #&gt; (Intercept) 0.50159 0.04885 10.267 #&gt; time 0.25157 0.04644 5.417 #&gt; #&gt; Correlation of Fixed Effects: #&gt; (Intr) #&gt; time 0.072 Gli effetti fissi che abbiamo ottenuto (\\(\\alpha\\) = 0.50159, \\(\\beta\\) = 0.25157) sono simili ai valori che abbiamo impostato per l’intercetta e la pendenza complessiva. Le varianze degli effetti casuali stimati (\\(1.0122^2\\), \\(1.0149^2\\)) sono molto simili al valore impostato di 1, la correlazione (0.15) è simile al valore impostato di 0.2 e la deviazione standard dei residui (0.4911) è simile al valore impostato di 0.5. "],["modello-di-crescita-latente.html", "29.2 Modello di crescita latente", " 29.2 Modello di crescita latente Analizziamo ora gli stessi dati con un modello LGM. Possiamo pensare ai modelli LGM come ad un’estensione del modello CFA dotato di meanstructure. Infatti, dobbiamo modellare la relazione tra le medie dei punteggi dei partecipanti in funzione del tempo. L’inclusione della meanstructure significa che non possiamo usare in input la matrice di covarianza campionaria, ma dobbiamo invece utilizzare i dati grezzi (ovvero, le singole osservazioni per ciascun partecipante). Come in precedenza, useremo lavaan, ma ora con una sintassi diversa, perché dobbiamo fissare le saturazioni fattoriali a valori specifici per implementare i vincoli del modello. Questo porta anche a un output non standard rispetto ad altri modelli SEM, poiché i parametri del modello saranno fissi non devono essere stimati. In particolare, avremo una variabile latente per le intercette casuali e una seconda variabile latente le pendenze casuali. Per il fattore che rappresenta le intercette, i valori delle saturazioni fattoriali sono fissati a 1. Le saturazioni per il fattore che specifica le pendenze casuali sono fissate ai valori che descrivono la variazione temporale: qui i valori \\(\\lambda\\) da 0 a 3 (riflettono la spaziatura temporale tra le misurazioni \\(y\\)). Iniziare la codifica da 0 consente di assegnare allo 0 un’interpretazione dotata di significato. Il modello di crescita latente può dunque essere specificato dal seguente modello a variabili latenti: \\[ y_j = \\alpha_0 + \\alpha_1 \\lambda_j + \\zeta_{00} + \\zeta_{11} \\lambda_j + \\epsilon_j, \\] dove \\(y_j\\) è la variabile di interesse che cambia nel tempo, con \\(j = 0, \\dots, 3\\). \\(\\alpha_0\\) rappresenta l’intercetta della retta di regressione al tempo \\(t = 0\\) (il punto di partenza della linea nera sopra). \\(\\alpha_1 \\lambda_j\\) è il tasso medio di crescita nel tempo (la pendenza della linea nera nel grafico sopra). Qui \\(\\lambda_j\\) è solo l’indice dei punti temporali considerati (0, 1, 2, 3). \\(\\zeta_{00}\\) è la varianza tra i soggetti nel punto \\(t = 0\\). \\(\\zeta_{11} \\lambda_j\\) è la varianza del tasso di crescita tra i soggetti. \\(\\epsilon_j\\) è la varianza di ciascun soggetto attorno alla sua retta di regressione. Tali relazioni statistiche vengono rappresentate dal modello di equazioni strutturali della figura 29.1. FIGURA 29.1: Modello di crescita latente. Un requisito degli LGM è che i dati devono essere forniti del formato wide (mentre per il precedente modello misto abbiamo usato il formato long), il che significa che ogni colonna rappresenta la variabile di esito in un diverso momento nel tempo. Si presume che ogni osservazione o riga sia indipendente dalle altre; le colonne mostrano invece una dipendenza temporale. Trasformiamo dunque i dati nel formato richiesto. dWide &lt;- d %&gt;% spread(time, y1) %&gt;% rename_at(vars(-subject), function(x) paste0(&quot;y&quot;, x)) head(dWide) #&gt; subject y0 y1 y2 y3 #&gt; 1 1 -0.5395258 -1.1823659 -2.2965593 -3.173465 #&gt; 2 2 -1.3232110 -4.0664952 -4.3738304 -6.358334 #&gt; 3 3 0.8185443 1.0549470 2.0104678 3.531232 #&gt; 4 4 0.4469440 -0.3162615 -1.7896354 -1.843919 #&gt; 5 5 1.8959902 5.5259110 9.6045869 12.546123 #&gt; 6 6 2.1829579 1.6287374 -0.3136214 -1.660328 Il modello misto che abbiamo descritto in precedenza corrisponde dunque ad un modello fattoriale con due variabili latenti: un fattore (\\(\\eta_0\\)) che rappresenta il “punteggio vero” delle intercette individuali e un fattore (\\(\\eta_1\\)) che rappresenta il “punteggio vero” delle pendenze delle rette di regressione per i singoli individui. Nella sintassi di lavaan il modello diventa: model &lt;- &quot; i =~ 1*y0 + 1*y1 + 1*y2 + 1*y3 s =~ 0*y0 + 1*y1 + 2*y2 + 3*y3 &quot; Possiamo adattare il modello ai dati usando una funzione specifica di lavaan, ovvero growth, che può essere usata per questa classe di modelli. growth_curve_model &lt;- growth(model, data = dWide) summary(growth_curve_model) #&gt; lavaan 0.6.15 ended normally after 41 iterations #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of model parameters 9 #&gt; #&gt; Number of observations 500 #&gt; #&gt; Model Test User Model: #&gt; #&gt; Test statistic 4.212 #&gt; Degrees of freedom 5 #&gt; P-value (Chi-square) 0.519 #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Standard #&gt; Information Expected #&gt; Information saturated (h1) model Structured #&gt; #&gt; Latent Variables: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; i =~ #&gt; y0 1.000 #&gt; y1 1.000 #&gt; y2 1.000 #&gt; y3 1.000 #&gt; s =~ #&gt; y0 0.000 #&gt; y1 1.000 #&gt; y2 2.000 #&gt; y3 3.000 #&gt; #&gt; Covariances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; i ~~ #&gt; s 0.162 0.051 3.137 0.002 #&gt; #&gt; Intercepts: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .y0 0.000 #&gt; .y1 0.000 #&gt; .y2 0.000 #&gt; .y3 0.000 #&gt; i 0.501 0.049 10.263 0.000 #&gt; s 0.252 0.046 5.428 0.000 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .y0 0.268 0.042 6.356 0.000 #&gt; .y1 0.237 0.022 10.713 0.000 #&gt; .y2 0.209 0.029 7.262 0.000 #&gt; .y3 0.299 0.066 4.556 0.000 #&gt; i 1.007 0.078 12.996 0.000 #&gt; s 1.021 0.068 14.953 0.000 Nell’output, Intercepts corrisponde agli effetti fissi: Intercepts: Estimate Std.Err z-value P(&gt;|z|) i 0.510 0.048 10.542 0.000 s 0.234 0.046 5.133 0.000 Potrebbe sembrare strano chiamare gli effetti fissi ‘intercette’, ma ha senso se pensiamo al modello a crescita latente come al modello misto descritto in precedenza. Si noti che le stime ottenute sono molto simili a quelle fornite dal modello misto fixef(mix_mod) #&gt; (Intercept) time #&gt; 0.5015932 0.2515722 Si noti inoltre che le stime degli effetti fissi del modello misto sono identiche a quelle trovate dalla regressione standard: lm(y1 ~ time, data = d) #&gt; #&gt; Call: #&gt; lm(formula = y1 ~ time, data = d) #&gt; #&gt; Coefficients: #&gt; (Intercept) time #&gt; 0.5016 0.2516 Consideriamo ora le stime della varianza nel modello a crescita latente. Covariances: Estimate Std.Err z-value P(&gt;|z|) i ~~ s 0.220 0.050 4.371 0.000 Variances: Estimate Std.Err z-value P(&gt;|z|) .y0 0.310 0.042 7.308 0.000 .y1 0.220 0.021 10.338 0.000 .y2 0.230 0.029 7.935 0.000 .y3 0.275 0.064 4.295 0.000 i 0.973 0.076 12.854 0.000 s 0.986 0.066 14.889 0.000 Confrontiamo questi valori con quelli ottenuti dal modello misto. VarCorr(mix_mod) #&gt; Groups Name Std.Dev. Corr #&gt; subject (Intercept) 1.01217 #&gt; time 1.01494 0.150 #&gt; Residual 0.49108 Si noti che il modello a crescita latente, per impostazione predefinita, assume una varianza eterogenea per ogni rilevazione temporale. I modelli misti per impostazione predefinita assumono la stessa varianza per ogni punto temporale ma, nella maggior parte dei pacchetti di modellizzazione, consentono di specificare una stima separata della varianza nelle diverse rilevazioni temporali. Se fissiamo le varianze come uguali, i due modelli producono stime identiche. model &lt;- &quot; # intercept and slope with fixed coefficients i =~ 1*y0 + 1*y1 + 1*y2 + 1*y3 s =~ 0*y0 + 1*y1 + 2*y2 + 3*y3 y0 ~~ resvar*y0 y1 ~~ resvar*y1 y2 ~~ resvar*y2 y3 ~~ resvar*y3 &quot; growth_curve_model &lt;- growth(model, data = dWide) summary(growth_curve_model) #&gt; lavaan 0.6.15 ended normally after 27 iterations #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of model parameters 9 #&gt; Number of equality constraints 3 #&gt; #&gt; Number of observations 500 #&gt; #&gt; Model Test User Model: #&gt; #&gt; Test statistic 6.180 #&gt; Degrees of freedom 8 #&gt; P-value (Chi-square) 0.627 #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Standard #&gt; Information Expected #&gt; Information saturated (h1) model Structured #&gt; #&gt; Latent Variables: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; i =~ #&gt; y0 1.000 #&gt; y1 1.000 #&gt; y2 1.000 #&gt; y3 1.000 #&gt; s =~ #&gt; y0 0.000 #&gt; y1 1.000 #&gt; y2 2.000 #&gt; y3 3.000 #&gt; #&gt; Covariances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; i ~~ #&gt; s 0.154 0.051 3.034 0.002 #&gt; #&gt; Intercepts: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .y0 0.000 #&gt; .y1 0.000 #&gt; .y2 0.000 #&gt; .y3 0.000 #&gt; i 0.502 0.049 10.278 0.000 #&gt; s 0.252 0.046 5.423 0.000 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .y0 (rsvr) 0.241 0.011 22.361 0.000 #&gt; .y1 (rsvr) 0.241 0.011 22.361 0.000 #&gt; .y2 (rsvr) 0.241 0.011 22.361 0.000 #&gt; .y3 (rsvr) 0.241 0.011 22.361 0.000 #&gt; i 1.022 0.076 13.502 0.000 #&gt; s 1.028 0.068 15.095 0.000 Per lme4 abbiamo: #&gt; Groups Name Variance Cov #&gt; subject (Intercept) 1.02448 #&gt; time 1.03011 0.154 #&gt; Residual 0.24116 In entrambi i casi, la varianza residua è uguale a 0.241 e la correlazione tra intercette e pendenze casuali è uguale a 0.154. Inoltre, le stime dei coefficienti casuali del modello misto sono identiche a quelle delle variabili latenti. ranef_latent &lt;- data.frame( coef(mix_mod)[[1]], lavPredict(growth_curve_model) ) %&gt;% rename( Int_mix = X.Intercept., Slope_mix = time, Int_lgc = i, Slope_lgc = s ) ranef_latent %&gt;% round(2) %&gt;% head() #&gt; Int_mix Slope_mix Int_lgc Slope_lgc #&gt; 1 -0.40 -0.91 -0.40 -0.91 #&gt; 2 -1.53 -1.59 -1.53 -1.59 #&gt; 3 0.54 0.88 0.54 0.88 #&gt; 4 0.31 -0.79 0.31 -0.79 #&gt; 5 2.03 3.53 2.03 3.53 #&gt; 6 2.06 -1.14 2.06 -1.14 "],["esplorazione-approfondita-del-modello-lgm.html", "29.3 Esplorazione approfondita del modello LGM", " 29.3 Esplorazione approfondita del modello LGM Consideriamo ora un secondo esempio che ci consentirà di approfondire la nostra conoscenza dei modelli LGM. L’esempio che discuteremo utilizza un campione di dati artificiali chiamato Demo.growth in cui si ipotizza che un determinato punteggio venga misurato su quattro punti temporali. I dati sono i seguenti: data(Demo.growth) glimpse(Demo.growth) #&gt; Rows: 400 #&gt; Columns: 10 #&gt; $ t1 &lt;dbl&gt; 1.7256454, -1.9841595, 0.3195183, 0.7769485, 0.4489440, -1.7469951,… #&gt; $ t2 &lt;dbl&gt; 2.1424005, -4.4006027, -1.2691171, 3.5313707, -0.7727747, -0.996340… #&gt; $ t3 &lt;dbl&gt; 2.77317167, -6.01655626, 1.56001603, 3.13821140, -1.50351504, -0.82… #&gt; $ t4 &lt;dbl&gt; 2.51595586, -7.02961801, 2.86852958, 5.36374139, 0.07846742, 0.5669… #&gt; $ x1 &lt;dbl&gt; -1.1641026, -1.7454025, 0.9202112, 2.3595236, -1.0887077, -0.513516… #&gt; $ x2 &lt;dbl&gt; 0.17422932, -1.57686022, -0.14181802, 0.70796813, -1.00999772, -0.1… #&gt; $ c1 &lt;dbl&gt; -0.02767765, -2.03196724, 0.05237496, 0.01911429, 0.65243274, -0.04… #&gt; $ c2 &lt;dbl&gt; 0.55492337, 0.12533477, -1.25774075, 0.64738300, 0.73091476, -0.416… #&gt; $ c3 &lt;dbl&gt; 0.254478433, -1.564232274, -1.803390895, -0.432379510, -0.753781573… #&gt; $ c4 &lt;dbl&gt; -1.00639541, 1.22926875, -0.32725761, -1.03239779, -0.02745598, 0.5… La variabile dipendente è rappresentata dalle quattro colonne chiamate t1, t2, t3 e t4 che corrispondono alla serie temporale con quattro misurazioni per ciascun soggetto. Trasformiamo i dati in formato long: demo_growth_long &lt;- Demo.growth %&gt;% dplyr::select(t1, t2, t3, t4) %&gt;% pivot_longer( cols = starts_with(&quot;t&quot;), names_to = &quot;t&quot;, values_to = &quot;y&quot; ) %&gt;% as.data.frame() demo_growth_long$time &lt;- rep(0:3, 400) demo_growth_long$id &lt;- rep(1:400, each = 4) Esaminiamo un campione casuale di 9 soggetti. È presente una notevole variazione da soggetto a soggetto: id_sel &lt;- sample(1:400, 9) d &lt;- demo_growth_long[demo_growth_long$id %in% id_sel, ] d %&gt;% ggplot(aes(x = time, y = y)) + geom_line() + facet_wrap(~id) Notiamo che una funzione lineare è appropriata per rendere conto della variazione temporale della variabile risposta: d %&gt;% ggplot(aes(x = time, y = y)) + geom_point() + stat_smooth(method = &quot;lm&quot;, se = FALSE) + facet_wrap(~id) Complessivamente, i dati suggeriscono un andamento crescente della variabile risposta in funzione del tempo: demo_growth_long %&gt;% ggplot(aes(time, y, group = id)) + geom_line(alpha = 0.1) + # add individual line with transparency stat_summary( # add average line aes(group = 1), fun = mean, geom = &quot;line&quot;, size = 1.5, color = &quot;black&quot; ) + labs(x = &quot;Time&quot;, y = &quot;y&quot;) Abbiamo visto come un modello lineare di crescita latente corrisponde ad un modello fattoriale con due variabili latenti: un fattore (\\(\\eta_0\\)) che specifica il “punteggio vero” delle intercette individuali e un fattore (\\(\\eta_1\\)) che speficita il “punteggio vero” delle pendenze delle rette di regressione per i singoli individui. Nella sintassi lavaan il modello LGM diventa: model &lt;- &quot; i =~ 1*t1 + 1*t2 + 1*t3 + 1*t4 s =~ 0*t1 + 1*t2 + 2*t3 + 3*t4 &quot; Si noti che, per il fattore \\(\\eta_0\\) (che rappresenta le intercette), i valori delle saturazioni fattoriali sono fissate a 1 – questo è il motivo per cui \\(\\alpha_0\\) e \\(\\zeta_{00}\\) compaiono da soli nell’equazione precedente: in maniera esplicita sono \\(1 \\cdot \\alpha_0\\) e \\(1 \\cdot \\zeta_{00}\\). Le saturazioni per il fattore \\(\\eta_1\\) (che specifica le pendenze delle funzioni lineari) sono fissate ai valori che descrivono la variazione temporale: qui i valori \\(\\lambda_j\\) da 0 a 3. Il modello include anche la correlazione tra \\(\\eta_0\\) e \\(\\eta_1\\), rappresentata dalla doppia freccia \\(\\zeta_{01}\\). Se \\(\\zeta_{01} &gt; 0\\), questo significa che, con il passare del tempo, i partecipanti tendono a diventare sempre più diversi tra loro; un’interpretazione opposta si ha se \\(\\zeta_{01}&lt; 0\\). Adattiamo il modello ai dati: fit &lt;- growth(model, data = Demo.growth) summary(fit) #&gt; lavaan 0.6.15 ended normally after 29 iterations #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of model parameters 9 #&gt; #&gt; Number of observations 400 #&gt; #&gt; Model Test User Model: #&gt; #&gt; Test statistic 8.069 #&gt; Degrees of freedom 5 #&gt; P-value (Chi-square) 0.152 #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Standard #&gt; Information Expected #&gt; Information saturated (h1) model Structured #&gt; #&gt; Latent Variables: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; i =~ #&gt; t1 1.000 #&gt; t2 1.000 #&gt; t3 1.000 #&gt; t4 1.000 #&gt; s =~ #&gt; t1 0.000 #&gt; t2 1.000 #&gt; t3 2.000 #&gt; t4 3.000 #&gt; #&gt; Covariances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; i ~~ #&gt; s 0.618 0.071 8.686 0.000 #&gt; #&gt; Intercepts: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .t1 0.000 #&gt; .t2 0.000 #&gt; .t3 0.000 #&gt; .t4 0.000 #&gt; i 0.615 0.077 8.007 0.000 #&gt; s 1.006 0.042 24.076 0.000 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .t1 0.595 0.086 6.944 0.000 #&gt; .t2 0.676 0.061 11.061 0.000 #&gt; .t3 0.635 0.072 8.761 0.000 #&gt; .t4 0.508 0.124 4.090 0.000 #&gt; i 1.932 0.173 11.194 0.000 #&gt; s 0.587 0.052 11.336 0.000 Esaminiamo il path diagram. semPaths( fit, layout = &quot;tree&quot;, intercepts = FALSE, posCol = c(&quot;black&quot;), edge.label.cex = 0.00001, sizeMan = 7, what = &quot;path&quot;, optimizeLatRes = TRUE, residuals = TRUE, style = &quot;lisrel&quot; ) Ci sono 6 tipi di parametri di interesse: kable(coef(fit), booktabs = TRUE, format = &quot;markdown&quot;) x t1~~t1 0.5952890 t2~~t2 0.6760337 t3~~t3 0.6348906 t4~~t4 0.5076449 i~~i 1.9319804 s~~s 0.5869142 i~~s 0.6178630 i~1 0.6146957 s~1 1.0062943 l’intercetta \\(i\\) = 0.615 è il valore atteso della variabile risposta al momento \\(t_0\\); la pendenza \\(s\\) = 1.006 è il tasso di cambiamento medio della variabile risposta nel tempo. Ad ogni successivo momento temporale, il valore medio della variabile risposta aumenta in media di 1.006 punti; varianza \\(i\\) = 1.932 misura la variazione tra i soggetti al momento \\(t_0\\) (ci dice quanto sono diverse le intercette delle rette di regressione tra i soggetti); varianza \\(s\\) = 0.587 misura la variazione del tasso di crescita tra i soggetti (ci dice quanto sono diverse le pendenze delle rette di regressione tra i soggetti); varianze t1, …, t4: i valori da 0.595 a 0.508 descrivono la variazione tra i soggetti in ciascun momento del tempo; la covarianza tra i e s = 0.618 ci dice che i valori della variabile risposta diventano via via più diversi nel tempo tra i rispondenti (un valore negativo avrebbe l’interpretazione opposta). Le stime dell’intercetta e della pendenza della funzione di crescita per ciascun partecipante si ottengono nel modo seguente: rand_eff &lt;- as.data.frame(lavPredict(fit)) head(rand_eff) #&gt; i s #&gt; 1 1.2275557 0.60278312 #&gt; 2 -2.6795847 -1.38498215 #&gt; 3 -0.2955058 0.88828376 #&gt; 4 1.1576419 1.34051395 #&gt; 5 -0.4355522 0.03193498 #&gt; 6 -1.3121802 0.50258530 Istogrammi delle stime individuali dell’intercetta e della pendenza della curva di crescita si ottengono nel modo seguente: gi &lt;- rand_eff %&gt;% ggplot(aes(x = i)) + geom_histogram() gh &lt;- rand_eff %&gt;% ggplot(aes(x = s)) + geom_histogram() gi + gh 29.3.1 Visualizzare il cambiamento È utile visualizzare i punteggi previsti dal modello. A tal fine, useremo qui la funzione predict() per creare un nuovo oggetto \\(\\mathsf{R}\\) che contiene i punteggi previsti a livello individuale per l’intercetta e la pendenza. pred_lgm &lt;- predict(fit) head(pred_lgm) #&gt; i s #&gt; [1,] 1.2275557 0.60278312 #&gt; [2,] -2.6795847 -1.38498215 #&gt; [3,] -0.2955058 0.88828376 #&gt; [4,] 1.1576419 1.34051395 #&gt; [5,] -0.4355522 0.03193498 #&gt; [6,] -1.3121802 0.50258530 Questi sono i valori previsti dal modello per ciascun partecipante. Se calcoliamo la media di queste variabili otteniamo gli stessi risultati che sono stati riportati sopra: # average of the intercepts (first column) mean(pred_lgm[, 1]) #&gt; [1] 0.6146957 # average of the slope (second column) mean(pred_lgm[, 2]) #&gt; [1] 1.006294 Il cambiamento nel tempo previsto dal modello per il soggetto \\(j\\)-esimo è \\[ y_j = \\eta_0 + \\lambda_j \\eta_1. \\] Il cambiamento previsto per tutti i soggetti può essere visualizzato nel modo seguente: # create long data for each individual pred_lgm_long &lt;- map( 0:3, # loop over time function(x) pred_lgm[, 1] + x * pred_lgm[, 2] ) %&gt;% reduce(cbind) %&gt;% # bring together the wave predictions as.data.frame() %&gt;% # make data frame setNames(str_c(&quot;time&quot;, 0:3)) %&gt;% # give names to variables mutate(id = row_number()) %&gt;% # make unique id gather(-id, key = time, value = pred) # make long format # make graph pred_lgm_long %&gt;% ggplot(aes(time, pred, group = id)) + # what variables to plot? geom_line(alpha = 0.1) + # add a transparent line for each person stat_summary( # add average line aes(group = 1), fun = mean, geom = &quot;line&quot;, size = 1.5, color = &quot;black&quot; ) + labs(y = &quot;y&quot;, x = &quot;time&quot;) La linea nera più spessa rappresenta l’intercetta media e la pendenza media della curva di crescita del modello LGM. Ogni individuo ha una sua specifica intercetta e uno specifico tasso di cambiamento e questa diversità è catturata nelle componenti di varianza del modello. 29.3.2 Dati ordinali vs. intervalli temporali La specificazione s =~ 0*t1 + 1*t2 + 2*t3 + 3*t4 assume che il tempo sia misurato per intervalli costanti. Questa sintassi può essere usata anche quando il tempo è misurato su una scala a livello ordinale, ovvero quando supponiamo diverse rilevazioni temporali e ci chiediamo cosa succede passando da una alla successiva, senza specificare precisamente qual è la distanza temporale tra le varie rilevazioni. In alternativa è possibile specificare in termini assoluti il tempo trascorso tra le diverse rilevazioni temporali – questo è possibile solo se tali distanze temporali sono costanti tra i vari soggetti. Ad esempio, se passano 2, 3 e 9 mesi dalla prima rilevazione, avremo il seguente modello. model_a &lt;- &quot; i =~ 1*t1 + 1*t2 + 1*t3 + 1*t4 s =~ 0*t1 + 2*t2 + 6*t3 + 9*t4 &quot; La scelta di utilizzare il tempo su scala ordinale rispetto a quello assoluto non cambia il numero di parametri del modello o i gradi di libertà. Tuttavia la media dei punteggi fattoriali che rappresentano l’intercetta e la pendenza può cambiare e l’interpretazione di questi termini cambierà di conseguenza. fit_a &lt;- growth(model_a, data = Demo.growth) kable(coef(fit_a), booktabs = TRUE, format = &quot;markdown&quot;) x t1~~t1 0.75840584 t2~~t2 0.80990552 t3~~t3 0.63209463 t4~~t4 0.49864811 i~~i 2.04046924 s~~s 0.05802979 i~~s 0.23300623 i~1 0.76120704 s~1 0.31906615 Mentre in precedenza l’interpretazione era che la media della variabile risposta aumenta in media 1.006 punti passando da una rilevazione temporale alla successiva, nel caso della presente specificazione temporale in mesi possiamo dire che media della variabile risposta aumenta in media 0.319 punti dopo l’incremento temporale di un mese. 29.3.3 Verifica di ipotesi È anche possibile utilizzare le funzionalità di lavaan per verificare specifiche ipotesi di interesse relative ai dati longitudinali. Ad esempio, una possibile domanda riguarda l’uguaglianza degli errori nel tempo. Tale domanda può essere affrontata introducendo dei vincoli nella specificazione del modello LGM (come abbiamo anche visto in precedenza) e, successivamente, confrontando la bontà dell’adattamento del modello vincolato e del modello generale. Il modello vincolato è model_eqerr &lt;- &quot; i =~ 1*t1 + 1*t2 + 1*t3 + 1*t4 s =~ 0*t1 + 1*t2 + 2*t3 + 3*t4 t1 ~~ a*t1 t2 ~~ a*t2 t3 ~~ a*t3 t4 ~~ a*t4 &quot; Adattiamo il modello vincolato: fit_eqerr &lt;- growth(model_eqerr, data = Demo.growth) Confrontiamo il modello vincolato con il modello libero: anova(fit, fit_eqerr) #&gt; #&gt; Chi-Squared Difference Test #&gt; #&gt; Df AIC BIC Chisq Chisq diff RMSEA Df diff Pr(&gt;Chisq) #&gt; fit 5 5528.1 5564.0 8.0687 #&gt; fit_eqerr 8 5523.7 5547.7 9.6779 1.6091 0 3 0.6573 Il test del rapporto di verosimiglianza (likelihood ratio) eseguito dalla funzione anova() produce un \\(p\\)-valore di 0.6573. Ciò significa che, per i dati esaminati, non emerge una decremento nella bontà dell’adattamento degna di nota se passiamo dal modello libero al modello vincolato. Per questi dati, dunque, sembra ragionevole assumere l’equaglianza della varianza degli errori nel tempo. 29.3.4 L’effetto delle covariate Un modello leggermente più complesso aggiunge due regressori (x1 e x2) che influenzano i fattori di crescita latenti. Inoltre, è stata aggiunta al modello una covariata c variabile nel tempo che influenza la misura del risultato (la variabile dipendente) nei quattro punti temporali. model2 &lt;- &quot; # intercept and slope with fixed coefficients i =~ 1*t1 + 1*t2 + 1*t3 + 1*t4 s =~ 0*t1 + 1*t2 + 2*t3 + 3*t4 # regressions i ~ x1 + x2 s ~ x1 + x2 # time-varying covariates t1 ~ c1 t2 ~ c2 t3 ~ c3 t4 ~ c4 &quot; fit2 &lt;- growth(model2, data = Demo.growth) summary(fit2) #&gt; lavaan 0.6.15 ended normally after 31 iterations #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of model parameters 17 #&gt; #&gt; Number of observations 400 #&gt; #&gt; Model Test User Model: #&gt; #&gt; Test statistic 26.059 #&gt; Degrees of freedom 21 #&gt; P-value (Chi-square) 0.204 #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Standard #&gt; Information Expected #&gt; Information saturated (h1) model Structured #&gt; #&gt; Latent Variables: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; i =~ #&gt; t1 1.000 #&gt; t2 1.000 #&gt; t3 1.000 #&gt; t4 1.000 #&gt; s =~ #&gt; t1 0.000 #&gt; t2 1.000 #&gt; t3 2.000 #&gt; t4 3.000 #&gt; #&gt; Regressions: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; i ~ #&gt; x1 0.608 0.060 10.134 0.000 #&gt; x2 0.604 0.064 9.412 0.000 #&gt; s ~ #&gt; x1 0.262 0.029 9.198 0.000 #&gt; x2 0.522 0.031 17.083 0.000 #&gt; t1 ~ #&gt; c1 0.143 0.050 2.883 0.004 #&gt; t2 ~ #&gt; c2 0.289 0.046 6.295 0.000 #&gt; t3 ~ #&gt; c3 0.328 0.044 7.361 0.000 #&gt; t4 ~ #&gt; c4 0.330 0.058 5.655 0.000 #&gt; #&gt; Covariances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .i ~~ #&gt; .s 0.075 0.040 1.855 0.064 #&gt; #&gt; Intercepts: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .t1 0.000 #&gt; .t2 0.000 #&gt; .t3 0.000 #&gt; .t4 0.000 #&gt; .i 0.580 0.062 9.368 0.000 #&gt; .s 0.958 0.029 32.552 0.000 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .t1 0.580 0.080 7.230 0.000 #&gt; .t2 0.596 0.054 10.969 0.000 #&gt; .t3 0.481 0.055 8.745 0.000 #&gt; .t4 0.535 0.098 5.466 0.000 #&gt; .i 1.079 0.112 9.609 0.000 #&gt; .s 0.224 0.027 8.429 0.000 kable(coef(fit2), booktabs = TRUE, format = &quot;markdown&quot;) x i~x1 0.60838657 i~x2 0.60410683 s~x1 0.26223932 s~x2 0.52173009 t1~c1 0.14335610 t2~c2 0.28900400 t3~c3 0.32753750 t4~c4 0.33049483 t1~~t1 0.57982241 t2~~t2 0.59559342 t3~~t3 0.48141221 t4~~t4 0.53520654 i~~i 1.07945768 s~~s 0.22376291 i~~s 0.07475324 i~1 0.58023837 s~1 0.95757971 I risultati mostrano che le due covariate \\(x\\) influenzano sia l’intercetta sia la pendenza della curva di crescita. Inoltre, vi sono evidenze di un effetto della covariata c. "],["crescita-non-lineare.html", "29.4 Crescita non lineare", " 29.4 Crescita non lineare Ripetiamo la procedura di analisi descritta sopra introducendo un cambiamento relativo alla descrizione del cambiamento: verrà considerato un modello nel quale la crescita non è lineare. Nelle analisi seguenti useremo i seguenti indici di bontà di adattamento. selected_fit_stats &lt;- c( &quot;chisq.scaled&quot;, &quot;df.scaled&quot;, ## must be &gt;0 to test G.O.F. &quot;pvalue.scaled&quot;, ## ideally n.s. &quot;cfi.scaled&quot;, ## ideally ≥ 0.95 &quot;rmsea.scaled&quot;, ## ideally ≤ 0.05 &quot;rmsea.pvalue.scaled&quot;, ## ideally n.s. &quot;srmr&quot; ## ideally &lt; 0.08 ) Supponiamo che la popolazione possa essere descritta dal seguente modello. growth_mod &lt;- &quot; ## intercept &amp; slope growth terms for X iX =~ 1*x1 + 1*x2 + 1*x3 + 1*x4 sX =~ 0*x1 + 1*x2 + 2*x3 + 3*x4 ## intercept, slope, &amp; quadratic terms for Y iY =~ 1*y1 + 1*y2 + 1*y3 + 1*y4 sY =~ 0*y1 + 1*y2 + 2*y3 + 3*y4 qY =~ 0*y1 + 1*y2 + 4*y3 + 9*y4 ## set variances y4 ~~ 2*y4 x4 ~~ 1*x4 ## set latent means/intercepts iX ~ 2*1 sX ~ 1*1 sY ~ -1*1 qY ~ -1.5*1 sY ~ 2*predictor outcome ~ 2*iX + 3*sY &quot; È possibile usare la funzione simulateData() di lavaan per simulare un campione di dati estratto da una popolazione definita come abbiamo fatto sopra. La simulazione include due variabili misurate in quattro punti temporali. sim_growth_dat &lt;- lavaan::simulateData( model = growth_mod, model.type = &quot;growth&quot;, seed = 82020, orthogonal = FALSE, auto.cov.y = TRUE, auto.var = TRUE ) Le variabili sono chiamate x1, x2, x3, x4, per la misurazione di x ai tempi 1, 2, 3, 4. Lo stesso per la y. head(sim_growth_dat) #&gt; x1 x2 x3 x4 y1 y2 y3 #&gt; 1 1.033229 2.746064 4.9423623 8.41058044 3.36324415 -1.196550 -11.103494 #&gt; 2 3.192802 3.057675 0.7965786 0.84592869 -1.60039704 -5.970381 -10.399366 #&gt; 3 3.758457 4.712351 5.6308218 4.76577291 2.58001675 -3.272134 -11.312994 #&gt; 4 2.700514 4.921257 6.7116263 10.13354061 0.03886676 0.510869 -5.937016 #&gt; 5 1.259807 1.526301 1.6663799 -0.09959486 0.53939838 -4.274106 -12.968362 #&gt; 6 2.547125 5.426192 4.9463195 8.48790397 2.18069542 1.590009 -2.253218 #&gt; y4 outcome predictor #&gt; 1 -31.509255 2.161186 -0.4893276 #&gt; 2 -19.908088 5.089750 0.5199749 #&gt; 3 -26.681111 3.173129 -0.5938816 #&gt; 4 -7.836099 1.035215 -0.7813707 #&gt; 5 -22.595311 -4.352557 -0.7067630 #&gt; 6 -8.892786 3.277985 -1.2978592 Aggiungo qui un codice identificativo per ciascun partecipante. sim_growth_dat$participant_n &lt;- 1:nrow(sim_growth_dat) Nei dati simulati, la variabile x cambia linearmente nel tempo e la variabile y cambia seguendo un andamento quadratico. Esaminiamo i dati con un grafico. x_plot &lt;- pivot_longer(sim_growth_dat, cols = x1:x4, names_to = &quot;x&quot;, names_prefix = &quot;x&quot; ) individual_x_trajectories &lt;- ggplot( x_plot, aes( x = as.numeric(x), y = value, group = participant_n, color = participant_n ) ) + geom_line(alpha = 0.2) + labs( title = &quot;Observed Trajectories of x&quot;, x = &quot;Timepoint&quot;, y = &quot;x&quot; ) + xlim(1, 4) + theme(legend.position = &quot;none&quot;) individual_x_trajectories Su può vedere che la variabile x segue una crescita lineare, ma un modello quadratico molto “debole” potrebbe adattarsi meglio ai dati, quindi sarà necessario controllare se in effetti questo è vero. Esaminiamo ora la variabile y. y_plot &lt;- pivot_longer(sim_growth_dat, cols = y1:y4, names_to = &quot;y&quot;, names_prefix = &quot;y&quot; ) individual_y_trajectories &lt;- ggplot( y_plot, aes( x = as.numeric(y), y = value, group = participant_n, color = participant_n ) ) + geom_line(alpha = 0.2) + labs( title = &quot;Observed trajectories of y&quot;, x = &quot;Timepoint&quot;, y = &quot;y&quot; ) + xlim(1, 4) + theme(legend.position = &quot;none&quot;) individual_y_trajectories È chiaro che la y diminuisce in media con il tempo, ma c’è anche molta variabilità in ciò che accade nei singoli casi. Per questi dati, sia un modello lineare sia un modello quadratico sembrano appropriati per descrivere il cambiamento nei dati, anche se un modello quadratico sembra più appropriato. 29.4.1 Stimatore Tutti i dati utilizzati sono continui, quindi si potrebbe usare la stima della massima verosimiglianza (stimatore = ML). Tuttavia, quando possibile, è preferibile usare la variante “robusta” di questo stimatore allo scopo di rendere conto della possibile non normalità dei dati (stimatore = MLR). 29.4.2 Assenza di crescita Iniziamo con un modello per la x che assume che non vi sia variazione in funzione del tempo. int_x_mod &lt;- &quot; iX =~ 1*x1 + 1*x2 + 1*x3 + 1*x4 &quot; Adattiamo il modello ai dati ed esaminiamo i risultati. int_x_fit &lt;- growth( model = int_x_mod, estimator = &quot;MLR&quot;, data = sim_growth_dat ) int_x_fit_stats &lt;- fitmeasures( int_x_fit, selected_fit_stats ) %&gt;% data.frame() round(int_x_fit_stats, 2) #&gt; . #&gt; chisq.scaled 1192.66 #&gt; df.scaled 8.00 #&gt; pvalue.scaled 0.00 #&gt; cfi.scaled 0.02 #&gt; rmsea.scaled 0.54 #&gt; rmsea.pvalue.scaled 0.00 #&gt; srmr 0.63 È chiaro che il modello di assenza di crescita non spiega i dati x. Consideriamo la variabile y. Anche in questo caso prendiamo in considerazione un modello di assenza di variazione nel tempo. int_y_mod &lt;- &quot; iY =~ 1*y1 + 1*y2 + 1*y3 + 1*y4 &quot; int_y_fit &lt;- growth( model = int_y_mod, estimator = &quot;MLR&quot;, data = sim_growth_dat ) int_y_fit_stats &lt;- fitmeasures( int_y_fit, selected_fit_stats ) %&gt;% data.frame() round(int_y_fit_stats, 2) #&gt; . #&gt; chisq.scaled 3136.54 #&gt; df.scaled 8.00 #&gt; pvalue.scaled 0.00 #&gt; cfi.scaled 0.00 #&gt; rmsea.scaled 0.88 #&gt; rmsea.pvalue.scaled 0.00 #&gt; srmr 0.98 Il modello di assenza di crescita non è adeguato neppure per la variabile y. 29.4.3 Crescita lineare Esaminiamo ora un modello di crescita lineare per la x. linear_x_mod &lt;- &quot; iX =~ 1*x1 + 1*x2 + 1*x3 + 1*x4 sX =~ 0*x1 + 1*x2 + 2*x3 + 3*x4 &quot; linear_x_fit &lt;- growth( model = linear_x_mod, estimator = &quot;MLR&quot;, data = sim_growth_dat ) linear_x_fit_stats &lt;- fitmeasures( linear_x_fit, selected_fit_stats ) %&gt;% data.frame() round(linear_x_fit_stats, 2) #&gt; . #&gt; chisq.scaled 4.03 #&gt; df.scaled 5.00 #&gt; pvalue.scaled 0.54 #&gt; cfi.scaled 1.00 #&gt; rmsea.scaled 0.00 #&gt; rmsea.pvalue.scaled 0.92 #&gt; srmr 0.02 Il modello di crescita lineare per la x fornisce un buon adattamento ai dati rispetto a tutti gli indici. Questo è ciò che ci aspettavamo esaminando il grafico dei dati. Esaminiamo un modello di crescita lineare per la y. linear_y_mod &lt;- &quot; iY =~ 1*y1 + 1*y2 + 1*y3 + 1*y4 sY =~ 0*y1 + 1*y2 + 2*y3 + 3*y4 &quot; linear_y_fit &lt;- growth( model = linear_y_mod, estimator = &quot;MLR&quot;, data = sim_growth_dat ) linear_y_fit_stats &lt;- fitmeasures( linear_y_fit, selected_fit_stats ) %&gt;% data.frame() round(linear_y_fit_stats, 2) #&gt; . #&gt; chisq.scaled 842.85 #&gt; df.scaled 5.00 #&gt; pvalue.scaled 0.00 #&gt; cfi.scaled 0.61 #&gt; rmsea.scaled 0.58 #&gt; rmsea.pvalue.scaled 0.00 #&gt; srmr 0.55 Il modello lineare è inadeguato per la y rispetto a tutti gli indici considerati. 29.4.4 Crescita quadratica I termini quadratici descrivono il tasso medio di variazione della pendenza tra le diverse rilevazioni temporali. Nei modelli SEM, una tale caratteristica viene detta “crescita quadratica”. Consideriamo dunque un modello di crescita quadratica per la x. quad_x_mod &lt;- &quot; iX =~ 1*x1 + 1*x2 + 1*x3 + 1*x4 sX =~ 0*x1 + 1*x2 + 2*x3 + 3*x4 qX =~ 0*x1 + 1*x2 + 4*x3 + 9*x4 &quot; quad_x_fit &lt;- growth( model = quad_x_mod, estimator = &quot;MLR&quot;, data = sim_growth_dat ) quad_x_fit_stats &lt;- fitmeasures( quad_x_fit, selected_fit_stats ) round(quad_x_fit_stats, 2) #&gt; chisq.scaled df.scaled pvalue.scaled cfi.scaled #&gt; 0.02 1.00 0.89 1.00 #&gt; rmsea.scaled rmsea.pvalue.scaled srmr #&gt; 0.00 0.94 0.00 Qui abbiamo un problema interessante, poiché la x si adatta bene sia a un modello lineare sia a uno quadratico. Abbiamo però un caso di Heywood: la varianza stimata della variabile x4 è negativa. lavInspect(quad_x_fit, &quot;est&quot;)$theta #&gt; x1 x2 x3 x4 #&gt; x1 1.171 #&gt; x2 0.000 0.718 #&gt; x3 0.000 0.000 1.213 #&gt; x4 0.000 0.000 0.000 -0.064 Questo è ovviamente un problema, in quanto il modello non sembra adeguato per i dati. È possibile introdurre dei vincoli sui parametri per poi valutare se, evitando il caso di Heywood, l’adattamento si mantiene a livelli adeguati. Tuttavia, per i fini di questo tutorial, ignoreremo il caso di Heywood e proseguiremo nell’analisi. Quando si hanno due modelli nidificati (nel nostro caso, modelli lineari e quadratici), possiamo confrontare formalmente l’adattamento relativo dei due modelli con il test del rapporto di verosimiglianza (LRT). L’ipotesi nulla è che non vi sia alcuna differenza nella covarianza spiegata dai due modelli. Se la covarianza spiegata è equivalente, preferiamo il modello più semplice. lavTestLRT(linear_x_fit, quad_x_fit) #&gt; #&gt; Scaled Chi-Squared Difference Test (method = &quot;satorra.bentler.2001&quot;) #&gt; #&gt; lavaan NOTE: #&gt; The &quot;Chisq&quot; column contains standard test statistics, not the #&gt; robust test that should be reported per model. A robust difference #&gt; test is a function of two standard (not robust) statistics. #&gt; #&gt; Df AIC BIC Chisq Chisq diff Df diff Pr(&gt;Chisq) #&gt; quad_x_fit 1 7570.4 7625.2 0.0200 #&gt; linear_x_fit 5 7566.4 7604.3 4.0675 4.0026 4 0.4056 Qui, un p-value \\(&gt; 0.05\\) (ovvero, nessuna evidenza di perdita di adattamento) ci dice che il modello lineare (ovvero, quello più semplice) è da preferire. Esaminiamo la y. quad_y_mod &lt;- &quot; iY =~ 1*y1 + 1*y2 + 1*y3 + 1*y4 sY =~ 0*y1 + 1*y2 + 2*y3 + 3*y4 qY =~ 0*y1 + 1*y2 + 4*y3 + 9*y4 &quot; quad_y_fit &lt;- growth( model = quad_y_mod, estimator = &quot;MLR&quot;, data = sim_growth_dat ) quad_y_fit_stats &lt;- fitmeasures( quad_y_fit, selected_fit_stats ) quad_y_fit_stats #&gt; chisq.scaled df.scaled pvalue.scaled cfi.scaled #&gt; 0.190 1.000 0.663 1.000 #&gt; rmsea.scaled rmsea.pvalue.scaled srmr #&gt; 0.000 0.813 0.001 Gli indici di bontà di adattamento sono eccellenti. lavTestLRT(linear_y_fit, quad_y_fit) #&gt; #&gt; Scaled Chi-Squared Difference Test (method = &quot;satorra.bentler.2001&quot;) #&gt; #&gt; lavaan NOTE: #&gt; The &quot;Chisq&quot; column contains standard test statistics, not the #&gt; robust test that should be reported per model. A robust difference #&gt; test is a function of two standard (not robust) statistics. #&gt; #&gt; Df AIC BIC Chisq Chisq diff Df diff Pr(&gt;Chisq) #&gt; quad_y_fit 1 9301.7 9356.5 0.1901 #&gt; linear_y_fit 5 10194.9 10232.9 901.4270 829.59 4 &lt; 2.2e-16 *** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Il test del rapporto di verosimiglianza ci dice che, per la y, il modello quadratico è sicuramente da preferire al modello lineare. "],["parallel-process-model.html", "29.5 Parallel Process Model", " 29.5 Parallel Process Model Esaminiamo ora un modello che include sia i termini lineari che quadratici (quando richiesti) delle variabili x e y. full_model &lt;- &quot; # intercept &amp; slope growth terms for X iX =~ 1*x1 + 1*x2 + 1*x3 + 1*x4 sX =~ 0*x1 + 1*x2 + 2*x3 + 3*x4 # intercept, slope, &amp; quadratic terms for Y iY =~ 1*y1 + 1*y2 + 1*y3 + 1*y4 sY =~ 0*y1 + 1*y2 + 2*y3 + 3*y4 qY =~ 0*y1 + 1*y2 + 4*y3 + 9*y4 # regress growth terms on predictor qY + iY + sX + iX ~ predictor sY ~ a1*predictor # regress outcome on growth terms outcome ~ iX + sX + iY + b1*sY + qY # testing indirect effect # predictor --&gt; sY --&gt; outcome predictor_sY_outcome := a1*b1 &quot; Adattiamo il modello ai dati. full_fit &lt;- growth( model = full_model, estimator = &quot;MLR&quot;, data = sim_growth_dat ) Esaminiamo il path diagram. semPaths( full_fit, layout = &quot;tree&quot;, intercepts = FALSE, posCol = c(&quot;black&quot;), edge.label.cex = 0.00001, sizeMan = 7, what = &quot;path&quot;, optimizeLatRes = TRUE, residuals = TRUE, style = &quot;lisrel&quot; ) Valutiamo l’adattamento. full_fit_stats &lt;- fitmeasures( full_fit, selected_fit_stats ) round(full_fit_stats, 2) #&gt; chisq.scaled df.scaled pvalue.scaled cfi.scaled #&gt; 28.23 34.00 0.75 1.00 #&gt; rmsea.scaled rmsea.pvalue.scaled srmr #&gt; 0.00 1.00 0.03 Si ottiene un ottimo adattamento del modello ai dati (il che non è sorprendente, in quanto i dati sono stati simulati in base a tale modello). 29.5.1 Interpretazione Dato che il modello si adatta bene ai dati, interpretiamo i risultati ottenuti. summary(full_fit) #&gt; lavaan 0.6.15 ended normally after 65 iterations #&gt; #&gt; Estimator ML #&gt; Optimization method NLMINB #&gt; Number of model parameters 29 #&gt; #&gt; Number of observations 500 #&gt; #&gt; Model Test User Model: #&gt; Standard Scaled #&gt; Test Statistic 28.456 28.233 #&gt; Degrees of freedom 34 34 #&gt; P-value (Chi-square) 0.736 0.746 #&gt; Scaling correction factor 1.008 #&gt; Yuan-Bentler correction (Mplus variant) #&gt; #&gt; Parameter Estimates: #&gt; #&gt; Standard errors Sandwich #&gt; Information bread Observed #&gt; Observed information based on Hessian #&gt; #&gt; Latent Variables: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; iX =~ #&gt; x1 1.000 #&gt; x2 1.000 #&gt; x3 1.000 #&gt; x4 1.000 #&gt; sX =~ #&gt; x1 0.000 #&gt; x2 1.000 #&gt; x3 2.000 #&gt; x4 3.000 #&gt; iY =~ #&gt; y1 1.000 #&gt; y2 1.000 #&gt; y3 1.000 #&gt; y4 1.000 #&gt; sY =~ #&gt; y1 0.000 #&gt; y2 1.000 #&gt; y3 2.000 #&gt; y4 3.000 #&gt; qY =~ #&gt; y1 0.000 #&gt; y2 1.000 #&gt; y3 4.000 #&gt; y4 9.000 #&gt; #&gt; Regressions: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; qY ~ #&gt; predictor 0.041 0.048 0.850 0.395 #&gt; iY ~ #&gt; predictor 0.034 0.060 0.564 0.573 #&gt; sX ~ #&gt; predictor 0.008 0.051 0.161 0.872 #&gt; iX ~ #&gt; predictor 0.067 0.060 1.119 0.263 #&gt; sY ~ #&gt; predictor (a1) 2.022 0.079 25.545 0.000 #&gt; outcome ~ #&gt; iX 1.994 0.145 13.755 0.000 #&gt; sX -0.017 0.146 -0.115 0.908 #&gt; iY -0.028 0.186 -0.149 0.881 #&gt; sY (b1) 2.973 0.104 28.596 0.000 #&gt; qY -0.242 0.161 -1.510 0.131 #&gt; #&gt; Intercepts: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 0.000 #&gt; .x2 0.000 #&gt; .x3 0.000 #&gt; .x4 0.000 #&gt; .y1 0.000 #&gt; .y2 0.000 #&gt; .y3 0.000 #&gt; .y4 0.000 #&gt; .outcome 0.000 #&gt; .iX 1.976 0.059 33.700 0.000 #&gt; .sX 0.991 0.051 19.350 0.000 #&gt; .iY 0.031 0.061 0.508 0.611 #&gt; .sY -1.153 0.082 -14.019 0.000 #&gt; .qY -1.548 0.048 -32.151 0.000 #&gt; #&gt; Variances: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; .x1 1.067 0.099 10.777 0.000 #&gt; .x2 0.885 0.069 12.924 0.000 #&gt; .x3 0.983 0.104 9.492 0.000 #&gt; .x4 1.113 0.197 5.646 0.000 #&gt; .y1 0.961 0.107 8.991 0.000 #&gt; .y2 0.868 0.083 10.470 0.000 #&gt; .y3 0.996 0.179 5.557 0.000 #&gt; .y4 2.467 0.949 2.601 0.009 #&gt; .outcome 0.814 0.927 0.878 0.380 #&gt; .iX 1.043 0.100 10.444 0.000 #&gt; .sX 1.094 0.076 14.393 0.000 #&gt; .iY 1.040 0.108 9.595 0.000 #&gt; .sY 1.131 0.125 9.078 0.000 #&gt; .qY 0.927 0.068 13.684 0.000 #&gt; #&gt; Defined Parameters: #&gt; Estimate Std.Err z-value P(&gt;|z|) #&gt; predctr_sY_tcm 6.011 0.159 37.874 0.000 Tra i coefficienti di regressione, quando viene considerata la variabile di esito (outcome), vi sono solo due risultati con \\(p &lt; .05\\): quelli relativi a iX e sY. Ciò significa che il modello offre evidenze di una associazione tra iX e sY e la variabile di esito. La grandezza dei coefficienti suggerisce che sY ha un impatto maggiore su outcome rispetto a iX. In altre parole, sia i livelli iniziali della x, sia il tasso lineare di cambiamento della y predicono outcome. L’effetto è positivo per entrambe le variabili: livelli maggiori dei valori x nella prima rilevazione temporale e tassi di cambiamento più rapidi nella y portano entrambi un aumento nel valore atteso di outcome. L’esempio discusso include anche la covariata predictor, la quale è invariante nel tempo. Poiché vi sono evidenze di un’associazione tra predictor e sY, e poiché vi sono evidenze di un’associazione tra sY e outcome, è ragionevole esaminare con più attenzione un tale effetto di mediazione. Per testare gli effetti indiretti è consigliato usare la tecnica di bootstrapping, in quanto gli intervalli di confidenza ottenuti con questa tecnica risultano più affidabili di quelli ottenibili mediante tecniche parametriche basate su ipotesi distributive stringenti relative alle distribuzioni dei parametri. Il bootstrapping è una tecnica statistica di ricampionamento con reimmissione spesso usata per la costruzione di intervalli di confidenza delle stime degli effetti indiretti. Il bootstrapping produce intervalli di confidenza più affidabili rispetto a quelli che possono essere ottenuti usando metodi parametrici. Per velocizzare la simulazione, esaminiamo qui solo 500 bootstrap samples (in generale, è meglio usare un numero di simulazioni molto maggiore). final_fit_boot &lt;- growth(full_fit, data = sim_growth_dat, estimator = &quot;ML&quot;, meanstructure = T, se = &quot;bootstrap&quot;, bootstrap = 500, # ~5000 better parallel = &quot;multicore&quot; ) parameterEstimates( final_fit_boot, level = .95, boot.ci.type = &quot;bca.simple&quot;, stand = TRUE )[61, c(4, 5, 9, 10)] #&gt; label est ci.lower ci.upper #&gt; 61 predictor_sY_outcome 6.011 5.68 6.325 Possiamo dunque concludere che il livello della y nella prima rilevazione temporale funge da mediazione tra predictor e outcome, con un effetto non standardizzato pari a 6.01, 95% bootstrap CI [5.71, 6.34]. In questo tutorial, dunque, abbiamo visto come sia possibile valutare se un predittore influenza la variazione temporale di un costrutto. Abbiamo anche verificato la presenza di un effetto indiretto e abbiamo quantificato l’entità di tale effetto. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
