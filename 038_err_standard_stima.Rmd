# La stima del punteggio vero 

```{r, include = FALSE}
source("_common.R")
```

Uno degli scopi principali della valutazione psicologica è quello di
stimare il punteggio vero del rispondente. Il punteggio osservato $X$
differisce dal punteggio vero $T$ a causa della presenza dell'errore
della misurazione: $X = T + E$. Poniamoci ora il problema di utilizzare
i concetti della Teoria Classica per stimare il punteggio vero di un
rispondente utilizzando il suo punteggio osservato e l'attendibilità del
test. Questa stima è utile soprattutto quando è necessario costruire un
intervallo di confidenza per il punteggio vero.

Per costruire l'intervallo di confidenza del punteggio vero dobbiamo
utilizzare due quantità:

-   una stima del punteggio vero, 
-   l'errore standard della stima (ovvero, una stima della deviazione
    standard della distribuzione delle stime del punteggio vero che si
    otterrebbe se il test venisse somministrato infinite volte sotto le
    stesse condizioni).

Iniziamo con il problema della stima del punteggio vero.

## Il paradosso di Kelley

Nella sua monografia del 1954, "Clinical versus statistical prediction:
A theoretical analysis and a review of the evidence", Paul Meehl suscitò
un grande scalpore con una convincente dimostrazione del fatto che
metodi meccanici di combinazione dei dati, come ad esempio la
regressione multipla, sono in grado di fornire delle predizioni migliori
di quanto sia in grado di fare la diagnosi clinica eseguita da esperti.
L'enorme quantità di letteratura che è stata prodotta in seguito a tale
contributo ha fornito forti e univoche evidenze a sostegno di questa
osservazione.

È interessante notare che Robyn Dawes (2005) ha pubblicato un articolo
su *Journal of Clinical Psychology* (61, 1245--1255) dal titolo
seguente: "The ethical implications of Paul Meehl's Work on comparing
clinical versus actuarial prediction methods". L'argomento principale
sostenuto da Dawes è che, date le evidenze molto convincenti che sono
disponibili, non è etico usare il giudizio clinico in preferenza all'uso
di modelli statistici di previsione. Citiamo dall'abstract:


> Whenever statistical prediction rules [...] are available for making a relevant prediction, they should be used in preference to intuition. [...] Providing service that assumes that clinicians "can do better" simply based on self-confidence or plausibility in the absence of evidence that they can actually do so is simply unethical.

Sulla base di quanto detto sopra, e in riferimento ai nostri scopi
presenti, si pone dunque il problema di capire come sia possibile
utilizzare il modello di regressione per ottenere una stima del
punteggio vero di un rispondente. A questo proposito si deve notare che
è necessario tenere in considerazione il fatto che le nostre variabili
indipendenti sono corrotte dall'errore di misurazione, mentre il modello
di regressione tradizionale presuppone che le variabili indipendenti
siano misurate senza errori. Le considerazioni seguenti sono state
proposte da Kelly negli anni '20.

Come dimostrato in seguito, la formula di Kelley si basa
sull'equivalenza algebrica secondo la quale l'attendibilità è uguale al
quadrato del coefficiente di correlazione tra i punteggi osservati e i
punteggi veri. In base alla formula di Kelley, il punteggio vero di un
rispondente può essere stimato nel modo seguente mediante il modello di
regressione: 

$$
\hat{T} = \mu_x + \rho  (X - \mu_x),
(\#eq:true-score)
$$ 
laddove $X$ è il punteggio osservato, $\mu_x$ è la media dei punteggi ottenuti da tutti i rispondenti di un campione e $\rho$ è l'attendibilità del test.

Quando l'attendibilità è perfetta ($\rho = 1$), il punteggio vero è
uguale al punteggio osservato. Quando l'attendibilità è zero (tutta la
varianza è dovuta all'errore della misurazione), allora la stima
migliore del punteggio vero è data dalla media del campione. Quando
$0 < \rho < 1$, la stima del punteggio vero corrisponde ad un valore che
si discosta dal punteggio osservato nella direzione della media del
campione. La stima del punteggio vero, dunque, esibisce la proprietà
della regressione verso la media del punteggio osservato, in funzione
dell'attendibilità del test[^1].

La \@ref(eq:true-score) può essere interpretata dicendo che, per
stimare il punteggio vero di un rispondente, partiamo dalla media della
distribuzione della popolazione dei rispondenti e ci spostiamo nella
direzione del punteggio osservato di un rispondente. Tuttavia, non
raggiungiamo il valore del punteggio osservato: la quantità di cui ci
spostiamo è proporzionale all'attendibilità. In altre parole, a seconda
della dimensione di $\rho$, la stima del punteggio vero di un individuo
è dovuta, in parte, a dove si trova l'individuo in relazione al gruppo
di appartenenza: la stima del punteggio vero dell'individuo si sposterà
verso l'alto se l'individuo è collocato sotto la media del gruppo di
appartenenza e si sposterà verso il basso se l'individuo è collocato al
di sopra della media del gruppo di appartenenza. Questa equazione è
stata chiamata il *paradosso di Kelley*.

È importante sottolineare che l'interpretazione precedente rivela che la
formula di Kelley contraddice la nozione intuitiva secondo cui il
punteggio osservato può essere utilizzato quale stima del punteggio vero
(cioè, $\hat{T} = X$). Tale ragionamento ingenuo sarebbe corretto se
l'attendibilità del test fosse perfetta ($\rho = 1$). All'altra
estremità dello spettro, quando $\rho = 0$, la formula di Kelley ci
suggerisce $\mu_x$ quale stima del punteggio vero, il che è equivale a
dire che il punteggio osservato deve essere ignorato -- infatti se la
varianza di $X$ è solamente dovuta all'errore di misurazione, allora il
test è del tutto inutile quale strumento inferenziale per differenziare
le abilità dei rispondenti. Fortunatamente, in pratica è molto
improbabile che $\rho = 0$. Se $\rho$ cade tra gli estremi di 0 e 1,
allora il punteggio vero stimato sarà compreso tra il punteggio
osservato e $\mu_x$. Per capire cosa esso catturi, possiamo citare
Kelley(1947), che osservò:

::: displayquote
This is an interesting equation in that it expresses the estimate of
true ability as the weighted sum of two separate estimates, -- one based
upon the individual's observed score, $X_1$ ($X$ nella notazione
corrente) and the other based upon the mean of the group to which he
belongs, $M_1$ ($\mu_x$ nella notazione corrente). If the test is
highly reliable, much weight is given to the test score and little to
the group mean, and vice versa.
:::

::: {.proof}
Come si arriva all'equazione di Kelley? Abbiamo visto in
precedenza come l'equazione che mette in relazione il punteggio
osservato con il punteggio vero non è altro che un modello di
regressione con intercetta nulla e pendenza unitaria:
$X = 0 + 1 \cdot T + E$. In questo caso, però, il problema è diverso, in
quanto noi vogliamo _predire_ il punteggio vero sulla base del punteggio
osservato per mezzo di un modello di regressione (Nunnally, 1978).
Avendo quale scopo quello di "predire" il punteggio vero $T$ sulla base
del punteggio osservato $X$, il modello di regressione diventa

$$
T = \alpha + \beta X + \varepsilon.
$$ 

Se esprimiamo le variabili come deviazioni dalla media, $x = X - \bar{X}$ e $\tau = T - \mathbb{E}(T)$, allora l'intercetta diventa uguale a zero e il modello diventa
$\tau = \beta x + \varepsilon$, ovvero $\hat{\tau} = \beta x.$ Il
problema è quello di calcolare il coefficiente $\beta$.

Nel modello $\hat{\tau} = \beta x$, la pendenza della retta di
regressione è uguale a $\beta = \frac{\sigma_{\tau x}}{\sigma^2_x}$.
Possiamo dunque scrivere il modello di regressione nel modo seguente:

\begin{equation}
\hat{\tau} = \frac{\sigma_{\tau x}}{\sigma^2_x} x.
(\#eq:hat-t-1)
\end{equation}

La correlazione tra $x$ (o $X$) e $\tau$ (o $T$) è uguale a $\rho_{\tau x} = \frac{\sigma_{\tau x}}{\sigma_x \sigma_{\tau}}$. Dunque $\sigma_{\tau x} = \rho_{\tau x}\sigma_x \sigma_{\tau}$ e l'equazione precedente diventa 

$$
\begin{equation}
\begin{aligned}
\hat{\tau} &= \frac{\sigma_{TX}}{\sigma^2_X} X  \notag\\
&= \frac{\rho_{\tau x}\sigma_x \sigma_{\tau}}{\sigma^2_x} x \notag\\
&= \rho_{\tau x}\frac{\sigma_{\tau}}{\sigma_x} x. \notag
\end{aligned}
\end{equation}
$$

In base alla definizione di attendibilità, la varianza del punteggio vero è
$\sigma^2_{\tau} = \sigma^2_x \rho_{xx^\prime}$. Dunque, la deviazione
standard del punteggio vero diventa
$\sigma_{\tau} = \sigma_x \sqrt{\rho_{xx^\prime}}$. Sostituendo questo
risultato nell'equazione precedente otteniamo 

$$
\begin{equation}
\begin{aligned}
\hat{\tau} &= \rho_{\tau x}\frac{\sigma_x \sqrt{\rho_{xx^\prime}}}{\sigma_x} x
\notag\\
&=  \rho_{\tau x}  \sqrt{\rho_{xx^\prime}} x. \notag
\end{aligned}
\end{equation}
$$

In precedenza abbiamo visto che $\rho^2_{\tau x} = \rho_{xx^\prime}$, dunque

$$
\begin{equation}
\begin{aligned}
\hat{\tau} &= \rho_{\tau x} \sqrt{\rho_{xx^\prime}} x \notag\\
        &= \sqrt{\rho_{xx^\prime}} \sqrt{\rho_{xx^\prime}} x \notag\\
        &= \rho_{xx^\prime} x.\notag
\end{aligned}
\end{equation}
$$

In conclusione, una stima del punteggio vero si ottiene moltiplicando il punteggio osservato, espresso come deviazione dalla media, per il coefficiente di attendibilità.

Riscriviamo ora la formula appena ottenuta nei termini del punteggio grezzo $X$ (non in termini di deviazioni dalla media. Per fare ciò, sommiamo $\bar{X}$ così da ottenere

$$
\hat{T} = \rho_{XX^\prime} (X - \bar{X}) + \bar{X}, 
$$ 

laddove $\hat{T}^\prime$ è la stima del punteggio vero grezzo. Sviluppando otteniamo

$$
\begin{equation}
\begin{aligned}
\hat{T} &= \rho_{XX^\prime} (X - \bar{X}) + \bar{X}\notag\\
 &=  X\rho_{XX^\prime}  - \bar{X} \rho_{XX^\prime} + \bar{X}\notag\\
&= \bar{X} (1 - \rho_{XX^\prime}) + X\rho_{XX^\prime}\notag\\
&= \bar{X} - \bar{X}\rho_{XX'} + X\rho_{XX^\prime}\notag\\
&= \bar{X} + \rho_{XX'} (X - \bar{X}).\notag
\end{aligned}
\end{equation}
$$

Per i dati campionari, la formula diventa:

$$
\hat{T} = \bar{X} + r_{XX^\prime}  (X - \bar{X}),
$$ 

dove $X$ è il punteggio (grezzo) osservato, $\bar{X}$ è la media dei punteggi
osservati di un campione di rispondenti e $r_{XX^\prime}$ è il coefficiente di
attendibilità.
:::

:::{.exercise}
Posto un coefficiente di attendibilità pari a 0.80 e una media del test pari a $\bar{X} = 100$, si trovi una stima del punteggio vero per un rispondente con un punteggio osservato uguale a $X$ = 115.

La stima del punteggio vero $\hat{T}$ è uguale a 

$$
\begin{equation}
\begin{aligned}
\hat{T} &= \bar{X} + r_{XX^\prime}  (X - \bar{X})\notag\\
&= 100 + 0.80 \cdot (115 - 100) = 112.
\end{aligned}
\end{equation}
$$
:::

## L'errore standard della stima

Oltre a ottenere una stima del punteggio vero da un punteggio osservato,
il modello di regressione di Kelley ci fornisce anche l'errore standard
della stima. È chiaro che la stima del punteggio vero è difficile da
interpretare se non è accompagnata da una qualche indicazione sulla
precisione della stima. Tale informazione viene appunto fornita
dall'*errore standard della stima*.

Se il test potesse essere somministrato ad un rispondente più volte
sotto le identiche condizioni, sarebbe possibile ottenere in ciascuna
somministrazione una stima del valore vero $\hat{T}$. A causa
dell'errore della misurazione, il punteggio osservato non può che
variare in ciascuna ipotetica somministrazioni del test e, di
conseguenza, in ciascuna ipotetica somministrazione varierà anche la
stima di $\hat{T}$. La deviazione standard di tali (ipotetiche) stime di
$\hat{T}$ è chiamata _errore standard della stima_. L'errore standard
della stima, $\sigma_{\hat{T}}$, si calcola con la formula seguente:

$$
\begin{equation}
\sigma_{\hat{T}} = \sigma_X \sqrt{\rho_{XX^\prime} (1 -\rho_{XX^\prime})}.
(\#eq:bistd-err-estimatenom)
\end{equation}
$$

::: {.proof}
Per ricavare la (\#eq:std-err-estimate) si definisce $\varepsilon$ l'errore
che si commette quando si stima il punteggio vero $\hat{T}$ con il
punteggio osservato $T$ (si veda Lord e Novick, 1968):

$$
\varepsilon = T - \hat{T}.
$$ 

Si presti attenzione alla notazione: $E = X - T$ indica l'errore della misurazione, ovvero la differenza tra il punteggio osservato e il punteggio vero. Invece
$\varepsilon = T - \hat{T}$ indica la differenza tra il punteggio vero e
la stima del punteggio vero. Avendo che $\hat{T} = \bar{X} + \rho_{XX^\prime} (X - \bar{X})$, la varianza di $\varepsilon = T - \hat{T}$ si può scrivere come 

$$
\begin{equation}
\begin{aligned}
\mathbb{V}(\varepsilon) &=  \mathbb{V}(T - \hat{T})\notag\\
&= \mathbb{V}(T - \bar{X} - \rho_{XX^\prime} X + \rho_{XX^\prime}\bar{X}).
\end{aligned}
\end{equation}
$$

Dato che la varianza di una variabile aleatoria non cambia sommando a
tale variabile una costante, dobbiamo semplicemente calcolare

$$
\begin{equation}
\mathbb{V}(\varepsilon) = \mathbb{V}(T - \rho_{XX^\prime}X).\notag
\end{equation}
$$

Dobbiamo trovare la varianza della somma di due variabili aleatorie, una delle
quali moltiplicata per una costante. Dunque: 

$$
\mathbb{V}(\varepsilon) = \mathbb{V}(T) + \rho_{XX^\prime}^2 \mathbb{V}(X) - 2 \rho_{XX^\prime} \mbox{Cov}(X,T),
$$

ovvero, semplificando la notazione, 

$$
\begin{equation}
\sigma^2_{\varepsilon} = \sigma^2_T + \rho_{XX^\prime}^2 \sigma^2_X - 2  \rho_{XX^\prime} \sigma_{XT}.\notag
\end{equation}
$$

La quantità $\rho_{XX^\prime}$ è il coefficiente di attendibilità. Quindi

$$
\begin{equation}
\sigma^2_{\varepsilon} = \sigma^2_T + \left(\frac{\sigma_T^2}{\sigma_X^2}\right)^2 \sigma^2_X - 2  \frac{\sigma_T^2}{\sigma_X^2} \sigma_{XT}.\notag
\end{equation}
$$

Semplificando otteniamo 

$$
\begin{equation}
\begin{aligned}
\sigma^2_{\varepsilon} &= \sigma^2_T + \frac{\sigma_T^4}{\sigma_X^4}
\sigma^2_X - 2  \frac{\sigma_T^2}{\sigma_X^2} \sigma_{XT}\notag\\ 
&= \sigma^2_T + \sigma^2_T\frac{\sigma_T^2}{\sigma_X^2} -  \sigma_T^2 2
\frac{\sigma_{XT}}{\sigma_X^2} \notag\\ 
&= \sigma^2_T \left(1 + \frac{\sigma_T^2}{\sigma_X^2} - 2
  \frac{\sigma_{XT}}{\sigma_X^2}\right).\notag 
  \end{aligned}
\end{equation}
$$
  
Dato che $\sigma_{XT}=\sigma^2_T$, l'equazione precedente diventa uguale a

$$
\begin{equation}
\begin{aligned}
\sigma^2_{\varepsilon} &= \sigma^2_T \left(1
  +\frac{\sigma_T^2}{\sigma_X^2} - 2
  \frac{\sigma_{T}^2}{\sigma_X^2}\right)\notag\\
&= \sigma^2_T \left(1 - 
  \frac{\sigma_{T}^2}{\sigma_X^2}\right).
\end{aligned}
\end{equation}
$$

L'errore standard della stima è dunque uguale a 

$$
\begin{equation}
\begin{aligned}
\sigma_{\varepsilon} 
&=\sigma_T \sqrt{1-\frac{\sigma^2_T}{\sigma^2_X}}\notag\\
&=\sigma_T \sqrt{\frac{\sigma^2_X - \sigma^2_T}{\sigma^2_X}}\notag\\
&=\frac{\sigma_T}{\sigma_X} \sqrt{\sigma^2_X - \sigma^2_T}.
\end{aligned}
\end{equation}
$$

Dato che $\sigma^2_X=\sigma^2_T+\sigma^2_E$, abbiamo 

$$
\begin{equation}
\begin{aligned}
\sigma_{\varepsilon} 
 &= \frac{\sigma_T}{\sigma_X} \sqrt{\sigma^2_E }\notag\\
&=  \frac{\sigma_T}{\sigma_X} \sigma_E \notag\\
&= \sqrt{\rho_{XX^\prime}} \sigma_E. \notag
\end{aligned}
\end{equation}
$$

Ricordando che l'errore standard della misurazione è $\sigma_E = \sigma_X \sqrt{1 - \rho_{XX^\prime}}$, possiamo scrivere

$$
\begin{equation}
\begin{aligned}
\sigma_{\varepsilon}  &= \sqrt{\rho_{XX^\prime}} \sigma_E \notag\\
&= \sqrt{\rho_{XX^\prime}} \sigma_X
\sqrt{1-\rho_{XX^\prime}} \notag\\
&= \sigma_X \sqrt{\rho_{XX^\prime} (1 - \rho_{XX^\prime})}.\notag
\end{aligned}
\end{equation}
$$
:::

Per dati campionari, l'errore standard della stima si calcola nel modo
seguente: 

$$
s_{\hat{T}} = s_X \sqrt{r_{XX^\prime} (1-r_{XX^\prime})},
$$ 

dove $s_X$ è deviazione standard del campione e $r_{XX^\prime}$ è il coefficiente di
attendibilità.

## Intervallo di confidenza per il punteggio vero

L'errore standard della stima $\sigma_{\hat{T}}$ viene usato per
calcolare l'intervallo di confidenza per il punteggio vero[^2]:

$$
\hat{T} \pm z  \sigma_{\hat{T}},
$$ 

laddove $\hat{T}$ è la stima del punteggio vero e $z$ è il quantile della normale standardizzata al livello di probabilità desiderato. Se il campione è piccolo (minore di
30) è opportuno usare $t$ anziché $z$.

Si osservi che l'intervallo $\hat{T} \pm z  \sigma_{\hat{T}}$ è centrato
sulla *stima puntuale del valore vero* e ha una ampiezza che dipende sia
dal livello di copertura desiderato (da cui dipende il quantile
$z_{\frac{\alpha}{2}}$), sia dal grado di precisione dello stimatore
misurato dall'errore standard della stima,
$\sigma_{\hat{T}} = \sigma_X \sqrt{\rho_{XX^\prime} (1 -\rho_{XX^\prime})}$.
L'errore standard della stima diventa tanto più grande quanto minore è
l'attendibilità $\rho_{XX^\prime}$ del test.

L'intervallo di confidenza ricorda allo psicologo quanto sia imprecisa
la misura che utilizza: tanto più grande è l'intervallo di confidenza,
tanto maggiore è l'incertezza dell'interpretazione. L'intervallo di
confidenza è lo strumento che consente allo psicologo di giungere ad una
conclusione sapendo qual è la probabilità che tale conclusione sia
sbagliata. Se la decisione è basata su un intervallo di confidenza al
95%, la probabilità di sbagliare è 0.05. Se lo psicologo vuole che la
probabilità d'errore sia più piccola, può costruire un intervallo di
confidenza utilizzando un valore $\alpha$ minore. La diminuzione di
$\alpha$, però, produce un aumento dell'ampiezza dell'intervallo di
confidenza. Valori accettabili per $\alpha$ sono 0.1 e 0.05.

:::{.exercise}
Charter (1996) discute l'effetto della variazione dell'attendibilità del
test sull'ampiezza dell'intervallo di confidenza per il punteggio vero.
Nell'esempio considera i punteggi del QI ($\mu$ = 100, $\sigma$ = 15)
immaginando di variare il coefficiente di attendibilità del test tramite
il quale il QI viene misurato. I valori esaminati sono 0.55, 0.65, 0.75,
0.85 e 0.95. Consideriamo, ad esempio, il caso di un punteggio osservato
pari a QI = 120 e poniamo che $\rho_{xx^\prime}$ = 0.65. In tali circostanze,
la stima del punteggio vero è pari a 

$$
\begin{equation}
\begin{aligned}
\hat{T} &= \bar{X} + r_{XX^\prime}  (X - \bar{X}) \notag\\
&= 100 + 0.65 (120 - 100)\notag\\
&= 113.\notag
\end{aligned}
\end{equation}
$$

L'errore standard della stima è uguale a

$$
\begin{equation}
\begin{aligned}
\sigma_{\hat{T}} &= \sigma_{X} \sqrt{r_{XX^\prime} (1 - r_{XX^\prime})} \notag\\
&= 15 \sqrt{0.65 (1 - 0.65)}\notag\\
&= 7.15.\notag
\end{aligned}
\end{equation}
$$

L'intervallo di confidenza al 95% per la
stima del punteggio vero diventa pertanto uguale a 

$$
113 \pm 1.96 \cdot 7.15 = [98.98, 127.02].
$$ 
:::


<!-- Lo stesso risultato si ottiene con la funzione `CI.tscore()` del -->
<!-- pacchetto `psychometric` che richiede i seguenti argomenti: il punteggio -->
<!-- osservato, la media del campione, la deviazione standard del campione e -->
<!-- l'attendibilità del test: -->

<!-- ```{r} -->
<!-- library("psychometric") -->
<!-- CI.tscore(120, 100, 15, 0.65) -->
<!-- ``` -->

## Cut-off

Uno degli usi possibili degli intervalli di confidenza per il punteggio
vero è quello di confrontare i limiti dell'intervallo di confidenza con
un cut-off. Sono possibili tre alternative: il limite inferiore
dell'intervallo di confidenza è maggiore del cut-off, il limite
superiore dell'intervallo è minore del cut-off, oppure il valore del
cut-off è contenuto all'interno dell'intervallo. Nel primo caso, lo
psicologo afferma, con un grado di certezza $1 -\alpha$, che il valore
vero del rispondente è superiore al cut-off. Nel secondo caso, lo
psicologo afferma, con un grado di certezza $1 -\alpha$, che il valore
vero del rispondente è inferiore al cut-off. Nel terzo caso lo psicologo
non può concludere né che il valore vero sia inferiore né che sia
superiore al cut-off.

:::{.exercise}
Si considerino i punteggi del QI, per cui $\bar{X}$ = 100 e $s_X$ = 15.
Sia l'attendibilità del test $\rho_{XX^\prime}$ = 0.95. Supponiamo che il
rispondente abbia un QI = 130. Poniamo che il cut-off per ammettere il
rispondente ad un corso avanzato sia 120. Ci sono tre alternative: il
valore vero del rispondente è sicuramente maggiore di 120; il valore
vero del rispondente è sicuramente inferiore di 120; le evidenze
disponibili ci lasciano in dubbio se il punteggio vero sia maggiore o
minore di 120. Svolgiamo i calcoli per trovare l'intervallo di
confidenza al livello di certezza del 95%:

```{r}
xm <- 100
sx <- 15
rho <- .95
x <- 130
t.hat <- xm + rho * (x - xm)
t.hat
se.t <- sx * sqrt(rho * (1 - rho))
se.t
t.hat + c(1, -1) * qnorm(.025, 0, 1) * se.t
```
  
Dato che il limite inferiore dell'intervallo di confidenza è maggiore
del cut-off, lo psicologo conclude che il punteggio vero del rispondente
è maggiore di 120. Quindi, raccomanda che il rispondente sia ammesso al
corso avanzato.

Continuiamo con l'esempio precedente, ma supponiamo che l'attendibilità
del test abbia un valore simile a quello che solitamente si ottiene
empiricamente, ovvero 0.80.

```{r}
xm <- 100
sx <- 15
rho <- .8
x <- 130
t.hat <- xm + rho * (x - xm)
t.hat
se.t <- sx * sqrt(rho * (1 - rho))
se.t
t.hat + c(1, -1) * qnorm(.025, 0, 1) * se.t
```

In questo secondo esempio, l'intervallo di confidenza al 95% è $[112.24,
135.76]$ e contiene il valore del cut-off. Dunque, la decisione dello
psicologo è che non vi sono evidenze sufficienti che il vero valore del
rispondente sia superiore al cut-off. Si noti come la diminuzione
dell'attendibilità del test porta all'aumento delle dimensioni
dell'intervallo di confidenza.
:::

## Procedure alternative

Non vi è un unico modo per costruire gli intervalli di confidenza per il
punteggio vero. Charter e Feldt (1991) descrivono altri quattro approcci
possibili, oltre a quello discusso qui, per costruire gli intervalli di
confidenza per il punteggio vero. L'approccio che abbiamo descritto è
accettato da tutti gli autori; le procedure alternative descritte da
Charter e Feldt (1991), non sono invece accettate come valide da tutti
gli autori.

La più comune delle procedure alternative descritte da Charter e Feldt
(1991), che rappresenta l'approccio tradizionale a questo problema,
centra l'intervallo di confidenza sul punteggio osservato di un
rispondente e utilizza l'errore standard della misurazione per
calcolare i limiti dell'intervallo di confidenza:

$$
X_j \pm z_{\frac{\alpha}{2}} \sigma_E,
$$ 

dove $\sigma_E = \sigma_X \sqrt{1 -\rho_{XX^\prime}}$. Tale procedura è però stata
criticata da diversi autori (es., Dudek, 1979).
