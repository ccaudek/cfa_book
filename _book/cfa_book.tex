% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  11pt,
]{krantz}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
  \setmonofont[Scale=0.775]{MesloLGS NF}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Appunti di Costruzione e validazione di strumenti di misura dell'efficacia dell'intervento psicologico in neuropsicologia -- B020881 (B213)},
  pdfauthor={Corrado Caudek},
  colorlinks=true,
  linkcolor={Maroon},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.33,0.33,0.33}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.61,0.61,0.61}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.06,0.06,0.06}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.5,0.5,0.5}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0,0,0}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.27,0.27,0.27}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.27,0.27,0.27}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.06,0.06,0.06}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.14,0.14,0.14}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.06,0.06,0.06}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0,0,0}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.27,0.27,0.27}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.43,0.43,0.43}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0,0,0}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.5,0.5,0.5}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.5,0.5,0.5}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0,0,0}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.5,0.5,0.5}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}

\defaultfontfeatures{Scale=MatchLowercase}

\usepackage{booktabs}
\usepackage{longtable}
\usepackage[bf,singlelinecheck=off]{caption}

\usepackage{framed,color}
\definecolor{shadecolor}{RGB}{248,248,248}

\renewcommand{\textfraction}{0.05}
\renewcommand{\topfraction}{0.8}
\renewcommand{\bottomfraction}{0.8}
\renewcommand{\floatpagefraction}{0.75}

\renewenvironment{quote}{\begin{VF}}{\end{VF}}
\let\oldhref\href
\renewcommand{\href}[2]{#2\footnote{\url{#1}}}

\ifxetex
  \usepackage{letltxmacro}
  \setlength{\XeTeXLinkMargin}{1pt}
  \LetLtxMacro\SavedIncludeGraphics\includegraphics
  \def\includegraphics#1#{% #1 catches optional stuff (star/opt. arg.)
    \IncludeGraphicsAux{#1}%
  }%
  \newcommand*{\IncludeGraphicsAux}[2]{%
    \XeTeXLinkBox{%
      \SavedIncludeGraphics#1{#2}%
    }%
  }%
\fi

\makeatletter
\newenvironment{kframe}{%
\medskip{}
\setlength{\fboxsep}{.8em}
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\renewenvironment{Shaded}{\begin{kframe}}{\end{kframe}}

\usepackage{makeidx}
\makeindex

\urlstyle{tt}

\usepackage{amsthm}
\makeatletter
\def\thm@space@setup{%
  \thm@preskip=8pt plus 2pt minus 4pt
  \thm@postskip=\thm@preskip
}
\makeatother

\DeclareMathOperator{\V}{\mathbb{V}} % Define variance operator
\DeclareMathOperator{\Var}{\mathbb{V}} % Define variance operator
\DeclareMathOperator{\SD}{SD} % Define sd operator
\DeclareMathOperator{\Cov}{Cov} % Define covariance operator
\DeclareMathOperator{\Corr}{Corr} % Define correlation operator
\DeclareMathOperator{\Me}{Me} % Define mediane operator
\DeclareMathOperator{\Mo}{Mo} % Define mode operator

\DeclareMathOperator{\Bin}{Binomial} % Define binomial operator
\DeclareMathOperator{\Bernoulli}{Bernoulli} % Define Bernoulli operator
\DeclareMathOperator{\Ber}{\mathscr{B}} % Define Bernoulli operator
\DeclareMathOperator{\Poi}{Poisson} % Define Poisson operator
\DeclareMathOperator{\Uniform}{Uniform} % Define Uniform operator
\DeclareMathOperator{\Cauchy}{Cauchy} % Define Cauchy operator
\DeclareMathOperator{\B}{B} % beta function
% \mbox{B}(a, b) % beta function
% \mbox{Beta}(a, b) % beta distribution

\DeclareMathOperator{\elpd}{elpd} % Define elpd operator
\DeclareMathOperator{\lppd}{lppd} % Define lppd operator
\DeclareMathOperator{\LOO}{LOO} % Define LOO operator
\DeclareMathOperator{\argmin}{arg\,min} 
\DeclareMathOperator{\argmax}{arg\,max} 

\newcommand{\E}{\mathbb{E}} % Define expected value operator
\newcommand{\R}{\textsf{R}} % Define R programming language symbol
\newcommand{\Real}{\mathbb{R}} % Define real number operator
\newcommand{\Prob}{\mathscr{P}}
\newcommand{\indep}{\perp \!\!\! \perp}

\usepackage[
 labelfont=bf,
 font={small, it}
]{caption}
\usepackage{upquote} % print correct quotes in verbatim-environments
\usepackage{empheq}
\usepackage{xfrac}

\usepackage{polyglossia}
\setmainlanguage{italian}

\frontmatter
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{apalike}

\title{Appunti di Costruzione e validazione di strumenti di misura dell'efficacia dell'intervento psicologico in neuropsicologia -- B020881 (B213)}
\author{Corrado Caudek}
\date{2022-03-28}

\usepackage{amsthm}
\newtheorem{theorem}{Teorema}[chapter]
\newtheorem{lemma}{Lemma}[chapter]
\newtheorem{corollary}{Corollario}[chapter]
\newtheorem{proposition}{Proposizione}[chapter]
\newtheorem{conjecture}{Congettura}[chapter]
\theoremstyle{definition}
\newtheorem{definition}{Definizione}[chapter]
\theoremstyle{definition}
\newtheorem{example}{Esempio}[chapter]
\theoremstyle{definition}
\newtheorem{exercise}{Esercizio}[chapter]
\theoremstyle{definition}
\newtheorem{hypothesis}{Hypothesis}[chapter]
\theoremstyle{remark}
\newtheorem*{remark}{Osservazione}
\newtheorem*{solution}{Soluzione}
\begin{document}
\maketitle

\cleardoublepage\newpage\thispagestyle{empty}\null
% \cleardoublepage\newpage\thispagestyle{empty}\null
%\cleardoublepage\newpage
\thispagestyle{empty}
\begin{center}
\Large{Appunti di Costruzione e validazione di strumenti di misura dell'efficacia dell'intervento psicologico in neuropsicologia -- AA 2021/2022}

\vskip20pt

\includegraphics{images/actually_2x.png}
\end{center}

\setlength{\abovedisplayskip}{-5pt}
\setlength{\abovedisplayshortskip}{-5pt}

{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}
\listoffigures
\listoftables
\hypertarget{prefazione}{%
\chapter*{Prefazione}\label{prefazione}}


La presente dispensa contiene il materiale delle lezioni dell'insegnamento di \emph{Costruzione e validazione di strumenti di misura dell'efficacia dell'intervento psicologico in neuropsicologia} B020881 (B213) rivolto agli studenti del secondo anno del Corso di Laurea Magistrale in Psicologia Clinica e della Salute e Neuropsicologia (curriculum: assessment e intervento psicologici in neuropsicologia - E21), A.A. 2021-2022. L'insegnamento si propone di fornire agli studenti un'introduzione all'assessment psicologico, ovvero un insieme di conoscenze/competenze che si pongono all'intersezione tra psicometria, statistica e informatica.

Nello specifico, l'insegnamento si focalizzerà sull'analisi fattoriale confermativa (\emph{confermatory factor analysis}, CFA) e sull'analisi fattoriale esplorativa, (\emph{explorative factor analysis}, EFA), cioè sugli strumenti che vengono usati durante il processo di sviluppo dei test psicometrici, ovvero che vengono usati per esaminare la struttura latente di una scala psicologica (ad esempio un questionario). In questo contesto, la CFA viene utilizzata per verificare il numero di dimensioni sottostanti gli indicatori (fattori) e l'intensità delle relazioni item-fattore (saturazioni fattoriali). La CFA consente anche di capire di come dovrebbe essere svolto lo scoring di un test. Quando la struttura latente è multifattoriale (cioè, a due o più fattori), il numero di fattori è indicativo del numero di sottoscale e di come esse dovrebbero essere codificate. La CFA è un importante strumento analitico anche per altri aspetti della valutazione psicometrica. Può essere utilizzata per stimare l'affidabilità di scala dei test psicometrici in modo da evitare i problemi della teoria classica dei test (ad es. alpha di Cronbach). Dati i recenti progressi nell'analisi dei dati categoriali, ora la CFA offre un quadro analitico comparabile a quello offerto dalla teoria di risposta agli item (IRT). In effetti, secondo \citet{brown2015confirmatory}, la CFA offre una maggiore flessibilità analitica rispetto al modello IRT tradizionale.

Un costrutto è un concetto teorico che può essere operazionalizzato nei termini di un fattore. In psicologia clinica, psichiatria e neuropsicologia, ad esempio, i disturbi mentali sono costrutti manifestati da vari insiemi di sintomi che sono riportati dal paziente o osservati da altri. La CFA è uno strumento analitico indispensabile per la validazione dei costrutti psicologici. I risultati della CFA possono fornire prove convincenti della validità convergente e discriminante dei costrutti teorici. La validità convergente è indicata dall'evidenza che diversi indicatori di costrutti teoricamente simili o sovrapposti sono fortemente correlati. La validità discriminante è indicata dai risultati che mostrano che gli indicatori di costrutti teoricamente distinti sono altamente incorrelati. Un punto di forza fondamentale degli approcci CFA per la costruzione e la validazione di uno strumento psicometrico è che le risultanti stime di validità convergente e discriminante sono corrette per l'errore di misurazione. Pertanto, la CFA fornisce un quadro analitico migliore rispetto ai metodi tradizionali che non tengono conto dell'errore di misurazione (ad esempio, gli approcci ordinari ai minimi quadrati come la correlazione/regressione multipla, i quali presuppongono che le variabili nell'analisi siano prive di errori di misurazione).

Spesso, parte della covariazione delle misure osservate è dovuta a fonti diverse dai fattori latenti di interesse. Questa covariazione aggiuntiva spesso riflette la varianza del metodo utilizzato per la misurazione. Gli effetti del metodo possono verificarsi anche all'interno di un'unica modalità di valutazione. Ad esempio, effetti del metodo sono solitamente presenti nei questionari che contengono una combinazione di elementi formulati positivamente e negativamente. Sfortunatamente, l'EFA non è in grado di stimare gli effetti del metodo. In effetti, l'uso di EFA quando esistono effetti del metodo può produrre risultati fuorvianti, ovvero suggerire la presenza di fattori aggiuntivi che corrispondono invece ad artefatti della misurazione. Nella CFA, invece, gli effetti del metodo possono essere specificati come parte della teoria dell'errore del modello di misurazione.

Un altro punto di forza della CFA è la sua capacità di affrontare il problema della generalizzabilità del modello di misurazione tra gruppi di individui o nel tempo. La valutazione dell'invarianza della misura è un aspetto importante dello sviluppo del test. Se un test è destinato a essere somministrato in una popolazione eterogenea, si dovrebbe stabilire che le sue proprietà di misurazione sono equivalenti in sottogruppi della popolazione (es. sesso, razza). Si dice che un test è distorto quando alcuni dei suoi elementi non misurano il costrutto sottostante in modo comparabile tra gruppi di rispondenti. Il test fornisce una stima distorta se, ad esempio, per un dato livello di vera intelligenza, gli uomini tendono a ottenere un punteggio di QI più alto rispetto alle donne. Il problema della generalizzabilità della validità del costrutto tra i gruppi può essere affrontato nella CFA esaminando gruppi multipli mediante modelli MIMIC (indicatori multipli, cause multiple). Inotre, è possibile chiedersi se il modello di misurazione sia equivalente tra i gruppi. Le soluzioni CFA a gruppi multipli vengono anche utilizzate per esaminare l'invarianza della misurazione longitudinale. Questo è un aspetto molto importante dell'analisi delle variabili latenti dei progetti di misure ripetute. In assenza di tale valutazione, non è possibile determinare se il cambiamento temporale in un costrutto sia dovuto a un vero cambiamento dei rispondenti o a cambiamenti nel modo di rispondere alla scala nel tempo. L'analisi a gruppi multipli può essere applicata a qualsiasi tipo di modello CFA. Ad esempio, queste procedure possono essere incorporate nell'analisi dei dati multitratto-multimetodo per esaminare la generalizzabilità della validità del costrutto tra gruppi.

In questo insegnamento la discussione delle teciche della CFA sarà preceduta da un'introduzione relativa alla EFA e la teoria classica dei test. La EFA, infatti, può essere concepita il metodo che viene utilizzato nei primi passi dello sviluppo di una scala psicometria, mentre la teoria classica dei test rappresenta la cornice teorica di partenza, di cui la CFA e i modelli di equazioni strutturali costituiscono uno sviluppo.

L'insegnamento pone una grande enfasi non solo sulla comprensione dei concetti teorici necessari per la costruzione e la validazione di uno strumento di misura in psicologia, ma anche sulla capacità di applicare tali concetti in situazioni concrete. Di conseguenza, la discussione dei concetti sarà sempre accompagnata da applicazioni pratiche. Tali applicazioni richiedono l'uso di un software. In questo insegnamento useremo \(\textsf{R}\) \citep{rmanual} quale linguaggio di programmazione probabilistica e, tra gli altri, il pacchetto \texttt{lavaan} che consente di svolgere le analisi statistiche della CFA e della EFA \citep{beaujean2014latent}. La teoria classica dei test verrà descritta con riferimento al classico testo di \citet{lord1968statistical}. Questa dispensa, inoltre, segue da vicino la trattazione della CFA fornita nei testi di \citet{mcdonald2013test} e di \citet{brown2015confirmatory}.

Trattando di argomenti avanzati, questo insegnamento presuppone la conoscenza di base dei concetti fondamentali della teoria delle probabilità; presuppone inoltre il possesso delle conoscenze di base necessarie per procedere all'utilizzo di \(\textsf{R}\). Informazioni su tali argomenti sono forniti nella dispensa di Psicometria (A.A. 2021-2022).

\begin{flushright}
Corrado Caudek\\
Marzo 2022 \end{flushright}

\mainmatter

\hypertarget{part-il-modello-lineare}{%
\part{Il modello lineare}\label{part-il-modello-lineare}}

\hypertarget{lanalisi-di-regressione}{%
\chapter{L'analisi di regressione}\label{lanalisi-di-regressione}}

Conoscere l'analisi di regressione aiuta a capire la teoria classica dei test, l'analisi fattoriale e i modelli di equazioni strutturali. Sebbene le tecniche dell'analisi di regressione analizzino solo le variabili osservate, i principi della regressione costituiscono la base delle tecniche più avanzate che includono anche le variabili latenti.

\hypertarget{regressione-bivariata}{%
\section{Regressione bivariata}\label{regressione-bivariata}}

Il modello di regressione bivariata descrive l'associazione tra il valore atteso di \(Y \mid x_i\) e \(x\) nei termini di una relazione lineare:

\[
\mathbb{E}(Y \mid x_i) = \alpha + \beta x_i,
\] dove i valori \(x_i\) sono considerati fissi per disegno. Nel modello ``classico'', si assume che le distribuzioni \(Y \mid x_i\) siano Normali con deviazione standard \(\sigma_\varepsilon\).

Il significato dei coefficienti di regressione è semplice:

\begin{itemize}
\tightlist
\item
  \(\alpha\) è il valore atteso di \(Y\) quando \(X = 0\);
\item
  \(\beta\) è l'incremento atteso nel valore atteso di \(Y\) quando \(X\) aumenta di un'unità.
\end{itemize}

Il modello statistico della regressione bivariata è rappresentato nella figura seguente.

\begin{center}\includegraphics{cfa_book_files/figure-latex/unnamed-chunk-3-1} \end{center}

Per fare un esempio pratico, consideriamo i dati dell'antropologo Sahlins, il quale si è chiesto se esiste un'associazione tra l'ampiezza del clan (\texttt{consumers}) e l'area occupata da quel clan (\texttt{acres}) in una popolazione di cacciatori-raccoglitori. I dati sono i seguenti:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data}\NormalTok{(Sahlins)}
\FunctionTok{head}\NormalTok{(Sahlins)}
\CommentTok{\#\textgreater{}   consumers acres}
\CommentTok{\#\textgreater{} 1      1.00  1.71}
\CommentTok{\#\textgreater{} 2      1.08  1.52}
\CommentTok{\#\textgreater{} 3      1.15  1.29}
\CommentTok{\#\textgreater{} 4      1.15  3.09}
\CommentTok{\#\textgreater{} 5      1.20  2.21}
\CommentTok{\#\textgreater{} 6      1.30  2.26}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Sahlins }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ consumers, }\AttributeTok{y =}\NormalTok{ acres)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_smooth}\NormalTok{(}\AttributeTok{method =}\NormalTok{ lm, }\AttributeTok{se =} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{cfa_book_files/figure-latex/unnamed-chunk-5-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fm }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(acres }\SpecialCharTok{\textasciitilde{}}\NormalTok{ consumers, }\AttributeTok{data =}\NormalTok{ Sahlins)}
\NormalTok{fm}\SpecialCharTok{$}\NormalTok{coef}
\CommentTok{\#\textgreater{} (Intercept)   consumers }
\CommentTok{\#\textgreater{}      1.3756      0.5163}
\end{Highlighting}
\end{Shaded}

Dalla figura notiamo che, se \texttt{consumers} aumenta di un'unità (da 1.2 a 2.2), allora la retta di regressione (ovvero, il valore atteso di \(Y\)) aumenta di circa 0.5 punti -- esattamente, aumenta di 0.5163 punti, come indicato dalla stima del coefficiente \(\beta\). L'interpretazione del coefficiente \(\alpha\) è più problematica, perché non ha senso pensare ad un clan di ampiezza 0. Per affrontare questo problema, centriamo il predittore.

\hypertarget{regressori-centrati}{%
\subsection{Regressori centrati}\label{regressori-centrati}}

Esprimiamo la variabile \texttt{consumers} nei termini degli scarti dalla media:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Sahlins }\OtherTok{\textless{}{-}}\NormalTok{ Sahlins }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{xc =}\NormalTok{ consumers }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(consumers)}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

Svolgiamo nuovamente l'analisi di regressione con il nuovo predittore:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fm1 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(acres }\SpecialCharTok{\textasciitilde{}}\NormalTok{ xc, }\AttributeTok{data =}\NormalTok{ Sahlins)}
\NormalTok{fm1}\SpecialCharTok{$}\NormalTok{coef}
\CommentTok{\#\textgreater{} (Intercept)          xc }
\CommentTok{\#\textgreater{}      2.1620      0.5163}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Sahlins }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ xc, }\AttributeTok{y =}\NormalTok{ acres)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_smooth}\NormalTok{(}\AttributeTok{method =}\NormalTok{ lm, }\AttributeTok{se =} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{cfa_book_files/figure-latex/unnamed-chunk-9-1} \end{center}

La stima di \(\beta\) è rimasta invariata ma ora possiamo attribuire un significato alla stima di \(\alpha\): questo coefficiente indica il valore atteso della \(Y\) quando \(X\) assume il suo valore medio.

\hypertarget{minimi-quadrati}{%
\subsection{Minimi quadrati}\label{minimi-quadrati}}

La stima dei coefficienti del modello di regressione può essere effettuata in modi diversi: massima verosimiglianza o metodi bayesiani. Se ci limitiamo qui alla massima verosimiglianza possiamo semplificare il problema assumento che le distribuzioni condizionate \(Y \mid x\) siano Normali. In tali circostanze, la stima dei coefficienti del modello di regressione può essere trovata con il metodo dei minimi quadrati.

In pratica, questo significa trovare i coefficienti \(a\) e \(b\) che minimizzano

\[
SS_{\text{res}} = \sum(y_i - \hat{y}_i)^2,
\] con \(\hat{y}_i = a + b x_i\).

Per fornire un'idea di come questo viene fatto, usiamo una simulazione. Per semplicità, supponiamo di conoscere \(a = 1.3756445\) e di volere stimare \(b\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}}\NormalTok{ Sahlins}\SpecialCharTok{$}\NormalTok{consumers}
\NormalTok{y }\OtherTok{\textless{}{-}}\NormalTok{ Sahlins}\SpecialCharTok{$}\NormalTok{acres}
\NormalTok{a }\OtherTok{\textless{}{-}} \FloatTok{1.3756445}

\NormalTok{nrep }\OtherTok{\textless{}{-}} \FloatTok{1e3}
\NormalTok{b }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\AttributeTok{length.out =}\NormalTok{ nrep)}

\NormalTok{ssres }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\ConstantTok{NA}\NormalTok{, nrep)}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{nrep) \{}
\NormalTok{  yhat }\OtherTok{\textless{}{-}}\NormalTok{ a }\SpecialCharTok{+}\NormalTok{ b[i] }\SpecialCharTok{*}\NormalTok{ x}
\NormalTok{  ssres[i] }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{((y }\SpecialCharTok{{-}}\NormalTok{ yhat)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Un grafico di \(SS_{\text{res}}\) in funzione di \(b\) mostra che il valore \(b\) che minimizza \(SS_{\text{res}}\) corrisponde, appunto, a 0.5163.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{tibble}\NormalTok{(b, ssres) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ b, }\AttributeTok{y =}\NormalTok{ ssres)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{cfa_book_files/figure-latex/unnamed-chunk-11-1} \end{center}

\hypertarget{relazione-tra-b-e-r}{%
\subsection{\texorpdfstring{Relazione tra \(b\) e \(r\)}{Relazione tra b e r}}\label{relazione-tra-b-e-r}}

Un altro modo per interpretare \(b\) è quello di considerare la relazione tra la pendenza della retta di regressione e il coefficiente di correlazione:

\[
b_X = r_{XY} \frac{S_X}{S_Y}
\]

L'equazione precedente rende chiaro che, se i dati sono standardizzati, \(b = r\).

Verifichiamo:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Sahlins }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{select}\NormalTok{(acres, consumers) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{cor}\NormalTok{()}
\CommentTok{\#\textgreater{}            acres consumers}
\CommentTok{\#\textgreater{} acres     1.0000    0.3757}
\CommentTok{\#\textgreater{} consumers 0.3757    1.0000}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fm2 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(}\FunctionTok{scale}\NormalTok{(acres) }\SpecialCharTok{\textasciitilde{}} \FunctionTok{scale}\NormalTok{(consumers), }\AttributeTok{data =}\NormalTok{ Sahlins)}
\NormalTok{fm2}\SpecialCharTok{$}\NormalTok{coef}
\CommentTok{\#\textgreater{}      (Intercept) scale(consumers) }
\CommentTok{\#\textgreater{}        9.917e{-}17        3.757e{-}01}
\end{Highlighting}
\end{Shaded}

\hypertarget{attenuazione}{%
\subsection{Attenuazione}\label{attenuazione}}

Il fenomeno dell'attenuazione si verifica quando \(X\) viene misurato con una componente di errore. Esaminiamo la seguente simulazione.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1234}\NormalTok{)}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{100}
\NormalTok{x }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{10}\NormalTok{, }\FloatTok{1.5}\NormalTok{)}
\NormalTok{y }\OtherTok{\textless{}{-}} \FloatTok{1.5} \SpecialCharTok{*}\NormalTok{ x }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{0}\NormalTok{, }\DecValTok{2}\NormalTok{)}
\FunctionTok{tibble}\NormalTok{(x, y) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(x, y)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{cfa_book_files/figure-latex/unnamed-chunk-14-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sim\_dat }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(x, y)}
\NormalTok{fm }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x, sim\_dat)}
\NormalTok{fm}\SpecialCharTok{$}\NormalTok{coef}
\CommentTok{\#\textgreater{} (Intercept)           x }
\CommentTok{\#\textgreater{}      0.4221      1.4652}
\end{Highlighting}
\end{Shaded}

Questi sono i coefficienti di regressione quando \(X\) è misurata senza errori.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sim\_dat }\OtherTok{\textless{}{-}}\NormalTok{ sim\_dat }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{x1 =}\NormalTok{ x }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{0}\NormalTok{, }\DecValTok{2}\NormalTok{)}
\NormalTok{  )}

\NormalTok{fm1 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1, sim\_dat)}
\NormalTok{fm1}\SpecialCharTok{$}\NormalTok{coef}
\CommentTok{\#\textgreater{} (Intercept)          x1 }
\CommentTok{\#\textgreater{}      8.3872      0.6296}
\end{Highlighting}
\end{Shaded}

Aggiungendo una componente d'errore su \(X\), la grandezza del coefficiente \(b\) diminuisce.

\hypertarget{coefficiente-di-determinazione}{%
\subsection{Coefficiente di determinazione}\label{coefficiente-di-determinazione}}

Tecnicamente, il coefficiente di determinazione è dato da:

\[
R^2 = \frac{\sum(\hat{y} - \bar{y})^2}{\sum(y_i - \bar{y})^2}
\]

Al denominatore abbiamo la \emph{devianza totale}, ovvero una misura della dispersione di \(y_i\) rispetto alla media \(\bar{y}\). Al numeratore abbiamo una misura della dispersione del valore atteso della \(Y\) rispetto alla sua media. Il rapporto, dunque, ci dice qual è la quota della variabilità totale di \(Y\) che può essere predetta in base al modello lineare.

Per i dati di Sahlins abbiamo:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mod }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(acres }\SpecialCharTok{\textasciitilde{}}\NormalTok{ consumers, }\AttributeTok{data =}\NormalTok{ Sahlins)}
\NormalTok{a }\OtherTok{\textless{}{-}}\NormalTok{ mod}\SpecialCharTok{$}\NormalTok{coef[}\DecValTok{1}\NormalTok{]}
\NormalTok{b }\OtherTok{\textless{}{-}}\NormalTok{ mod}\SpecialCharTok{$}\NormalTok{coef[}\DecValTok{2}\NormalTok{]}
\NormalTok{yhat }\OtherTok{\textless{}{-}}\NormalTok{ a }\SpecialCharTok{+}\NormalTok{ b }\SpecialCharTok{*}\NormalTok{ Sahlins}\SpecialCharTok{$}\NormalTok{consumers}
\NormalTok{ss\_tot }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{((Sahlins}\SpecialCharTok{$}\NormalTok{acres }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(Sahlins}\SpecialCharTok{$}\NormalTok{acres))}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\NormalTok{ss\_reg }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{((yhat }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(Sahlins}\SpecialCharTok{$}\NormalTok{acres))}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\NormalTok{r2 }\OtherTok{\textless{}{-}}\NormalTok{ ss\_reg }\SpecialCharTok{/}\NormalTok{ ss\_tot}
\NormalTok{r2}
\CommentTok{\#\textgreater{} [1] 0.1411}
\end{Highlighting}
\end{Shaded}

Verifichiamo:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(mod)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Call:}
\CommentTok{\#\textgreater{} lm(formula = acres \textasciitilde{} consumers, data = Sahlins)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Residuals:}
\CommentTok{\#\textgreater{}     Min      1Q  Median      3Q     Max }
\CommentTok{\#\textgreater{} {-}0.8763 {-}0.1873 {-}0.0211  0.2135  1.1206 }
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Coefficients:}
\CommentTok{\#\textgreater{}             Estimate Std. Error t value Pr(\textgreater{}|t|)   }
\CommentTok{\#\textgreater{} (Intercept)    1.376      0.468    2.94   0.0088 **}
\CommentTok{\#\textgreater{} consumers      0.516      0.300    1.72   0.1026   }
\CommentTok{\#\textgreater{} {-}{-}{-}}
\CommentTok{\#\textgreater{} Signif. codes:  }
\CommentTok{\#\textgreater{} 0 \textquotesingle{}***\textquotesingle{} 0.001 \textquotesingle{}**\textquotesingle{} 0.01 \textquotesingle{}*\textquotesingle{} 0.05 \textquotesingle{}.\textquotesingle{} 0.1 \textquotesingle{} \textquotesingle{} 1}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Residual standard error: 0.454 on 18 degrees of freedom}
\CommentTok{\#\textgreater{} Multiple R{-}squared:  0.141,  Adjusted R{-}squared:  0.0934 }
\CommentTok{\#\textgreater{} F{-}statistic: 2.96 on 1 and 18 DF,  p{-}value: 0.103}
\end{Highlighting}
\end{Shaded}

Da cui deriva che \(R^2\) è uguale al quadrato del coefficiente di correlazione:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cor}\NormalTok{(Sahlins}\SpecialCharTok{$}\NormalTok{acres, Sahlins}\SpecialCharTok{$}\NormalTok{consumers)}\SpecialCharTok{\^{}}\DecValTok{2}
\CommentTok{\#\textgreater{} [1] 0.1411}
\end{Highlighting}
\end{Shaded}

\hypertarget{errore-standard-della-regressione}{%
\subsection{Errore standard della regressione}\label{errore-standard-della-regressione}}

L'errore standard della regressione è una stima della dispersione di \(y \mid x_i\) nella popolazione. Non è altro che la deviazione standard dei residui

\[
e = y_i - \hat{y}_i
\]

che, al denominatore, riporta \(n-2\). La ragione è che, per calcolare \(\hat{y}\), vengono ``perduti'' due gradi di libertà -- il calcolo di \(\hat{y}\) è basato sulla stima di due coefficienti: \(a\) e \(b\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{e }\OtherTok{\textless{}{-}}\NormalTok{ yhat }\SpecialCharTok{{-}}\NormalTok{ Sahlins}\SpecialCharTok{$}\NormalTok{acres}
\NormalTok{(}\FunctionTok{sum}\NormalTok{(e}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) }\SpecialCharTok{/}\NormalTok{ (}\FunctionTok{length}\NormalTok{(Sahlins}\SpecialCharTok{$}\NormalTok{acres) }\SpecialCharTok{{-}} \DecValTok{2}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{sqrt}\NormalTok{()}
\CommentTok{\#\textgreater{} [1] 0.4543}
\end{Highlighting}
\end{Shaded}

Il valore trovato corrisponde a quello riportato nell'output di \texttt{lm()}.

\hypertarget{regressione-multipla}{%
\section{Regressione multipla}\label{regressione-multipla}}

Nella regressione multipla vengono utilizzati \(k > 1\) predittori:

\[
y_i = \alpha + \sum_{j=1}^k \beta_j x_i + \varepsilon_i.
\]

L'interpretazione geometrica è simile a quella del modello bivariato. Nel caso di due predittori, il valore atteso della \(y\) può essere rappresentato da un piano; nel caso di \(k > 2\) predittori, da un iper-piano. Nel caso di \(k=2\), tale piano è posto in uno spazio di dimensioni \(x_1\), \(x_2\) (che possiamo immaginare definire un piano orizzontale) e \(y\) (ortogonale a tale piano). La superficie piana che rappresenta \(\mathbb{E}(y)\) è inclinata in maniera tale che l'angolo tra il piano e l'asse \(x_1\) corrisponde a \(\beta_1\) e l'angolo tra il piano e l'asse \(x_2\) corrisponde a \(\beta_2\).

\hypertarget{significato-dei-coefficienti-parziali-di-regressione}{%
\subsection{Significato dei coefficienti parziali di regressione}\label{significato-dei-coefficienti-parziali-di-regressione}}

Ai coefficienti parziali del modello di regressione multipla possiamo assegnare la seguente interpretazione:

\emph{Il coefficiente parziale di regressione \(\beta_j\) rappresenta l'incremento atteso della \(y\) se \(x_j\) viene incrementata di un'unità, tenendo costante il valore delle altre variabili indipendenti.}

Un modo per interpretare la locuzione ``al netto dell'effetto delle altre variabili indipendenti'' è quello di esaminare la relazione tra la \(y\) parzializzata e la \(x_j\) parzializzata. In questo contesto, parzializzare significa decomporre una variabile di due componenti: una componente che è linearmente predicibile da una o più altre variabili e una componente che è linearmente incorrelata con tali varibili ``terze''.

Se eseguiamo questa ``depurazione'' dell'effetto delle variabili ``terze'' sia sulla \(y\) sia su \(x_j\), possiamo poi esaminare la relazione bivariata che intercorre tra la componente della \(y\) linearmente indipendente dalle variabili ``terze'' e la componente della \(x_j\) linearmente indipendente dalle variabili ``terze''. Il coefficiente di regressione bivariato così ottenuto sarà identico al coefficiente parziale di regressione nel modello di regressione multipla. Questa procedura ci consente di assegnare un'interpretazione ``intuitiva'' al coefficiente parziale di regressione \(\beta_j\).

Esaminiamo un caso concreto.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d }\OtherTok{\textless{}{-}}\NormalTok{ rio}\SpecialCharTok{::}\FunctionTok{import}\NormalTok{(}
\NormalTok{  here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{(}\StringTok{"data"}\NormalTok{, }\StringTok{"kidiq.dta"}\NormalTok{)}
\NormalTok{)}
\FunctionTok{glimpse}\NormalTok{(d)}
\CommentTok{\#\textgreater{} Rows: 434}
\CommentTok{\#\textgreater{} Columns: 5}
\CommentTok{\#\textgreater{} $ kid\_score \textless{}dbl\textgreater{} 65, 98, 85, 83, 115, 98, 69, 106, 1\textasciitilde{}}
\CommentTok{\#\textgreater{} $ mom\_hs    \textless{}dbl\textgreater{} 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\textasciitilde{}}
\CommentTok{\#\textgreater{} $ mom\_iq    \textless{}dbl\textgreater{} 121.12, 89.36, 115.44, 99.45, 92.75\textasciitilde{}}
\CommentTok{\#\textgreater{} $ mom\_work  \textless{}dbl\textgreater{} 4, 4, 4, 3, 4, 1, 4, 3, 1, 1, 1, 4,\textasciitilde{}}
\CommentTok{\#\textgreater{} $ mom\_age   \textless{}dbl\textgreater{} 27, 25, 27, 25, 27, 18, 20, 23, 24,\textasciitilde{}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fm }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(}
\NormalTok{  kid\_score }\SpecialCharTok{\textasciitilde{}}\NormalTok{ mom\_iq }\SpecialCharTok{+}\NormalTok{ mom\_work }\SpecialCharTok{+}\NormalTok{ mom\_age }\SpecialCharTok{+}\NormalTok{ mom\_hs,}
  \AttributeTok{data =}\NormalTok{ d}
\NormalTok{)}
\NormalTok{fm}\SpecialCharTok{$}\NormalTok{coef}
\CommentTok{\#\textgreater{} (Intercept)      mom\_iq    mom\_work     mom\_age }
\CommentTok{\#\textgreater{}     20.8226      0.5621      0.1337      0.2199 }
\CommentTok{\#\textgreater{}      mom\_hs }
\CommentTok{\#\textgreater{}      5.5612}
\end{Highlighting}
\end{Shaded}

Eseguiamo la parzializzazione di \(y\) in funzione delle variabili \texttt{mom\_work}, \texttt{mom\_age} e \texttt{mom\_hs}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fm\_y }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(kid\_score }\SpecialCharTok{\textasciitilde{}}\NormalTok{ mom\_work }\SpecialCharTok{+}\NormalTok{ mom\_age }\SpecialCharTok{+}\NormalTok{ mom\_hs, }\AttributeTok{data =}\NormalTok{ d)}
\end{Highlighting}
\end{Shaded}

Lo stesso per \texttt{mom\_iq}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fm\_x }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(mom\_iq }\SpecialCharTok{\textasciitilde{}}\NormalTok{ mom\_work }\SpecialCharTok{+}\NormalTok{ mom\_age }\SpecialCharTok{+}\NormalTok{ mom\_hs, }\AttributeTok{data =}\NormalTok{ d)}
\end{Highlighting}
\end{Shaded}

Esaminiamo ora la regressione bivariata tra le componenti parzializzate della \(y\) e di \(x_j\):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mod }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(fm\_y}\SpecialCharTok{$}\NormalTok{residuals }\SpecialCharTok{\textasciitilde{}}\NormalTok{ fm\_x}\SpecialCharTok{$}\NormalTok{residuals)}
\NormalTok{mod}\SpecialCharTok{$}\NormalTok{coef}
\CommentTok{\#\textgreater{}    (Intercept) fm\_x$residuals }
\CommentTok{\#\textgreater{}     {-}1.652e{-}15      5.621e{-}01}
\end{Highlighting}
\end{Shaded}

Si vede come il coefficiente di regressione bivariato risulta identico al corrispondente coefficiente parziale di regressione.

\hypertarget{relazioni-causali}{%
\subsection{Relazioni causali}\label{relazioni-causali}}

Un altro modo per interpretare i coefficienti parziali di regressione è nell'ambito dei quelli che vengono chiamati i \emph{path diagrams}. I diagrammi di percorso, che tratteremo in seguito e qui solo anticipiamo, descrivono le relazioni ``causali'' tra variabili: le variabili a monte del diagramma di percorso rappresentano le ``cause'' esogene e le variabili a valle indicano gli effetti, ovvero le variabili endogene. I coefficienti di percorso vengono rappresentati graficamente come frecce orientate e corrispondono all'effetto \emph{diretto} sulla variabile verso cui punta la freccia della variabile a monte della freccia. In tale rappresentazione grafica, i coefficienti di percorso non sono altro che i coefficienti parziali di regressione del modello di regressione multipla. In questo contesto, indicano l'effetto \emph{diretto} atteso sulla variabile endogena in conseguenza dell'incremento di un'unità della variabile esogena, \emph{lasciano immutate tutte le altre relazioni strutturali} del modello.

Usiamo la funzione \texttt{sem()} del pacchetto \texttt{lavaan} per definire il modello rappresentato nel successivo diagramma di percorso:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model }\OtherTok{\textless{}{-}} \StringTok{"}
\StringTok{  kid\_score \textasciitilde{} mom\_hs + mom\_iq + mom\_work + mom\_age}
\StringTok{"}
\end{Highlighting}
\end{Shaded}

Adattiamo il modello ai dati

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{sem}\NormalTok{(model, }\AttributeTok{data =}\NormalTok{ d)}
\end{Highlighting}
\end{Shaded}

Il diagramma di percorso si ottiene con le seguenti istruzioni:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{semPaths}\NormalTok{(}
\NormalTok{  fit, }\StringTok{"est"}\NormalTok{,}
  \AttributeTok{posCol =} \FunctionTok{c}\NormalTok{(}\StringTok{"black"}\NormalTok{),}
  \AttributeTok{edge.label.cex =} \FloatTok{0.9}\NormalTok{,}
  \AttributeTok{sizeMan =} \DecValTok{7}\NormalTok{,}
  \AttributeTok{what =} \StringTok{"path"}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{cfa_book_files/figure-latex/unnamed-chunk-28-1} \end{center}

Come indicato nel diagramma, l'effetto diretto di \texttt{mom\_iq} su \texttt{kid\_score} è identico al corrispondente coefficiente parziale di regressione.

Il problema di capire se sia appropriato utilizzare un modello di regressione per descrivere le relazioni causali tra le variabili è affrontato nel prossimo paragrafo in riferimento all'errore di specificazione.

\hypertarget{errore-di-specificazione}{%
\subsection{Errore di specificazione}\label{errore-di-specificazione}}

Spiritosamente chiamato ``heartbreak of L.O.V.E.'' {[}Left-Out Variable Error; \citet{mauro1990understanding}{]}, l'errore di specificazione è una caratteristica fondamentale dei modelli di regressione che deve sempre essere tenuta a mente quando interpretiamo i risultati di questa tecnica di analisi statistica.

L'errore di specificazione si verifica quando escludiamo dal modello di regressione una variabile che ha due caratteristiche:

\begin{itemize}
\tightlist
\item
  è associata con altre variabili inserite nel modello,
\item
  ha un effetto diretto sulla \(y\).
\end{itemize}

Come conseguenza dell'errore di specificazione, l'intensità e il segno dei coefficienti parziali di regressione risultano sistematicamente distorti.

Consideriamo un esempio con dati simulati nei quali immaginiamo che la prestazione sia positivamente associata alla motivazione e negativamente associata all'ansia. Immaginiamo inoltre che vi sia una correlazione positiva tra ansia a motivazione. Ci chiediamo cosa succede al coefficiente parziale della variabile ``motivazione'' se la variabile ``ansia'' viene esclusa dal modello di regressione.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{400}
\NormalTok{anxiety }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{10}\NormalTok{, }\FloatTok{1.5}\NormalTok{)}
\NormalTok{motivation }\OtherTok{\textless{}{-}} \FloatTok{4.0} \SpecialCharTok{*}\NormalTok{ anxiety }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{0}\NormalTok{, }\FloatTok{3.5}\NormalTok{)}
\FunctionTok{cor}\NormalTok{(anxiety, motivation)}
\CommentTok{\#\textgreater{} [1] 0.8618}
\end{Highlighting}
\end{Shaded}

Creo la variabile \texttt{performance} come una combinazione lineare di motivazione e ansia nella quale la motivazione ha un effetto piccolo, ma positivo, sulla prestazione, e l'ansia ha un grande effetto negativo sulla prestazione:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{performance }\OtherTok{\textless{}{-}} \FloatTok{0.5} \SpecialCharTok{*}\NormalTok{ motivation }\SpecialCharTok{{-}} \FloatTok{5.0} \SpecialCharTok{*}\NormalTok{ anxiety }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{0}\NormalTok{, }\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Salvo i dati in un DataFrame:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sim\_dat2 }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(performance, motivation, anxiety)}
\end{Highlighting}
\end{Shaded}

Eseguo l'analisi di regressione specificando in maniera corretta il modello, ovvero usando come predittori sia l'ansia che la depressione:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fm1 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(performance }\SpecialCharTok{\textasciitilde{}}\NormalTok{ motivation }\SpecialCharTok{+}\NormalTok{ anxiety, sim\_dat2)}
\end{Highlighting}
\end{Shaded}

Le stime dei coefficienti parziali di regressione recuperano correttamente l'intensità e il segno dei coefficienti utilizzati nel modello generatore dei dati:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{coef}\NormalTok{(fm1)}
\CommentTok{\#\textgreater{} (Intercept)  motivation     anxiety }
\CommentTok{\#\textgreater{}      1.3712      0.4954     {-}5.1052}
\end{Highlighting}
\end{Shaded}

Eseguo ora l'analisi di regressione ignorando il predittore \texttt{anxiety} che ha le due caratteristiche di essere associato a \texttt{motivation} e di avere un effetto diretto sulla prestazione:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fm2 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(performance }\SpecialCharTok{\textasciitilde{}}\NormalTok{ motivation, sim\_dat2)}
\FunctionTok{summary}\NormalTok{(fm2)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Call:}
\CommentTok{\#\textgreater{} lm(formula = performance \textasciitilde{} motivation, data = sim\_dat2)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Residuals:}
\CommentTok{\#\textgreater{}     Min      1Q  Median      3Q     Max }
\CommentTok{\#\textgreater{} {-}13.501  {-}3.409   0.005   3.311  12.616 }
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Coefficients:}
\CommentTok{\#\textgreater{}             Estimate Std. Error t value Pr(\textgreater{}|t|)    }
\CommentTok{\#\textgreater{} (Intercept) {-}12.3972     1.4459   {-}8.57  2.2e{-}16 ***}
\CommentTok{\#\textgreater{} motivation   {-}0.4372     0.0355  {-}12.31  \textless{} 2e{-}16 ***}
\CommentTok{\#\textgreater{} {-}{-}{-}}
\CommentTok{\#\textgreater{} Signif. codes:  }
\CommentTok{\#\textgreater{} 0 \textquotesingle{}***\textquotesingle{} 0.001 \textquotesingle{}**\textquotesingle{} 0.01 \textquotesingle{}*\textquotesingle{} 0.05 \textquotesingle{}.\textquotesingle{} 0.1 \textquotesingle{} \textquotesingle{} 1}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Residual standard error: 4.87 on 398 degrees of freedom}
\CommentTok{\#\textgreater{} Multiple R{-}squared:  0.276,  Adjusted R{-}squared:  0.274 }
\CommentTok{\#\textgreater{} F{-}statistic:  151 on 1 and 398 DF,  p{-}value: \textless{}2e{-}16}
\end{Highlighting}
\end{Shaded}

Si noti che, al di là della ``significatività statistica'' (si vedano le considerazioni fornite nel paragrafo sulla stepwise regression), il risultato prodotto dal modello di regressione è totalmente sbagliato: come conseguenza dell'errore di specificazione, il segno del coefficiente parziale di regressione della variabile ``motivazione'' è negativo, anche se nel modello generatore dei dati tale coefficiente aveva il segno opposto.

Quindi, se interpretiamo il coefficiente parziale ottenuto in termini casuali, siamo portati a concludere che la motivazione fa diminuire la prestazione. Ma in realtà è vero l'opposto.

È facile vedere perché si verifica l'errore di specificazione. Supponiamo che il vero modello sia

\[
y = \alpha + \beta_1 X_1 + \beta_2 X_2 + \varepsilon
\]

il quale verrebbe stimato da

\[
y = a + b_1 X_1 + b_2 X_2 + e.
\]

Supponiamo però che il ricercatore creda invece che

\[
y = \alpha^\prime + \beta_1^\prime X_1 + \varepsilon^\prime
\]

e quindi stimi

\[
y = a^\prime + b_1^\prime X_1 + e^\prime
\]

omettendo \(X_2\) dal modello.

Per capire che relazione intercorre tra \(b_1^\prime\) e \(b_1\), iniziamo a scrivere la formula per \(b_1^\prime\):

\begin{equation}
b_1^\prime = \frac{\mbox{Cov}(X_1, Y)}{\mbox{Var}(X_1)}.
\end{equation}

Sviluppando, otteniamo

\begin{equation}
\begin{aligned}
b_1^\prime &= \frac{\mbox{Cov}(X_1, a + b_1 X_1 + b_2 X_2 + e)}{\mbox{Var}(X_1)}\notag\\
&= \frac{\mbox{Cov}(X_1, a)+b_1 \mbox{Cov}(X_1, X_1) + b_2 \mbox{Cov}(X_1, X_2) + \mbox{Cov}(X_1, e)}{\mbox{Var}(X_1)}\notag\\
&= \frac{0 + b_1 \mbox{Var}(X_1) + b_2 \mbox{Cov}(X_1, X_2) + 0}{\mbox{Var}(X_1)}\notag\\
&= b_1 + b_2 \frac{\mbox{Cov}(X_1, X_2)}{\mbox{Var}(X_1)}.
\end{aligned}
\end{equation}

Quindi, se erroneamente omettiamo \(X_2\) dal modello, abbiamo che

\begin{equation}
\mathbb{E}(b_1^\prime) = \beta_1 + \beta_2 \frac{\sigma_{12}}{\sigma_1^2}.
\label{eq:specific-err}
\end{equation}

Verifichiamo tale conclusione per i dati dell'esempio che stiamo discutendo. Nel caso presente, \(X_1\) è \texttt{motivation} e \(X_2\) è \texttt{anxiety}. Applicando la \eqref{eq:specific-err} otteniamo lo stesso valore per il coefficiente di regressione associato a \texttt{motivation} che era stato ottenuto adattando ai dati il modello \texttt{performance\ \textasciitilde{}\ motivation}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fm1}\SpecialCharTok{$}\NormalTok{coef[}\DecValTok{2}\NormalTok{] }\SpecialCharTok{+}\NormalTok{ fm1}\SpecialCharTok{$}\NormalTok{coef[}\DecValTok{3}\NormalTok{] }\SpecialCharTok{*}
  \FunctionTok{cov}\NormalTok{(sim\_dat2}\SpecialCharTok{$}\NormalTok{motivation, sim\_dat2}\SpecialCharTok{$}\NormalTok{anxiety) }\SpecialCharTok{/}
  \FunctionTok{var}\NormalTok{(sim\_dat2}\SpecialCharTok{$}\NormalTok{motivation)}
\CommentTok{\#\textgreater{} motivation }
\CommentTok{\#\textgreater{}    {-}0.4372}
\end{Highlighting}
\end{Shaded}

Possiamo dunque concludere che \(b_1^\prime\) è uno stimatore distorto di \(\beta_1\). Si noti che questa distorsione non scompare all'aumentare della numerosità campionaria, il che (in termini statistici) significa che un tale stimatore è \emph{inconsistente}. Quello che succede in pratica è che alla variabile \(X_1\) vengono attribuiti gli effetti delle variabili che sono state omesse dal modello. Si noti che una tale distorsione sistematica di \(b_1^\prime\) può essere evitata solo se si verificano due condizioni:

\begin{itemize}
\tightlist
\item
  \(\beta_2 = 0\). Questo è ovvio, dato che, se \(\beta_2 = 0\), ciò significa che il modello non è specificato in modo errato, cioè \(X_2\) non appartiene al modello perché non ha un effetto diretto sulla \(Y\).
\item
  \(\sigma_{12} = 0\). Cioè, se \(X_1\) e \(X_2\) sono incorrelate, allora l'omissione di una delle due variabili non comporta stime distorte dell'effetto dell'altra.
\end{itemize}

\hypertarget{soppressione}{%
\subsection{Soppressione}\label{soppressione}}

Le conseguenze dell'errore di specificazione sono chiamate ``soppressione'' (\emph{suppression}). In generale, si ha soppressione quando (1) il valore assoluto del peso beta di un predittore è maggiore di quello della sua correlazione bivariata con il criterio o (2) i due hanno segni opposti.

\begin{itemize}
\tightlist
\item
  L'esempio descritto sopra è un caso di \emph{soppressione negativa}, dove il predittore ha correlazioni bivariate positive con il criterio, ma si riceve un peso beta negativo nell'analisi di regressione multipla.
\item
  Un secondo tipo di soppressione è la \emph{soppressione classica}, in cui un predittore non è correlato al criterio ma riceve un peso beta diverso da zero.
\item
  C'è anche la \emph{soppressione reciproca} che può verificarsi quando due variabili sono correlate positivamente con il criterio ma negativamente tra loro.
\end{itemize}

\hypertarget{stepwise-regression}{%
\subsection{Stepwise regression}\label{stepwise-regression}}

Un'implicazione della soppressione è che i predittori non dovrebbero essere selezionati in base ai valori delle correlazioni bivariate con il criterio. Queste associazioni, dette di ordine zero, non controllano gli effetti degli altri predittori, quindi i loro valori possono essere fuorvianti rispetto ai coefficienti di regressione parziale per le stesse variabili. Per lo stesso motivo, il fatto che le correlazioni bivariate con il criterio siano statisticamente significative o meno è irrilevante per quanto riguarda la selezione dei predittori. Sebbene le procedure informatiche di regressione rendano facile i processi di selezione dei predittori in base a tali criteri, tali procedure sono da evitare. Il rischio è che anche piccole, ma non rilevate, non-linearità o effetti indiretti tra i predittori possano seriamente distocere i coefficienti di regressione parziale. È meglio selezionare giudiziosamente il minor numero di predittori sulla base di ragioni teoriche o dei risultati di ricerche precedenti. In altri termini, le procedure di stepwise regression non dovrebbero mai essere usate.

Una volta che sono stati selezionati, i predittori possono essere inseriti nell'equazione di regressione in due modi diversi:

\begin{itemize}
\tightlist
\item
  tutti i predittori possono essere inseriti nel modello contemporaneamente;
\item
  i predittori possono essere inseriti nel modello sequenzialmente, mediante una serie di passaggi.
\end{itemize}

L'ordine di ingresso può essere determinato in base a standard: teorici (razionali) o empirici (statistici). Lo standard razionale corrisponde alla \emph{regressione gerarchica}, in cui si comunica al computer un ordine fisso per inserire i predittori. Ad esempio, a volte le variabili demografiche vengono inserite nel primo passaggio, quindi nel secondo passaggio viene inserita una variabile psicologica di interesse. Questo ordine non solo controlla le variabili demografiche ma permette anche di valutare il potere predittivo della variabile psicologica, al di là di quello delle semplici variabili demografiche. Quest'ultimo può essere stimato come l'aumento della correlazione multipla al quadrato, o \(\Delta R^2\), da quella della fase 1 con solo predittori demografici a quella della fase 2 con tutti i predittori nell'equazione di regressione.

Un esempio di standard statistico è la regressione \emph{stepwise}, in cui il computer seleziona l'inserimento dei predittori in base esclusivamente alla significatività statistica; cioè, viene chiesto: quale predittore, se inserito nell'equazione, avrebbe il valore\_\(p\) più piccolo per il test del suo coefficiente di regressione parziale? Dopo la selezione, i predittori in una fase successiva possono essere rimossi dall'equazione di regressione in base ai loro valori-\(p\) (ad esempio, se \(p \geq\) .05). Il processo stepwise si interrompe quando, aggiungendo più predittori, \(\Delta R^2\) non migliora. Varianti della regressione stepwise includono \emph{forward inclusion}, in cui i predittori selezionati non vengono successivamente rimossi dal modello, e \emph{backward elimination}, che inizia con tutti i predittori nel modello per poi rimuoverne alcuni in passi successivi. Per le ragioni descritte nel paragrafo sull'errore di specificazione, i metodi basati sulle procedure di stepwise regression non dovrebbero mai essere usati. Infatti, i problemi relativi a tale procedura sono così gravi che varie riviste non accettano studi che fanno uso di una tale tecnica statistica. I risultati ottenuti con tali metodi, infatti, sono quasi certamente non replicabili in campioni diversi.

Una considerazione finale riguarda l'idea di rimuovere i predittori ``non significativi'' dal modello di regressione. Questa è una cattiva idea. Il ricercatore non deve sentirsi in dovere di trascurare quei predittore che non risultano ``statisticamente significativi''. In campioni piccoli, la potenza dei test di significatività è bassa e la rimozione di un predittore non significativo può alterare sostanzialmente la soluzione. Se c'è una buona ragione per includere un predittore, allora è meglio lasciarlo nel modello, fino a prova contraria. In termini generali, qualsiasi considerazione basata sulla ``significatività statistia'' è fuorviante.

\hypertarget{part-la-teoria-classica-dei-test}{%
\part{La teoria classica dei test}\label{part-la-teoria-classica-dei-test}}

\hypertarget{ch:teoria_classica}{%
\chapter{Fondamenti teorici}\label{ch:teoria_classica}}

\hypertarget{valutazione-psicometrica-come-ragionamento-inferenziale}{%
\section{Valutazione psicometrica come ragionamento inferenziale}\label{valutazione-psicometrica-come-ragionamento-inferenziale}}

In apparenza, i test psicometrici sono solo dei test. Somministriamo un test, otteniamo un punteggio ed è naturale pensare che sia tutto lì. Nonostante le apparenze, la valutazione psicologica e neuropsicologica non consiste soltanto nell'assegnare di punteggi: si tratta di ragionare su ciò che osserviamo di quello che le persone dicono, fanno o producono, in maniera tale da giungere a delle concezioni più ampie di tali persone a proposito di aspetti che non abbiamo -- e spesso non possiamo -- osservare. Più specificamente, possiamo considerare la valutazione psicologica e neuropsicologica come un esempio di ragionamento che fa uso di modelli probabilistici per giungere a delle spiegazioni, previsioni o conclusioni.

I dati osservati diventano un'evidenza quando sono ritenuti rilevanti per l'inferenza desiderata attraverso l'instaurazione di relazioni tra i dati e l'obiettivo dell'inferenza. Spesso utilizziamo dati provenienti da più fonti. Queste possono essere di tipo simile (ad esempio, item di test aventi lo stesso formato) o di tipo molto diverso (ad esempio, il curriculum di un richiedente oltre al colloquio, la storia medica della famiglia di un paziente, \(\dots\)). Le evidenze possono essere contraddittorie (ad esempio, uno studente riesce a svolgere un compito difficile ma fallisce in un uno facile) e quasi sempre non sono del tutto conclusive.

Queste caratteristiche hanno due implicazioni. In primo luogo, è difficile capire cosa le evidenze implicano. I processi inferenziali sono sempre complessi. In secondo luogo, a causa della natura non conclusiva delle evidenze disponibili, non siamo mai del tutto certi delle nostre inferenze. Per affrontare tale incertezza, la teoria psicometria ci fornisce gli strumenti che ci possono aiutare nel processo inferenziale, dai dati disponibili alle decisioni che prendiamo.

Un secolo fa, la relazione tra prestazioni osservate, da un lato, e l'abilità inosservabile del rispondente, dall'altro, iniziò a essere formalizzata nei termini dell'\emph{errore di misurazione}. \citet{gulliksen1961measurement} ha descritto ``il problema centrale della teoria dei test'' come ``la relazione tra l'abilità dell'individuo e il suo punteggio osservato sul test'' (p.~101). Tale caratterizzazione è valida ancora oggi, con una definizione opportunamente ampia di ``abilità'' e di ``punteggio sul test'' che sia in grado di comprendere le diverse forme di assessment psicologico e neuropsicologico. Comprendere e essere in grado di rappresentare la relazione tra le prestazioni osservate e la capacità soggiacente è dunque fondamentale per le forme di ragionamento che vengono impiegate nella valutazione psicologica e neuropsicologica.

Come risultato dell'errore di misurazione, i ragionamenti che compiamo nella valutazione psicologica e neuropsicologica costituiscono un esempio di ragionamento in condizioni di incertezza. A causa della natura imperfetta della misurazione e dell'incompletezza dell'informazione disponibile, le nostre inferenze sono incerte e possono essere sempre invalidate o riviste. Ragionare da ciò che è parziale (ciò che vediamo uno paziente dire, fare o produrre) a ciò che è generale (la ``vera'' abilità del paziente) è necessariamente incerto, e le nostre inferenze o conclusioni sono sempre prone ad errori.

Quali strumenti devono essere impiegati per affrontare la nostra incertezza sulla relazione che intercorre tra prestazioni osservate e abilità soggiacenti? Secondo Lewis, molti dei progressi nella teoria psicometrica sono resi possibili ``trattando lo studio della relazione tra le risposte agli item di un test e il tratto ipotizzato di un individuo come problema di inferenza statistica'' \citep{lewis1986test}. Una connessione diretta tra errore di misura e approccio probabilistico è stata anche proposta da Samejima: ``There may be an enormous number of factors eliciting a student's specific overt reactions to a stimulus, and, therefore, it is suitable, even necessary, to handle the situation in terms of the probabilistic relationship between the two'' \citep{samejima1983constant}.

Questo punto di vista è diventato quello dominante nella psicometria moderna e sottolinea l'utilità di utilizzare il linguaggio e gli strumenti della teoria della probabilità per comunicare il carattere parziale dei dati di cui dispone lo psicologo e l'incertezza delle inferenze che ne derivano.

I reattivi psicologici possono essere costruiti e la validati mediante vari approcci probabilistici: la Teoria Classica dei test (\emph{classical test theory}, in breve CTT) e la teoria di risposta all'item (\emph{item response theory}, in breve IRT) sono quelli più noti. Recentemente, il problema della valutazione psicologica è stato anche formulato in un'ottica bayesiana. In questo insegnamento esamineremo la CTT e i suoi sviluppi più recenti.

\hypertarget{la-teoria-classica}{%
\section{La Teoria Classica}\label{la-teoria-classica}}

La CTT nasce alla fine dell'Ottocento (Alfred Binet e altri, 1894) allo scopo di studiare l'attendibilità e la validità dei risultati dei questionari utilizzati per valutare le caratteristiche psico-sociali, non direttamente osservabili, delle persone esaminate. L'impiego su vasta scala e lo sviluppo della CTT ha inizio negli anni Trenta, anche se il modello formale su cui tale teoria si basa viene proposta da Spearman all'inizio del Novecento \citep{ch1904general}. La tecnica dell'analisi fattoriale esplorativa (\emph{Exploratory Factor Analysis}, EFA), verrà poi affinata da \citet{thurstone1947multiple} alla fine della seconda guerra mondiale. Tra la fine degli anni '60 e gli inizi degli anni '70, \citet{joreskog1969general} sviluppa l'analisi fattoriale confermativa (\emph{Confirmatory Factor Analysis}, CFA). Negli anni '70, l'analisi fattoriale viene integrata con la path analysis nel lavoro di \citet{joreskog1978structural} che dà origine ai modelli di equazioni strutturali (\emph{Structural Equation Modeling}, SEM).

Iniziamo qui ad esaminare queste tecniche psicometriche prendendo in esame, per prima, la teoria classica dei test. Seguiremo la trattazione proposta da \citet{lord1968statistical}.

L'equazione fondamentale alla quale si riconduce la teoria classica dei test è quella che ipotizza una relazione lineare e additiva tra il punteggio osservato di un test (\(X\)), la misura della variabile latente (\(T\)) e la componente casuale dell'errore (\(E\)). L'aspetto cruciale nella CTT riguarda la varianza dell'errore. Minore è la varianza dell'errore, più accuratamente il punteggio reale viene riflesso dai nostri punteggi osservati. In un mondo perfetto, tutti i valori di errore sarebbero uguali a 0. Cioè, ogni partecipante otterrebbe il punteggio esatto. Questo però non è possibile. Pertanto, abbiamo una certa varianza negli errori. La corrispondente deviazione standard di tali errori ha il un nome: si chiama \emph{errore standard di misurazione}, indicato da \(\sigma_E\). Uno dei principali obiettivi della CTT è quello di ottenere una stima di \(\sigma_E\) in modo da potere valutare la qualità di una scala psicometrica.

\hypertarget{le-due-componenti-del-punteggio-osservato}{%
\section{Le due componenti del punteggio osservato}\label{le-due-componenti-del-punteggio-osservato}}

CTT si occupa delle relazioni tra \(X\), \(T\) ed \(E\). La CTT si basa su un modello relativamente semplice in cui il punteggio osservato, nel quale il punteggio vero (cioè l'abilità inosservabile del rispondente) e l'errore aleatorio di misurazione sono legati da una relazione lineare. Indicati con \(T_{\nu j}\) (\emph{true score}) l'abilità latente da misurare dell'individuo \(\nu\) nella prova \(j\), con \(X_{\nu j}\) la variabile osservata (\emph{observed score}) per l'individuo \(\nu\) nella prova \(j\) e con \(E_{\nu j}\) l'errore aleatorio di misurazione, il modello è

\begin{equation}
X_{\nu j} = T_{\nu} + E_{\nu j}. 
\label{eq:observed-true-plus-error}
\end{equation}

Dunque, in base alla \eqref{eq:observed-true-plus-error} il punteggio osservato \(X_{\nu j}\) differisce da quello vero \(T_{\nu j}\) a causa di una componente di errore casuale la quale viene assunta essere \(E_{\nu j} \sim \mathcal{N}(0, \sigma_E)\). Uno degli obiettivi centrali della CTT è quello di quantificare l'entità di tale errore (ovvero, di stimare \(\sigma_E\)). Vedremo come questa quantificazione verrà fornita in due forme: l'attendibilità del test e la stima dell'errore standard della misurazione.

\begin{itemize}
\tightlist
\item
  L'attendibilità (o affidabilità) rappresenta l'accuratezza con cui un test può misurare il punteggio vero (Coaley, 2014) e corrisponde al rapporto tra la varianza dei punteggi veri e la varianza dei punteggi osservati:

  \begin{itemize}
  \tightlist
  \item
    se l'attendibilità è grande, \(\sigma_E\) è piccolo -- \(X\) ha un piccolo errore di misurazione e sarà vicino a \(T\).
  \item
    se l'attendibilità è piccola, \(\sigma_E\) è grande -- \(X\) presenta un grande errore di misurazione e si discosterà molto da \(T\).
  \end{itemize}
\item
  La stima dell'errore standard della misurazione è appunto una stima della deviazione standard della variabile casuale \(E\) (ovvero \(\sigma_E\)) che corrompe i punteggi veri.
\end{itemize}

\hypertarget{il-punteggio-vero}{%
\subsection{Il punteggio vero}\label{il-punteggio-vero}}

La \eqref{eq:observed-true-plus-error} ci dice che il punteggio osservato è dato dalla somma di due componenti: una componente sistematica (il punteggio vero) e una componente casuale (l'errore di misurazione). Ma che cos'è il punteggio vero? CTT attribuisce diverse interpretazioni al punteggio vero.

\begin{itemize}
\tightlist
\item
  La CTT considera un reattivo psicologico come una selezione casuale di item da un universo/popolazione di item attinenti al costrutto da misurare \citep{nunnally1994psychometric, kline2013handbook}. Se il reattivo psicologico viene concepito in questo modo, il punteggio vero diventa il punteggio che un rispondente otterrebbe se fosse misurato su tutto l'universo degli item proprio del costrutto in esame. L'errore di misurazione riflette dunque il grado in cui gli item che costituiscono il test non riescono a rappresentare l'intero universo degli item attinenti al costrutto.
\item
  In maniera equivalente, il punteggio vero può essere concepito come il punteggio non ``distorto'' da componenti estranee al costrutto, ovvero da effetti di apprendimento, fatica, memoria, motivazione, eccetera. Essendo concepita come del tutto casuale (ovvero, priva di qualunque natura sistematica), la componente casuale non introduce alcun bias nella tendenza centrale della misurazione (la media di \(E\) viene assunta essere uguale a 0).
\item
  In termini puramente statistici, il punteggio vero è un punteggio inosservabile che corrisponde al valore atteso di infinite realizzazioni del punteggio ottenuto:
\end{itemize}

\[
T = \E(X) \equiv \mu_X \equiv \mu_{T}.
\]

Combinando la seconda e la terza definizione presentate sopra, \citet{lord1968statistical} concepiscono il punteggio vero come la media dei punteggi che un soggetto otterrebbe se il test venisse somministrato ripetutamente nelle stesse condizioni, in assenza di effetti di apprendimento e/o fatica.

\hypertarget{somministrazioni-ripetute}{%
\subsection{Somministrazioni ripetute}\label{somministrazioni-ripetute}}

Nella formulazione del modello della CTT si possono distinguere due tipi di esperimenti aleatori: uno che considera l'unità di osservazione (l'individuo) come campionaria, l'altro che considera il punteggio, per un determinato individuo, come una variabile casuale. Un importante risultato è dato dall'unione dei due esperimenti casuali, ovvero dalla dimostrazione che i risultati della CTT, la quale è stata sviluppata ipotizzando ipotetiche somministrazioni ripetute del test allo stesso individuo sotto le medesime condizioni, si generalizzano al caso di una singola somministrazione del test ad un campione di individui \citep{allen2001introduction}. In base a questo risultato, se consideriamo la somministrazione del test ad una popolazione di individui, allora diventa più facile assegnare un contenuto empirico alle quantità della CTT:

\begin{itemize}
\tightlist
\item
  \(\sigma^2_X\) è la varianza del punteggio osservato nella popolazione,
\item
  \(\sigma^2_T\) è la varianza dei punteggio vero nella popolazione,
\item
  \(\sigma^2_E\) è la varianza della componente d'errore nella popolazione.
\end{itemize}

\hypertarget{le-assunzioni-sul-punteggio-ottenuto}{%
\subsection{Le assunzioni sul punteggio ottenuto}\label{le-assunzioni-sul-punteggio-ottenuto}}

La CTT \emph{assume} che la media del punteggio osservato \(X\) sia uguale alla media del punteggio vero,

\[
\mu_X \equiv \mu_{T},
\label{eq:assunzione-media-x-media-t}
\]

in altri termini, assume che il punteggio osservato fornisca una stima statisticamente corretta dell'abilità latente (punteggio vero).

In pratica, il punteggio osservato non sarà mai uguale all'abilità latente, ma corrisponde solo ad uno dei possibili punteggi che il soggetto può ottenere, subordinatamente alla sua abilità latente. L'errore della misura è la differenza tra il punteggio osservato e il punteggio vero:

\[E \equiv X - T.\]

In base all'assunzione secondo cui il valore atteso dei punteggi è uguale alla media del valore vero, segue che

\[
\E(E) = \E(X - T) = \E(X) - \E(T) = \mu_{T} - \mu_{T} = 0,
\]

ovvero, il valore atteso degli errori è uguale a zero.

\hypertarget{lerrore-standard-della-misurazione-sigma_e}{%
\section{\texorpdfstring{L'errore standard della misurazione \(\sigma_E\)}{L'errore standard della misurazione \textbackslash sigma\_E}}\label{lerrore-standard-della-misurazione-sigma_e}}

La radice quadrata della varianza degli errori di misurazione, ovvero la deviazione standard degli errori, \(\sigma_E\), è la quantità fondamentale della CTT ed è chiamata \emph{errore standard della misurazione}. La stima dell'errore standard della misurazione costituisce uno degli obiettivi più importanti della CTT.

Ricordiamo che la deviazione standard è simile (ma non identica) alla media del valore assoluto degli scarti dei valori di una distribuzione dalla media. Possiamo dunque utilizzare questa proprietà per descrivere il modo in cui la CTT interpreta \(\sigma_E\). In altre parole, l'errore standard della misurazione \(\sigma_E\) ci dice qual è, approssimativamente, la variazione attesa del punteggio osservato, se il test venisse somministrato ripetute volte al rispondente sotto le stesse condizioni (in assenza di effetti di apprendimento o di fatica).

\hypertarget{assiomi-della-teoria-classica}{%
\section{Assiomi della Teoria Classica}\label{assiomi-della-teoria-classica}}

La CTT \emph{assume} che gli errori siano delle variabili casuali incorrelate tra loro

\[
\rho(E_i, E_k \mid T) = 0, \qquad\text{con}\; i \neq k,
\]

e incorrelate con il punteggio vero,

\[
\rho(E, T) = 0,
\]

le quali seguono una distribuzione gaussiana con media zero e deviazione standard pari a \(\sigma_E\):

\[
E \sim \mathcal{N}(0, \sigma_E).
\]

La quantità \(\sigma_E\) è appunto chiamata errore standard della misurazione. Sulla base di tali assunzioni la CTT deriva la formula dell'attendibilità di un test. Si noti che le assunzioni della CTT hanno una corrispondenza puntuale con le assunzioni su cui si basa il modello di regressione lineare.

\hypertarget{lattendibilituxe0-del-test}{%
\section{L'attendibilità del test}\label{lattendibilituxe0-del-test}}

In questo paragrafo vedremo come il coefficiente di attendibilità (altri termini che vengono usati sono: affidabilità, costanza, credibilità) fornisce una stima della quota della varianza del punteggio osservato che può essere attribuita all'abilità latente (``punteggio vero'', cioè privo di errore di misurazione). In generale, un coefficiente di attendibilità maggiore di 0.80 viene ritenuto soddisfacente perché indica che l'80\% o più della varianza dei punteggi ottenuti è causata da ciò che il test intende misurare, anziché dall'errore di misurazione.

Per definire l'attendibilità, la CTT si serve di due quantità:

\begin{itemize}
\tightlist
\item
  la varianza del punteggio osservato,
\item
  la correlazione tra punteggio osservato e punteggio vero.
\end{itemize}

Vediamo come queste quantità possano essere ottenute sulla base delle assunzioni del modello statistico che sta alla base della CTT.

\hypertarget{la-varianza-del-punteggio-osservato}{%
\subsection{La varianza del punteggio osservato}\label{la-varianza-del-punteggio-osservato}}

La varianza del punteggio osservato \(X\) è uguale alla somma della varianza del punteggio vero e della varianza dell'errore di misurazione.

\begin{proof}
La varianza del punteggio osservato è uguale a

\[
\sigma^2_X =  \V(T+E) =  \sigma_T^2 + \sigma_E^2 + 2 \sigma_{TE}.
\label{eq:3-2-4}
\]

Dato che \(\sigma_{TE}=\rho_{TE}\sigma_T \sigma_E=0\), in quanto \(\rho_{TE}=0\), ne segue che

\[
\sigma^2_X =   \sigma_T^2 + \sigma_E^2.
\label{eq:var-sum}
\]
\end{proof}

\hypertarget{la-covarianza-tra-punteggio-osservato-e-punteggio-vero}{%
\subsection{La covarianza tra punteggio osservato e punteggio vero}\label{la-covarianza-tra-punteggio-osservato-e-punteggio-vero}}

La covarianza tra punteggio osservato \(X\) e punteggio vero \(T\) è uguale alla varianza del punteggio vero.

\begin{proof}
La covarianza tra punteggio osservato e punteggio vero è uguale a

\[
\begin{aligned}
\sigma_{X T} &= \E(XT) - \E(X)\E(T)\notag\\
&=  \E[(T+E)T] - \E(T+E)\E(T)\notag\\
&=  \E(T^2) + \underbrace{\E(ET)}_{=0} - [\E(T)]^2 -  \underbrace{\E(E)}_{=0} \E(T)\notag\\
&=\E(T^2) - [\E(T)]^2\notag \\
&= \sigma_T^2.
\end{aligned}
\]
\end{proof}

\hypertarget{correlazione-tra-punteggio-osservato-e-punteggio-vero}{%
\subsection{Correlazione tra punteggio osservato e punteggio vero}\label{correlazione-tra-punteggio-osservato-e-punteggio-vero}}

La correlazione tra punteggio osservato \(X\) e punteggio vero \(T\) è uguale al rapporto tra la covarianza tra \(X\) e \(T\) divisa per il prodotto delle due deviazioni standard:

\begin{equation}
\begin{aligned}
\rho_{XT} &= \frac{\sigma_{XT}}{\sigma_X \sigma_T} = \frac{\sigma^2_{T}}{\sigma_X \sigma_T} = \frac{\sigma_{T}}{\sigma_X}.
\label{eq:sd-ratio}
\end{aligned}
\end{equation}

\hypertarget{definizione-e-significato-dellattendibilituxe0}{%
\subsection{Definizione e significato dell'attendibilità}\label{definizione-e-significato-dellattendibilituxe0}}

Sulla base della \eqref{eq:sd-ratio} giungiamo alla definizione dell'attendibilità. La CTT definisce attendibilità di un test (o di un item) come il quadrato della correlazione tra punteggio osservato \(X\) e punteggio vero \(T\), ovvero come il rapporto tra la varianza del punteggio vero e la varianza del punteggio osservato:

\begin{equation}
\rho_{XT}^2 = \frac{\sigma_{T}^2}{\sigma_X^2}.
\label{eq:reliability-1}
\end{equation}

Questa è la quantità fondamentale della CTT e misura il grado di variazione del punteggio vero rispetto alla variazione del punteggio osservato. Dato che \(\sigma^2_X = \sigma_T^2 + \sigma_E^2\), in base alla \eqref{eq:reliability-1} possiamo scrivere

\begin{equation}
\begin{aligned}
\rho_{XT}^2 &= \frac{\sigma_{T}^2}{\sigma_X^2} =\frac{\sigma_{X}^2 - \sigma^2_E}{\sigma_X^2}
 = 1-\frac{\sigma_{E}^2}{\sigma_X^2}.
 \label{eq:3-2-6}
\end{aligned}
\end{equation}

Questo significa che il coefficiente di attendibilità assume valore \(1\) se la varianza degli errori \(\sigma_{E}^2\) è nulla e assume valore \(0\) se la varianza degli errori è uguale alla varianza del punteggio osservato. Il coefficiente di attendibilità è dunque un numero puro contenuto nell'intervallo compreso tra \(0\) e \(1\).

\hypertarget{attendibilituxe0-e-modello-di-regressione-lineare}{%
\section{Attendibilità e modello di regressione lineare}\label{attendibilituxe0-e-modello-di-regressione-lineare}}

Il modello di regressione lineare sta alla base della CTT. Infatti si può dire che tutte le proprietà della CTT che abbiamo discusso in precedenza non sono altro che le caratteristiche di un modello di regressione lineare nel quale

\begin{itemize}
\tightlist
\item
  i punteggi osservati \(X\) sono la variabile dipendente,
\item
  i punteggi veri \(T\) sono la variabile indipendente.
\end{itemize}

Se rappresentiamo la CTT in questo modo, il coefficiente di attendibilità \(\rho_{XT}^2 = \frac{\sigma_{T}^2}{\sigma_X^2}\) non diventa altro che la quota di varianza del punteggio osservato \(X\) che viene spiegata dal punteggio vero \(T\) in base ad un modello lineare con pendenza unitaria e intercetta nulla:

\[
X = 0 + 1 \cdot T + E.
\]

Nei termini di una tale rappresentazione, il coefficiente di attendibilità è uguale al coefficiente di determinazione del modello di regressione.

\hypertarget{simulazione}{%
\subsection{Simulazione}\label{simulazione}}

Per dare un contenuto concreto alle affermazioni precedenti, consideriamo la seguente simulazione svolta in \(\textsf{R}\). In tale simulazione il punteggio vero \(T\) e l'errore \(E\) sono creati in modo tale da soddisfare i vincoli della CTT: \(T\) e \(E\) sono variabili casuali gaussiane tra loro incorrelate. Nella simulazione generiamo 100 coppie di valori \(X\) e \(T\) con i seguenti parametri: \(T \sim \mathcal{N}(\mu_T = 12, \sigma^2_T = 6)\), \(E \sim \mathcal{N}(\mu_E = 0, \sigma^2_T = 3)\):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}
\FunctionTok{library}\NormalTok{(}\StringTok{"MASS"}\NormalTok{)}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{100}
\NormalTok{Sigma }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{6}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{3}\NormalTok{), }\AttributeTok{byrow =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{ncol =} \DecValTok{2}\NormalTok{)}
\NormalTok{Sigma}
\CommentTok{\#\textgreater{}      [,1] [,2]}
\CommentTok{\#\textgreater{} [1,]    6    0}
\CommentTok{\#\textgreater{} [2,]    0    3}
\NormalTok{mu }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{12}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{mu}
\CommentTok{\#\textgreater{} [1] 12  0}
\NormalTok{Y }\OtherTok{\textless{}{-}} \FunctionTok{mvrnorm}\NormalTok{(n, mu, Sigma, }\AttributeTok{empirical =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{T }\OtherTok{\textless{}{-}}\NormalTok{ Y[, }\DecValTok{1}\NormalTok{]}
\NormalTok{E }\OtherTok{\textless{}{-}}\NormalTok{ Y[, }\DecValTok{2}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

Le istruzioni precedenti (\texttt{empirical\ =\ TRUE}) creano un campione di valori nei quali le medie e la matrice di covarianze assumono esattamente i valori richiesti. Possiamo dunque immaginare tale insieme di dati come la ``popolazione''.

Secondo la CTT, il punteggio osservato è \(X = T + E\). Simuliamo dunque il punteggio osservato \(X\) come:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{X }\OtherTok{\textless{}{-}}\NormalTok{ T }\SpecialCharTok{+}\NormalTok{ E}
\end{Highlighting}
\end{Shaded}

Le prime 6 osservazioni così ottenute sono:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{head}\NormalTok{(}\FunctionTok{cbind}\NormalTok{(T, E, X))}
\CommentTok{\#\textgreater{}           T       E      X}
\CommentTok{\#\textgreater{} [1,] 11.148 {-}1.5708  9.577}
\CommentTok{\#\textgreater{} [2,] 13.138 {-}0.3335 12.804}
\CommentTok{\#\textgreater{} [3,] 10.391  2.5457 12.937}
\CommentTok{\#\textgreater{} [4,] 11.452 {-}0.1955 11.257}
\CommentTok{\#\textgreater{} [5,]  9.978 {-}0.4920  9.486}
\CommentTok{\#\textgreater{} [6,] 10.730  2.9609 13.691}
\end{Highlighting}
\end{Shaded}

Un diagramma di dispersione è fornito nella figura seguente:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{tibble}\NormalTok{(X, T) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(X, T)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{cfa_book_files/figure-latex/unnamed-chunk-40-1} 

}

\caption{Simulazione della relazione tra punteggio osservato e punteggio vero per 100 individui in base alle assunzioni della CTT.}\label{fig:unnamed-chunk-40}
\end{figure}

Secondo la CTT, il valore atteso di \(T\) è uguale al valore atteso di \(X\). Verifichiamo questa assunzione nei nostri dati:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mean}\NormalTok{(T)}
\CommentTok{\#\textgreater{} [1] 12}
\FunctionTok{mean}\NormalTok{(X)}
\CommentTok{\#\textgreater{} [1] 12}
\end{Highlighting}
\end{Shaded}

L'errore deve avere media zero, varianza \(\sigma_E^2\) e deve essere incorrelato con \(T\):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mean}\NormalTok{(E)}
\CommentTok{\#\textgreater{} [1] 4.061e{-}18}
\FunctionTok{var}\NormalTok{(E)}
\CommentTok{\#\textgreater{} [1] 3}
\FunctionTok{cor}\NormalTok{(T, E)}
\CommentTok{\#\textgreater{} [1] {-}1.947e{-}16}
\end{Highlighting}
\end{Shaded}

Ricordiamo che la radice quadrata della varianza degli errori è l'errore standard della misurazione, \(\sigma_E\). La quantità \(\sqrt{\sigma_E^2}\) fornisce una misura della dispersione del punteggio osservato attorno al valore vero, nella condizione ipotetica di ripetute somministrazioni del test:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sqrt}\NormalTok{(}\DecValTok{3}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 1.732}
\end{Highlighting}
\end{Shaded}

Dato che \(T\) e \(E\) sono incorrelati, ne segue che la varianza del punteggio osservato \(X\) è uguale alla somma della varianza del punteggio vero \(T\) e della varianza degli errori \(E\):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{var}\NormalTok{(X)}
\CommentTok{\#\textgreater{} [1] 9}
\FunctionTok{var}\NormalTok{(T) }\SpecialCharTok{+} \FunctionTok{var}\NormalTok{(E)}
\CommentTok{\#\textgreater{} [1] 9}
\end{Highlighting}
\end{Shaded}

La varianza del punteggio vero \(T\) è uguale alla covarianza tra il punteggio vero \(T\) e il punteggio osservato \(X\):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{var}\NormalTok{(T)}
\CommentTok{\#\textgreater{} [1] 6}
\FunctionTok{cov}\NormalTok{(T, X)}
\CommentTok{\#\textgreater{} [1] 6}
\end{Highlighting}
\end{Shaded}

La correlazione tra punteggio osservato e punteggio vero è uguale al rapporto tra la deviazione standard del punteggio vero e la deviazione standard del punteggio osservato:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cor}\NormalTok{(X, T)}
\CommentTok{\#\textgreater{} [1] 0.8165}
\FunctionTok{sd}\NormalTok{(T) }\SpecialCharTok{/} \FunctionTok{sd}\NormalTok{(X)}
\CommentTok{\#\textgreater{} [1] 0.8165}
\end{Highlighting}
\end{Shaded}

Per la CTT, l'attendibilità è uguale al quadrato del coefficiente di correlazione tra il punteggio vero \(T\) e il punteggio osservato \(X\), ovvero:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cor}\NormalTok{(X, T)}\SpecialCharTok{\^{}}\DecValTok{2}
\CommentTok{\#\textgreater{} [1] 0.6667}
\end{Highlighting}
\end{Shaded}

La motivazione di questa simulazione è quella di mettere in relazione il coefficiente di attendibilità, calcolato con la formula della CTT (come abbiamo fatto sopra), con il modello di regressione lineare. Analizziamo dunque i dati della simulazione mediante il seguente modello di regressione lineare:

\[
X = a + b T + E.
\]

Usando \(\textsf{R}\) otteniamo:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fm }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(X }\SpecialCharTok{\textasciitilde{}}\NormalTok{ T)}
\FunctionTok{summary}\NormalTok{(fm)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Call:}
\CommentTok{\#\textgreater{} lm(formula = X \textasciitilde{} T)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Residuals:}
\CommentTok{\#\textgreater{}    Min     1Q Median     3Q    Max }
\CommentTok{\#\textgreater{} {-}4.197 {-}1.101  0.052  1.155  4.239 }
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Coefficients:}
\CommentTok{\#\textgreater{}             Estimate Std. Error t value Pr(\textgreater{}|t|)    }
\CommentTok{\#\textgreater{} (Intercept) 8.53e{-}15   8.75e{-}01       0        1    }
\CommentTok{\#\textgreater{} T           1.00e+00   7.14e{-}02      14   \textless{}2e{-}16 ***}
\CommentTok{\#\textgreater{} {-}{-}{-}}
\CommentTok{\#\textgreater{} Signif. codes:  }
\CommentTok{\#\textgreater{} 0 \textquotesingle{}***\textquotesingle{} 0.001 \textquotesingle{}**\textquotesingle{} 0.01 \textquotesingle{}*\textquotesingle{} 0.05 \textquotesingle{}.\textquotesingle{} 0.1 \textquotesingle{} \textquotesingle{} 1}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Residual standard error: 1.74 on 98 degrees of freedom}
\CommentTok{\#\textgreater{} Multiple R{-}squared:  0.667,  Adjusted R{-}squared:  0.663 }
\CommentTok{\#\textgreater{} F{-}statistic:  196 on 1 and 98 DF,  p{-}value: \textless{}2e{-}16}
\end{Highlighting}
\end{Shaded}

Si noti che la retta di regressione ha intercetta 0 e pendenza 1. Questo è coerente con l'assunzione \(\E(X) = \E(T)\). Ma il risultato più importante di questa simulazione è che il coefficiente di determinazione (\(R^2\) = 0.67) del modello di regressione \(X = 0 + 1 \times T + E\) è identico al coefficiente di attendibilità che si può calcolare con la formula \(\rho_{XT}^2 = \frac{\sigma_{T}^2}{\sigma_X^2}\):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{var}\NormalTok{(T) }\SpecialCharTok{/} \FunctionTok{var}\NormalTok{(X)}
\CommentTok{\#\textgreater{} [1] 0.6667}
\end{Highlighting}
\end{Shaded}

Ciò ci consente di interpretare il coefficiente di attendibilità nel modo seguente: l'attendibilità di un test non è altro che la quota di varianza del punteggio osservato \(X\) che viene spiegata dalla regressione di \(X\) sul punteggio vero \(T\) in un modello di regressione lineare dove \(\alpha\) = 0 e \(\beta\) = 1.

\hypertarget{misurazioni-parallele-e-affidabilituxe0}{%
\section{Misurazioni parallele e affidabilità}\label{misurazioni-parallele-e-affidabilituxe0}}

L'equazione \(\rho_{XT}^2 = \frac{\sigma_{T}^2}{\sigma_X^2}\) definisce il coefficiente di attendibilità ma non ci fornisce gli strumenti per calcolarlo in pratica, dato che la varianza del punteggio vero \(\sigma_{T}^2\) è una quantità incognita. Il metodo utilizzato dalla CTT per ottenere una stima empirica dell'attendibilità è quello delle \emph{forme parallele} del test: se è possibile elaborare versioni alternative dello stesso test che risultino equivalenti tra loro in termini di contenuto, modalità di risposta e caratteristiche statistiche, allora diventa anche possibile stimare il coefficiente di attendibilità.

Secondo la CTT, due test \(X=T+E\) e \(X^\prime=T^\prime+E^\prime\) si dicono misurazioni parallele della stessa abilità latente se

\begin{itemize}
\tightlist
\item
  \(T = T^\prime\),
\item
  \(\V(E) = \V(E^\prime)\).
\end{itemize}

Da tali assunzioni segue che \(\E(X) = \E(X^\prime)\).

\begin{proof}
Dato che \(\E(X) = T\) e che \(\E(X^\prime) = T\), è immediato vedere che \(\E(X) =\E(X^\prime)\) in quanto \(\E(E) = \E(E^\prime) = 0\).
\end{proof}

In maniera corrispondente, anche le varianze dei punteggi osservati di due misurazioni parallele devono essere uguali, \(\V(X) = \V(X^\prime)\).

\begin{proof}
Per \(X\) abbiamo che \(\V(X) = \V(T + E) = \V(T) + \V(E)\); per \(X^\prime\) abbiamo che \(\V(X^\prime) = \V(T^\prime + E^\prime) = \V(T^\prime) + \V(E^\prime)\). Dato che \(\V(E) = \V(E^\prime)\) e che \(T = T^\prime\), ne segue che \(\V(X) = \V(X^\prime)\).
\end{proof}

Per costruzione, inoltre, gli errori \(E\) e \(E^\prime\) devono essere incorrelati con \(T\) e tra loro.

\hypertarget{la-correlazione-tra-due-forme-parallele-del-test}{%
\subsection{La correlazione tra due forme parallele del test}\label{la-correlazione-tra-due-forme-parallele-del-test}}

Dimostriamo ora che, in base alle assunzioni della CTT, la correlazione tra due forme parallele del test è uguale al rapporto tra la varianza del punteggio vero e la varianza del punteggio osservato.

\begin{proof}
Assumendo, senza perdita di generalità, che \(\E(X)=\E(X')=\E(T)=0\), possiamo scrivere

\begin{equation}
\begin{aligned}
\rho_{X X^\prime} &= \frac{\sigma(X, X^\prime)}{\sigma(X) \sigma(X^\prime)}\notag\\
&= \frac{\E(XX^\prime)}{\sigma(X) \sigma(X^\prime)}\notag\\
&=\frac{\E[(T+E)(T+E^\prime)]}{\sigma(X) \sigma(X^\prime)}\notag\\
&=\frac{\E(T^2)+\E(TE^\prime)+\E(TE)+ \E(EE^\prime)}{\sigma(X) \sigma(X^\prime)}.\notag
\end{aligned}
\end{equation}

Ma \(\E(TE) = \E(TE^\prime) = \E(EE^\prime)=0\). Inoltre, \(\sigma(X) =\sigma(X^\prime)= \sigma_X\). Dunque,

\begin{equation}
\rho_{X X^\prime} =\frac{\E(T^2)}{\sigma_X \sigma_X} = \frac{\sigma^2_T}{\sigma^2_X}.
\label{eq:3-3-5}
\end{equation}
\end{proof}

Si noti come la \eqref{eq:3-3-5} e l'equazione che definisce il coefficiente di attendibilità, ovvero \(\rho_{XT}^2 = \frac{\sigma_{T}^2}{\sigma_X^2}\), riportano tutte e due la stessa quantità a destra dell'uguale. Otteniamo così un importante risultato: il coefficiente di attendibilità, ovvero il quadrato del coefficiente di correlazione tra il punteggio osservato e il punteggio vero, è uguale alla correlazione tra il valore osservato di due misurazioni parallele:

\begin{equation}
\rho^2_{XT} =  \rho_{XX^\prime}.
\label{eq:rho2xt-rhoxx}
\end{equation}

Tale risultato è importante perché consente di esprimere la quantità inosservabile \(\rho^2_{XT}\) nei termini della quantità \(\rho_{XX^\prime}\) che può essere calcolata sulla base dei punteggi osservati di due forme parallele del test. Quindi, la stima di \(\rho^2_{XT}\) si riduce alla stima di \(\rho^2_{XX^\prime}\). Per questa ragione, la \eqref{eq:rho2xt-rhoxx} è forse la formula più importante della CTT.

\hypertarget{la-correlazione-tra-punteggio-osservato-e-punteggio-vero}{%
\subsection{La correlazione tra punteggio osservato e punteggio vero}\label{la-correlazione-tra-punteggio-osservato-e-punteggio-vero}}

Consideriamo ora la correlazione tra punteggio osservato e punteggio vero. La \eqref{eq:rho2xt-rhoxx} si può scrivere come

\[
\rho_{XT} = \sqrt{\rho_{XX^\prime}}.
\]

In altri termini: la radice quadrata del coefficiente di attendibilità è uguale alla correlazione tra il punteggio osservato e il punteggio vero.

\hypertarget{i-fattori-che-influenzano-lattendibilituxe0}{%
\subsection{I fattori che influenzano l'attendibilità}\label{i-fattori-che-influenzano-lattendibilituxe0}}

Considerando le tre equazioni

\[
\rho^2_{XT} = \rho_{XX'},\quad
\rho_{XT}^2 = \frac{\sigma_{T}^2}{\sigma_X^2}, \quad
\rho_{XT}^2 = 1-\frac{\sigma_{E}^2}{\sigma_X^2},
\]

possiamo dire che ci sono tre modi equivalenti per concludere che l'attendibilità di un test è alta. L'attendibilità di un test è alta

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  se è alta la correlazione tra le forme parallele del test,
\item
  se è grande la varianza del punteggio vero relativamente alla varianza del punteggio osservato,
\item
  se è piccola la varianza dell'errore di misura relativamente alla varianza del punteggio osservato.
\end{enumerate}

Tali considerazioni hanno importanti implicazioni per le scelte che devono guidare la costruzione di un test. Si consideri, in particolare, l'equazione \(\rho^2_{XT} = \rho_{XX'}\). Se interpretiamo \(\rho_{XX'}\) come la correlazione tra due item, allora tale equazione ci fornisce un criterio per la scelta degli item da includere in un test: devono essere inclusi nel test gli item che correlano maggiormente tra loro. In questo modo, infatti, l'attendibilità del test aumenterà perché gli item inclusi nel test sono maggiormente correlati con il punteggio vero.

\hypertarget{metodi-alternativi-per-la-stima-del-coefficiente-di-attendibilituxe0}{%
\section{Metodi alternativi per la stima del coefficiente di attendibilità}\label{metodi-alternativi-per-la-stima-del-coefficiente-di-attendibilituxe0}}

Come si stima in pratica l'affidabilità? Un modo grossolano (e molto impreciso) consiste nel somministrare allo stesso gruppo di individui lo stesso test in due differenti momenti e di calcolare il coefficiente di correlazione dei punteggi totali (\emph{test-retest reliability}). \citet{mcdonald2013test} afferma che tale procedura può essere giustificata in due modi diversi. La prima giustificazione è basata sull'assunzione che il valore vero non varia tra le due somministrazioni del test. Se le cose stanno in questo modo, gli errori saranno indipendenti e la correlazione tra il punteggio osservato nelle due somministrazioni ci fornirà una stima di \(\rho_{XX^\prime}\). Il problema è che non disponiamo di nessuno strumento per distinguere questa situazione ideale dal caso in cui viene violata l'assunzione dell'invarianza del punteggio vero. Una seconda giustificazione del metodo test-retest ci porta a definire il punteggio vero di retest come la componente del punteggio osservato che non varia tra le due somministrazioni. Il tal senso, il coefficiente di attendibilità viene concepito come un coefficiente di stabilità temporale. In generale, maggiore è l'intervallo temporale tra le due somministrazioni, minore sarà il valore del coefficiente di stabilità temporale. Uno dei problemi del metodo test-retest è che due somministrazioni successive di un test ci forniscono soltanto un sottoinsieme delle possibili informazioni che verrebbero raccolte da uno studio longitudinale che copre un periodo temporale maggiore. Se tale studio longitudinale venisse eseguito, potremmo trovare la funzione che descrive la variazione del punteggio osservato in funzione del tempo. In generale, tale funzione non può essere descritta da un singolo parametro. Resta aperta la domanda di quale sia relazione tra questa funzione e il coefficiente di attendibilità.

Se sono disponibili due forme parallele dello stesso test, l'affidabilità può essere calcolata mediante il coefficiente di correlazione dei punteggi totali dei due test (\emph{parallel-forms reliability}), valendo l'uguaglianza \(\rho_{XX^\prime} = \rho^2_{XT}\). Anche questo metodo, come il metodo del test-retest, non è esente da errori.

Il metodo di stima più diffuso è quello dell'attendibilità come consistenza interna (\emph{internal consistency reliability}), originariamente ricavato da \citet{kuder1937theory} per item dicotomici e poi generalizzato da \citet{cronbach1951coefficient} per item a risposte ordinali. L'idea su cui si basa consiste nel fatto che ogni singolo item del test, se confrontato con tutti gli altri, può essere usato per stimare l'affidabilità del test. L'analisi degli item valuta dunque la misura in cui gli item del test sono espressione dello stesso costrutto.

\hypertarget{ch:err_stnd_mis}{%
\chapter{L'incertezza della misura}\label{ch:err_stnd_mis}}

Lord e Novick (1968) fanno notare come l'errore \(E = X - T\) sia la variabile aleatoria di primario interesse per la CTT, in quanto lo scopo è stimare il punteggio vero di ciascun rispondente e confrontare le stime ottenute nel caso di rispondenti diversi. La grandezza dell'errore che si commette utilizzando il punteggio osservato quale misura del punteggio vero può essere quantificata mediante la deviazione standard di \(E\), ovvero mediante ciò che viene chiamato l'\emph{errore standard della misurazione}, \(\sigma_E\) (\emph{Standard Error of Measurement}, \emph{SEM}). Ma come è possibile stimare \(\sigma_E\)?

\hypertarget{la-stima-dellerrore-standard-della-misurazione}{%
\section{La stima dell'errore standard della misurazione}\label{la-stima-dellerrore-standard-della-misurazione}}

L'errore standard della misurazione quantifica il grado di incertezza presente nei punteggi di un test. Può essere dimostrato che una stima dell'errore standard della misurazione (\(\sigma_E\)) è data da:

\[
\sigma_E = \sigma_X \sqrt{1 -\rho_{XX^\prime}},
\label{eq:err-stnd-mis}
\]

dove \(\sigma_X\) è la deviazione standard dei punteggi ottenuti in un campione di rispondenti e \(\rho_{XX^\prime}\) è il coefficiente di attendibilità. Per stimare \(\sigma_E\) è dunque necessario sottrarre da uno l'attendibilità del test, prendere la radice quadrata della differenza e moltiplicare la radice quadrata per la deviazione standard dei punteggi del test.

Si noti che l'errore standard della misurazione \(\sigma_E\) è direttamente associato all'attendibilità del test: l'errore standard della misurazione diminuisce al crescere dell'attendibilità del test. Se l'attendibilità del test è uguale a 0 \(\sigma_E\) diventa uguale alla deviazione standard del punteggio osservato del test. Se l'attendibilità del test è uguale a 1 \(\sigma_E\) diventa uguale a zero: se il test è perfettamente affidabile non ci sono errori e \(\sigma_E\) è uguale a zero.

\hypertarget{interpretazione}{%
\subsection{Interpretazione}\label{interpretazione}}

McDonald afferma che il termine \(E\) segue una \emph{propensity distribution}, ovvero rappresenta le fluttuazioni casuali nel tempo di un rispondente, che corrispondono a fluttuazioni di umore, motivazione, ecc. L'errore standard della misura fornisce una stima della deviazione standard di tali punteggi, ovvero una stima della deviazione standard dei punteggi che un un singolo individuo otterrebbe nel caso di ipotetiche infinite somministrazioni di un test (o di forme parallele di un test) sotto le stesse identiche condizioni, se il punteggio vero rimane costante.

La CTT assume i punteggi ottenuti da un individuo, nel caso di ipotetiche infinite somministrazioni di un test nelle stesse identiche condizioni, abbiano una distribuzione normale centrata sul valore vero. L'errore standard della misurazione è la stima della deviazione standard di una tale distribuzione di punteggi ipotetici. Maggiore è l'errore standard della misurazione, maggiore è l'errore che si compie usando il test per valutare l'abilità latente del rispondente.

Il coefficiente di attendibilità, la varianza dell'errore e l'errore standard della misurazione sono tutti indicatori diretti o indiretti della precisione del test. Tuttavia, questi indici forniscono informazioni diverse sul grado di precisione del test:

\begin{itemize}
\tightlist
\item
  l'errore standard della misurazione ci consente di fare inferenze sulla precisione del punteggio osservato di un singolo rispondente, ma non è possibile assegnare tale interpretazione al coefficiente di attendibilità;
\item
  l'errore standard della misurazione è espresso nella stessa unità di misura del punteggio osservato, mentre la varianza di \(E\) è espressa nei termini del quadrato del punteggio osservato;
\item
  l'attendibilità corrisponde ad un rapporto tra varianze e dunque è un numero puro (privo di unità di misura).
\end{itemize}

Supponiamo che un test di intelligenza produca un punteggio medio pari a 100 con una deviazione standard di 15. Supponiamo inoltre che il test abbia una attendibilità pari a 0.73. Si calcoli l'errore standard della misurazione.

Applicando la formula dell'errore standard della misurazione, otteniamo

\begin{equation}
\begin{aligned}
\sigma_E &= \sigma_X \sqrt{1 -\rho_{XX^\prime}} \notag\\
&= 15 \sqrt{1 - 0.73} \notag\\
&= 7.79.\notag
\end{aligned}
\end{equation}

Il valore di 7.79 significa che, se immaginiamo di somministrare molte volte il test ad un rispondente, sotto le stesse identiche condizioni, ci aspettiamo che i valori ottenuti differiscano tra loro, in media, di circa 8 punti tra le successive somministrazioni del test. Inoltre, se immaginiamo di somministrare molte volte il test ad un rispondente, sotto le stesse identiche condizioni, ci aspettiamo che il 95\% dei punteggi così ottenuti sia compreso nell'intervallo

\[
\text{punteggio vero del rispondente} \pm 1.96 \cdot \text{errore standard della misurazione}. 
\] Questa è una proprietà della distribuzione gaussiana.

Per il caso presente, questo intervallo è uguale a \(2 \cdot 1.96 \cdot 7.79 = 30.54\) punti. In altre parole, ci possiamo aspettare che, nel caso di somministrazioni ripetute del test sotto le stesse identiche condizioni, i punteggi del QI di un singolo rispondente varino tra loro all'interno di un intervallo di 30 punti. Ciò significa che, se il test avesse un'attendibilità pari a 0.73, e se la deviazione standard dei punteggi del test nella popolazione fosse pari a 15, la somministrazione di un tale test ad un singolo individuo sarebbe di scarsa utilità, a causa dell'enorme errore di misurazione. Per fare un confronto con i dati di questo esempio, la Full Scale IQ (FSIQ) della WAIS-IV \citep{wechsler2008wechsler} ha un'attendibilità split-half pari a 0.98, con errore standard di misurazione pari a 2.16.

Continuando con l'esempio precedente, per gli ipotetici dati riportati sopra, poniamoci ora la seguente domanda: qual è la probabilità che un rispondente ottenga un punteggio minore o uguale a 116 nel test, se il suo punteggio vero è uguale a 120?

Il problema si risolve rendendosi conto che i punteggi del rispondente si distribuiscono normalmente attorno al punteggio vero di 120, con una deviazione standard uguale a 7.79. Dobbiamo dunque trovare l'area sottesa alla normale \(\mathcal{N}(120, 7.79)\) nell'intervallo \([-\infty, 116]\). Utilizzando , la soluzione si trova nel modo seguente:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pnorm}\NormalTok{(}\DecValTok{116}\NormalTok{, }\DecValTok{120}\NormalTok{, }\FloatTok{7.79}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 0.3038}
\end{Highlighting}
\end{Shaded}

Se la variabile aleatorie corrispondente al punteggio osservato segue una distribuzione \(\mathcal{N}(120, 7.79)\), la probabilità che il rispondente ottenga un punteggio minore o uguale a 116 è dunque uguale a 0.30.

Poniamoci ora la seguente domanda: quale intervallo di valori centrato sul punteggio vero contiene, con una probabilità di 0.95, i punteggi che il rispondente otterrebbe in ipotetiche somministrazioni ripetute del test sotto le stesse identiche condizioni?

Dobbiamo trovare i quantili della distribuzione \(\mathcal{N}(120, 7.79)\) a cui sono associate le probabilità di 0.025 e 0.975. La soluzione è dunque data da:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{qnorm}\NormalTok{(}\FunctionTok{c}\NormalTok{(.}\DecValTok{025}\NormalTok{, .}\DecValTok{975}\NormalTok{), }\DecValTok{120}\NormalTok{, }\FloatTok{7.79}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 104.7 135.3}
\end{Highlighting}
\end{Shaded}

L'intervallo cercato è dunque \([104.7, 135.3]\).

\hypertarget{simulazione-1}{%
\subsection{Simulazione}\label{simulazione-1}}

Ritorniamo ora alla simulazione precedente nella quale abbiamo messo in relazione il modello della CTT con il modello di regressione lineare. In base a tale simulazione, poniamoci lo scopo di chiarire il significato dell'errore standard della misurazione.

Impostiamo la simulazione come abbiamo fatto in precedenza. Chiamiamo \(X\) il valore osservato in un test. Per la CTT, il punteggio osservato \(X\) è costituito da due componenti, la componente vera \(T\) e la componente d'errore \(E\). Si suppone che gli errori siano gaussiani e incorrelati con la componente vera. Immaginiamo di somministrare 200 volte il test ad un individuo sotto le stesse identiche condizioni.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(}\StringTok{"MASS"}\NormalTok{)}
\FunctionTok{library}\NormalTok{(}\StringTok{"arm"}\NormalTok{)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{200}
\NormalTok{Sigma }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}
  \FunctionTok{c}\NormalTok{(}
    \DecValTok{11}\NormalTok{, }\DecValTok{0}\NormalTok{,}
    \DecValTok{0}\NormalTok{, }\DecValTok{4}
\NormalTok{  ),}
  \AttributeTok{byrow =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{ncol =} \DecValTok{2}
\NormalTok{)}
\NormalTok{mu }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{100}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{Y }\OtherTok{\textless{}{-}} \FunctionTok{mvrnorm}\NormalTok{(n, mu, Sigma, }\AttributeTok{empirical =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{T }\OtherTok{\textless{}{-}}\NormalTok{ Y[, }\DecValTok{1}\NormalTok{]}
\NormalTok{E }\OtherTok{\textless{}{-}}\NormalTok{ Y[, }\DecValTok{2}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

Verifichiamo l'incorrelazione tra \(T\) ed \(E\):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cor}\NormalTok{(T, E)}
\CommentTok{\#\textgreater{} [1] {-}1.069e{-}16}
\end{Highlighting}
\end{Shaded}

I valori ottenuti sono la somma del valore vero e della componente d'errore:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{X }\OtherTok{\textless{}{-}}\NormalTok{ T }\SpecialCharTok{+}\NormalTok{ E}
\end{Highlighting}
\end{Shaded}

Per questi dati, il coefficiente di attendibilità è uguale a:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rxx }\OtherTok{\textless{}{-}} \FunctionTok{cor}\NormalTok{(X, T)}\SpecialCharTok{\^{}}\DecValTok{2}
\NormalTok{rxx}
\CommentTok{\#\textgreater{} [1] 0.7333}
\end{Highlighting}
\end{Shaded}

Possiamo ora calcolare l'errore standard della misurazione utilizzando la \eqref{eq:err-stnd-mis}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sd}\NormalTok{(X) }\SpecialCharTok{*} \FunctionTok{sqrt}\NormalTok{(}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ rxx)}
\CommentTok{\#\textgreater{} [1] 2}
\end{Highlighting}
\end{Shaded}

Si noti che tale valore non è altro che la deviazione standard degli errori della misurazione:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sd}\NormalTok{(E)}
\CommentTok{\#\textgreater{} [1] 2}
\end{Highlighting}
\end{Shaded}

Ovvero, nei termini del modello di regressione \(X = 0 + 1 \cdot T + E\), l'errore standard della misurazione corrisponde all'errore standard della regressione:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fm }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(}\AttributeTok{formula =}\NormalTok{ X }\SpecialCharTok{\textasciitilde{}}\NormalTok{ T)}
\FunctionTok{summary}\NormalTok{(fm)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Call:}
\CommentTok{\#\textgreater{} lm(formula = X \textasciitilde{} T)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Residuals:}
\CommentTok{\#\textgreater{}    Min     1Q Median     3Q    Max }
\CommentTok{\#\textgreater{} {-}4.432 {-}1.404 {-}0.147  1.219  7.212 }
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Coefficients:}
\CommentTok{\#\textgreater{}              Estimate Std. Error t value Pr(\textgreater{}|t|)    }
\CommentTok{\#\textgreater{} (Intercept) {-}1.93e{-}13   4.29e+00     0.0        1    }
\CommentTok{\#\textgreater{} T            1.00e+00   4.29e{-}02    23.3   \textless{}2e{-}16 ***}
\CommentTok{\#\textgreater{} {-}{-}{-}}
\CommentTok{\#\textgreater{} Signif. codes:  }
\CommentTok{\#\textgreater{} 0 \textquotesingle{}***\textquotesingle{} 0.001 \textquotesingle{}**\textquotesingle{} 0.01 \textquotesingle{}*\textquotesingle{} 0.05 \textquotesingle{}.\textquotesingle{} 0.1 \textquotesingle{} \textquotesingle{} 1}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Residual standard error: 2.01 on 198 degrees of freedom}
\CommentTok{\#\textgreater{} Multiple R{-}squared:  0.733,  Adjusted R{-}squared:  0.732 }
\CommentTok{\#\textgreater{} F{-}statistic:  545 on 1 and 198 DF,  p{-}value: \textless{}2e{-}16}
\end{Highlighting}
\end{Shaded}

Si noti che, nell'output di \(\textsf{R}\) fornito sopra, l'errore standard della regressione, ovvero \texttt{residual\ sd}, corrisponde a 2.01 anziché a 2.0. Ciò si verifica in quanto \(\textsf{R}\) ha calcolato una stima della deviazione standard dei residui nella popolazione utilizzando, al denominatore, \(n - 2\). Nel nostro caso è invece necessario dividere per \(n\) in quanto i dati della simulazione sono quelli della popolazione, non di un campione.

\hypertarget{dimostrazione}{%
\section{Dimostrazione}\label{dimostrazione}}

Poniamoci ora il problema di derivare la formula dell'errore standard della misurazione. Per derivare la formula \(\sigma_E = \sigma_X \sqrt{1 -\rho_{XX^\prime}}\) sono necessari due passi: prima dobbiamo trovare la varianza del punteggio vero; poi dobbiamo esprimere il punteggio osservato come la somma della varianza del punteggio vero e la varianza dell'errore.

\begin{proof}
In base alla definizione del coefficiente di attendibilità \(\rho_{XX^\prime} = \frac{\sigma^2_T}{\sigma^2_X}\) possiamo scrivere \(\sigma^2_T = \rho_{XX^\prime} \sigma^2_X\), dove \(X\) e \(X^\prime\) sono due forme parallele di un test. Ricordiamo che misurazioni parallele hanno le seguenti proprietà: \(\E(X) = \E(X^\prime)\) e \(\V(X) = \V(X^\prime)\). Dato che \(\sigma_{X}=\sigma_{X^\prime}\), l'equazione precedente diventa \(\sigma^2_T = \rho_{XX^\prime} \sigma_X\sigma_{X^\prime}.\) Utilizzando la definizione della covarianza tra \(X\) e \(X^\prime\), ovvero, \(\sigma_{XX^\prime}=\rho_{XX^\prime}\sigma_X\sigma_{X^\prime}\), possiamo concludere che la varianza del punteggio vero è uguale alla covarianza tra due misurazioni parallele:

\[
\sigma^2_T =  \sigma_{XX^\prime}.
\]

Essendo l'attendibilità del test il rapporto tra la varianza del punteggio vero e la varianza del punteggio osservato, ed essendo che la varianza del punteggio vero uguale alla covarianza tra due misurazioni parallele, possiamo concludere che l'attendibilità aumenta all'aumentare della covarianza media tra gli item del test. Si noti come questo importante risultato della CTT dipenda dall'ipotesi di omogeneità delle varianze degli item del test.

Calcoliamo ora la varianza di \(E\). La varianza del punteggio osservato è uguale a \(\sigma^2_X = \sigma^2_T + \sigma^2_E.\) Sulla base della definizione di attendibilità \(\sigma^2_T = \rho_{XX^\prime} \sigma^2_X\), la varianza del punteggio osservato si può scrivere come \(\sigma^2_X =\rho_{XX^\prime} \sigma^2_X + \sigma^2_E\), da cui

\begin{equation}
\begin{aligned}
\sigma^2_E &= \sigma^2_X - \sigma^2_X\rho_{XX^\prime}\notag\\
&= \sigma^2_X (1 -\rho_{XX^\prime}).
\end{aligned}
\end{equation}

La varianza degli errori della misurazione \(\sigma^2_E = \sigma^2_X (1 -\rho_{XX^\prime})\) è dunque uguale al prodotto di due fattori: il primo fattore è la varianza del punteggio osservato; il secondo fattore è uguale a uno meno la correlazione tra due forme parallele del test. Possiamo così calcolare una quantità incognita, \(\sigma^2_E\), nei termini di due quantità osservabili, \(\sigma^2_X\) e \(\rho_{XX^\prime}\).
\end{proof}

\hypertarget{intervallo-di-confidenza-per-il-punteggio-vero-e-sigma_e}{%
\section{\texorpdfstring{Intervallo di confidenza per il punteggio vero e \(\sigma_E\)}{Intervallo di confidenza per il punteggio vero e \textbackslash sigma\_E}}\label{intervallo-di-confidenza-per-il-punteggio-vero-e-sigma_e}}

Uno degli usi che vengono fatti dell'errore standard della misurazione è quello di costruire, con essi, gli intervalli di confidenza per il punteggio vero. Tale uso, però, non è corretto \citep{charter1996revisiting}. Gli intervalli di confidenza costruiti usando l'errore standard della misurazione vengono talvolta incorrettamente interpretati in modo tale da suggerire che l'intervallo di confidenza al \((1 - \alpha)\%\) identifica una gamma di valori, \emph{centrata sul valore osservato}, entro il quale cadono i punteggi veri del test nel \((1 - \alpha)\%\) di ipotetiche somministrazioni ripetute del test. Ma le cose non stanno così. In realtà, come abbiamo detto sopra, l'errore standard della misurazione è la deviazione standard, calcolata rispetto al valore vero, di ipotetiche misurazioni ripetute dello stesso test. Si può ribadire questo concetto nel modo seguente: ``In spite of \citet{dudek1979continuing}'s reminder that the SEM should not be used to construct confidence intervals, many test manuals, computer-scoring programs, and texts in psychology and education continue to do so. Because authors of many textbooks and manuals make these errors, it is understandable that those who learned from and look to these sources for guidance also make these errors. In summary, the SEM should not be used to construct confidence intervals for test scores'' (p.~1141). Sembra piuttosto chiaro.

\hypertarget{ch:err_stnd_stima}{%
\chapter{La stima del punteggio vero}\label{ch:err_stnd_stima}}

Uno degli scopi principali della valutazione psicologica è quello di stimare il punteggio vero del rispondente. Il punteggio osservato \(X\) differisce dal punteggio vero \(T\) a causa della presenza dell'errore della misurazione: \(X = T + E\). Poniamoci ora il problema di utilizzare i concetti della Teoria Classica per stimare il punteggio vero di un rispondente utilizzando il suo punteggio osservato e l'attendibilità del test. Questa stima è utile soprattutto quando è necessario costruire un intervallo di confidenza per il punteggio vero.

Per costruire l'intervallo di confidenza del punteggio vero dobbiamo utilizzare due quantità:

\begin{itemize}
\tightlist
\item
  una stima del punteggio vero,
\item
  l'errore standard della stima (ovvero, una stima della deviazione standard della distribuzione delle stime del punteggio vero che si otterrebbe se il test venisse somministrato infinite volte sotto le stesse condizioni).
\end{itemize}

Iniziamo con il problema della stima del punteggio vero.

\hypertarget{il-paradosso-di-kelley}{%
\section{Il paradosso di Kelley}\label{il-paradosso-di-kelley}}

Nella sua monografia del 1954, ``Clinical versus statistical prediction: A theoretical analysis and a review of the evidence'', Paul Meehl suscitò un grande scalpore con una convincente dimostrazione del fatto che metodi meccanici di combinazione dei dati, come ad esempio la regressione multipla, sono in grado di fornire delle predizioni migliori di quanto sia in grado di fare la diagnosi clinica eseguita da esperti. L'enorme quantità di letteratura che è stata prodotta in seguito a tale contributo ha fornito forti e univoche evidenze a sostegno di questa osservazione.

È interessante notare che Robyn Dawes (2005) ha pubblicato un articolo su \emph{Journal of Clinical Psychology} (61, 1245--1255) dal titolo seguente: ``The ethical implications of Paul Meehl's Work on comparing clinical versus actuarial prediction methods''. L'argomento principale sostenuto da Dawes è che, date le evidenze molto convincenti che sono disponibili, non è etico usare il giudizio clinico in preferenza all'uso di modelli statistici di previsione. Citiamo dall'abstract:

Whenever statistical prediction rules {[}\ldots{]} are available for making a relevant prediction, they should be used in preference to intuition. {[}\ldots{]} Providing service that assumes that clinicians ``can do better'' simply based on self-confidence or plausibility in the absence of evidence that they can actually do so is simply unethical.

Sulla base di quanto detto sopra, e in riferimento ai nostri scopi presenti, si pone dunque il problema di capire come sia possibile utilizzare il modello di regressione per ottenere una stima del punteggio vero di un rispondente. A questo proposito si deve notare che è necessario tenere in considerazione il fatto che le nostre variabili indipendenti sono corrotte dall'errore di misurazione, mentre il modello di regressione tradizionale presuppone che le variabili indipendenti siano misurate senza errori. Le considerazioni seguenti sono state proposte da Kelly negli anni '20.

Come dimostrato in seguito, la formula di Kelley si basa sull'equivalenza algebrica secondo la quale l'attendibilità è uguale al quadrato del coefficiente di correlazione tra i punteggi osservati e i punteggi veri. In base alla formula di Kelley, il punteggio vero di un rispondente può essere stimato nel modo seguente mediante il modello di regressione:

\[
\hat{T} = \mu_x + \rho  (X - \mu_x),
\label{eq:true-score}
\] laddove \(X\) è il punteggio osservato, \(\mu_x\) è la media dei punteggi ottenuti da tutti i rispondenti di un campione e \(\rho\) è l'attendibilità del test.

Quando l'attendibilità è perfetta (\(\rho = 1\)), il punteggio vero è uguale al punteggio osservato. Quando l'attendibilità è zero (tutta la varianza è dovuta all'errore della misurazione), allora la stima migliore del punteggio vero è data dalla media del campione. Quando \(0 < \rho < 1\), la stima del punteggio vero corrisponde ad un valore che si discosta dal punteggio osservato nella direzione della media del campione. La stima del punteggio vero, dunque, esibisce la proprietà della regressione verso la media del punteggio osservato, in funzione dell'attendibilità del test{[}\^{}1{]}.

La \eqref{eq:true-score} può essere interpretata dicendo che, per stimare il punteggio vero di un rispondente, partiamo dalla media della distribuzione della popolazione dei rispondenti e ci spostiamo nella direzione del punteggio osservato di un rispondente. Tuttavia, non raggiungiamo il valore del punteggio osservato: la quantità di cui ci spostiamo è proporzionale all'attendibilità. In altre parole, a seconda della dimensione di \(\rho\), la stima del punteggio vero di un individuo è dovuta, in parte, a dove si trova l'individuo in relazione al gruppo di appartenenza: la stima del punteggio vero dell'individuo si sposterà verso l'alto se l'individuo è collocato sotto la media del gruppo di appartenenza e si sposterà verso il basso se l'individuo è collocato al di sopra della media del gruppo di appartenenza. Questa equazione è stata chiamata il \emph{paradosso di Kelley}.

È importante sottolineare che l'interpretazione precedente rivela che la formula di Kelley contraddice la nozione intuitiva secondo cui il punteggio osservato può essere utilizzato quale stima del punteggio vero (cioè, \(\hat{T} = X\)). Tale ragionamento ingenuo sarebbe corretto se l'attendibilità del test fosse perfetta (\(\rho = 1\)). All'altra estremità dello spettro, quando \(\rho = 0\), la formula di Kelley ci suggerisce \(\mu_x\) quale stima del punteggio vero, il che è equivale a dire che il punteggio osservato deve essere ignorato -- infatti se la varianza di \(X\) è solamente dovuta all'errore di misurazione, allora il test è del tutto inutile quale strumento inferenziale per differenziare le abilità dei rispondenti. Fortunatamente, in pratica è molto improbabile che \(\rho = 0\). Se \(\rho\) cade tra gli estremi di 0 e 1, allora il punteggio vero stimato sarà compreso tra il punteggio osservato e \(\mu_x\). Per capire cosa esso catturi, possiamo citare Kelley(1947), che osservò:

This is an interesting equation in that it expresses the estimate of true ability as the weighted sum of two separate estimates, -- one based upon the individual's observed score, \(X_1\) (\(X\) nella notazione corrente) and the other based upon the mean of the group to which he belongs, \(M_1\) (\(\mu_x\) nella notazione corrente). If the test is highly reliable, much weight is given to the test score and little to the group mean, and vice versa.

\begin{proof}
Come si arriva all'equazione di Kelley? Abbiamo visto in precedenza come l'equazione che mette in relazione il punteggio osservato con il punteggio vero non è altro che un modello di regressione con intercetta nulla e pendenza unitaria: \(X = 0 + 1 \cdot T + E\). In questo caso, però, il problema è diverso, in quanto noi vogliamo \emph{predire} il punteggio vero sulla base del punteggio osservato per mezzo di un modello di regressione (Nunnally, 1978). Avendo quale scopo quello di ``predire'' il punteggio vero \(T\) sulla base del punteggio osservato \(X\), il modello di regressione diventa

\[
T = \alpha + \beta X + \varepsilon.
\]

Se esprimiamo le variabili come deviazioni dalla media, \(x = X - \bar{X}\) e \(\tau = T - \E(T)\), allora l'intercetta diventa uguale a zero e il modello diventa \(\tau = \beta x + \varepsilon\), ovvero \(\hat{\tau} = \beta x.\) Il problema è quello di calcolare il coefficiente \(\beta\).

Nel modello \(\hat{\tau} = \beta x\), la pendenza della retta di regressione è uguale a \(\beta = \frac{\sigma_{\tau x}}{\sigma^2_x}\). Possiamo dunque scrivere il modello di regressione nel modo seguente:

\begin{equation}
\hat{\tau} = \frac{\sigma_{\tau x}}{\sigma^2_x} x.
\label{eq:hat-t-1}
\end{equation}

La correlazione tra \(x\) (o \(X\)) e \(\tau\) (o \(T\)) è uguale a \(\rho_{\tau x} = \frac{\sigma_{\tau x}}{\sigma_x \sigma_{\tau}}\). Dunque \(\sigma_{\tau x} = \rho_{\tau x}\sigma_x \sigma_{\tau}\) e l'equazione precedente diventa

\begin{equation}
\begin{aligned}
\hat{\tau} %&= \frac{\sigma_{TX}}{\sigma^2_X} X  \notag\\[10pt]
&= \frac{\rho_{\tau x}\sigma_x \sigma_{\tau}}{\sigma^2_x} x  \notag\\
&= \rho_{\tau x}\frac{\sigma_{\tau}}{\sigma_x} x. \notag
\label{eq:hat-t-2}
\end{aligned}
\end{equation}

In base alla definizione di attendibilità, la varianza del punteggio vero è \(\sigma^2_{\tau} = \sigma^2_x \rho_{xx^\prime}\). Dunque, la deviazione standard del punteggio vero diventa \(\sigma_{\tau} = \sigma_x \sqrt{\rho_{xx^\prime}}\). Sostituendo questo risultato nell'equazione precedente otteniamo

\begin{equation}
\begin{aligned}
\hat{\tau} &= \rho_{\tau x}\frac{\sigma_x \sqrt{\rho_{xx^\prime}}}{\sigma_x} x
\notag\\
&=  \rho_{\tau x}  \sqrt{\rho_{xx^\prime}} x. \notag
\end{aligned}
\end{equation}

In precedenza abbiamo visto che \(\rho^2_{\tau x} = \rho_{xx^\prime}\), dunque

\begin{equation}
\begin{aligned}
\hat{\tau} &= \rho_{\tau x} \sqrt{\rho_{xx^\prime}} x \notag\\
        &= \sqrt{\rho_{xx^\prime}} \sqrt{\rho_{xx^\prime}} x \notag\\
        &= \rho_{xx^\prime} x.
\label{eq:hat-t-part}
\end{aligned}
\end{equation}

In conclusione, una stima del punteggio vero si ottiene moltiplicando il punteggio osservato, espresso come deviazione dalla media, per il coefficiente di attendibilità.

Riscriviamo ora la formula appena ottenuta nei termini del punteggio grezzo \(X\) (non in termini di deviazioni dalla media. Per fare ciò, sommiamo \(\bar{X}\) così da ottenere

\[
\hat{T} = \rho_{XX^\prime} (X - \bar{X}) + \bar{X}, 
\]

laddove \(\hat{T}^\prime\) è la stima del punteggio vero grezzo. Sviluppando otteniamo

\begin{equation}
\begin{aligned}
\hat{T} &= \rho_{XX^\prime} (X - \bar{X}) + \bar{X}\notag\\
 &=  X\rho_{XX^\prime}  - \bar{X} \rho_{XX^\prime} + \bar{X}\notag\\
&= \bar{X} (1 - \rho_{XX^\prime}) + X\rho_{XX^\prime}\notag\\
&= \bar{X} - \bar{X}\rho_{XX'} + X\rho_{XX^\prime}\notag\\
&= \bar{X} + \rho_{XX'} (X - \bar{X}).\notag
\end{aligned}
\end{equation}

Per i dati campionari, la formula diventa:

\[
\hat{T} = \bar{X} + r_{XX^\prime}  (X - \bar{X}),
\]

dove \(X\) è il punteggio (grezzo) osservato, \(\bar{X}\) è la media dei punteggi osservati di un campione di rispondenti e \(r_{XX^\prime}\) è il coefficiente di attendibilità.
\end{proof}

\begin{exercise}
Posto un coefficiente di attendibilità pari a 0.80 e una media del test pari a \(\bar{X} = 100\), si trovi una stima del punteggio vero per un rispondente con un punteggio osservato uguale a \(X\) = 115.

La stima del punteggio vero \(\hat{T}\) è uguale a

\begin{equation}
\begin{aligned}
\hat{T} &= \bar{X} + r_{XX^\prime}  (X - \bar{X})\notag\\
&= 100 + 0.80 \cdot (115 - 100) = 112.
\end{aligned}
\end{equation}
\end{exercise}

\hypertarget{lerrore-standard-della-stima}{%
\section{L'errore standard della stima}\label{lerrore-standard-della-stima}}

Oltre a ottenere una stima del punteggio vero da un punteggio osservato, il modello di regressione di Kelley ci fornisce anche l'errore standard della stima. È chiaro che la stima del punteggio vero è difficile da interpretare se non è accompagnata da una qualche indicazione sulla precisione della stima. Tale informazione viene appunto fornita dall'\emph{errore standard della stima}.

Se il test potesse essere somministrato ad un rispondente più volte sotto le identiche condizioni, sarebbe possibile ottenere in ciascuna somministrazione una stima del valore vero \(\hat{T}\). A causa dell'errore della misurazione, il punteggio osservato non può che variare in ciascuna ipotetica somministrazioni del test e, di conseguenza, in ciascuna ipotetica somministrazione varierà anche la stima di \(\hat{T}\). La deviazione standard di tali (ipotetiche) stime di \(\hat{T}\) è chiamata \emph{errore standard della stima}. L'errore standard della stima, \(\sigma_{\hat{T}}\), si calcola con la formula seguente:

\begin{equation}
\sigma_{\hat{T}} = \sigma_X \sqrt{\rho_{XX^\prime} (1 -\rho_{XX^\prime})}.
\label{eq:bistd-err-estimatenom}
\end{equation}

\begin{proof}
Per ricavare la \label{eq:std-err-estimate} si definisce \(\varepsilon\) l'errore che si commette quando si stima il punteggio vero \(\hat{T}\) con il punteggio osservato \(T\) (si veda Lord e Novick, 1968):

\[
\varepsilon = T - \hat{T}.
\]

Si presti attenzione alla notazione: \(E = X - T\) indica l'errore della misurazione, ovvero la differenza tra il punteggio osservato e il punteggio vero. Invece \(\varepsilon = T - \hat{T}\) indica la differenza tra il punteggio vero e la stima del punteggio vero. Avendo che \(\hat{T} = \bar{X} + \rho_{XX^\prime} (X - \bar{X})\), la varianza di \(\varepsilon = T - \hat{T}\) si può scrivere come

\begin{equation}
\begin{aligned}
\V(\varepsilon) &=  \V(T - \hat{T})\notag\\
&= \V(T - \bar{X} - \rho_{XX^\prime} X + \rho_{XX^\prime}\bar{X}).
\end{aligned}
\end{equation}

Dato che la varianza di una variabile aleatoria non cambia sommando a tale variabile una costante, dobbiamo semplicemente calcolare

\begin{equation}
\V(\varepsilon) = \V(T - \rho_{XX^\prime}X).\notag
\end{equation}

Dobbiamo trovare la varianza della somma di due variabili aleatorie, una delle quali moltiplicata per una costante. Dunque:

\[
\V(\varepsilon) = \V(T) + \rho_{XX^\prime}^2 \V(X) - 2 \rho_{XX^\prime} \mbox{Cov}(X,T),
\]

ovvero, semplificando la notazione,

\begin{equation}
\sigma^2_{\varepsilon} = \sigma^2_T + \rho_{XX^\prime}^2 \sigma^2_X - 2  \rho_{XX^\prime} \sigma_{XT}.\notag
\end{equation}

La quantità \(\rho_{XX^\prime}\) è il coefficiente di attendibilità. Quindi

\begin{equation}
\sigma^2_{\varepsilon} = \sigma^2_T + \left(\frac{\sigma_T^2}{\sigma_X^2}\right)^2 \sigma^2_X - 2  \frac{\sigma_T^2}{\sigma_X^2} \sigma_{XT}.\notag
\end{equation}

Semplificando otteniamo

\begin{equation}
\begin{aligned}
\sigma^2_{\varepsilon} &= \sigma^2_T + \frac{\sigma_T^4}{\sigma_X^4}
\sigma^2_X - 2  \frac{\sigma_T^2}{\sigma_X^2} \sigma_{XT}\notag\\ 
&= \sigma^2_T + \sigma^2_T\frac{\sigma_T^2}{\sigma_X^2} -  \sigma_T^2 2
\frac{\sigma_{XT}}{\sigma_X^2} \notag\\ 
&= \sigma^2_T \left(1 + \frac{\sigma_T^2}{\sigma_X^2} - 2
  \frac{\sigma_{XT}}{\sigma_X^2}\right).\notag 
  \end{aligned}
\end{equation}

Dato che \(\sigma_{XT}=\sigma^2_T\), l'equazione precedente diventa uguale a

\begin{equation}
\begin{aligned}
\sigma^2_{\varepsilon} &= \sigma^2_T \left(1
  +\frac{\sigma_T^2}{\sigma_X^2} - 2
  \frac{\sigma_{T}^2}{\sigma_X^2}\right)\notag\\
&= \sigma^2_T \left(1 - 
  \frac{\sigma_{T}^2}{\sigma_X^2}\right).
\end{aligned}
\end{equation}

L'errore standard della stima è dunque uguale a

\begin{equation}
\begin{aligned}
\sigma_{\varepsilon} 
&=\sigma_T \sqrt{1-\frac{\sigma^2_T}{\sigma^2_X}}\notag\\
&=\sigma_T \sqrt{\frac{\sigma^2_X - \sigma^2_T}{\sigma^2_X}}\notag\\
&=\frac{\sigma_T}{\sigma_X} \sqrt{\sigma^2_X - \sigma^2_T}.
\end{aligned}
\end{equation}

Dato che \(\sigma^2_X=\sigma^2_T+\sigma^2_E\), abbiamo

\begin{equation}
\begin{aligned}
\sigma_{\varepsilon} 
 &= \frac{\sigma_T}{\sigma_X} \sqrt{\sigma^2_E }\notag\\
&=  \frac{\sigma_T}{\sigma_X} \sigma_E \notag\\
&= \sqrt{\rho_{XX^\prime}} \sigma_E. \notag
\end{aligned}
\end{equation}

Ricordando che l'errore standard della misurazione è \(\sigma_E = \sigma_X \sqrt{1 - \rho_{XX^\prime}}\), possiamo scrivere

\begin{equation}
\begin{aligned}
\sigma_{\varepsilon}  &= \sqrt{\rho_{XX^\prime}} \sigma_E \notag\\
&= \sqrt{\rho_{XX^\prime}} \sigma_X
\sqrt{1-\rho_{XX^\prime}} \notag\\
&= \sigma_X \sqrt{\rho_{XX^\prime} (1 - \rho_{XX^\prime})}.\notag
\end{aligned}
\end{equation}
\end{proof}

Per dati campionari, l'errore standard della stima si calcola nel modo seguente:

\[
s_{\hat{T}} = s_X \sqrt{r_{XX^\prime} (1-r_{XX^\prime})},
\]

dove \(s_X\) è deviazione standard del campione e \(r_{XX^\prime}\) è il coefficiente di attendibilità.

\hypertarget{intervallo-di-confidenza-per-il-punteggio-vero}{%
\section{Intervallo di confidenza per il punteggio vero}\label{intervallo-di-confidenza-per-il-punteggio-vero}}

L'errore standard della stima \(\sigma_{\hat{T}}\) viene usato per calcolare l'intervallo di confidenza per il punteggio vero{[}\^{}2{]}:

\[
\hat{T} \pm z  \sigma_{\hat{T}},
\]

laddove \(\hat{T}\) è la stima del punteggio vero e \(z\) è il quantile della normale standardizzata al livello di probabilità desiderato. Se il campione è piccolo (minore di 30) è opportuno usare \(t\) anziché \(z\).

Si osservi che l'intervallo \(\hat{T} \pm z \sigma_{\hat{T}}\) è centrato sulla \emph{stima puntuale del valore vero} e ha una ampiezza che dipende sia dal livello di copertura desiderato (da cui dipende il quantile \(z_{\frac{\alpha}{2}}\)), sia dal grado di precisione dello stimatore misurato dall'errore standard della stima, \(\sigma_{\hat{T}} = \sigma_X \sqrt{\rho_{XX^\prime} (1 -\rho_{XX^\prime})}\). L'errore standard della stima diventa tanto più grande quanto minore è l'attendibilità \(\rho_{XX^\prime}\) del test.

L'intervallo di confidenza ricorda allo psicologo quanto sia imprecisa la misura che utilizza: tanto più grande è l'intervallo di confidenza, tanto maggiore è l'incertezza dell'interpretazione. L'intervallo di confidenza è lo strumento che consente allo psicologo di giungere ad una conclusione sapendo qual è la probabilità che tale conclusione sia sbagliata. Se la decisione è basata su un intervallo di confidenza al 95\%, la probabilità di sbagliare è 0.05. Se lo psicologo vuole che la probabilità d'errore sia più piccola, può costruire un intervallo di confidenza utilizzando un valore \(\alpha\) minore. La diminuzione di \(\alpha\), però, produce un aumento dell'ampiezza dell'intervallo di confidenza. Valori accettabili per \(\alpha\) sono 0.1 e 0.05.

\begin{exercise}
Charter (1996) discute l'effetto della variazione dell'attendibilità del test sull'ampiezza dell'intervallo di confidenza per il punteggio vero. Nell'esempio considera i punteggi del QI (\(\mu\) = 100, \(\sigma\) = 15) immaginando di variare il coefficiente di attendibilità del test tramite il quale il QI viene misurato. I valori esaminati sono 0.55, 0.65, 0.75, 0.85 e 0.95. Consideriamo, ad esempio, il caso di un punteggio osservato pari a QI = 120 e poniamo che \(\rho_{xx^\prime}\) = 0.65. In tali circostanze, la stima del punteggio vero è pari a

\begin{equation}
\begin{aligned}
\hat{T} &= \bar{X} + r_{XX^\prime}  (X - \bar{X}) \notag\\
&= 100 + 0.65 (120 - 100)\notag\\
&= 113.\notag
\end{aligned}
\end{equation}

L'errore standard della stima è uguale a

\begin{equation}
\begin{aligned}
\sigma_{\hat{T}} &= \sigma_{X} \sqrt{r_{XX^\prime} (1 - r_{XX^\prime})} \notag\\
&= 15 \sqrt{0.65 (1 - 0.65)}\notag\\
&= 7.15.\notag
\end{aligned}
\end{equation}

L'intervallo di confidenza al 95\% per la stima del punteggio vero diventa pertanto uguale a

\[
113 \pm 1.96 \cdot 7.15 = [98.98, 127.02].
\]
\end{exercise}

Lo stesso risultato si ottiene con la funzione \texttt{CI.tscore()} del pacchetto \texttt{psychometric} che richiede i seguenti argomenti: il punteggio osservato, la media del campione, la deviazione standard del campione e l'attendibilità del test:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(}\StringTok{"psychometric"}\NormalTok{)}
\FunctionTok{CI.tscore}\NormalTok{(}\DecValTok{120}\NormalTok{, }\DecValTok{100}\NormalTok{, }\DecValTok{15}\NormalTok{, }\FloatTok{0.65}\NormalTok{)}
\CommentTok{\#\textgreater{}   SE.Est   LCL T.Score UCL}
\CommentTok{\#\textgreater{} 1  7.155 98.98     113 127}
\end{Highlighting}
\end{Shaded}

\hypertarget{cut-off}{%
\section{Cut-off}\label{cut-off}}

Uno degli usi possibili degli intervalli di confidenza per il punteggio vero è quello di confrontare i limiti dell'intervallo di confidenza con un cut-off. Sono possibili tre alternative: il limite inferiore dell'intervallo di confidenza è maggiore del cut-off, il limite superiore dell'intervallo è minore del cut-off, oppure il valore del cut-off è contenuto all'interno dell'intervallo. Nel primo caso, lo psicologo afferma, con un grado di certezza \(1 -\alpha\), che il valore vero del rispondente è superiore al cut-off. Nel secondo caso, lo psicologo afferma, con un grado di certezza \(1 -\alpha\), che il valore vero del rispondente è inferiore al cut-off. Nel terzo caso lo psicologo non può concludere né che il valore vero sia inferiore né che sia superiore al cut-off.

\begin{exercise}
Si considerino i punteggi del QI, per cui \(\bar{X}\) = 100 e \(s_X\) = 15. Sia l'attendibilità del test \(\rho_{XX^\prime}\) = 0.95. Supponiamo che il rispondente abbia un QI = 130. Poniamo che il cut-off per ammettere il rispondente ad un corso avanzato sia 120. Ci sono tre alternative: il valore vero del rispondente è sicuramente maggiore di 120; il valore vero del rispondente è sicuramente inferiore di 120; le evidenze disponibili ci lasciano in dubbio se il punteggio vero sia maggiore o minore di 120. Svolgiamo i calcoli per trovare l'intervallo di confidenza al livello di certezza del 95\%:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{xm }\OtherTok{\textless{}{-}} \DecValTok{100}
\NormalTok{sx }\OtherTok{\textless{}{-}} \DecValTok{15}
\NormalTok{rho }\OtherTok{\textless{}{-}}\NormalTok{ .}\DecValTok{95}
\NormalTok{x }\OtherTok{\textless{}{-}} \DecValTok{130}
\NormalTok{t.hat }\OtherTok{\textless{}{-}}\NormalTok{ xm }\SpecialCharTok{+}\NormalTok{ rho }\SpecialCharTok{*}\NormalTok{ (x }\SpecialCharTok{{-}}\NormalTok{ xm)}
\NormalTok{t.hat}
\CommentTok{\#\textgreater{} [1] 128.5}
\NormalTok{se.t }\OtherTok{\textless{}{-}}\NormalTok{ sx }\SpecialCharTok{*} \FunctionTok{sqrt}\NormalTok{(rho }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ rho))}
\NormalTok{se.t}
\CommentTok{\#\textgreater{} [1] 3.269}
\NormalTok{t.hat }\SpecialCharTok{+} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{) }\SpecialCharTok{*} \FunctionTok{qnorm}\NormalTok{(.}\DecValTok{025}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ se.t}
\CommentTok{\#\textgreater{} [1] 122.1 134.9}
\end{Highlighting}
\end{Shaded}

Dato che il limite inferiore dell'intervallo di confidenza è maggiore del cut-off, lo psicologo conclude che il punteggio vero del rispondente è maggiore di 120. Quindi, raccomanda che il rispondente sia ammesso al corso avanzato.

Continuiamo con l'esempio precedente, ma supponiamo che l'attendibilità del test abbia un valore simile a quello che solitamente si ottiene empiricamente, ovvero 0.80.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{xm }\OtherTok{\textless{}{-}} \DecValTok{100}
\NormalTok{sx }\OtherTok{\textless{}{-}} \DecValTok{15}
\NormalTok{rho }\OtherTok{\textless{}{-}}\NormalTok{ .}\DecValTok{8}
\NormalTok{x }\OtherTok{\textless{}{-}} \DecValTok{130}
\NormalTok{t.hat }\OtherTok{\textless{}{-}}\NormalTok{ xm }\SpecialCharTok{+}\NormalTok{ rho }\SpecialCharTok{*}\NormalTok{ (x }\SpecialCharTok{{-}}\NormalTok{ xm)}
\NormalTok{t.hat}
\CommentTok{\#\textgreater{} [1] 124}
\NormalTok{se.t }\OtherTok{\textless{}{-}}\NormalTok{ sx }\SpecialCharTok{*} \FunctionTok{sqrt}\NormalTok{(rho }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ rho))}
\NormalTok{se.t}
\CommentTok{\#\textgreater{} [1] 6}
\NormalTok{t.hat }\SpecialCharTok{+} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{) }\SpecialCharTok{*} \FunctionTok{qnorm}\NormalTok{(.}\DecValTok{025}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ se.t}
\CommentTok{\#\textgreater{} [1] 112.2 135.8}
\end{Highlighting}
\end{Shaded}

In questo secondo esempio, l'intervallo di confidenza al 95\% è \([112.24, 135.76]\) e contiene il valore del cut-off. Dunque, la decisione dello psicologo è che non vi sono evidenze sufficienti che il vero valore del rispondente sia superiore al cut-off. Si noti come la diminuzione dell'attendibilità del test porta all'aumento delle dimensioni dell'intervallo di confidenza.
\end{exercise}

\hypertarget{procedure-alternative}{%
\section{Procedure alternative}\label{procedure-alternative}}

Non vi è un unico modo per costruire gli intervalli di confidenza per il punteggio vero. Charter e Feldt (1991) descrivono altri quattro approcci possibili, oltre a quello discusso qui, per costruire gli intervalli di confidenza per il punteggio vero. L'approccio che abbiamo descritto è accettato da tutti gli autori; le procedure alternative descritte da Charter e Feldt (1991), non sono invece accettate come valide da tutti gli autori.

La più comune delle procedure alternative descritte da Charter e Feldt (1991), che rappresenta l'approccio tradizionale a questo problema, centra l'intervallo di confidenza sul punteggio osservato di un rispondente e utilizza l'errore standard della misurazione per calcolare i limiti dell'intervallo di confidenza:

\[
X_j \pm z_{\frac{\alpha}{2}} \sigma_E,
\]

dove \(\sigma_E = \sigma_X \sqrt{1 -\rho_{XX^\prime}}\). Tale procedura è però stata criticata da diversi autori (es., Dudek, 1979).

\hypertarget{part-lanalisi-fattoriale}{%
\part{L'analisi fattoriale}\label{part-lanalisi-fattoriale}}

\hypertarget{ch:sviluppo}{%
\chapter{Utilizzo e costruzione di test psicometrici}\label{ch:sviluppo}}

La maggior parte degli psicologi che utilizzano i test non costruiscono dei test ad hoc ma utilizzano i test già validati e interpretano i punteggi attenuti sulla base delle norme fornite nel manuale del test. Nella selezione del test che è più appropriato per il problema che lo psicologo deve affrontare, si devono considerare domande quali: Qual è il valore minimo di attendibilità che è richiesto? Ovvero, a che livello di precisione dobbiamo essere in grado di differenziare tra i rispondenti? Che tipo di validità è importante? Quali sono le caratteristiche della popolazione che il gruppo normativo deve rappresentare? Qual è il livello di istruzione necessario per completare il test? Qual è il tempo disponibile per la somministrazione del test e per lo scoring dei risultati? Quali sono i costi necessari per la somministrazione del test e per lo scoring dei risultati? Avendo dato una risposta a tali domande, la selezione del test solitamente si riduce ad una scelta tra poche alternative. Per giungere ad una decisione tra tali alternative è importante consultare la letteratura specialistica che discute le proprietà psicometriche dei test e la loro validità.

Ciascuno psicologo ha l'obbligo di dimostrare che il test che usa per un certo scopo costituisca lo strumento migliore, tra quelli disponibili, per giungere ad una decisione razionale e obiettiva relativamente al problema che si trova ad affrontare (si veda il Codice Deontologico). Se nessuno dei test disponibili si dimostra appropriato per misurare un determinato tratto psicologico, si procede alla costruzione di un nuovo reattivo. La costruzione di un test richiede sia conoscenze specialistiche di tipo psicometrico, sia una conoscenza specialistica del fenomeno considerato.

Le fasi di costruzione dei test comprendono la definizione delle aree di contenuto che andranno misurate dal test; la generazione degli item per ciascuna area in un numero di circa tre volte superiore a quello che ci si aspetta farà parte della versione finale del test; la somministrazione degli item ad un campione sufficientemente numeroso (centinaia di rispondenti selezionati in modo tale che il campione sia rappresentativo della popolazione di interesse); l'analisi degli item che ci consente di selezionare gli item migliori; infine, la somministrazione della versione revisionata del test ad un nuovo campione per stabilire se la versione finale del test sia soddisfacente dal punto di vista psicometrico. In caso affermativo, il campione esaminato fornisce le norme del test e questa fase va sotto il nome di \emph{standardizzazione del test}.

\hypertarget{caratteristiche-dellanalisi-fattoriale}{%
\section{Caratteristiche dell'analisi fattoriale}\label{caratteristiche-dellanalisi-fattoriale}}

La teoria psicometria è l'unico strumento che abbiamo a disposizione per creare strumenti di misurazione validi e attendibili per l'assessment psicologico e neuropsicologico. La psicometria comprende due diversi approcci metodologici per la costruzione dei reattivi psicologici: la teoria classica dei test e la teoria di risposta all'item (\emph{item response theory}). Esamineremo qui gli aspetti di base della teoria classica dei test e ci focalizzeremo, in particolare, sull'analisi fattoriale.

Se vogliamo costruire un test psicometrico per la valutazione di un particolare deficit psicologico o neuropsicologico, prima di iniziare lo studio, dobbiamo fornire una risposta ad una serie di domande. Per esempio, come dobbiamo selezionare gli item? Gli item scelti coprono tutto il dominio del fenomeno considerato? Quanti item dobbiamo usare? A quanti soggetti dobbiamo somministrare lo strumento? Quali analisi statistiche dobbiamo svolgere sui dati raccolti?

L'analisi fattoriale è uno strumento statistico che può essere utilizzato per trovare una risposta a queste domande. Chiariamo subito che l'analisi fattoriale è una tecnica statistica complessa che richiede l'uso di un software. Per gli scopi di questo insegnamento useremo il pacchetto \texttt{lavaan} del linguaggio statistico .

L'analisi fattoriale può essere pensata come una tecnica statistica per la ricerca di variabili latenti a partire da alcune variabili osservate. La distinzione tra variabili latenti e variabili osservate si basa sulla osservabilità, ossia sulla possibilità di rilevazione empirica. Le prime sono variabili non direttamente osservabili in quanto rappresentano concetti molto generali o complessi, mentre le seconde sono facilmente rilevabili. In ogni caso, entrambe possono essere operazionalizzate, per cui anche nel caso delle variabili latenti c'è una sostanziale differenza con i concetti.

Ma che cos'è una variabile latente o fattore? Un fattore può essere descritto come una combinazione lineare di variabili manifeste tra loro associate le quali rappresentano una specifica dimensione di un costrutto psicologico, la quale si distingue da altre dimensioni dello stesso costrutto o dalle dimensioni di costrutti diversi (Tabachnick \& Fidell, 2001). Per esempio, la Wechsler Adult Intelligence Scale -- Fourth Edition (WAIS-IV) dà una valutazione complessiva delle capacità cognitive di adolescenti e adulti e distingue tra quattro dimensioni dell'intelligenza: comprensione verbale, ragionamento visuo-percettivo, memoria di lavoro e velocità di elaborazione.

L'analisi fattoriale viene usata per lo sviluppo e la validazione di un test psicometrico e per stabilire la validità di costrutto di uno strumento per una specifica popolazione. Una volta che la struttura interna di un costrutto è stata chiarita, l'analisi fattoriale può essere usata per identificare le variabili esterne (per esempio, il genere o il livello di istruzione) che sono associate alle varie dimensioni del costrutto di interesse (Nunnally \& Bernstein, 1994).

\hypertarget{lanalisi-fattoriale-esplorativa-e-confermativa}{%
\subsection{L'analisi fattoriale esplorativa e confermativa}\label{lanalisi-fattoriale-esplorativa-e-confermativa}}

Nei suoi primi modelli matematici, l'analisi fattoriale era una tecnica di analisi esplorativa appunto perché permetteva di ``esplorare'' le relazioni nascoste fra un gran numero di variabili. In tempi più recenti, la tecnica delle equazioni strutturali ha permesso di sviluppare una tecnica di analisi fattoriale di tipo confermativo, che cioè permette di verificare se effettivamente i fattori ipotizzati servono a spiegare le variabili misurate. In tempi ancora più recenti è stato notato che i vincoli posti dai modelli SEM sono, alle volte, troppo restrittivi per cui le tecniche dell'analisi fattoriale esplorativa vengono integrate con i modelli di equazioni strutturali in maniera tale da produrre un nuovo approccio alla definizione delle variabili latenti, ovvero quelli che si chiamano modelli ESEM (Exploratory Structural Equation Modeling).

\hypertarget{assunzioni-dellanalisi-fattoriale}{%
\subsection{Assunzioni dell'analisi fattoriale}\label{assunzioni-dellanalisi-fattoriale}}

L'assunzione di base dell'analisi fattoriale esplorativa è che, dato un insieme di variabili osservate, esista un insieme più piccolo di fattori latenti i quali siano in grado di spiegare i legami, le interrelazioni e le dipendenze tra le variabili statistiche osservate. Dato che l'analisi fattoriale si propone di spiegare una matrice di correlazioni, molte delle assunzioni che stanno alla base del calcolo delle correlazioni si applicano anche all'analisi fattoriale: campioni di grande numerosità, il fatto che le variabili considerate abbiano una distribuzione di probabilità continua, la linearità nella relazione tra le variabili. In generale, queste assunzioni si riducono al requisito della normalità multivariata, ovvero il requisito per il quale tutte le variabili considerate e tutte le combinazioni lineari tra tali variabili sono distribuite normalmente.

Molto spesso, però, l'assunzione di normalità multivariata è violata a causa del fatto che, anziché essere delle variabili continue, gli item sono spesso variabili (discrete) che derivano da risposte a questionari fornite utilizzando scale di tipo Likert. Vedremo come questo problema può essere superato utilizzando le correlazioni policoriche.

\hypertarget{sviluppo-storico-dellanalisi-fattoriale}{%
\subsection{Sviluppo storico dell'analisi fattoriale}\label{sviluppo-storico-dellanalisi-fattoriale}}

L'analisi fattoriale è un metodo di analisi multivariata che, dal punto di vista storico, risulta fortemente interconnessa con i modelli psicometrici. Alcuni concetti basilari per i successivi sviluppi dell'analisi fattoriale si possono trovare in Galton (1888, 1889) con il concetto di \emph{fonte comune} (\emph{common source}) e in Pearson (1901) con l'introduzione delle \emph{componenti principali} come metodo di riduzione dei dati. Si deve però a Spearman (1904) l'elaborazione del primo \emph{modello di analisi fattoriale} secondo il quale le risposte fornite ad un insieme di test di abilità sono riconducibili ad un unico fattore generale di intelligenza.

L'analisi fattoriale è stata sviluppata da diversi gruppi di psicologi inglesi e americani che, tra l'inizio del '900 e il 1930, svilupparono una serie di tecniche statistiche per affrontare problemi quali quello di determinare le dimensioni dell'intelligenza (Garnett, 1919; Pearson, 1901; Spearman, 1904, 1923, 1927, 1929; Thurstone, 1935, 1937a, 1937b; Wilson, 1928).

In Inghilterra, Spearman e i suoi colleghi (Burt, 1939, 1941; Garnett, 1919; Ledermann, 1937, 1938; Spearman, 1904, 1922, 1923, 1927, 1928, 1929, 1930a, 1930b; Thomson, 1934, 1936, 1938) svilupparono il concetto della teoria dei due fattori dell'intelligenza umana secondo cui esiste un fattore generale, \emph{g}, che esprime l'intelligenza generale, è ereditario e compare in maggiore o minor misura in tutti i test, e esistono inoltre tanti fattori specifici, \emph{s}, che rappresentano l'acquisizione specifica attraverso l'apprendimento e l'esperienza, e sono presenti in modo differenziato in ogni singolo test. Dato che i fattori specifici sono incorrelati tra loro, il fattore \emph{g} spiega la maggior parte delle correlazioni tra i punteggi delle abilità mentali (Nunnally \& Bernstein, 1994). Anche se successive ricerche non confermarono totalmente l'ipotesi di Spearman dell'esistenza di un fattore \emph{g}, e particolarmente vennero alla luce dei fattori di gruppo, che potevano spiegare le correlazioni esistenti tra test simili (Garnett, 1919; Spearman, 1927), la maggior parte dello sviluppo iniziale dell'analisi fattoriale fu dedicata alla ricerca di un singolo fattore per l'intelligenza.

Spearman analizzò molti insiemi di dati nel tentativo di trovare conferma al modello uni-fattoriale: alcuni di questi, tuttavia, non risultarono compatibili con il modello dei due fattori. La generalizzazione del modello fattoriale al caso in cui sono presenti più fattori comuni si deve a Thurstone (1938, 1947). Nel modello di Thurstone non viene fatto più riferimento ad un fattore generale che influenza tutte le variabili osservate: si ipotizza invece la presenza di una molteplicità di fattori comuni i quali determinano le variabili osservate. I contributi di Thurstone riguardano alcuni degli aspetti fondamentali dell'analisi fattoriale esplorativa, quali il concetto di struttura semplice e i fattori obliqui.

Thurstone e collaboratori applicarono la teoria dei fattori multipli a vari problemi psicometrici (Thurstone, 1931, 1940, 1947, 1948, 1954) diventando ben presto il riferimento più importante per lo sviluppo delle procedure dell'analisi fattoriale. La centralità della scuola statunitense continuò fino alla fine degli anni '60, quando un numero di importanti psicometristi europei contribuirono a spostare il focus dell'assessment psicologico dall'approccio esplorativo a quello confermativo (Jöreskog, 1967, 1969, 1970; Jöreskog \& Goldberger, 1972; Sörbom, 1974). I contributi statistici di Jöreskog e Sörbom hanno contribuito a sviluppare quelli che oggi chiamiamo i modelli di equazioni strutturali (Structural Equation Models, SEM), i quali costituiscono una delle tecniche più utilizzate per l'analisi dei dati nelle discipline psicologiche e sociali.

Un'ulteriore linea di ricerca venne sviluppata nel campo della biometria, ad opera di Sewall Wright (1934). In un tale approccio vengono utilizzati modelli di equazioni simultanee, che includono però solo variabili osservabili, per analizzare particolari schemi di rappresentazione dei nessi di influenza tra le variabili noti come \emph{analisi dei percorsi} (\emph{path analysis}).

A partire dalla metà degli anni cinquanta, con la diffusione dei centri calcolo, l'analisi fattoriale è diventata uno dei metodi di analisi dei dati più largamente utilizzati in psicologia e, in particolare, nelle ricerche volte alla costruzione dei reattivi psicologici. Le tradizioni di ricerca dei modelli di equazioni simultanee con variabili osservate, da una parte, e dei modelli di equazioni strutturali con variabili osservate e latenti, dall'altra, sono rimaste sostanzialmente indipendenti fino agli anni '60 dello scorso secolo, quando metodologi delle scienze sociali, come Blalock (1961, 1963), Boudon (1965) e Duncan (1966) hanno cominciato a sottolineare i vantaggi derivanti dalla possibilità di combinare la semplicità di rappresentare nessi di influenza tra le variabili tramite i diagrammi tipici della \emph{path analysis}, con il rigore derivante dalla specificazione delle equazioni simultanee, in modo tale da includere sia variabili osservate sia variabili latenti. La disponibilità di programmi per computer che permettono di tradurre in un linguaggio non matematico le complesse operazioni matematiche connesse alla risoluzione simultanea di sistemi di equazioni lineari con variabili latenti ha poi facilitato enormemente la diffusione delle tecniche dell'analisi fattoriale confermativa. A partire dalla fine degli anni sessanta, soprattutto grazie a Karl Jöreskog, il modello di analisi fattoriale si è ulteriormente raffinato e sviluppato verso un approccio confermativo orientato prevalentemente all'esame di ipotesi teoriche.

Sebbene l'analisi fattoriale confermativa (CFA) possa essere vista come una motivazione per la creazione di modelli di misurazione parsimoniosi, tali modelli spesso includono un certo livello di errore di misurazione sistematico che deriva dal fatto che gli item sono raramente indicatori puri dei corrispondenti costrutti, e quindi ci si può aspettare un certo grado di associazione rilevante per il costrutto anche tra item e costrutti non target, ma concettualmente associati (Morin et al., 2016). Quando tali associazioni restano inespresse nel modello, a causa dei vincoli restrittivi dell'approccio CFA (cioè, del fatto che gli item possono essere indicatori di un unico fattore), allora i risultati dell'analisi possono risultare sistematicamente distorti. In particolare, si può osservare una sovrastima delle associazioni tra i fattori. Inoltre, i vincoli eccessivamente restrittivi dei modelli CFA possono anche minare la bontà di adattamento dei modelli e la validità discriminante dei fattori (Marsh et al., 2010, 2014). I contemporanei modelli ESEM si pongono l'obiettivo di affrontare questo tipo di problemi.

\hypertarget{fasi-dellanalisi-fattoriale}{%
\subsection{Fasi dell'analisi fattoriale}\label{fasi-dellanalisi-fattoriale}}

Indipendentemente dal software statistico che viene utilizzato e dal livello di esperienza del ricercatore, lo sviluppo di un test psicometrico inizia con l'analisi fattoriale esplorativa. In essa si possono distinguere otto stadi successivi:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  la specificazione del problema,
\item
  la scelta degli item,
\item
  la verifica dell'adeguatezza della matrice di correlazione,
\item
  l'estrazione iniziale dei fattori,
\item
  la rotazione dei fattori,
\item
  l'ulteriore selezione degli item,
\item
  l'interpretazione dei risultati,
\item
  la costruzione di un report della ricerca,
\item
  la validazione dei risultati.
\end{enumerate}

Queste diverse fasi della costruzione e validazione di un reattivo psicologivo verranno discusse nel seguito di queste dispense.

\hypertarget{ch:spearman}{%
\chapter{Il modello unifattoriale}\label{ch:spearman}}

In questo capitolo verranno presentate le basi teoriche dell'analisi fattoriale, ovvero di quel modello statistico che offre la possibilità di ricostruire le correlazioni osservate tra le variabili manifeste considerando le saturazioni delle variabili in uno o più fattori generali. Nell'analisi fattoriale \(p\) variabili manifeste (item) vengono concepite come condizionalmente indipendenti date \(m\) variabili latenti chiamate \emph{fattori}. L'analisi fattoriale si pone lo scopo di interpretare i fattori come dei costrutti teorici inosservabili. Infatti, il desiderio di spiegare mediante il concetto di intelligenza le correlazioni osservate tra le prestazioni di un gruppo di individui in una serie di compiti è stato la forza trainante nello sviluppo originale dell'analisi fattoriale. L'analisi fattoriale consente di identificare i costrutti di cui gli item sono espressione e di stabilire in che misura ciascun item rappresenta il costrutto. Il modello unifattoriale ipotizza \(m = 1\); il modello multifattoriale ipotizza \(m > 1\). Lo scopo di questo capitolo è quello di introdurre il modello fattoriale che assume l'esistenza di un unico fattore comune latente.

\hypertarget{modello-monofattoriale}{%
\section{Modello monofattoriale}\label{modello-monofattoriale}}

Con \(p\) variabili manifeste \(y_i\), il caso più semplice è quello di un solo fattore comune:

\begin{equation}
y_i = \mu_i + \lambda_{i} \xi +  1 \cdot \varepsilon_i \qquad i=1, \dots, p,
\label{eq:mod-unifattoriale}
\end{equation}

dove \(\xi\) rappresenta il fattore comune a tutte le \(y_i\), \(\varepsilon_i\) sono i fattori specifici o unici di ogni variabile osservata e \(\lambda_i\) sono le saturazioni (o pesi) fattoriali le quali stabiliscono il peso del fattore latente su ciascuna variabile osservata.

Si noti che il modello di analisi fattoriale è solo apparentemente simile al modello di regressione. Infatti, sia il fattore comune \(\xi\) sia i fattori specifici \(\varepsilon_i\) sono inosservabili: tutto ciò che giace a destra dell'uguaglianza è dunque incognito. L'analisi di regressione e l'analisi fattoriale si differenziano non solo per tale aspetto, ma anche per il fatto di avere obiettivi diversi. L'analisi di regressione ha l'obiettivo di individuare le variabili esplicative, direttamente osservabili, che sono in grado di spiegare la maggior parte della \emph{varianza} della variabile dipendente. Il problema dell'analisi unifattoriale, invece, è quello di identificare la variabile esplicativa inosservabile che è in grado di spiegare la maggior parte della \emph{covarianza} tra le variabili osservate.

Nel caso di cinque variabili osservate e un solo fattore comune, ad esempio, il modellofattoriale \eqref{eq:mod-unifattoriale} può essere rappresentato graficamente nel modo seguente.

Si suole assumere per comodità che \(\mu=0\), il che corrisponde a considerare le variabili \(y_i\) come ottenute dagli scarti dalle medie \(\mu_i\), per \(i = 1, \dots, p\):

\begin{equation}
y_i -\mu_i = \lambda_i \xi + 1 \cdot \varepsilon_i.
\label{eq:mod-monofattoriale}
\end{equation}

Si assume che il fattore comune abbia media zero, \(\E(\xi)=0\), e varianza unitaria, \(\V(\xi)=1\), i fattori specifici abbiano media zero, \(\E(\varepsilon_j)=0\), varianza \(\V(\varepsilon_i)=\psi_{i}\) e siano incorrelati tra loro, \(\E(\varepsilon_i \varepsilon_k)=0\), e con il fattore comune, \(\E(\varepsilon_i \xi)=0\). In questo modello, poiché i fattori specifici sono tra loro incorrelati, l'interdipendenza tra le variabili è completamente spiegata dal fattore comune.

Dalle ipotesi precedenti è possibile ricavare:

\begin{itemize}
\tightlist
\item
  la covarianza tra \(y_i\) e il fattore comune,
\item
  la varianza della \(i\)-esima variabile osservabile \(y_i\),
\item
  la covarianza tra due variabili \(y_i\) e \(y_k\).
\end{itemize}

Questo sarà l'obiettivo della discussione presente in questo capitolo.

\hypertarget{correlazione-parziale}{%
\section{Correlazione parziale}\label{correlazione-parziale}}

Prima di discutere il modello statistico dell'analisi fattoriale, chiariamo il concetto di correlazione parziale. La nascita dell'analisi fattoriale viene di solito attribuita a Charles Spearman. Nel 1904, Sperman pubblicò un articolo dal titolo ``General Intelligence, objectively determined and measured'' dove propose la Teoria dei Due Fattori. Nel suo articolo del 1904, Spearman dimostrò come, mediante il metodo dell'annullamento della tetrade (\emph{tetrad differences}), sia possibile identificare un fattore inosservabile a partire da una matrice di correlazioni. L'annullamento della tetrade rappresenta un'applicazione della teoria della correlazione parziale. Il problema è quello di stabilire se, controllando un insieme di variabili inosservabili \(\xi_j\), dette fattori, le correlazioni tra le variabili osservabili \(Y_i\), al netto degli effetti lineari delle \(\xi_j\), diventino statisticamente nulle.

Consideriamo un esempio nel quale sono presenti solo tre variabili: \(Y_1\), \(Y_2\) e \(F\). In generale, la correlazione \(r_{1,2}\) tra due variabili \(Y_1\) e \(Y_2\) può risultare dalla loro associazione con una terza variabile \(F\). Per calcolare la correlazione parziale tra \(Y_1\) e \(Y_2\) al netto dell'effetto lineare di \(F\) è necessario trovare le componenti di \(Y_1\) e di \(Y_2\) che sono linearmente indipendenti da \(F\).

Vediamo come si può ottenere questo risultato. La componente di \(Y_1\) linearmente indipendente da \(F\) è data dai residui \(E_1\) del modello

\[
Y_1 = b_{01} + b_{11}F + E_1.
\]

La componente di \(Y_2\) linearmente indipendente da \(F\) è data dai residui \(E_2\) del modello

\[
Y_2 = b_{02} + b_{12}F + E_2.
\]

La correlazione parziale \(r_{1,2 \mid F}\) è la correlazione di Pearson tra \(E_1\) e \(E_2\), ovvero la correlazione tra le componenti di \(Y_1\) e \(Y_2\) linearmente indipendenti da \(F\).

La correlazione parziale tra \(Y_1\) e \(Y_2\) al netto dell'effetto di \(F\) può essere calcolata direttamente dalle correlazioni semplici tra le tre variabili \(Y_1\), \(Y_2\) e \(F\) mediante la seguente formula:

\begin{equation}
r_{1,2 \mid F} = \frac{r_{12} - r_{1F}r_{2F}}{\sqrt{(1-r_{1F}^2)(1-r_{2F}^2)}}
\label{eq:corr-parz}
\end{equation}

Facciamo un esempio numerico. Sia \(f\) una variabile su cui misuriamo \(n\) valori

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{1000}
\NormalTok{f }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{24}\NormalTok{, }\DecValTok{12}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Siano \(y_1\) e \(y_2\) funzioni lineari di \(f\), a cui viene aggiunta una componente d'errore gaussiano:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y1 }\OtherTok{\textless{}{-}} \DecValTok{10} \SpecialCharTok{+} \DecValTok{7} \SpecialCharTok{*}\NormalTok{ f }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{0}\NormalTok{, }\DecValTok{50}\NormalTok{)}
\NormalTok{y2 }\OtherTok{\textless{}{-}} \DecValTok{3} \SpecialCharTok{+} \DecValTok{2} \SpecialCharTok{*}\NormalTok{ f }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{0}\NormalTok{, }\DecValTok{50}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

La correlazione tra \(y_1\) e \(y_2\) (\(r_{12}= 0.355\)) deriva dal fatto che \(\hat{y}_1\) e \(\hat{y}_2\) sono entrambe funzioni lineari di \(f\):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Y }\OtherTok{\textless{}{-}} \FunctionTok{cbind}\NormalTok{(y1, y2, f)}
\NormalTok{R }\OtherTok{\textless{}{-}} \FunctionTok{cor}\NormalTok{(Y)}
\FunctionTok{round}\NormalTok{(R, }\DecValTok{3}\NormalTok{)}
\CommentTok{\#\textgreater{}       y1    y2     f}
\CommentTok{\#\textgreater{} y1 1.000 0.380 0.867}
\CommentTok{\#\textgreater{} y2 0.380 1.000 0.423}
\CommentTok{\#\textgreater{} f  0.867 0.423 1.000}
\end{Highlighting}
\end{Shaded}

Eseguiamo le regressioni di \(y_1\) su \(f\) e di \(y_2\) su \(F\):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fm1 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(y1 }\SpecialCharTok{\textasciitilde{}}\NormalTok{ f)}
\NormalTok{fm2 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(y2 }\SpecialCharTok{\textasciitilde{}}\NormalTok{ f)}
\end{Highlighting}
\end{Shaded}

Nella regressione, ciascuna osservazione \(y_{i1}\) viene scomposta in due componenti linearmente indipendenti, i valori adattati \(\hat{y}_{i}\) e i residui, \(e_{i}\): \(y_i = \hat{y}_i + e_1\). Nel caso di \(y_1\) abbiamo

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{round}\NormalTok{(}\FunctionTok{head}\NormalTok{(}\FunctionTok{cbind}\NormalTok{(y1, }\AttributeTok{y1.hat =}\NormalTok{ fm1}\SpecialCharTok{$}\NormalTok{fit, }\AttributeTok{e =}\NormalTok{ fm1}\SpecialCharTok{$}\NormalTok{res, fm1}\SpecialCharTok{$}\NormalTok{fit }\SpecialCharTok{+}\NormalTok{ fm1}\SpecialCharTok{$}\NormalTok{res)), }\DecValTok{3}\NormalTok{)}
\CommentTok{\#\textgreater{}       y1 y1.hat        e       }
\CommentTok{\#\textgreater{} 1  81.13  130.5  {-}49.375  81.13}
\CommentTok{\#\textgreater{} 2 106.67  159.7  {-}53.037 106.67}
\CommentTok{\#\textgreater{} 3 308.03  317.8   {-}9.813 308.03}
\CommentTok{\#\textgreater{} 4 177.31  186.3   {-}8.971 177.31}
\CommentTok{\#\textgreater{} 5  61.39  191.5 {-}130.089  61.39}
\CommentTok{\#\textgreater{} 6 374.09  331.7   42.426 374.09}
\end{Highlighting}
\end{Shaded}

Lo stesso può dirsi di \(y_2\). La correlazione parziale \(r_{12 \mid f}\) tra \(y_1\) e \(y_2\) dato \(f\) è uguale alla correlazione di Pearson tra i residui \(e_1\) e \(e_2\) calcolati mediante i due modelli di regressione descritti sopra:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cor}\NormalTok{(fm1}\SpecialCharTok{$}\NormalTok{res, fm2}\SpecialCharTok{$}\NormalTok{res)}
\CommentTok{\#\textgreater{} [1] 0.02829}
\end{Highlighting}
\end{Shaded}

La correlazione parziale tra \(y_1\) e \(y_2\) al netto di \(f\) è .02829.

Per i dati esaminati sopra, dunque, la correlazione parziale tra le variabili \(y_1\) e \(y_2\) diventa uguale a zero se la variabile \(f\) viene controllata (ovvero, se escludiamo da \(y_1\) e da \(y_2\) l'effetto lineare di \(f\)). Il fatto che la correlazione parziale sia zero significa che la correlazione che abbiamo osservato tra \(y_1\) e \(y_2\) (\(r = 0.355\)) non dipendeva dall'effetto che una variabile \(y\) esercitava sull'altra, ma bensì dal fatto che c'era una terza variabile, \(f\), che influenzava sia \(y_1\) sia \(y_2\). In altre parole, le variabili \(y_1\) e \(y_2\) sono condizionalmente indipendenti dato \(f\). Ciò significa, come abbiamo visto sopra, che la componente di \(y_1\) linearmente indipendente da \(f\) è incorrelata con la componente di \(y_2\) linearmente indipendente da \(f\).

La correlazione che abbiamo calcolato tra i residui di due modelli di regressione non è altro che la correlazione che viene calcolata applicando la \eqref{eq:corr-parz}. Infatti, inserendo nella \eqref{eq:corr-parz} i valori delle correlazioni esaminate otteniamo

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(R[}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{] }\SpecialCharTok{{-}}\NormalTok{ R[}\DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{] }\SpecialCharTok{*}\NormalTok{ R[}\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{]) }\SpecialCharTok{/}
  \FunctionTok{sqrt}\NormalTok{((}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ R[}\DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{]}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ R[}\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{]}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{round}\NormalTok{(}\DecValTok{3}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 0.02828}
\end{Highlighting}
\end{Shaded}

In conclusione, possiamo dunque attribuire alla \eqref{eq:corr-parz} la seguente interpretazione: la correlazione parziale tra le variabili \(y_1\) e \(y_2\) dato \(f\) non è altro che la correlazione tra le componenti di \(y_1\) e \(y_2\) da cui l'effetto lineare di \(f\) è stato rimosso.

\hypertarget{principio-base-dellanalisi-fattoriale}{%
\section{Principio base dell'analisi fattoriale}\label{principio-base-dellanalisi-fattoriale}}

Attualmente, l'inferenza statistica nell'analisi fattoriale spesso si svolge mediante il calcolo di stime della massima verosimiglianza ottenute mediante procedure iterative come l'algoritmo EM (Rubin \& Thayer, 1982). All'inizio dell'analisi fattoriale, tuttavia, la procedura di estrazione dei fattori faceva leva sulle relazioni invarianti che il modello fattoriale impone agli elementi della matrice di covarianza delle variabili osservate. Il più conosciuto tra tali invarianti è la \emph{tetrade} che si presenta nei modelli ad un fattore.

La tetrade è una combinazione di quattro correlazioni. Se l'associazione osservata tra le variabili dipende effettivamente dal fatto che le variabili in questione sono state causalmente generate da un fattore comune inosservabile, allora è possibile generare una combinazione delle correlazioni tra le variabili che porta all'annullamento della tetrade. In altre parole, l'analisi fattoriale si chiede se esiste un insieme esiguo di \(m<p\) variabili inosservabili che rendono significativamente nulle tutte le correlazioni parziali tra le \(p\) variabili osservate al netto dei fattori comuni. Se il metodo della correlazione parziale consente di identificare \(m\) variabili latenti, allora lo psicologo conclude che tali fattori corrispondono agli \(m\) costrutti che intende misurare.

Per chiarire il metodo dell'annullamento della tetrade consideriamo la matrice di correlazioni riportata nella Tabella @ref(tab:corr\_parziale). Nella tabella, la correlazione parziale tra ciascuna coppia di variabili \(y_i\), \(y_j\) (con \(i \neq j\)) dato \(\xi\) è sempre uguale a zero. Ad esempio, la correlazione parziale tra \(y_3\) e \(y_5\) dato \(\xi\) è:

\begin{equation}
\begin{aligned}
  r_{35 \mid \xi} &= \frac{r_{35} - r_{3\xi}r_{5\xi}}
  {\sqrt{(1-r_{3\xi}^2)(1-r_{5\xi}^2)}} \notag \\[12pt]
  &= \frac{0.35 - 0.7 \times 0.5}
  {\sqrt{(1-0.7^2)(1-0.5^2)}} = 0. \notag
  \end{aligned}
\end{equation}

Lo stesso risultato si trova per qualunque altra coppia di variabili \(y_i\) e \(y_j\), ovvero \(r_{ij \mid \xi} = 0\).

\hypertarget{tab:corr-parziale}{}
\begin{longtable}[]{@{}lcccccc@{}}
\caption{Matrice di correlazioni nella quale tutte le correlazioni parziali tra le variabili \(Y\) al netto dell'effetto di \(\xi\) sono nulle.}\tabularnewline
\toprule
& \(\xi\) & \(y_1\) & \(y_2\) & \(y_3\) & \(y_4\) & \(y_5\) \\
\midrule
\endfirsthead
\toprule
& \(\xi\) & \(y_1\) & \(y_2\) & \(y_3\) & \(y_4\) & \(y_5\) \\
\midrule
\endhead
\(\xi\) & \textbf{1.00} & & & & & \\
\(y_1\) & \textbf{0.90} & 1.00 & & & & \\
\(y_2\) & \textbf{0.80} & 0.72 & 1.00 & & & \\
\(y_3\) & \textbf{0.70} & 0.63 & 0.56 & 1.00 & & \\
\(y_4\) & \textbf{0.60} & 0.54 & 0.48 & 0.42 & 1.00 & \\
\(y_5\) & \textbf{0.50} & 0.45 & 0.40 & 0.35 & 0.30 & 1.00 \\
\bottomrule
\end{longtable}

Possiamo dunque dire che, per la matrice di correlazioni della Tabella precedente, esiste un'unica variabile \(\xi\) la quale, quando viene controllata, spiega tutte le

\[
p(p-1)/2 = 5(5-1)/2=10
\]

correlazioni tra le variabili \(y\). Questo risultato non è sorprendente, in quanto la matrice di correlazioni della Tabella esaminata è stata costruita in modo tale da possedere tale proprietà.

Ma supponiamo di essere in una situazione diversa, ovvero di avere osservato soltanto le variabili \(y_i\) e di non conoscere \(\xi\). In tali circostanze ci possiamo porre la seguente domanda: ``esiste una variabile inosservabile \(\xi\) la quale, se venisse controllata, renderebbe uguali a zero tutte le correlazioni parziali tra le variabili \(y\)?'' Se una tale variabile inosservabile esiste, ed è in grado di spiegare tutte le correlazioni tra le variabili osservate \(y\), allora essa viene chiamata \emph{fattore}.

\begin{definition}
Un fattore è una variabile inosservabile in grado di rendere significativamente nulle tutte le correlazioni parziali tra le variabili manifeste.
\end{definition}

\hypertarget{vincoli-sulle-correlazioni}{%
\subsection{Vincoli sulle correlazioni}\label{vincoli-sulle-correlazioni}}

Come si può stabilire se esiste una variabile inosservabile in grado di rendere nulle tutte le correlazioni parziali tra le variabili osservate? Riscriviamo la \eqref{eq:corr-parz} per specificare la correlazione parziale tra le variabili \(y_i\) e \(y_j\) dato \(\xi\):

\[
  r_{ij \mid \xi} = \frac{r_{ij} - r_{i\xi}r_{j\xi}}
  {\sqrt{(1-r_{i\xi}^2)(1-r_{j\xi}^2)}}
\]

Affinché \(r_{ij \mid \xi}\) sia uguale a zero è necessario che

\[
r_{ij} - r_{i\xi}r_{j\xi}=0
\]

ovvero

\[
r_{ij} = r_{i\xi}r_{j\xi}.
\]

In altri termini, se esiste un fattore non osservato \(\xi\) in grado di rendere uguali a zero tutte le correlazioni parziali \(r_{ih \mid \xi}\), allora la correlazione tra ciascuna coppia di variabili \(y\) deve essere uguale al prodotto delle correlazioni tra ciascuna \(y\) e il fattore latente \(\xi\). Questo è il principio base dell'analisi fattoriale.

\hypertarget{teoria-dei-due-fattori}{%
\subsection{Teoria dei Due Fattori}\label{teoria-dei-due-fattori}}

Per fare un esempio concreto relativo al metodo dell'annullamento della tetrade, esaminiamo la matrice di correlazioni originariamente analizzata da Spearman. Spearman (1904) raccolse alcune misure di capacità intellettuale su un piccolo numero di studenti di una scuola superiore. Nello specifico, esaminò i voti di tali studenti nelle seguenti materie: studio dei classici (\(c\)), letteratura inglese (\(e\)) e abilità matematiche (\(m\)). Considerò anche la prestazione in un compito di discriminazione dell'altezza di suoni (\emph{pitch discrimination}) (\(p\)), ovvero un'abilità diversa da quelle richieste nei test scolastici.

Secondo la Teoria dei Due Fattori, le prestazioni relative ad un determinato compito intellettuale possiedono una componente comune (detta fattore ``g'') con le prestazioni in un qualunque altro compito intellettuale e una componente specifica a quel determinato compito. Il modello dell'intelligenza di Spearman prevede dunque due fattori, uno generale e uno specifico (detto fattore ``s''). Il fattore ``g'' costituisce la componente invariante dell'abilità intellettiva, mente il fattore ``s'' è una componente che varia da condizione a condizione.

Come è possibile stabilire se esiste una variabile latente in grado di spiegare le correlazioni tra le variabili osservate da Spearman? Lo strumento proposto da Spearman per rispondere a questa domanda è \emph{l'annullamento della tetrade}. L'annullamento della tetrade utilizza i vincoli sulle correlazioni che derivano dalla definizione di correlazione parziale. In precedenza abbiamo visto che la correlazione parziale tra le variabili \(y\) indicizzate da \(i\) e \(j\), al netto dell'effetto di \(\xi\), è nulla se

\[
r_{ij} = r_{i\xi}r_{j\xi}.
\]

Nel caso dei dati di Spearman, dunque, le correlazioni parziali sono nulle se la correlazione tra ``studi classici'' e ``letteratura inglese'' è uguale al prodotto della correlazione tra ``studi classici'' e il fattore \(\xi\) e della correlazione tra ``letteratura inglese'' e il fattore \(\xi\). Inoltre, la correlazione tra ``studi classici'' e ``abilità matematica'' deve essere uguale al prodotto della correlazione tra ``studi classici'' e il fattore \(\xi\) e della correlazione tra ``abilità matematica'' e il fattore \(\xi\); e così via.

Le correlazioni tra le variabili manifeste e il fattore latente sono dette \emph{saturazioni fattoriali} e vengono denotate con la lettera \(\lambda\). Se il modello di Spearman è corretto, avremo che

\[
r_{ec}=\lambda_e \times \lambda_{c},
\]

dove \(r_{ec}\) è la correlazione tra ``letteratura inglese'' (e) e ``studi classici'' (c), \(\lambda_e\) è la correlazione tra ``letteratura inglese'' e \(\xi\), e \(\lambda_{c}\) è la correlazione tra ``studi classici'' e \(\xi\).

Allo stesso modo, la correlazione tra ``studi classici'' e ``matematica'' (m) dovrà essere uguale a

\[
\lambda_c \times \lambda_m,
\]

eccetera.

\hypertarget{annullamento-della-tetrade}{%
\subsection{Annullamento della tetrade}\label{annullamento-della-tetrade}}

Date le correlazioni tra tre coppie di variabili manifeste, il metodo dell'annullamento della tetrade rende possibile stimare i valori delle saturazioni fattoriali \(\lambda\). Ad esempio, per le variabili \(c\), \(m\) ed \(e\), possiamo scrivere le seguenti tre equazioni in tre incognite:

\begin{equation}
\begin{aligned}
  r_{cm} &= \lambda_c \times \lambda_m, \notag \\
  r_{em} &= \lambda_e \times \lambda_m,  \\
  r_{ce} &= \lambda_c \times \lambda_e. \notag
\end{aligned}
\end{equation}

Risolvendo il precedente sistema di equazioni lineari, il coefficiente di saturazione \(\lambda_m\) della variabile \(y_m\) nel fattore comune \(\xi\), ad esempio, può essere calcolato a partire dalle correlazioni tra le variabili manifeste \(c\), \(m\), ed \(e\) nel modo seguente:

\begin{equation}
\lambda_m = \sqrt{ \frac{r_{cm} r_{em}}{r_{ce}}}.
\label{eq:tetradi}
\end{equation}

Lo stesso vale per le altre due saturazioni \(\lambda_c\) e \(\lambda_e\).

Nel suo articolo del 1904, Spearman osservò le seguenti correlazioni tra le variabili \(Y_c\), \(Y_e\), \(Y_m\) e \(Y_p\):

\[
\begin{array}{ccccc}
  \hline
    & Y_C & Y_E & Y_M & Y_P \\
  \hline
  Y_C & 1.00 & 0.78 & 0.70 & 0.66 \\
  Y_E &   & 1.00 & 0.64 & 0.54 \\
  Y_M &   &   & 1.00 & 0.45 \\
  Y_P &   &   &   & 1.00 \\
  \hline
\end{array}
\]

Utilizzando la \eqref{eq:tetradi}, mediante le correlazioni \(r_{cm}\), \(r_{em}\), e \(r_{ce}\) fornite dalla tabella precedente, la saturazione \(\lambda_m\) diventa uguale a:

\[
  \hat{\lambda}_m = \sqrt{ \frac{r_{cm} r_{em}}{r_{ce}} } = \sqrt{
    \frac{0.70 \times 0.64}{0.78} } = 0.76.
\]

È importante notare che il metodo dell'annullamento della tetrade produce risultati falsificabili. Infatti, ci sono modi diversi per calcolare la stessa saturazione fattoriale. Se il modello fattoriale è corretto si deve ottenere lo stesso risultato in tutti i casi. Nel caso presente, la saturazione fattoriale \(\lambda_m\) può essere calcolata in altri due modi:

\begin{equation}
\begin{aligned}
  \hat{\lambda}_m &= \sqrt{ \frac{r_{cm} r_{mp}}{r_{cp}} } = \sqrt{ \frac{0.78 \times 0.45}{0.66} } = 0.69, \notag \\
  \hat{\lambda}_m &= \sqrt{ \frac{r_{em} r_{mp}}{r_{ep}} } = \sqrt{
    \frac{0.64 \times 0.45}{0.54} } = 0.73. \notag\end{aligned}
\end{equation}

I tre valori che sono stati ottenuti sono molto simili. Qual è allora la stima migliore di \(\lambda_m\)?

\hypertarget{metodo-del-centroide}{%
\subsection{Metodo del centroide}\label{metodo-del-centroide}}

La soluzione più semplice è quella di fare la media di questi tre valori (\(\bar{\lambda}_m = 0.73\)). Un metodo migliore (meno vulnerabile ai valori anomali) è dato dal rapporto tra la somma dei numeratori e dei denominatori:

\[
  \hat{\lambda}_m = \sqrt{ \frac{0.70 \times 0.64 + 0.78 \times 0.45 + 0.64
      \times 0.45}{0.78+0.66+0.54} } = 0.73
\]

In questo caso, i due metodi danno lo stesso risultato. Le altre tre saturazioni fattoriali trovate mediante il metodo del centroide sono:

\[
\hat{\lambda}_c = 0.97, \quad \hat{\lambda}_e = 0.84, \quad
\hat{\lambda}_p = 0.65.
\]

In conclusione,

\[
\boldsymbol{\hat{\Lambda}}^\prime=
(\hat{\lambda}_c, \hat{\lambda}_e, \hat{\lambda}_m, \hat{\lambda}_p) = (0.97, 0.84, 0.73, 0.65).
\]

\hypertarget{introduzione-a-lavaan}{%
\subsection{\texorpdfstring{Introduzione a \texttt{lavaan}}{Introduzione a lavaan}}\label{introduzione-a-lavaan}}

Analizziamo ora nuovamente gli stessi dati usando un metodo di stima moderno (massima verosimiglianza), mediante le funzioni del pacchetto \texttt{lavaan}. La matrice completa dei dati di Spearman è messa a disposizione da \citet{kan2019extending}. Iniziamo a caricare i pacchetti necessari:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(}\StringTok{"lavaan"}\NormalTok{)}
\FunctionTok{library}\NormalTok{(}\StringTok{"semPlot"}\NormalTok{)}
\FunctionTok{library}\NormalTok{(}\StringTok{"knitr"}\NormalTok{)}
\FunctionTok{library}\NormalTok{(}\StringTok{"kableExtra"}\NormalTok{)}
\FunctionTok{library}\NormalTok{(}\StringTok{"tidyr"}\NormalTok{)}
\FunctionTok{library}\NormalTok{(}\StringTok{"corrplot"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Specifichiamo il nome delle variabili manifeste

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{varnames }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}
  \StringTok{"Classics"}\NormalTok{, }\StringTok{"French"}\NormalTok{, }\StringTok{"English"}\NormalTok{, }\StringTok{"Math"}\NormalTok{, }\StringTok{"Pitch"}\NormalTok{, }\StringTok{"Music"}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

e il loro numero

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ny }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(varnames)}
\end{Highlighting}
\end{Shaded}

Leggiamo la matrice di correlazione:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spearman\_cor\_mat }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}
  \FunctionTok{c}\NormalTok{(}
    \FloatTok{1.00}\NormalTok{, .}\DecValTok{83}\NormalTok{, .}\DecValTok{78}\NormalTok{, .}\DecValTok{70}\NormalTok{, .}\DecValTok{66}\NormalTok{, .}\DecValTok{63}\NormalTok{,}
\NormalTok{    .}\DecValTok{83}\NormalTok{, }\FloatTok{1.00}\NormalTok{, .}\DecValTok{67}\NormalTok{, .}\DecValTok{67}\NormalTok{, .}\DecValTok{65}\NormalTok{, .}\DecValTok{57}\NormalTok{,}
\NormalTok{    .}\DecValTok{78}\NormalTok{, .}\DecValTok{67}\NormalTok{, }\FloatTok{1.00}\NormalTok{, .}\DecValTok{64}\NormalTok{, .}\DecValTok{54}\NormalTok{, .}\DecValTok{51}\NormalTok{,}
\NormalTok{    .}\DecValTok{70}\NormalTok{, .}\DecValTok{67}\NormalTok{, .}\DecValTok{64}\NormalTok{, }\FloatTok{1.00}\NormalTok{, .}\DecValTok{45}\NormalTok{, .}\DecValTok{51}\NormalTok{,}
\NormalTok{    .}\DecValTok{66}\NormalTok{, .}\DecValTok{65}\NormalTok{, .}\DecValTok{54}\NormalTok{, .}\DecValTok{45}\NormalTok{, }\FloatTok{1.00}\NormalTok{, .}\DecValTok{40}\NormalTok{,}
\NormalTok{    .}\DecValTok{63}\NormalTok{, .}\DecValTok{57}\NormalTok{, .}\DecValTok{51}\NormalTok{, .}\DecValTok{51}\NormalTok{, .}\DecValTok{40}\NormalTok{, }\FloatTok{1.00}
\NormalTok{  ),}
\NormalTok{  ny, ny,}
  \AttributeTok{byrow =} \ConstantTok{TRUE}\NormalTok{,}
  \AttributeTok{dimnames =} \FunctionTok{list}\NormalTok{(varnames, varnames)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Specifichiamo l'ampiezza campionaria:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{33}
\end{Highlighting}
\end{Shaded}

Esaminiamo la sintassi usata da \texttt{lavaan} a livello degli item:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Regression}
\NormalTok{y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ f1 }\SpecialCharTok{+}\NormalTok{ f2 }\SpecialCharTok{+}\NormalTok{ x1 }\SpecialCharTok{+}\NormalTok{ x2}
\NormalTok{f1 }\SpecialCharTok{\textasciitilde{}}\NormalTok{ f2 }\SpecialCharTok{+}\NormalTok{ f3}
\NormalTok{f2 }\SpecialCharTok{\textasciitilde{}}\NormalTok{ f3 }\SpecialCharTok{+}\NormalTok{ x1 }\SpecialCharTok{+}\NormalTok{ x2}
\CommentTok{\# Latent variables}
\NormalTok{f1 }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\NormalTok{ y1 }\SpecialCharTok{+}\NormalTok{ y2 }\SpecialCharTok{+}\NormalTok{ y3}
\NormalTok{f2 }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\NormalTok{ y4 }\SpecialCharTok{+}\NormalTok{ y5 }\SpecialCharTok{+}\NormalTok{ y6}
\NormalTok{f3 }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\NormalTok{ y7 }\SpecialCharTok{+}\NormalTok{ y8 }\SpecialCharTok{+}\NormalTok{ y9 }\SpecialCharTok{+}\NormalTok{ y10}
\CommentTok{\# Variances and covariances}
\NormalTok{y1 }\SpecialCharTok{\textasciitilde{}} \ErrorTok{\textasciitilde{}}\NormalTok{y1}
\NormalTok{y1 }\SpecialCharTok{\textasciitilde{}} \ErrorTok{\textasciitilde{}}\NormalTok{y2}
\NormalTok{f1 }\SpecialCharTok{\textasciitilde{}} \ErrorTok{\textasciitilde{}}\NormalTok{f2}
\CommentTok{\# Intercepts}
\NormalTok{y1 }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}
\NormalTok{f1 }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}
\end{Highlighting}
\end{Shaded}

Definiamo il modello unifattoriale in \texttt{lavaan}. L'operatore \texttt{=\textasciitilde{}} si può leggere dicendo che la variabile latente a sinistra dell'operatore viene identificata dalle variabili manifeste elencate a destra dell'operatore e separate dal segno \texttt{+}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spearman\_mod }\OtherTok{\textless{}{-}} \StringTok{"}
\StringTok{  g =\textasciitilde{} Classics + French + English + Math + Pitch + Music}
\StringTok{"}
\end{Highlighting}
\end{Shaded}

Adattiamo il modello ai dati con la funzione \texttt{cfa()}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit1 }\OtherTok{\textless{}{-}}\NormalTok{ lavaan}\SpecialCharTok{::}\FunctionTok{cfa}\NormalTok{(}
\NormalTok{  spearman\_mod,}
  \AttributeTok{sample.cov =}\NormalTok{ spearman\_cor\_mat,}
  \AttributeTok{sample.nobs =}\NormalTok{ n,}
  \AttributeTok{std.lv =} \ConstantTok{TRUE}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

L'argomento \texttt{std.lv\ =\ TRUE} specifica che imponiamo una varianza pari a 1 a tutte le variabili latenti comuni (nel caso presente, solo una). Ciò consente di stimare le saturazioni fattoriali. Possiamo esaminare la soluzione ottenuta con la seguente istruzione:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(}
\NormalTok{  fit1,}
  \AttributeTok{fit.measures =} \ConstantTok{TRUE}\NormalTok{,}
  \AttributeTok{standardized =} \ConstantTok{TRUE}
\NormalTok{)}
\CommentTok{\#\textgreater{} lavaan 0.6{-}10 ended normally after 23 iterations}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}   Estimator                                         ML}
\CommentTok{\#\textgreater{}   Optimization method                           NLMINB}
\CommentTok{\#\textgreater{}   Number of model parameters                        12}
\CommentTok{\#\textgreater{}                                                       }
\CommentTok{\#\textgreater{}   Number of observations                            33}
\CommentTok{\#\textgreater{}                                                       }
\CommentTok{\#\textgreater{} Model Test User Model:}
\CommentTok{\#\textgreater{}                                                       }
\CommentTok{\#\textgreater{}   Test statistic                                 2.913}
\CommentTok{\#\textgreater{}   Degrees of freedom                                 9}
\CommentTok{\#\textgreater{}   P{-}value (Chi{-}square)                           0.968}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Model Test Baseline Model:}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}   Test statistic                               133.625}
\CommentTok{\#\textgreater{}   Degrees of freedom                                15}
\CommentTok{\#\textgreater{}   P{-}value                                        0.000}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} User Model versus Baseline Model:}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}   Comparative Fit Index (CFI)                    1.000}
\CommentTok{\#\textgreater{}   Tucker{-}Lewis Index (TLI)                       1.086}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Loglikelihood and Information Criteria:}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}   Loglikelihood user model (H0)               {-}212.547}
\CommentTok{\#\textgreater{}   Loglikelihood unrestricted model (H1)       {-}211.091}
\CommentTok{\#\textgreater{}                                                       }
\CommentTok{\#\textgreater{}   Akaike (AIC)                                 449.094}
\CommentTok{\#\textgreater{}   Bayesian (BIC)                               467.052}
\CommentTok{\#\textgreater{}   Sample{-}size adjusted Bayesian (BIC)          429.622}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Root Mean Square Error of Approximation:}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}   RMSEA                                          0.000}
\CommentTok{\#\textgreater{}   90 Percent confidence interval {-} lower         0.000}
\CommentTok{\#\textgreater{}   90 Percent confidence interval {-} upper         0.000}
\CommentTok{\#\textgreater{}   P{-}value RMSEA \textless{}= 0.05                          0.976}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Standardized Root Mean Square Residual:}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}   SRMR                                           0.025}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Parameter Estimates:}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}   Standard errors                             Standard}
\CommentTok{\#\textgreater{}   Information                                 Expected}
\CommentTok{\#\textgreater{}   Information saturated (h1) model          Structured}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Latent Variables:}
\CommentTok{\#\textgreater{}                    Estimate  Std.Err  z{-}value  P(\textgreater{}|z|)}
\CommentTok{\#\textgreater{}   g =\textasciitilde{}                                                }
\CommentTok{\#\textgreater{}     Classics          0.942    0.129    7.314    0.000}
\CommentTok{\#\textgreater{}     French            0.857    0.137    6.239    0.000}
\CommentTok{\#\textgreater{}     English           0.795    0.143    5.545    0.000}
\CommentTok{\#\textgreater{}     Math              0.732    0.149    4.923    0.000}
\CommentTok{\#\textgreater{}     Pitch             0.678    0.153    4.438    0.000}
\CommentTok{\#\textgreater{}     Music             0.643    0.155    4.142    0.000}
\CommentTok{\#\textgreater{}    Std.lv  Std.all}
\CommentTok{\#\textgreater{}                   }
\CommentTok{\#\textgreater{}     0.942    0.956}
\CommentTok{\#\textgreater{}     0.857    0.871}
\CommentTok{\#\textgreater{}     0.795    0.807}
\CommentTok{\#\textgreater{}     0.732    0.743}
\CommentTok{\#\textgreater{}     0.678    0.689}
\CommentTok{\#\textgreater{}     0.643    0.653}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Variances:}
\CommentTok{\#\textgreater{}                    Estimate  Std.Err  z{-}value  P(\textgreater{}|z|)}
\CommentTok{\#\textgreater{}    .Classics          0.083    0.051    1.629    0.103}
\CommentTok{\#\textgreater{}    .French            0.234    0.072    3.244    0.001}
\CommentTok{\#\textgreater{}    .English           0.338    0.094    3.610    0.000}
\CommentTok{\#\textgreater{}    .Math              0.434    0.115    3.773    0.000}
\CommentTok{\#\textgreater{}    .Pitch             0.510    0.132    3.855    0.000}
\CommentTok{\#\textgreater{}    .Music             0.556    0.143    3.893    0.000}
\CommentTok{\#\textgreater{}     g                 1.000                           }
\CommentTok{\#\textgreater{}    Std.lv  Std.all}
\CommentTok{\#\textgreater{}     0.083    0.086}
\CommentTok{\#\textgreater{}     0.234    0.242}
\CommentTok{\#\textgreater{}     0.338    0.349}
\CommentTok{\#\textgreater{}     0.434    0.447}
\CommentTok{\#\textgreater{}     0.510    0.526}
\CommentTok{\#\textgreater{}     0.556    0.573}
\CommentTok{\#\textgreater{}     1.000    1.000}
\end{Highlighting}
\end{Shaded}

È possibile semplificare l'output dalla funzione \texttt{summary()} in maniera tale da stampare solo la tabella completa delle stime dei parametri e degli errori standard, ecc.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{kable}\NormalTok{(}\FunctionTok{coef}\NormalTok{(fit1), }\AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{format =} \StringTok{"markdown"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}lr@{}}
\toprule
& x \\
\midrule
\endhead
g=\textasciitilde Classics & 0.94153 \\
g=\textasciitilde French & 0.85749 \\
g=\textasciitilde English & 0.79480 \\
g=\textasciitilde Math & 0.73208 \\
g=\textasciitilde Pitch & 0.67826 \\
g=\textasciitilde Music & 0.64325 \\
Classics\textasciitilde\textasciitilde Classics & 0.08322 \\
French\textasciitilde\textasciitilde French & 0.23441 \\
English\textasciitilde\textasciitilde English & 0.33799 \\
Math\textasciitilde\textasciitilde Math & 0.43375 \\
Pitch\textasciitilde\textasciitilde Pitch & 0.50965 \\
Music\textasciitilde\textasciitilde Music & 0.55593 \\
\bottomrule
\end{longtable}

Anziché stampare direttamente la tabella dei parametri, è meglio riformattarla con \texttt{kable} quando utilizziamo RMarkdown. Senza usare \texttt{kable}, l'output diventa:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{parameterEstimates}\NormalTok{(fit1, }\AttributeTok{standardized =} \ConstantTok{TRUE}\NormalTok{)}
\CommentTok{\#\textgreater{}         lhs op      rhs   est    se     z pvalue}
\CommentTok{\#\textgreater{} 1         g =\textasciitilde{} Classics 0.942 0.129 7.314  0.000}
\CommentTok{\#\textgreater{} 2         g =\textasciitilde{}   French 0.857 0.137 6.239  0.000}
\CommentTok{\#\textgreater{} 3         g =\textasciitilde{}  English 0.795 0.143 5.545  0.000}
\CommentTok{\#\textgreater{} 4         g =\textasciitilde{}     Math 0.732 0.149 4.923  0.000}
\CommentTok{\#\textgreater{} 5         g =\textasciitilde{}    Pitch 0.678 0.153 4.438  0.000}
\CommentTok{\#\textgreater{} 6         g =\textasciitilde{}    Music 0.643 0.155 4.142  0.000}
\CommentTok{\#\textgreater{} 7  Classics \textasciitilde{}\textasciitilde{} Classics 0.083 0.051 1.629  0.103}
\CommentTok{\#\textgreater{} 8    French \textasciitilde{}\textasciitilde{}   French 0.234 0.072 3.244  0.001}
\CommentTok{\#\textgreater{} 9   English \textasciitilde{}\textasciitilde{}  English 0.338 0.094 3.610  0.000}
\CommentTok{\#\textgreater{} 10     Math \textasciitilde{}\textasciitilde{}     Math 0.434 0.115 3.773  0.000}
\CommentTok{\#\textgreater{} 11    Pitch \textasciitilde{}\textasciitilde{}    Pitch 0.510 0.132 3.855  0.000}
\CommentTok{\#\textgreater{} 12    Music \textasciitilde{}\textasciitilde{}    Music 0.556 0.143 3.893  0.000}
\CommentTok{\#\textgreater{} 13        g \textasciitilde{}\textasciitilde{}        g 1.000 0.000    NA     NA}
\CommentTok{\#\textgreater{}    ci.lower ci.upper std.lv std.all std.nox}
\CommentTok{\#\textgreater{} 1     0.689    1.194  0.942   0.956   0.956}
\CommentTok{\#\textgreater{} 2     0.588    1.127  0.857   0.871   0.871}
\CommentTok{\#\textgreater{} 3     0.514    1.076  0.795   0.807   0.807}
\CommentTok{\#\textgreater{} 4     0.441    1.024  0.732   0.743   0.743}
\CommentTok{\#\textgreater{} 5     0.379    0.978  0.678   0.689   0.689}
\CommentTok{\#\textgreater{} 6     0.339    0.948  0.643   0.653   0.653}
\CommentTok{\#\textgreater{} 7    {-}0.017    0.183  0.083   0.086   0.086}
\CommentTok{\#\textgreater{} 8     0.093    0.376  0.234   0.242   0.242}
\CommentTok{\#\textgreater{} 9     0.154    0.522  0.338   0.349   0.349}
\CommentTok{\#\textgreater{} 10    0.208    0.659  0.434   0.447   0.447}
\CommentTok{\#\textgreater{} 11    0.251    0.769  0.510   0.526   0.526}
\CommentTok{\#\textgreater{} 12    0.276    0.836  0.556   0.573   0.573}
\CommentTok{\#\textgreater{} 13    1.000    1.000  1.000   1.000   1.000}
\end{Highlighting}
\end{Shaded}

Se invece usiamo \texttt{kable}, con gli opportuni parametri, otteniamo:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{parameterEstimates}\NormalTok{(fit1, }\AttributeTok{standardized =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{filter}\NormalTok{(op }\SpecialCharTok{==} \StringTok{"=\textasciitilde{}"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{select}\NormalTok{(}
    \StringTok{"Latent Factor"} \OtherTok{=}\NormalTok{ lhs,}
    \AttributeTok{Indicator =}\NormalTok{ rhs,}
    \AttributeTok{B =}\NormalTok{ est,}
    \AttributeTok{SE =}\NormalTok{ se,}
    \AttributeTok{Z =}\NormalTok{ z,}
    \StringTok{"p{-}value"} \OtherTok{=}\NormalTok{ pvalue,}
    \AttributeTok{Beta =}\NormalTok{ std.all}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
    \AttributeTok{digits =} \DecValTok{3}\NormalTok{, }\AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{format =} \StringTok{"markdown"}\NormalTok{,}
    \AttributeTok{caption =} \StringTok{"Factor Loadings"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}llrrrrr@{}}
\caption{\label{tab:unnamed-chunk-84}Factor Loadings}\tabularnewline
\toprule
Latent Factor & Indicator & B & SE & Z & p-value & Beta \\
\midrule
\endfirsthead
\toprule
Latent Factor & Indicator & B & SE & Z & p-value & Beta \\
\midrule
\endhead
g & Classics & 0.942 & 0.129 & 7.314 & 0 & 0.956 \\
g & French & 0.857 & 0.137 & 6.239 & 0 & 0.871 \\
g & English & 0.795 & 0.143 & 5.545 & 0 & 0.807 \\
g & Math & 0.732 & 0.149 & 4.923 & 0 & 0.743 \\
g & Pitch & 0.678 & 0.153 & 4.438 & 0 & 0.689 \\
g & Music & 0.643 & 0.155 & 4.142 & 0 & 0.653 \\
\bottomrule
\end{longtable}

Esaminiamo la matrice delle correlazioni residue:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cor\_table }\OtherTok{\textless{}{-}} \FunctionTok{residuals}\NormalTok{(fit1, }\AttributeTok{type =} \StringTok{"cor"}\NormalTok{)}\SpecialCharTok{$}\NormalTok{cov}
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
\NormalTok{  cor\_table,}
  \AttributeTok{digits =} \DecValTok{3}\NormalTok{,}
  \AttributeTok{format =} \StringTok{"markdown"}\NormalTok{,}
  \AttributeTok{booktabs =} \ConstantTok{TRUE}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}lrrrrrr@{}}
\toprule
& Classics & French & English & Math & Pitch & Music \\
\midrule
\endhead
Classics & 0.000 & -0.003 & 0.008 & -0.011 & 0.001 & 0.005 \\
French & -0.003 & 0.000 & -0.033 & 0.023 & 0.050 & 0.001 \\
English & 0.008 & -0.033 & 0.000 & 0.040 & -0.016 & -0.017 \\
Math & -0.011 & 0.023 & 0.040 & 0.000 & -0.062 & 0.024 \\
Pitch & 0.001 & 0.050 & -0.016 & -0.062 & 0.000 & -0.050 \\
Music & 0.005 & 0.001 & -0.017 & 0.024 & -0.050 & 0.000 \\
\bottomrule
\end{longtable}

Creiamo un qq-plot dei residui:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{res1 }\OtherTok{\textless{}{-}} \FunctionTok{residuals}\NormalTok{(fit1, }\AttributeTok{type =} \StringTok{"cor"}\NormalTok{)}\SpecialCharTok{$}\NormalTok{cov}
\NormalTok{res1[}\FunctionTok{upper.tri}\NormalTok{(res1, }\AttributeTok{diag =} \ConstantTok{TRUE}\NormalTok{)] }\OtherTok{\textless{}{-}} \ConstantTok{NA}
\NormalTok{v1 }\OtherTok{\textless{}{-}} \FunctionTok{as.vector}\NormalTok{(res1)}
\NormalTok{v2 }\OtherTok{\textless{}{-}}\NormalTok{ v1[}\SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(v1)]}

\FunctionTok{tibble}\NormalTok{(v2) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{sample =}\NormalTok{ v2)) }\SpecialCharTok{+}
  \FunctionTok{stat\_qq}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{stat\_qq\_line}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{cfa_book_files/figure-latex/unnamed-chunk-86-1} \end{center}

Il pacchetto \texttt{semPlot} consente di disegnare diagrammi di percorso per vari modelli SEM. La funzione \texttt{semPaths} prende in input un oggetto creato da \texttt{lavaan} e disegna il diagramma, con diverse opzioni disponibili. Il diagramma qui prodotto controlla le dimensioni dei caratteri/etichette, la visualizzazione dei residui e il colore dei percorsi/coefficienti. Sono disponibili queste e molte altre opzioni di controllo.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{semPaths}\NormalTok{(}
\NormalTok{  fit1,}
  \AttributeTok{residuals =} \ConstantTok{FALSE}\NormalTok{,}
  \AttributeTok{sizeMan =} \DecValTok{7}\NormalTok{,}
  \StringTok{"std"}\NormalTok{,}
  \AttributeTok{posCol =} \FunctionTok{c}\NormalTok{(}\StringTok{"black"}\NormalTok{),}
  \AttributeTok{edge.label.cex =} \FloatTok{1.2}\NormalTok{,}
  \AttributeTok{layout =} \StringTok{"circle2"}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{cfa_book_files/figure-latex/unnamed-chunk-87-1} \end{center}

In una versione alternativa del diagramma di percorso aggiungiamo anche le specificità:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{semPaths}\NormalTok{(}
\NormalTok{  fit1,}
  \StringTok{"std"}\NormalTok{,}
  \AttributeTok{posCol =} \FunctionTok{c}\NormalTok{(}\StringTok{"black"}\NormalTok{),}
  \AttributeTok{edge.label.cex =} \FloatTok{1.2}\NormalTok{,}
  \AttributeTok{sizeMan =} \DecValTok{7}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{cfa_book_files/figure-latex/unnamed-chunk-88-1} \end{center}

Il calcolo delle saturazioni fattoriali con il metodo del centroide aveva prodotto il risultato: \(\boldsymbol{\hat{\Lambda}}'= (0.97, 0.84, 0.73, 0.65)\). Si noti la somiglianza con i valori ottenuti mediante il metodo di massima verosimiglianza.

\hypertarget{conclusioni}{%
\section*{Conclusioni}\label{conclusioni}}


Nel presente capitolo abbiamo introdotto il metodo dell'annullamento della tetrade che consente di stimare le saturazioni di un modello monofattoriale. Abbiamo anche visto che il metodo dell'annullamento della tetrade non è altro che un'applicazione della correlazione parziale.

Possiamo dire che un tema cruciale nella costruzione dei test psicologici è quello di stabilire il numero di fattori/tratti che sono soggiacenti all'insieme degli indicatori che vengono considerati. La teoria classica dei test richiede che il test sia monofattoriale, ovvero che gli indicatori considerati siano l'espressione di un unico tratto latente. La violazione della monodimensionalità rende problematica l'applicazione dei principi della teoria classica dei test ai punteggi di un test che non possiede tale proprietà. L'esame della dimensionalità di un gruppo di indicatori rappresenta dunque una fase cruciale nel processo di costruzione di un test e, solitamente, questo esame è affrontato mediante l'analisi fattoriale. In questo capitolo abbiamo presentato le proprietà di base del modello unifattoriale.

\hypertarget{ch:mod_unifattoriale}{%
\chapter{Il modello statistico dell'analisi fattoriale}\label{ch:mod_unifattoriale}}

\hypertarget{modello-monofattoriale-1}{%
\section{Modello monofattoriale}\label{modello-monofattoriale-1}}

Il punto di partenza dell'\emph{analisi fattoriale esplorativa} è rappresentato da una marice di dimensioni \(p \times p\) (dove \(p\) è il numero di variabili osservate) che contiene i coefficienti di correlazione (o di covarianza) tra le variabili. Il punto di arrivo è rappresentato da una matrice di dimensioni \(p \times k\) (dove \(k\)) è il numero di fattori comuni che contiene i coefficienti (le \emph{saturazioni}) che esprimono la relazione tra i fattori e le variabili osservate. Considereremo ora il modello matematico dell'analisi fattoriale esplorativa, con un solo fattore comune, che rappresenta il caso più semplice.

Con \(p\) variabili manifeste \(Y_i\), il modello ad un fattore comune può essere espresso algebricamente nel modo seguente:

\[
Y_i = \mu_i + \lambda_{i} \xi + \delta_i \qquad i=1, \dots, p
\]

dove \(\xi\) rappresenta il fattore latente, chiamato anche \emph{fattore comune}, poiché è comune a tutte le \(Y_i\), i \(\delta_i\) sono invece specifici di ogni variabile osservata e per tale ragione vengono chiamati \emph{fattori specifici} o \emph{unici}, e infine i \(\lambda_i\) sono detti \emph{saturazioni} (o \emph{pesi}) fattoriali poiché consentono di valutare il peso del fattore latente su ciascuna variabile osservata. Si suole assumere per comodità che \(\mu=0\), il che corrisponde a considerare le variabili \(Y_i\) come ottenute dagli scarti dalle medie \(\mu_i\) per \(i = 1, \dots, p\):

\[
Y_i -\mu_i = \lambda_i \xi + \delta_i.
\]

Si assume che il fattore comune abbia media zero, \(\E(\xi)=0\), e varianza unitaria, \(\V(\xi)=1\), che i fattori specifici abbiano media zero, \(\E(\delta_j)=0\), e varianza \(\V(\delta_j)=\psi_{i}\), che i fattori specifici siano incorrelati tra loro, \(\E(\delta_i \delta_k)=0\), e che i fattori specifici siano incorrelati con il fattore comune, \(\E(\delta_i \xi)=0\).

In questo modello, poiché i fattori specifici sono tra loro incorrelati, l'interdipendenza tra le variabili manifeste è completamente spiegata dal fattore comune. Dalle ipotesi precedenti è possibile ricavare la covarianza tra \(Y_i\) e il fattore comune, la varianza della \(i\)-esima variabile manifesta \(Y_i\) e la covarianza tra due variabili manifeste \(Y_i\) e \(Y_k\).

\hypertarget{covarianza-tra-un-indicatore-e-il-fattore-comune}{%
\section{Covarianza tra un indicatore e il fattore comune}\label{covarianza-tra-un-indicatore-e-il-fattore-comune}}

Dal modello monofattoriale è possibile determinare l'espressione della covarianza teorica tra una variabile manifesta \(Y_i\) e il fattore comune \(\xi\):

\[
\mbox{Cov}(Y_i,\xi)=\E(Y_i \xi)-\E(Y_i)\E(\xi).
\]

Dato che \(\E(\xi)=0\), possiamo scrivere

\begin{equation}
\begin{aligned}
  \mbox{Cov}(Y_i,\xi) &= \E(Y_i \xi)=\E[(\lambda_i \xi + \delta_i) \xi]\notag\\
  &=\E(\lambda_i \xi^2 + \delta_i \xi)\notag\\
  &=\lambda_i\underbrace{\E(\xi^2)}_{\V(\xi)=1} + \underbrace{\E(\delta_i \xi)}_{\mbox{Cov}(\delta_i, \xi)=0}\notag\\
  &= \lambda_i.\notag
\end{aligned}
\end{equation}

Nel modello a un solo fattore, dunque, la saturazione \(\lambda_j\) rappresenta la covarianza la variabile manifesta \(Y_i\) e il fattore comune \(\xi\) e indica l'importanza del fattore nel determinare il punteggio osservato. Se le variabili \(Y_i\) sono standardizzate, la saturazione fattoriale \(\lambda_i\) corrisponde alla correlazione tra \(Y_i\) e \(\xi\).

\hypertarget{espressione-fattoriale-della-varianza}{%
\section{Espressione fattoriale della varianza}\label{espressione-fattoriale-della-varianza}}

Nell'ipotesi che le variabili \(Y_i\) abbiano media nulla, la varianza di \(Y_i\)

\begin{equation}
  \V(Y_i) = \E(Y_i^2) -[\E(Y_i)]^2 = \E(Y_i^2)\notag
\end{equation}

è data da

\begin{equation}
\begin{aligned}
  \V(Y_i) &= \E[(\lambda_i \xi + \delta_i)^2 ]\notag\\
  &=\lambda_i^2 \underbrace{\E(\xi^2) }_{\V(\xi)=1} + \underbrace{ \E(\delta_i^2) }_{\V(\delta_i)=\psi_{i}} + 2\lambda_i \underbrace{ \E(\xi \delta_i) }_{\mbox{Cov}(\xi, \delta_{i})=0}\notag\\
  &=\lambda^2_i + \psi_{i}.
\end{aligned}
\end{equation}

La quantità \(\lambda^2_i\) è denominata \emph{comunalità} della \(i\)-esima variabile manifesta e corrisponde alla quota della varianza della \(Y_i\) spiegata dal fattore comune. Di conseguenza \(\psi_{i}\) è la parte residua della varianza di \(Y_i\) non spiegata dal fattore comune ed è denominata \emph{unicità} di \(Y_i\). Nel caso di variabili standardizzate, l'unicità diventa uguale a

\[
\psi_{i}=1-\lambda^2_i.
\]

In definitiva, la varianza totale di una variabile osservata può essere divisa in una quota che ciascuna variabile condivide con le altre variabili ed è spiegata dal fattore comune (questa quota è chiamata \emph{comunalità} ed è uguale uguale al quadrato della saturazione della variabile osservata nel fattore comune, ovvero \(h^2_i = \lambda_i^2\)), e in una quota che è spiegata dal fattore specifico (questa parte è chiamata \emph{unicità} ed è uguale a \(u_i = \psi_{i}\)).

\begin{exercise}
Riprendiamo l'analisi della matrice di correlazioni di Spearman. Nell'output prodotto dalla funzione \texttt{factanal()} viene riportata la quantità denominata \texttt{SS\ loadings}.

Tale quantità indica la porzione della varianza totale delle 4 variabili manifeste che viene spiegata dal fattore comune. Ciascuna variabile standardizzata contribuisce con un'unità di varianza; nel caso presente, dunque la varianza totale è uguale a 4. Si ricordi che, nella statistica multivariata, per \emph{varianza totale} si intende la somma delle varianze delle variabili manifeste (nel linguaggio dell'algebra matriciale questa quantità corrisponde alla \emph{traccia} della matrice di covarianze). La quota della varianza totale spiegata dal modello, invece, è data dalla somma delle comunalità delle quattro variabili, ovvero dalla somma delle saturazioni fattoriali innalzate al quadrato.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Spearman }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{c}\NormalTok{(}
  \FloatTok{1.0}\NormalTok{, .}\DecValTok{78}\NormalTok{, .}\DecValTok{70}\NormalTok{, .}\DecValTok{66}\NormalTok{,}
\NormalTok{  .}\DecValTok{78}\NormalTok{, }\FloatTok{1.0}\NormalTok{, .}\DecValTok{64}\NormalTok{, .}\DecValTok{54}\NormalTok{,}
\NormalTok{  .}\DecValTok{70}\NormalTok{, .}\DecValTok{64}\NormalTok{, }\FloatTok{1.0}\NormalTok{, .}\DecValTok{45}\NormalTok{,}
\NormalTok{  .}\DecValTok{66}\NormalTok{, .}\DecValTok{54}\NormalTok{, .}\DecValTok{45}\NormalTok{, }\FloatTok{1.0}
\NormalTok{),}
\AttributeTok{byrow =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{ncol =} \DecValTok{4}
\NormalTok{)}
\FunctionTok{rownames}\NormalTok{(Spearman) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"C"}\NormalTok{, }\StringTok{"E"}\NormalTok{, }\StringTok{"M"}\NormalTok{, }\StringTok{"P"}\NormalTok{)}
\FunctionTok{colnames}\NormalTok{(Spearman) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"C"}\NormalTok{, }\StringTok{"E"}\NormalTok{, }\StringTok{"M"}\NormalTok{, }\StringTok{"P"}\NormalTok{)}
\NormalTok{Spearman}
\CommentTok{\#\textgreater{}      C    E    M    P}
\CommentTok{\#\textgreater{} C 1.00 0.78 0.70 0.66}
\CommentTok{\#\textgreater{} E 0.78 1.00 0.64 0.54}
\CommentTok{\#\textgreater{} M 0.70 0.64 1.00 0.45}
\CommentTok{\#\textgreater{} P 0.66 0.54 0.45 1.00}
\end{Highlighting}
\end{Shaded}

Eseguiamo l'analisi fattoriale:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fm }\OtherTok{\textless{}{-}} \FunctionTok{factanal}\NormalTok{(}\AttributeTok{covmat =}\NormalTok{ Spearman, }\AttributeTok{factors =} \DecValTok{1}\NormalTok{)}
\NormalTok{fm}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Call:}
\CommentTok{\#\textgreater{} factanal(factors = 1, covmat = Spearman)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Uniquenesses:}
\CommentTok{\#\textgreater{}     C     E     M     P }
\CommentTok{\#\textgreater{} 0.086 0.329 0.460 0.539 }
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Loadings:}
\CommentTok{\#\textgreater{}   Factor1}
\CommentTok{\#\textgreater{} C 0.956  }
\CommentTok{\#\textgreater{} E 0.819  }
\CommentTok{\#\textgreater{} M 0.735  }
\CommentTok{\#\textgreater{} P 0.679  }
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}                Factor1}
\CommentTok{\#\textgreater{} SS loadings      2.587}
\CommentTok{\#\textgreater{} Proportion Var   0.647}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} The degrees of freedom for the model is 2 and the fit was 0.023}
\end{Highlighting}
\end{Shaded}

Le saturazioni fattoriali sono:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{L }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(fm}\SpecialCharTok{$}\NormalTok{load[}\DecValTok{1}\NormalTok{], fm}\SpecialCharTok{$}\NormalTok{load[}\DecValTok{2}\NormalTok{], fm}\SpecialCharTok{$}\NormalTok{load[}\DecValTok{3}\NormalTok{], fm}\SpecialCharTok{$}\NormalTok{load[}\DecValTok{4}\NormalTok{])}
\NormalTok{L}
\CommentTok{\#\textgreater{} [1] 0.9563 0.8194 0.7350 0.6790}
\end{Highlighting}
\end{Shaded}

Facendo il prodotto interno otteniamo:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{t}\NormalTok{(L) }\SpecialCharTok{\%*\%}\NormalTok{ L}
\CommentTok{\#\textgreater{}       [,1]}
\CommentTok{\#\textgreater{} [1,] 2.587}
\end{Highlighting}
\end{Shaded}

In termini proporzionali, la quota della varianza totale delle variabile manifeste che viene spiegata dal modello ad un fattore comune è dunque uguale a \(2.587 / 4 = 0.647\). Questa quantità è indicata nell'output con la denominazione \texttt{Proportion\ Var}.
\end{exercise}

Si dice unicità (\emph{uniqueness}) la quota della varianza della variabile considerata che non viene spiegata dalla soluzione fattoriale:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{round}\NormalTok{(fm}\SpecialCharTok{$}\NormalTok{uniqueness, }\DecValTok{3}\NormalTok{)}
\CommentTok{\#\textgreater{}     C     E     M     P }
\CommentTok{\#\textgreater{} 0.086 0.329 0.460 0.539}
\end{Highlighting}
\end{Shaded}

La comunalità (ovvero, la quota di varianza di ciascuna variabile manifesta che viene spiegata dal fattore comune) può essere trovata come:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{round}\NormalTok{(}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ fm}\SpecialCharTok{$}\NormalTok{uniqueness, }\DecValTok{3}\NormalTok{)}
\CommentTok{\#\textgreater{}     C     E     M     P }
\CommentTok{\#\textgreater{} 0.914 0.671 0.540 0.461}
\end{Highlighting}
\end{Shaded}

oppure con

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{L}\SpecialCharTok{\^{}}\DecValTok{2}
\CommentTok{\#\textgreater{} [1] 0.9144 0.6714 0.5403 0.4611}
\end{Highlighting}
\end{Shaded}

\hypertarget{covarianza-tra-due-variabili-manifeste}{%
\section{Covarianza tra due variabili manifeste}\label{covarianza-tra-due-variabili-manifeste}}

Nell'ipotesi che le variabili \(Y_i\) abbiano media nulla, la covarianza tra \(Y_i\) e \(Y_k\)

\[
\mbox{Cov}(Y_i, Y_k)=\E(Y_i Y_k) -
\E(Y_i)\E(Y_k)=\E(Y_i Y_k)
\]

è uguale al prodotto delle corrispondenti saturazioni fattoriali.

\begin{equation}
\begin{aligned}
 \mbox{Cov}(Y_i, Y_k) &= \E(Y_i Y_k) \notag\\
  & =\E[(\lambda_i \xi + \delta_i)(\lambda_k \xi +  \delta_k)]\notag\\
  &=\E(\lambda_i\lambda_k\xi^2 + \lambda_i  \xi \delta_k + \lambda_k \delta_i \xi + \delta_i \delta_k)\notag\\
  &=\lambda_i\lambda_k\underbrace{\E(\xi^2)}_{\V(\xi)=1}+\lambda_i\underbrace{\E(\xi \delta_k)}_{\mbox{Cov}(\xi, \delta_k) =0}+\notag\\ \;&+\lambda_k\underbrace{\E(\delta_i \xi)}_{\mbox{Cov}(\delta_i, \xi) =0} +\underbrace{\E(\delta_i \delta_k)}_{\mbox{Cov}(\delta_i, \delta_k)=0}\notag\\
  &=\lambda_i\lambda_k
\end{aligned}
\end{equation}

\hypertarget{correlazioni-osservate-e-correlazioni-riprodotte-dal-modello}{%
\section{Correlazioni osservate e correlazioni riprodotte dal modello}\label{correlazioni-osservate-e-correlazioni-riprodotte-dal-modello}}

In generale possiamo affermare che il modello monofattoriale è adeguato se si verifica che \(\mbox{Cov}(Y_i, Y_k \mid \xi) = 0\) (\(i, k = 1, \dots,p; \; i\neq k\)), ossia se il fattore comune spiega tutta la covarianza tra le variabili osservate. La matrice di correlazioni riprodotte dal modello è chiamata \(\boldsymbol{\Sigma}\) e può essere espressa come:

\[
\boldsymbol{\Sigma} = \boldsymbol{\Lambda} \boldsymbol{\Lambda}^\prime + \boldsymbol{\Psi}
\]

In altri termini, il modello monofattoriale è adeguato se è nulla la differenza tra la matrice di correlazioni osservate e la matrice di correlazioni riprodotte dal modello. Per i dati di Spearman, le correlazioni riprodotte dal modello ad un fattore sono

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{round}\NormalTok{(L }\SpecialCharTok{\%*\%} \FunctionTok{t}\NormalTok{(L) }\SpecialCharTok{+} \FunctionTok{diag}\NormalTok{(fm}\SpecialCharTok{$}\NormalTok{uniq), }\DecValTok{3}\NormalTok{)}
\CommentTok{\#\textgreater{}       [,1]  [,2]  [,3]  [,4]}
\CommentTok{\#\textgreater{} [1,] 1.000 0.784 0.703 0.649}
\CommentTok{\#\textgreater{} [2,] 0.784 1.000 0.602 0.556}
\CommentTok{\#\textgreater{} [3,] 0.703 0.602 1.000 0.499}
\CommentTok{\#\textgreater{} [4,] 0.649 0.556 0.499 1.000}
\end{Highlighting}
\end{Shaded}

La matrice delle differenze tra le correlazioni campionarie e quelle riprodotte è

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{round}\NormalTok{(Spearman }\SpecialCharTok{{-}}\NormalTok{ (L }\SpecialCharTok{\%*\%} \FunctionTok{t}\NormalTok{(L) }\SpecialCharTok{+} \FunctionTok{diag}\NormalTok{(fm}\SpecialCharTok{$}\NormalTok{uniq)), }\DecValTok{3}\NormalTok{)}
\CommentTok{\#\textgreater{}        C      E      M      P}
\CommentTok{\#\textgreater{} C  0.000 {-}0.004 {-}0.003  0.011}
\CommentTok{\#\textgreater{} E {-}0.004  0.000  0.038 {-}0.016}
\CommentTok{\#\textgreater{} M {-}0.003  0.038  0.000 {-}0.049}
\CommentTok{\#\textgreater{} P  0.011 {-}0.016 {-}0.049  0.000}
\end{Highlighting}
\end{Shaded}

Lo scarto maggiore tra le correlazioni campionarie e quelle riprodotte è uguale a 0.049. Si può dunque concludere che il modello monofattoriale spiega in maniera ragionevole i dati di Spearman.

\hypertarget{bontuxe0-di-adattamento-del-modello-ai-dati}{%
\section{Bontà di adattamento del modello ai dati}\label{bontuxe0-di-adattamento-del-modello-ai-dati}}

La verifica della bontà di adattamento del modello ai dati si determina mediante un test statistico che valuta la differenza tra la matrice di correlazioni (o di covarianze) osservata e la matrice di correlazioni (o covarianze) predetta dal modello fattoriale. L'ipotesi nulla che viene valutata è che la matrice delle correlazioni residue sia dovuta semplicemente agli errori di campionamento, ovvero che la matrice di correlazioni predetta dal modello \(\boldsymbol{\Sigma}(\theta)\) sia uguale alla matrice di correlazioni \(\boldsymbol{\Sigma}\) nella popolazione.

La statistica test \(v\) è una funzione della differenza tra la matrice riprodotta \(\boldsymbol{S}(\theta)\) e quella osservata \(\boldsymbol{S}\)

\[
v = f\left[\boldsymbol{S}(\theta) - \boldsymbol{S}\right]
\]

e si distribuisce come una \(\chi^2\) con \(\nu\) gradi di libertà

\[
\nu = p(p+1)/ 2 - q,
\]

dove \(p\) è il numero di variabili manifeste e \(q\) è il numero di parametri stimati dal modello fattoriale (ovvero, \(\lambda\) e \(\psi\)).

La statistica \(v\) assume valore 0 se i parametri del modello riproducono esattamente la matrice di correlazioni tra le variabili nella popolazione. Tanto maggiore è la statistica \(v\) tanto maggiore è la discrepanza tra le correlazioni osservate e quelle predette dal modello fattoriale.

Un risultato statisticamente significativo (es., \(p\) \textless{} .05) -- il quale suggerisce che una tale differenza \emph{non} è uguale a zero -- rivela dunque una discrepanza tra il modello e i dati. Il test del modello fattoriale mediante la statistica \(\chi^2\) segue dunque una logica diversa da quella utilizzata nei normali test di ipotesi statistiche: \emph{un risultato statisticamente significativo indica una mancanza di adattamento del modello ai dati}.

L'applicazione del test \(\chi^2\) per valutare la bontà di adattamento del modello ai dati richiede che ciascuna variabile manifesta sia distribuita normalmente -- più precisamente, richiede che le variabili manifeste siano un campione casuale che deriva da una normale multivariata. Questo requisito non è facile da rispettare in pratica.

Tuttavia, il limite principale della statistica \(\chi^2\) è che essa dipende fortemente dalle dimensioni del campione: al crescere delle dimensioni campionarie è più facile ottenere un risultato statisticamente significativo (ovvero, concludere che vi è un cattivo adattamento del modello ai dati). Per questa ragione, la bontà di adattamento del modello ai dati viene valutata da molteplici indici, non soltanto dalla statistica \(\chi^2\). Più comune è calcolare il rapporto \(\chi^2 / \nu\) e usare tale rapporto per valutare la bontà dell'adattamento. Valori minori di 3 o 4 suggeriscono che il modello ben si adatta ai dati.

\hypertarget{lerrore-standard-della-misurazione-e-il-modello-fattoriale}{%
\section{L'errore standard della misurazione e il modello fattoriale}\label{lerrore-standard-della-misurazione-e-il-modello-fattoriale}}

Per concludere, prendiamo nuovamente in esame la nozione dell'errore standard della misurazione, uno dei concetti centrali della CTT, e vediamo come tale concetto possa essere ``ripensato'' in riferimento al modello statistico dell'analisi fattoriale. Iniziamo con una dimostrazione.

\begin{proof}
Secondo la CTT, il punteggio \(X\) ottenuto dalla somministrazione del test è uguale a \(X = T + E\), dove \(E\) è una variabile aleatorie indipendente da \(T\). Se consideriamo il rispondente \(i\)-esimo, il modello diventa \(X_i = T_i + E_i\), dove \(T_i\) è il valore vero ed \(E_i\) è una variabile aleatoria con media 0.

Riscriviamo ora questa equazione nei termini di un modello monofattoriale con \(p\) variabili manifeste (item). Per ciascun item avremo:

\begin{equation}
\begin{aligned}
 Y_{1i} &=  \lambda_1 \xi_i + \delta_{1i} \notag\\
 Y_{2i} &=  \lambda_2 \xi_i + \delta_{2i} \notag\\
  \dots\notag\\
 Y_{pi} &=  \lambda_p \xi_i + \delta_{pi} \notag\end{aligned}
 \end{equation}

Il punteggio totale \(X_i\) per il rispondente \(i\)-esimo è dato dalla somma dei punteggi osservati in ciascun item, ovvero

\begin{equation}
\begin{aligned}
 X_i &= \sum_{j=1}^p Y_{ji} = \sum_{j=1}^p \lambda_j \xi_i + \sum_{j=1}^p \delta_{ji}\notag\\[12pt]
  &=  \left( \sum_{j=1}^p \lambda_j \right) \xi_i  +  \sum_{j=1}^p \delta_{ji} \notag\\[12pt]
  &= T_i + E_i\notag
\end{aligned}
\end{equation}

Secondo la CTT, la varianza del punteggio osservato \(X_i\) si scompone in due componenti: \(\sigma^2_{X_i} = \sigma^2_{T_i} + \sigma^2_{E_i}\). Nei termini del modello fattoriale, la varianza della componente vera del punteggio totale del test, \(\sigma^2_{T_i}\), è data dal quadrato della somma delle satutazioni fattoriali:

\begin{equation}
\begin{aligned}
 \sigma^2_{T_i} &= \V\left[ \left( \sum_{j=1}^p \lambda_j \right) \xi_i \right]\notag\\
 &= \left( \sum_{j=1}^p \lambda_j \right)^2 \V(\xi_i)\notag\\
 &= \left( \sum_{j=1}^p \lambda_j \right)^2 \notag
\end{aligned}
\end{equation}

Nei termini del modello fattoriale, se consideriamo il punteggio totale del test, la varianza della componente dell'errore della misurazione, \(\sigma^2_{E_i}\), è data dalla somma delle unicità:

\begin{equation}
\begin{aligned}
 \sigma^2_{E_i} &= \V\left( \sum_{j=1}^p \delta_{ji} \right)\notag\\
 &= \sum_{j=1}^p \V\left( \delta_{ji} \right)\notag\\
 &= \sum_{j=1}^p \Psi_j\notag
\end{aligned}
\end{equation}

Nei termini del modello fattoriale, dunque, una stima dell'errore standard della misurazione del punteggio totale del test è data dalla radice quadrata della quantità precedente, ovvero:

\begin{equation}
\sigma_{E} = \sqrt{\sum_{j=1}^p \Psi_j}
\label{eq:err-stnd-meas-FA}
\end{equation}
\end{proof}

\hypertarget{un-caso-concreto}{%
\subsection{Un caso concreto}\label{un-caso-concreto}}

Applichiamo ora il risultato precedente ad un caso concreto. Consideriamo i dati utilizzati nella validazione italiana del \emph{Cognitive Style Questionnaire - Short Form} (CSQ-SF, Meins et al.~2012). Il CSQ-SF viene utilizzato per misurare la vulnerabilità all'ansia e alla depressione. È costituito da cinque sottoscale: \emph{Internality}, \emph{Globality}, \emph{Stability}, \emph{Negative consequences} e \emph{Self-worth}.

Leggiamo i dati in \(\textsf{R}\):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{csq }\OtherTok{\textless{}{-}}\NormalTok{ rio}\SpecialCharTok{::}\FunctionTok{import}\NormalTok{(here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{(}\StringTok{"data"}\NormalTok{, }\StringTok{"csq540.csv"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Il numero di partecipanti è

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(csq)}
\NormalTok{n}
\CommentTok{\#\textgreater{} [1] 540}
\end{Highlighting}
\end{Shaded}

Le statistiche descrittive si ottengono con la seguente istruzione:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{psych}\SpecialCharTok{::}\FunctionTok{describe}\NormalTok{(csq, }\AttributeTok{type =} \DecValTok{2}\NormalTok{)}
\CommentTok{\#\textgreater{}   vars   n  mean    sd median trimmed   mad min max}
\CommentTok{\#\textgreater{} I    1 540 47.76  5.78     48   47.87  4.45  21  64}
\CommentTok{\#\textgreater{} G    2 540 45.00 11.94     42   44.55 11.86  16  78}
\CommentTok{\#\textgreater{} S    3 540 44.60 12.18     42   44.24 13.34  16  77}
\CommentTok{\#\textgreater{} N    4 540 22.01  6.92     21   21.86  7.41   8  39}
\CommentTok{\#\textgreater{} W    5 540 44.05 13.10     43   43.66 13.34  16  79}
\CommentTok{\#\textgreater{}   range  skew kurtosis   se}
\CommentTok{\#\textgreater{} I    43 {-}0.31     1.07 0.25}
\CommentTok{\#\textgreater{} G    62  0.34    {-}0.70 0.51}
\CommentTok{\#\textgreater{} S    61  0.27    {-}0.77 0.52}
\CommentTok{\#\textgreater{} N    31  0.21    {-}0.74 0.30}
\CommentTok{\#\textgreater{} W    63  0.31    {-}0.53 0.56}
\end{Highlighting}
\end{Shaded}

Esaminiamo la matrice di correlazione:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{psych}\SpecialCharTok{::}\FunctionTok{pairs.panels}\NormalTok{(csq)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{cfa_book_files/figure-latex/unnamed-chunk-102-1} \end{center}

Specifichiamo il modello unifattoriale nella sintassi di \texttt{lavaan}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mod\_csq }\OtherTok{\textless{}{-}} \StringTok{"}
\StringTok{   F =\textasciitilde{} NA*I + G + S + N + W}
\StringTok{   F \textasciitilde{}\textasciitilde{} 1*F}
\StringTok{"}
\end{Highlighting}
\end{Shaded}

Adattiamo il modello ai dati:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit }\OtherTok{\textless{}{-}}\NormalTok{ lavaan}\SpecialCharTok{:::}\FunctionTok{cfa}\NormalTok{(}
\NormalTok{  mod\_csq,}
  \AttributeTok{data =}\NormalTok{ csq}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Esaminiamo i risultati:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(}
\NormalTok{  fit,}
  \AttributeTok{standardized =} \ConstantTok{TRUE}\NormalTok{,}
  \AttributeTok{fit.measures =} \ConstantTok{TRUE}
\NormalTok{)}
\CommentTok{\#\textgreater{} lavaan 0.6{-}10 ended normally after 26 iterations}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}   Estimator                                         ML}
\CommentTok{\#\textgreater{}   Optimization method                           NLMINB}
\CommentTok{\#\textgreater{}   Number of model parameters                        10}
\CommentTok{\#\textgreater{}                                                       }
\CommentTok{\#\textgreater{}   Number of observations                           540}
\CommentTok{\#\textgreater{}                                                       }
\CommentTok{\#\textgreater{} Model Test User Model:}
\CommentTok{\#\textgreater{}                                                       }
\CommentTok{\#\textgreater{}   Test statistic                                46.716}
\CommentTok{\#\textgreater{}   Degrees of freedom                                 5}
\CommentTok{\#\textgreater{}   P{-}value (Chi{-}square)                           0.000}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Model Test Baseline Model:}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}   Test statistic                              2361.816}
\CommentTok{\#\textgreater{}   Degrees of freedom                                10}
\CommentTok{\#\textgreater{}   P{-}value                                        0.000}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} User Model versus Baseline Model:}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}   Comparative Fit Index (CFI)                    0.982}
\CommentTok{\#\textgreater{}   Tucker{-}Lewis Index (TLI)                       0.965}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Loglikelihood and Information Criteria:}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}   Loglikelihood user model (H0)              {-}8741.781}
\CommentTok{\#\textgreater{}   Loglikelihood unrestricted model (H1)      {-}8718.423}
\CommentTok{\#\textgreater{}                                                       }
\CommentTok{\#\textgreater{}   Akaike (AIC)                               17503.562}
\CommentTok{\#\textgreater{}   Bayesian (BIC)                             17546.478}
\CommentTok{\#\textgreater{}   Sample{-}size adjusted Bayesian (BIC)        17514.734}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Root Mean Square Error of Approximation:}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}   RMSEA                                          0.124}
\CommentTok{\#\textgreater{}   90 Percent confidence interval {-} lower         0.093}
\CommentTok{\#\textgreater{}   90 Percent confidence interval {-} upper         0.158}
\CommentTok{\#\textgreater{}   P{-}value RMSEA \textless{}= 0.05                          0.000}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Standardized Root Mean Square Residual:}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}   SRMR                                           0.033}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Parameter Estimates:}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}   Standard errors                             Standard}
\CommentTok{\#\textgreater{}   Information                                 Expected}
\CommentTok{\#\textgreater{}   Information saturated (h1) model          Structured}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Latent Variables:}
\CommentTok{\#\textgreater{}                    Estimate  Std.Err  z{-}value  P(\textgreater{}|z|)}
\CommentTok{\#\textgreater{}   F =\textasciitilde{}                                                }
\CommentTok{\#\textgreater{}     I                 0.725    0.253    2.867    0.004}
\CommentTok{\#\textgreater{}     G               {-}11.322    0.384  {-}29.481    0.000}
\CommentTok{\#\textgreater{}     S               {-}11.342    0.398  {-}28.513    0.000}
\CommentTok{\#\textgreater{}     N                {-}6.163    0.233  {-}26.398    0.000}
\CommentTok{\#\textgreater{}     W               {-}11.598    0.444  {-}26.137    0.000}
\CommentTok{\#\textgreater{}    Std.lv  Std.all}
\CommentTok{\#\textgreater{}                   }
\CommentTok{\#\textgreater{}     0.725    0.126}
\CommentTok{\#\textgreater{}   {-}11.322   {-}0.949}
\CommentTok{\#\textgreater{}   {-}11.342   {-}0.932}
\CommentTok{\#\textgreater{}    {-}6.163   {-}0.891}
\CommentTok{\#\textgreater{}   {-}11.598   {-}0.886}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Variances:}
\CommentTok{\#\textgreater{}                    Estimate  Std.Err  z{-}value  P(\textgreater{}|z|)}
\CommentTok{\#\textgreater{}     F                 1.000                           }
\CommentTok{\#\textgreater{}    .I                32.840    2.000   16.420    0.000}
\CommentTok{\#\textgreater{}    .G                14.038    1.473    9.532    0.000}
\CommentTok{\#\textgreater{}    .S                19.508    1.718   11.353    0.000}
\CommentTok{\#\textgreater{}    .N                 9.847    0.725   13.573    0.000}
\CommentTok{\#\textgreater{}    .W                36.892    2.685   13.737    0.000}
\CommentTok{\#\textgreater{}    Std.lv  Std.all}
\CommentTok{\#\textgreater{}     1.000    1.000}
\CommentTok{\#\textgreater{}    32.840    0.984}
\CommentTok{\#\textgreater{}    14.038    0.099}
\CommentTok{\#\textgreater{}    19.508    0.132}
\CommentTok{\#\textgreater{}     9.847    0.206}
\CommentTok{\#\textgreater{}    36.892    0.215}
\end{Highlighting}
\end{Shaded}

Recuperiamo le specificità:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{psi }\OtherTok{\textless{}{-}} \FunctionTok{parameterEstimates}\NormalTok{(fit)}\SpecialCharTok{$}\NormalTok{est[}\DecValTok{7}\SpecialCharTok{:}\DecValTok{11}\NormalTok{]}
\NormalTok{psi}
\CommentTok{\#\textgreater{} [1] 32.840 14.038 19.508  9.847 36.892}
\end{Highlighting}
\end{Shaded}

Stimiamo l'errore standard della misurazione con la \eqref{eq:err-stnd-meas-FA}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sqrt}\NormalTok{(}\FunctionTok{sum}\NormalTok{(psi))}
\CommentTok{\#\textgreater{} [1] 10.64}
\end{Highlighting}
\end{Shaded}

Applichiamo ora la formula della TCT:

\[
\sigma_E = \sigma_X \sqrt{1 -\rho_{XX^\prime}}.
\]

Per trovare \(\sigma\) calcoliamo prima il punteggio totale:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tot\_score }\OtherTok{\textless{}{-}} \FunctionTok{rowSums}\NormalTok{(csq)}
\end{Highlighting}
\end{Shaded}

La deviazione standard di \texttt{tot\_score} ci fornisce una stima di \(\sigma_X\):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sigma }\OtherTok{\textless{}{-}} \FunctionTok{sd}\NormalTok{(tot\_score)}
\NormalTok{sigma}
\CommentTok{\#\textgreater{} [1] 41.26}
\end{Highlighting}
\end{Shaded}

Per applicare la formula della TCT abbiamo bisogno dell'attendibilità. La stimiamo usando la funzione \texttt{reliability} del pacchetto \texttt{semTools} dall'oggetto creato da \texttt{lavaan:::cfa()}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rel }\OtherTok{\textless{}{-}}\NormalTok{ semTools}\SpecialCharTok{::}\FunctionTok{reliability}\NormalTok{(fit)}
\NormalTok{rel}
\CommentTok{\#\textgreater{}             F}
\CommentTok{\#\textgreater{} alpha  0.8507}
\CommentTok{\#\textgreater{} omega  0.9330}
\CommentTok{\#\textgreater{} omega2 0.9330}
\CommentTok{\#\textgreater{} omega3 0.9273}
\CommentTok{\#\textgreater{} avevar 0.7917}
\end{Highlighting}
\end{Shaded}

Utilizzando \(\Omega\) otteniamo:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sigma }\SpecialCharTok{*} \FunctionTok{sqrt}\NormalTok{(}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ rel[}\DecValTok{2}\NormalTok{])}
\CommentTok{\#\textgreater{} [1] 10.68}
\end{Highlighting}
\end{Shaded}

Si noti come il risultato sia quasi identico a quello trovato con la formula della TCT.

\hypertarget{ch:mod_multifattoriale}{%
\chapter{Il modello multifattoriale}\label{ch:mod_multifattoriale}}

\hypertarget{modello-multifattoriale-fattori-ortogonali}{%
\section{Modello multifattoriale: fattori ortogonali}\label{modello-multifattoriale-fattori-ortogonali}}

La teoria dei due fattori ha orientato per diversi anni le ricerche sull'intelligenza, finché Thurstone (1945) non propose una sua modifica, conosciuta come teoria multifattoriale. Secondo Thurstone la covariazione tra le variabili manifeste non può essere spiegata da un unico fattore generale. Invece è necessario ipotizzare l'azione causale di diversi fattori, definiti comuni, i quali si riferiscono solo ad alcune delle variabili considerate.

Il modello plurifattoriale assume che ciascuna variabile manifesta sia espressa come funzione lineare di un certo numero \(m\) di fattori comuni, \(\xi_1, \xi_2, \dots, \xi_m\), responsabili della correlazione con le altre variabili, e di un solo fattore specifico (termine d'errore), responsabile della variabilità della variabile stessa. Per \(p\) variabili manifeste, \(Y_1, Y_2, \dots, Y_p\), il modello fattoriale diventa quello indicato dal sistema di equazioni lineari descritto di seguito. Idealmente, \(m\) dovrebbe essere molto più piccolo di \(p\) così da consentire una descrizione parsimoniosa delle variabili manifeste in funzione di pochi fattori soggiacenti.

Le variabili manifeste \(Y\) sono indicizzate da \(i = 1, \dots, p.\) Le variabili latenti \(\xi\) (fattori) sono indicizzate da \(j = 1, \dots, m.\) I fattori specifici \(\delta\) sono indicizzati da \(i = 1, \dots, p.\) Le saturazioni fattoriali si distinguono dunque tramite due indici, \(i\) e \(j\): il primo indice si riferisce alle variabili manifeste, il secondo si riferisce ai fattori latenti.

Indichiamo con \(\mu_i\), con \(i=1, \dots, p\) le medie delle \(p\) variabili manifeste \(Y_1, Y_2, \dots, Y_p\). Se non vi è alcun effetto delle variabili comuni latenti, allora la variabile \(Y_{ijk}\), dove \(k\) è l'indice usato per i soggetti, sarà uguale a:

\begin{equation}
\begin{cases} 
  Y_{1k}    &= \mu_1 + \delta_{1k} \\
&\vdots\\
Y_{ik}   &= \mu_i + \delta_{ik}\\
&\vdots\\
Y_{pk}   &= \mu_p + \delta_{pk} \notag
\end{cases}
\end{equation}

Se invece le variabili manifeste rappresentano la somma dell'effetto causale di \(m\) fattori comuni e di \(p\) fattori specifici, allora possiamo scrivere:

\begin{equation}
\begin{cases} 
  Y_1  - \mu_1  &= \lambda_{11}\xi_1 + \dots + \lambda_{1k}\xi_k \dots +\lambda_{1m}\xi_m + \delta_1 \\
&\vdots\\
Y_i -  \mu_i  &= \lambda_{i1}\xi_1 + \dots +  \lambda_{ik}\xi_k \dots +\lambda_{im}\xi_m + \delta_i\\
&\vdots\\
Y_p - \mu_p  &= \lambda_{p1}\xi_1 + \dots +  \lambda_{pk}\xi_k \dots +\lambda_{pm}\xi_m + \delta_p \notag
\end{cases}
\end{equation}

Nel precedente sistema di equazioni lineari,

\begin{itemize}
\tightlist
\item
  \(\xi_j\), con \(j=1, \dots, m\), rappresenta la \(j\)-esima variabile inosservabile a fattore comune (ossia il \(j\)-esimo fattore comune a tutte le variabili \(Y_i\));
\item
  \(\lambda_{ij}\) rappresenta il parametro, detto \emph{saturazione} o \emph{peso} fattoriale, che riflette l'importanza del \(j\)-esimo fattore comune nella composizione della \(i\)-esima variabile osservabile;
\item
  \(\delta_i\) rappresenta il fattore specifico (o unico) di ogni variabile manifesta \(Y_i\).
\end{itemize}

In conclusione, secondo il modello multifattoriale, le variabili manifeste \(Y_i\), con \(i=1, \dots, p\), sono il risultato di una \emph{combinazione lineare} di \(m < p\) fattori inosservabili ad esse comuni \(\xi_j\), con \(j=1, \dots, m\), e di \(p\) fattori specifici \(\delta_i\), con \(i=1, \dots, p\), anch'essi inosservabili e di natura residua.

\hypertarget{assunzioni-del-modello-multifattoriale}{%
\subsection{Assunzioni del modello multifattoriale}\label{assunzioni-del-modello-multifattoriale}}

Le variabili inosservabili a fattore comune \(\xi_j\), con \(j=1, \dots, m\), in quanto latenti, non possiedono unità di misura. Pertanto, per semplicità si assume che abbiano media zero, \(\E (\xi_j)=0\), abbiano varianza unitaria, \(\V (\xi_j)= \E (\xi_j^2) - [\E (\xi_j)]^2=1\), e siano incorrelate tra loro, \(\mbox{Cov}(\xi_j, \xi_h)=0\), con \(j, h = 1, \dots, m; \;j \neq h\). Si assume inoltre che le variabili a fattore specifico \(\delta_i\) siano tra loro incorrelate, \(\mbox{Cov}(\delta_i,\delta_k)=0\), con \(i, k = 1, \dots, p, \; i \neq k\), abbiano media zero, \(\E (\delta_i)=0\), e varianza uguale a \(\V (\delta_i) = \psi_{ii}\). La varianza \(\psi_{ii}\) è detta \emph{varianza specifica} o \emph{unicità} della \(i\)-esima variabile manifesta \(Y_i\). Si assume infine che i fattori specifici siano linearmente incorrelati con i fattori comuni, ovvero \(\mbox{Cov}(\xi_j, \delta_i)=0\) per ogni \(j=1, \dots, m\) e per ogni \(i=1\dots,p\).

\hypertarget{interpretazione-dei-parametri-del-modello}{%
\subsection{Interpretazione dei parametri del modello}\label{interpretazione-dei-parametri-del-modello}}

Quale esempio, consideriamo il caso di \(p=5\) variabili osservabili e \(m=2\) fattori ortogonali. Se le variabili manifeste sono `centrate' (ovvero, se a ciascuna di esse sottraiamo la rispettiva media), allora il modello multifattoriale diventa +

\begin{equation}
\begin{aligned}
  Y_1 &= \lambda_{11} \xi_1 + \lambda_{12} \xi_2 + \delta_1,\notag\\
  Y_2 &= \lambda_{21} \xi_1 + \lambda_{22} \xi_2 + \delta_2,\notag\\
  Y_3 &= \lambda_{31} \xi_1 + \lambda_{32} \xi_2 + \delta_3,\notag\\
  Y_4 &= \lambda_{41} \xi_1 + \lambda_{42} \xi_2 + \delta_4,\notag\\
  Y_5 &= \lambda_{51} \xi_1 + \lambda_{52} \xi_2 + \delta_5.\notag
\label{eq:plurifattore2}
\end{aligned}
\end{equation}

\hypertarget{covarianza-tra-variabili-e-fattori}{%
\subsection{Covarianza tra variabili e fattori}\label{covarianza-tra-variabili-e-fattori}}

Nell'ipotesi che le variabili \(Y_i\) abbiano media nulla, la covarianza tra \(Y_i\) e \(\xi_j\) è uguale alla saturazione fattoriale \(\lambda_{ij}\):

\begin{equation}
\begin{aligned}
  \mbox{Cov}(Y_i, \xi_j) &= \E(Y_i \xi_j)\notag\\
  &=\E\left[(\lambda_{i1} \xi_1 + \dots + \lambda_{im} \xi_m + \delta_i)\xi_j \right]\notag\\
  &= \lambda_{i1}\underbrace{\E(\xi_1\xi_j)}_{=0} + \dots + 
\lambda_{ij}\underbrace{\E(\xi_j^2)}_{=1} + \dots \notag\\
& \; + \lambda_{im}\underbrace{\E(\xi_m\xi_j)}_{=0} +
  \underbrace{\E(\delta_i \xi_j)}_{=0}\notag\\
  &= \lambda_{ij}.\notag
  \label{eq:cov-multifatt-orto}
\end{aligned}
\end{equation}

Anche nel modello multifattoriale, dunque, le saturazioni fattoriali rappresentano le covarianze tra le variabili e i fattori:

\[
\mbox{Cov}(Y_i, \xi_j) = \lambda_{ij} \qquad i=1, \dots, p; \quad j= 1, \dots, m. 
\]

Naturalmente, se le variabili sono standardizzate, le saturazioni fattoriali diventano correlazioni:

\[
r_{ij} = \lambda_{ij}. 
\]

\hypertarget{espressione-fattoriale-della-varianza-1}{%
\subsection{Espressione fattoriale della varianza}\label{espressione-fattoriale-della-varianza-1}}

Come nel modello monofattoriale, la varianza delle variabili manifeste si decompone in una componente dovuta ai fattori comuni, chiamata \emph{comunalità}, e in una componente specifica alle \(Y_i\), chiamata \emph{unicità}. Nell'ipotesi che le variabili \(Y_i\) abbiano media nulla, la varianza di \(Y_i\) è uguale a

\begin{equation}
\begin{aligned}
  \V (Y_i) 
  &=\E\left[ (\lambda_{i1} \xi_1 + \dots +
    \lambda_{im} \xi_m + \delta_i)^2 \right].
\end{aligned}
\label{eq:eq-var-multifatt}
\end{equation}

Come si sviluppa il polinomio precedente? Il quadrato di un polinomio è uguale alla somma dei quadrati di tutti i termini più il doppio prodotto di ogni termine per ciascuno di quelli che lo seguono. Il valore atteso del quadrato del primo termine è uguale a \(\lambda_{i1}^2\E(\xi_1^2)\) ma, essendo la varianza di \(\xi_1\) uguale a \(1\), otteniamo semplicemente \(\lambda_{i1}^2\). Lo stesso vale per i quadrati di tutti i termini seguenti tranne l'ultimo. Infatti, \(\E(\delta_i^2)=\psi_{ii}\). Per quel che riguarda i doppi prodotti, sono tutti nulli. In primo luogo perché, nel caso di fattori ortogonali, la covarianza tra i fattori comuni è nulla, \(\E(\xi_j \xi_h)=0\), con \(j \neq h\). In secondo luogo perché il fattori comuni cono incorrelati con i fattori specifici, quindi \(\E(\delta_i \xi_j)=0\).

In conclusione,

\begin{equation}
\begin{aligned}
  \V(Y_i) &= \lambda_{i1}^2 + \lambda_{i2}^2 + \dots + \lambda_{im}^2 + \psi_{ii} \notag\\
  &= \sum_{j=1}^m \lambda_{ij}^2 + \psi_{ii}\notag\\
  &= h_i^2 + \psi_{ii}\notag\\
  &=\text{communalità} + \text{unicità},\notag
\end{aligned}
\end{equation}

la varianza della variabile manifesta \(Y_i\) è suddivisa in due parti: il primo addendo è definito comunalità poiché rappresenta la parte di variabilità della \(Y_i\) spiegata dai fattori comuni; il secondo addendo è invece definito varianza specifica (o unicità) poiché esprime la parte di variabilità della \(Y_i\) non spiegata dai fattori comuni.

\hypertarget{espressione-fattoriale-della-covarianza}{%
\subsection{Espressione fattoriale della covarianza}\label{espressione-fattoriale-della-covarianza}}

Per semplificare, consideriamo il caso particolare esaminato prima, ovvero quello con \(p=5\) variabili osservabili e \(m=2\) fattori ortogonali. Nell'ipotesi che le variabili \(Y_i\) abbiano media nulla, la covarianza tra \(Y_1\) e \(Y_2\), ad esempio, è uguale a:

\begin{equation}
\begin{aligned}
  \mbox{Cov}(Y_1, Y_2) &= \E\left( Y_1 Y_2\right) \notag\\
  &= \E \left[ 
  (\lambda_{11} \xi_1 + \lambda_{12} \xi_2 + \delta_1)
   (\lambda_{21} \xi_1 + \lambda_{22} \xi_2 +  \delta_2)
  \right]\notag\\
  &= \lambda_{11} \lambda_{21} \E (\xi_1^2) +
      \lambda_{11} \lambda_{22} \E (\xi_1 \xi_2) +\notag 
      \lambda_{11} \E (\xi_1 \delta_2) +\notag\\
    &\quad \lambda_{12} \lambda_{21}\E(\xi_1 \xi_2)\, + 
      \lambda_{12} \lambda_{22}\E(\xi^2_2)\, + 
      \lambda_{12} \E (\xi_2\delta_2) +\notag\\
    &\quad \lambda_{21} \E(\xi_1\delta_1) +\notag 
     \lambda_{22} \E(\xi_2\delta_1) + \E(\delta_1 \delta_2)\notag\\
   &= \lambda_{11} \lambda_{21} + \lambda_{12} \lambda_{22}.\notag
\end{aligned}
\end{equation}

In conclusione, la covarianza tra le variabili manifeste \(Y_l\) e \(Y_m\) riprodotta dal modello è data dalla somma dei prodotti delle saturazioni \(\lambda_l \lambda_m\) nei due fattori.

\begin{exercise}

Consideriamo i dati riportati da \citet{brown2015confirmatory}, ovvero otto misure di personalità raccolte su un campione di 250 pazienti che hanno concluso un programma di psicoterapia. Le scale sono le seguenti:

\begin{itemize}
\tightlist
\item
  anxiety (N1),
\item
  hostility (N2),
\item
  depression (N3),
\item
  self-consciousness (N4),
\item
  warmth (E1),
\item
  gregariousness (E2),
\item
  assertiveness (E3),
\item
  positive emotions (E4).
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{varnames }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"N1"}\NormalTok{, }\StringTok{"N2"}\NormalTok{, }\StringTok{"N3"}\NormalTok{, }\StringTok{"N4"}\NormalTok{, }\StringTok{"E1"}\NormalTok{, }\StringTok{"E2"}\NormalTok{, }\StringTok{"E3"}\NormalTok{, }\StringTok{"E4"}\NormalTok{)}
\NormalTok{sds }\OtherTok{\textless{}{-}} \StringTok{"5.7  5.6  6.4  5.7  6.0  6.2  5.7  5.6"}

\NormalTok{cors }\OtherTok{\textless{}{-}} \StringTok{"}
\StringTok{ 1.000}
\StringTok{ 0.767  1.000}
\StringTok{ 0.731  0.709  1.000}
\StringTok{ 0.778  0.738  0.762  1.000}
\StringTok{{-}0.351  {-}0.302  {-}0.356  {-}0.318  1.000}
\StringTok{{-}0.316  {-}0.280  {-}0.300  {-}0.267  0.675  1.000}
\StringTok{{-}0.296  {-}0.289  {-}0.297  {-}0.296  0.634  0.651  1.000}
\StringTok{{-}0.282  {-}0.254  {-}0.292  {-}0.245  0.534  0.593  0.566  1.000"}

\NormalTok{psychot\_cor\_mat }\OtherTok{\textless{}{-}} \FunctionTok{getCov}\NormalTok{(cors, }\AttributeTok{names =}\NormalTok{ varnames)}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{250}
\end{Highlighting}
\end{Shaded}

Eseguiamo l'analisi fattoriale esplorativa con il metodo della massima verosimiglianza ipotizzando due fattori comuni incorrelati:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n\_facs }\OtherTok{\textless{}{-}} \DecValTok{2}
\NormalTok{fit\_efa }\OtherTok{\textless{}{-}} \FunctionTok{factanal}\NormalTok{(}
  \AttributeTok{covmat =}\NormalTok{ psychot\_cor\_mat,}
  \AttributeTok{factors =}\NormalTok{ n\_facs,}
  \AttributeTok{rotation =} \StringTok{"varimax"}\NormalTok{,}
  \AttributeTok{n.obs =}\NormalTok{ n}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Esaminiamo le saturazioni fattoriali:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lambda }\OtherTok{\textless{}{-}}\NormalTok{ fit\_efa}\SpecialCharTok{$}\NormalTok{loadings}
\NormalTok{lambda}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Loadings:}
\CommentTok{\#\textgreater{}    Factor1 Factor2}
\CommentTok{\#\textgreater{} N1  0.854  {-}0.228 }
\CommentTok{\#\textgreater{} N2  0.826  {-}0.194 }
\CommentTok{\#\textgreater{} N3  0.811  {-}0.233 }
\CommentTok{\#\textgreater{} N4  0.865  {-}0.186 }
\CommentTok{\#\textgreater{} E1 {-}0.202   0.773 }
\CommentTok{\#\textgreater{} E2 {-}0.139   0.829 }
\CommentTok{\#\textgreater{} E3 {-}0.158   0.771 }
\CommentTok{\#\textgreater{} E4 {-}0.147   0.684 }
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}                Factor1 Factor2}
\CommentTok{\#\textgreater{} SS loadings      2.923   2.526}
\CommentTok{\#\textgreater{} Proportion Var   0.365   0.316}
\CommentTok{\#\textgreater{} Cumulative Var   0.365   0.681}
\end{Highlighting}
\end{Shaded}

La soluzione fattoriale conferma la presenza di due fattori: il primo fattore satura sulle scale di neutoricismo, il secono sulle scale di estroversione.

La correlazione riprodotta \(r_{12}\) è uguale a \(\lambda_{11}\lambda_{21} + \lambda_{12}\lambda_{22}\)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lambda[}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{] }\SpecialCharTok{*}\NormalTok{ lambda[}\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{] }\SpecialCharTok{+}\NormalTok{ lambda[}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{] }\SpecialCharTok{*}\NormalTok{ lambda[}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{]}
\CommentTok{\#\textgreater{} [1] 0.7493}
\end{Highlighting}
\end{Shaded}

e corrisponde da vicino alla correlazione osservata 0.767.

L'intera matrice di correlazioni riprodotte è \(\boldsymbol{\Lambda} \boldsymbol{\Lambda}^{\ensuremath{\mathsf{T}}} + \boldsymbol{\psi}\):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Rr }\OtherTok{\textless{}{-}}\NormalTok{ lambda }\SpecialCharTok{\%*\%} \FunctionTok{t}\NormalTok{(lambda) }\SpecialCharTok{+} \FunctionTok{diag}\NormalTok{(fit\_efa}\SpecialCharTok{$}\NormalTok{uniq)}
\NormalTok{Rr }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{round}\NormalTok{(}\DecValTok{3}\NormalTok{)}
\CommentTok{\#\textgreater{}        N1     N2     N3     N4     E1     E2     E3}
\CommentTok{\#\textgreater{} N1  1.000  0.749  0.745  0.781 {-}0.348 {-}0.307 {-}0.311}
\CommentTok{\#\textgreater{} N2  0.749  1.000  0.715  0.751 {-}0.317 {-}0.276 {-}0.281}
\CommentTok{\#\textgreater{} N3  0.745  0.715  1.000  0.745 {-}0.344 {-}0.306 {-}0.308}
\CommentTok{\#\textgreater{} N4  0.781  0.751  0.745  1.000 {-}0.318 {-}0.274 {-}0.280}
\CommentTok{\#\textgreater{} E1 {-}0.348 {-}0.317 {-}0.344 {-}0.318  1.000  0.669  0.628}
\CommentTok{\#\textgreater{} E2 {-}0.307 {-}0.276 {-}0.306 {-}0.274  0.669  1.000  0.661}
\CommentTok{\#\textgreater{} E3 {-}0.311 {-}0.281 {-}0.308 {-}0.280  0.628  0.661  1.000}
\CommentTok{\#\textgreater{} E4 {-}0.281 {-}0.254 {-}0.279 {-}0.254  0.558  0.587  0.550}
\CommentTok{\#\textgreater{}        E4}
\CommentTok{\#\textgreater{} N1 {-}0.281}
\CommentTok{\#\textgreater{} N2 {-}0.254}
\CommentTok{\#\textgreater{} N3 {-}0.279}
\CommentTok{\#\textgreater{} N4 {-}0.254}
\CommentTok{\#\textgreater{} E1  0.558}
\CommentTok{\#\textgreater{} E2  0.587}
\CommentTok{\#\textgreater{} E3  0.550}
\CommentTok{\#\textgreater{} E4  1.000}
\end{Highlighting}
\end{Shaded}

La differenza tra la matrice di correlazioni riprodotte e la matrice di correlazioni osservate è uguale a:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(psychot\_cor\_mat }\SpecialCharTok{{-}}\NormalTok{ Rr) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{round}\NormalTok{(}\DecValTok{3}\NormalTok{)}
\CommentTok{\#\textgreater{}        N1     N2     N3     N4     E1     E2     E3}
\CommentTok{\#\textgreater{} N1  0.000  0.018 {-}0.014 {-}0.003 {-}0.003 {-}0.009  0.015}
\CommentTok{\#\textgreater{} N2  0.018  0.000 {-}0.006 {-}0.013  0.015 {-}0.004 {-}0.008}
\CommentTok{\#\textgreater{} N3 {-}0.014 {-}0.006  0.000  0.017 {-}0.012  0.006  0.011}
\CommentTok{\#\textgreater{} N4 {-}0.003 {-}0.013  0.017  0.000  0.000  0.007 {-}0.016}
\CommentTok{\#\textgreater{} E1 {-}0.003  0.015 {-}0.012  0.000  0.000  0.006  0.006}
\CommentTok{\#\textgreater{} E2 {-}0.009 {-}0.004  0.006  0.007  0.006  0.000 {-}0.010}
\CommentTok{\#\textgreater{} E3  0.015 {-}0.008  0.011 {-}0.016  0.006 {-}0.010  0.000}
\CommentTok{\#\textgreater{} E4 {-}0.001  0.000 {-}0.013  0.009 {-}0.024  0.006  0.016}
\CommentTok{\#\textgreater{}        E4}
\CommentTok{\#\textgreater{} N1 {-}0.001}
\CommentTok{\#\textgreater{} N2  0.000}
\CommentTok{\#\textgreater{} N3 {-}0.013}
\CommentTok{\#\textgreater{} N4  0.009}
\CommentTok{\#\textgreater{} E1 {-}0.024}
\CommentTok{\#\textgreater{} E2  0.006}
\CommentTok{\#\textgreater{} E3  0.016}
\CommentTok{\#\textgreater{} E4  0.000}
\end{Highlighting}
\end{Shaded}

\end{exercise}

\begin{exercise}
Consideriamo nuovamente i dati precedenti ma, in questo caso, eseguiamo un'analisi fattoriale confermativa. Usando \texttt{lavaan} il modello diventa:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cfa\_mod }\OtherTok{\textless{}{-}} \StringTok{"}
\StringTok{  N =\textasciitilde{} N1 + N2 + N3 + N4}
\StringTok{  E =\textasciitilde{} E1 + E2 + E3 + E4}
\StringTok{"}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_cfa }\OtherTok{\textless{}{-}}\NormalTok{ lavaan}\SpecialCharTok{::}\FunctionTok{cfa}\NormalTok{(}
\NormalTok{  cfa\_mod,}
  \AttributeTok{sample.cov =}\NormalTok{ psychot\_cor\_mat,}
  \AttributeTok{sample.nobs =}\NormalTok{ n,}
  \AttributeTok{orthogonal =} \ConstantTok{TRUE}\NormalTok{,}
  \AttributeTok{std.lv =} \ConstantTok{TRUE}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Il path diagram si ottiene nel modo seguente:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{semPaths}\NormalTok{(}
\NormalTok{  fit\_cfa,}
  \StringTok{"std"}\NormalTok{,}
  \AttributeTok{posCol =} \FunctionTok{c}\NormalTok{(}\StringTok{"black"}\NormalTok{),}
  \AttributeTok{edge.label.cex =} \FloatTok{1.2}\NormalTok{,}
  \AttributeTok{sizeMan =} \DecValTok{7}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{cfa_book_files/figure-latex/unnamed-chunk-121-1} \end{center}

Esaminiamo le saturazioni fattoriali:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{parameterEstimates}\NormalTok{(fit\_cfa, }\AttributeTok{standardized =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{filter}\NormalTok{(op }\SpecialCharTok{==} \StringTok{"=\textasciitilde{}"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{select}\NormalTok{(}
    \StringTok{"Latent Factor"} \OtherTok{=}\NormalTok{ lhs,}
    \AttributeTok{Indicator =}\NormalTok{ rhs,}
    \AttributeTok{B =}\NormalTok{ est,}
    \AttributeTok{SE =}\NormalTok{ se,}
    \AttributeTok{Z =}\NormalTok{ z,}
    \StringTok{"p{-}value"} \OtherTok{=}\NormalTok{ pvalue,}
    \AttributeTok{Beta =}\NormalTok{ std.all}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
    \AttributeTok{digits =} \DecValTok{3}\NormalTok{, }\AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{format =} \StringTok{"markdown"}\NormalTok{,}
    \AttributeTok{caption =} \StringTok{"Factor Loadings"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}llrrrrr@{}}
\caption{\label{tab:unnamed-chunk-122}Factor Loadings}\tabularnewline
\toprule
Latent Factor & Indicator & B & SE & Z & p-value & Beta \\
\midrule
\endfirsthead
\toprule
Latent Factor & Indicator & B & SE & Z & p-value & Beta \\
\midrule
\endhead
N & N1 & 0.882 & 0.051 & 17.42 & 0 & 0.884 \\
N & N2 & 0.847 & 0.052 & 16.34 & 0 & 0.849 \\
N & N3 & 0.840 & 0.052 & 16.13 & 0 & 0.842 \\
N & N4 & 0.882 & 0.051 & 17.43 & 0 & 0.884 \\
E & E1 & 0.795 & 0.056 & 14.28 & 0 & 0.796 \\
E & E2 & 0.838 & 0.054 & 15.37 & 0 & 0.839 \\
E & E3 & 0.788 & 0.056 & 14.10 & 0 & 0.789 \\
E & E4 & 0.697 & 0.058 & 11.94 & 0 & 0.699 \\
\bottomrule
\end{longtable}

Il risultato sembra sensato: le saturazioni su ciascun fattore sono molto alte. Tuttavia, la matrice delle correlazioni residue

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cor\_table }\OtherTok{\textless{}{-}} \FunctionTok{residuals}\NormalTok{(fit\_cfa, }\AttributeTok{type =} \StringTok{"cor"}\NormalTok{)}\SpecialCharTok{$}\NormalTok{cov}
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
\NormalTok{  cor\_table,}
  \AttributeTok{digits =} \DecValTok{3}\NormalTok{,}
  \AttributeTok{format =} \StringTok{"markdown"}\NormalTok{,}
  \AttributeTok{booktabs =} \ConstantTok{TRUE}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}lrrrrrrrr@{}}
\toprule
& N1 & N2 & N3 & N4 & E1 & E2 & E3 & E4 \\
\midrule
\endhead
N1 & 0.000 & 0.017 & -0.013 & -0.003 & -0.351 & -0.316 & -0.296 & -0.282 \\
N2 & 0.017 & 0.000 & -0.006 & -0.012 & -0.302 & -0.280 & -0.289 & -0.254 \\
N3 & -0.013 & -0.006 & 0.000 & 0.018 & -0.356 & -0.300 & -0.297 & -0.292 \\
N4 & -0.003 & -0.012 & 0.018 & 0.000 & -0.318 & -0.267 & -0.296 & -0.245 \\
E1 & -0.351 & -0.302 & -0.356 & -0.318 & 0.000 & 0.007 & 0.006 & -0.022 \\
E2 & -0.316 & -0.280 & -0.300 & -0.267 & 0.007 & 0.000 & -0.011 & 0.007 \\
E3 & -0.296 & -0.289 & -0.297 & -0.296 & 0.006 & -0.011 & 0.000 & 0.015 \\
E4 & -0.282 & -0.254 & -0.292 & -0.245 & -0.022 & 0.007 & 0.015 & 0.000 \\
\bottomrule
\end{longtable}

rivela che il modello ipotizzato dall'analisi fattoriale confermativa non è adeguato.
\end{exercise}

\hypertarget{modello-fattoriale-fattori-obliqui}{%
\section{Modello fattoriale: Fattori obliqui}\label{modello-fattoriale-fattori-obliqui}}

Anche nel caso di fattori comuni correlati è possibile esprimere nei termini dei parametri del modello la covarianza teorica tra una variabile manifesta \(Y_i\) e uno dei fattori comuni, la covarianza teorica tra due variabili manifeste, e la comunalità di ciascuna variabile manifesta. Dato però che i fattori comuni risultano correlati, l'espressione fattoriale di tali quantità è più complessa che nel caso di fattori comuni ortogonali.

\hypertarget{covarianza-teorica-tra-variabili-e-fattori}{%
\subsection{Covarianza teorica tra variabili e fattori}\label{covarianza-teorica-tra-variabili-e-fattori}}

In base al modello multifattoriale con \(m\) fattori comuni la variabile \(Y_i\) è

\[
Y_i = \lambda_{i1} \xi_1 + \dots + \lambda_{im} \xi_m + \delta_i.
\label{eq:mod-multifact}
\]

Poniamoci il problema di trovare la covarianza teorica tra la variabile manifesta \(Y_i\) e il fattore comune \(\xi_j\). Come in precedenza, il problema si riduce a quello di trovare \(\E(Y_i \xi_j)\). Ne segue che

\begin{equation}
\begin{aligned}
  \mbox{Cov}(Y_i, \xi_j) &= \E(Y_i \xi_j)\notag\\
  &=\E\left[(\lambda_{i1} \xi_1 + \dots + \lambda_{ij} \xi_j + \dots + \lambda_{im} \xi_m + \delta_i)\xi_j \right]\notag\\
  &= \lambda_{i1}\underbrace{\E(\xi_1\xi_j)}_{\neq 0} + \dots + \lambda_{ij}\underbrace{\E(\xi_j^2)}_{=1} + \dots \notag\\
& \quad + \lambda_{im}\underbrace{\E(\xi_m\xi_j)}_{\neq 0} + \underbrace{\E(\delta_i \xi_j)}_{=0}\notag\\
  &= \lambda_{ij} + \lambda_{i1} \mbox{Cov}(\xi_1, \xi_j) + \dots + \lambda_{im} \mbox{Cov}(\xi_m, \xi_j).
\label{eq:cov-multifatt-obli}
\end{aligned}
\end{equation}

Ad esempio, nel caso di tre fattori comuni \(\xi_1, \xi_2, \xi_3\), la covarianza tra \(Y_1\) e \(\xi_{1}\) diventa

\[
\lambda_{11} + \lambda_{12}\mbox{Cov}(\xi_1, \xi_2) + \lambda_{13}\mbox{Cov}(\xi_1, \xi_3).
\]

\hypertarget{espressione-fattoriale-della-varianza-2}{%
\subsection{Espressione fattoriale della varianza}\label{espressione-fattoriale-della-varianza-2}}

Poniamoci ora il problema di trovare la varianza teorica della variabile manifesta \(Y_i\). In base al modello fattoriale, la variabile \(Y_i\) è specificata come nella \eqref{eq:mod-multifact}. La varianza di \(Y_i\) è \(\V(Y_i) = \E(Y_i^2) -[\E(Y_i)]^2\). Però, avendo espresso \(Y_i\) nei termini della differenza dalla sua media, l'espressione della varianza si riduce a \(\V(Y_i) = \E(Y_i^2)\). Dobbiamo dunque sviluppare l'espressione

\[
\E(Y_i^2) = \E[(\lambda_{i1} \xi_1 + \dots + \lambda_{im} \xi_m + \delta_i)^2].
\]

In conclusione, la varianza teorica di \(Y_i\) è uguale a

\begin{equation}
\begin{split}
\V(Y_i) &= \lambda_{i1}^2 + \lambda_{i2}^2 + \dots + \lambda_{im}^2  + \\
&\quad 2 \lambda_{i1} \lambda_{i2} \mbox{Cov}(\xi_1, \xi_2) + \dots + 2 \lambda_{i,m-1} \lambda_{im} \mbox{Cov}(\xi_{m-1}, \xi_m) + \\
&\quad \psi_{ii}.\notag
\end{split}
\end{equation}

Ad esempio, nel caso di tre fattori comuni, \(\xi_1, \xi_2, \xi_3\), la varianza di \(Y_1\) è

\begin{equation}
\begin{split}
\V(Y_1) = &\lambda_{11}^2 + \lambda_{12}^2 + \lambda_{13}^2 +\\ 
&\quad 2 \lambda_{11} \lambda_{12} \mbox{Cov}(\xi_1, \xi_2) + \\ 
&\quad 2 \lambda_{11} \lambda_{13} \mbox{Cov}(\xi_1, \xi_3) + \\ 
&\quad 2 \lambda_{12} \lambda_{13} \mbox{Cov}(\xi_2, \xi_3) + \\ 
&\quad \psi_{11}. \notag
\end{split}
\end{equation}

\hypertarget{covarianza-teorica-tra-due-variabili}{%
\subsection{Covarianza teorica tra due variabili}\label{covarianza-teorica-tra-due-variabili}}

Consideriamo ora il caso più semplice di due soli fattori comuni correlati e calcoliamo la covarianza tra \(Y_1\) e \(Y_2\):

\begin{equation}
\begin{aligned}
\E(Y_1 Y_2) =\E[(&\lambda_{11}\xi_1 + \lambda_{12}\xi_2+\delta_1) (\lambda_{21}\xi_1 + \lambda_{22}\xi_2+\delta_2)]\notag\\
=\E( 
&\lambda_{11}\lambda_{21}\xi_1^2 +
\lambda_{11}\lambda_{22}\xi_1\xi_2 +
\lambda_{11}\xi_1\delta_2 +\notag\\
+&\lambda_{12}\lambda_{21}\xi_1\xi_2 +
\lambda_{12}\lambda_{22}\xi_2^2 +
\lambda_{12}\xi_2\delta_2 +\notag\\
+&\lambda_{21}\xi_1\delta_1 +
\lambda_{22}\xi_2\delta_1 +
\delta_1\delta_2).\notag
\end{aligned}
\end{equation}

Distribuendo l'operatore di valore atteso, dato che \(\E(\xi^2)=1\) e \(\E(\xi \delta)=0\), otteniamo

\[
\mbox{Cov}(Y_1, Y_2) = \lambda_{11} \lambda_{21} + \lambda_{12} \lambda_{22} + 
\lambda_{12} \lambda_{21}\mbox{Cov}(\xi_1, \xi_2) +\lambda_{11} \lambda_{22}\mbox{Cov}(\xi_1, \xi_2).
\]

In termini matriciali si scrive

\[
\boldsymbol{\Sigma} =\boldsymbol{\Lambda} \boldsymbol{\Phi} \boldsymbol{\Lambda}^{\mathsf{T}} + \boldsymbol{\Psi}, 
\]

dove \(\boldsymbol{\Phi}\) è la matrice di ordine \(m \times m\) di varianze e covarianze tra i fattori comuni e \(\boldsymbol{\Psi}\) è una matrice diagonale di ordine \(p\) con le unicità delle variabili.

\begin{exercise}

Consideriamo nuovamente i dati esaminati negli esercizi precedenti, ma questa volta il modello consente una correlazione tra i due fattori comuni:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit2\_cfa }\OtherTok{\textless{}{-}}\NormalTok{ lavaan}\SpecialCharTok{::}\FunctionTok{cfa}\NormalTok{(}
\NormalTok{  cfa\_mod,}
  \AttributeTok{sample.cov =}\NormalTok{ psychot\_cor\_mat,}
  \AttributeTok{sample.nobs =}\NormalTok{ n,}
  \AttributeTok{orthogonal =} \ConstantTok{FALSE}\NormalTok{,}
  \AttributeTok{std.lv =} \ConstantTok{TRUE}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Visualizziamo il modello nel modo seguente:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{semPaths}\NormalTok{(}
\NormalTok{  fit2\_cfa,}
  \StringTok{"std"}\NormalTok{,}
  \AttributeTok{posCol =} \FunctionTok{c}\NormalTok{(}\StringTok{"black"}\NormalTok{),}
  \AttributeTok{edge.label.cex =} \FloatTok{1.1}\NormalTok{,}
  \AttributeTok{sizeMan =} \DecValTok{7}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{cfa_book_files/figure-latex/unnamed-chunk-125-1} \end{center}

Esaminiamo le saturazioni fattoriali:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{parameterEstimates}\NormalTok{(fit2\_cfa, }\AttributeTok{standardized =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{filter}\NormalTok{(op }\SpecialCharTok{==} \StringTok{"=\textasciitilde{}"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{select}\NormalTok{(}
    \StringTok{"Latent Factor"} \OtherTok{=}\NormalTok{ lhs,}
    \AttributeTok{Indicator =}\NormalTok{ rhs,}
    \AttributeTok{B =}\NormalTok{ est,}
    \AttributeTok{SE =}\NormalTok{ se,}
    \AttributeTok{Z =}\NormalTok{ z,}
    \StringTok{"p{-}value"} \OtherTok{=}\NormalTok{ pvalue,}
    \AttributeTok{Beta =}\NormalTok{ std.all}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
    \AttributeTok{digits =} \DecValTok{3}\NormalTok{, }\AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{format =} \StringTok{"markdown"}\NormalTok{,}
    \AttributeTok{caption =} \StringTok{"Factor Loadings"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}llrrrrr@{}}
\caption{\label{tab:unnamed-chunk-126}Factor Loadings}\tabularnewline
\toprule
Latent Factor & Indicator & B & SE & Z & p-value & Beta \\
\midrule
\endfirsthead
\toprule
Latent Factor & Indicator & B & SE & Z & p-value & Beta \\
\midrule
\endhead
N & N1 & 0.883 & 0.051 & 17.47 & 0 & 0.885 \\
N & N2 & 0.847 & 0.052 & 16.34 & 0 & 0.849 \\
N & N3 & 0.842 & 0.052 & 16.19 & 0 & 0.844 \\
N & N4 & 0.880 & 0.051 & 17.38 & 0 & 0.882 \\
E & E1 & 0.800 & 0.055 & 14.46 & 0 & 0.802 \\
E & E2 & 0.832 & 0.054 & 15.29 & 0 & 0.834 \\
E & E3 & 0.788 & 0.056 & 14.15 & 0 & 0.789 \\
E & E4 & 0.698 & 0.058 & 11.97 & 0 & 0.699 \\
\bottomrule
\end{longtable}

Le saturazioni sono simili a quelle che abbiamo trovato in precedenza, In questo caso, però, la matrice delle correlazioni residue è adeguata:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cor\_table }\OtherTok{\textless{}{-}} \FunctionTok{residuals}\NormalTok{(fit2\_cfa, }\AttributeTok{type =} \StringTok{"cor"}\NormalTok{)}\SpecialCharTok{$}\NormalTok{cov}
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
\NormalTok{  cor\_table,}
  \AttributeTok{digits =} \DecValTok{3}\NormalTok{,}
  \AttributeTok{format =} \StringTok{"markdown"}\NormalTok{,}
  \AttributeTok{booktabs =} \ConstantTok{TRUE}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}lrrrrrrrr@{}}
\toprule
& N1 & N2 & N3 & N4 & E1 & E2 & E3 & E4 \\
\midrule
\endhead
N1 & 0.000 & 0.016 & -0.015 & -0.002 & -0.042 & 0.005 & 0.008 & -0.013 \\
N2 & 0.016 & 0.000 & -0.007 & -0.010 & -0.006 & 0.028 & 0.002 & 0.004 \\
N3 & -0.015 & -0.007 & 0.000 & 0.018 & -0.062 & 0.006 & -0.007 & -0.035 \\
N4 & -0.002 & -0.010 & 0.018 & 0.000 & -0.010 & 0.053 & 0.007 & 0.023 \\
E1 & -0.042 & -0.006 & -0.062 & -0.010 & 0.000 & 0.006 & 0.001 & -0.027 \\
E2 & 0.005 & 0.028 & 0.006 & 0.053 & 0.006 & 0.000 & -0.007 & 0.010 \\
E3 & 0.008 & 0.002 & -0.007 & 0.007 & 0.001 & -0.007 & 0.000 & 0.014 \\
E4 & -0.013 & 0.004 & -0.035 & 0.023 & -0.027 & 0.010 & 0.014 & 0.000 \\
\bottomrule
\end{longtable}

\end{exercise}

\begin{exercise}

Esaminiamo più da vicino la matrice di correlazioni riprodotta dal modello, nel caso di fattori obliqui. Le saturazioni fattoriali sono:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lambda }\OtherTok{\textless{}{-}} \FunctionTok{inspect}\NormalTok{(fit2\_cfa, }\AttributeTok{what =} \StringTok{"std"}\NormalTok{)}\SpecialCharTok{$}\NormalTok{lambda}
\NormalTok{lambda}
\CommentTok{\#\textgreater{}        N     E}
\CommentTok{\#\textgreater{} N1 0.885 0.000}
\CommentTok{\#\textgreater{} N2 0.849 0.000}
\CommentTok{\#\textgreater{} N3 0.844 0.000}
\CommentTok{\#\textgreater{} N4 0.882 0.000}
\CommentTok{\#\textgreater{} E1 0.000 0.802}
\CommentTok{\#\textgreater{} E2 0.000 0.834}
\CommentTok{\#\textgreater{} E3 0.000 0.789}
\CommentTok{\#\textgreater{} E4 0.000 0.699}
\end{Highlighting}
\end{Shaded}

La matrice di intercorrelazoni fattoriali è

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Phi }\OtherTok{\textless{}{-}} \FunctionTok{inspect}\NormalTok{(fit2\_cfa, }\AttributeTok{what =} \StringTok{"std"}\NormalTok{)}\SpecialCharTok{$}\NormalTok{psi}
\NormalTok{Phi}
\CommentTok{\#\textgreater{}   N      E     }
\CommentTok{\#\textgreater{} N  1.000       }
\CommentTok{\#\textgreater{} E {-}0.435  1.000}
\end{Highlighting}
\end{Shaded}

Le varianze residue sono:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Psi }\OtherTok{\textless{}{-}} \FunctionTok{inspect}\NormalTok{(fit2\_cfa, }\AttributeTok{what =} \StringTok{"std"}\NormalTok{)}\SpecialCharTok{$}\NormalTok{theta}
\NormalTok{Psi}
\CommentTok{\#\textgreater{}    N1    N2    N3    N4    E1    E2    E3    E4   }
\CommentTok{\#\textgreater{} N1 0.217                                          }
\CommentTok{\#\textgreater{} N2 0.000 0.280                                    }
\CommentTok{\#\textgreater{} N3 0.000 0.000 0.288                              }
\CommentTok{\#\textgreater{} N4 0.000 0.000 0.000 0.222                        }
\CommentTok{\#\textgreater{} E1 0.000 0.000 0.000 0.000 0.357                  }
\CommentTok{\#\textgreater{} E2 0.000 0.000 0.000 0.000 0.000 0.305            }
\CommentTok{\#\textgreater{} E3 0.000 0.000 0.000 0.000 0.000 0.000 0.377      }
\CommentTok{\#\textgreater{} E4 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.511}
\end{Highlighting}
\end{Shaded}

Mediante i parametri del modello la matrice di correlazione si riproduce nel modo seguente:

\[
\boldsymbol{\Sigma} =\boldsymbol{\Lambda} \boldsymbol{\Phi} \boldsymbol{\Lambda}^{\mathsf{T}} + \boldsymbol{\Psi}. 
\]

Le corrispondenti istruzioni \(\textsf{R}\) sono:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{R\_hat }\OtherTok{\textless{}{-}}\NormalTok{ lambda }\SpecialCharTok{\%*\%}\NormalTok{ Phi }\SpecialCharTok{\%*\%} \FunctionTok{t}\NormalTok{(lambda) }\SpecialCharTok{+}\NormalTok{ Psi}
\NormalTok{R\_hat }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{round}\NormalTok{(}\DecValTok{3}\NormalTok{)}
\CommentTok{\#\textgreater{}    N1     N2     N3     N4     E1     E2     E3    }
\CommentTok{\#\textgreater{} N1  1.000                                          }
\CommentTok{\#\textgreater{} N2  0.751  1.000                                   }
\CommentTok{\#\textgreater{} N3  0.746  0.716  1.000                            }
\CommentTok{\#\textgreater{} N4  0.780  0.748  0.744  1.000                     }
\CommentTok{\#\textgreater{} E1 {-}0.309 {-}0.296 {-}0.294 {-}0.308  1.000              }
\CommentTok{\#\textgreater{} E2 {-}0.321 {-}0.308 {-}0.306 {-}0.320  0.669  1.000       }
\CommentTok{\#\textgreater{} E3 {-}0.304 {-}0.291 {-}0.290 {-}0.303  0.633  0.658  1.000}
\CommentTok{\#\textgreater{} E4 {-}0.269 {-}0.258 {-}0.257 {-}0.268  0.561  0.583  0.552}
\CommentTok{\#\textgreater{}    E4    }
\CommentTok{\#\textgreater{} N1       }
\CommentTok{\#\textgreater{} N2       }
\CommentTok{\#\textgreater{} N3       }
\CommentTok{\#\textgreater{} N4       }
\CommentTok{\#\textgreater{} E1       }
\CommentTok{\#\textgreater{} E2       }
\CommentTok{\#\textgreater{} E3       }
\CommentTok{\#\textgreater{} E4  1.000}
\end{Highlighting}
\end{Shaded}

Le correlazioni residue sono:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(psychot\_cor\_mat }\SpecialCharTok{{-}}\NormalTok{ R\_hat) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{round}\NormalTok{(}\DecValTok{3}\NormalTok{)}
\CommentTok{\#\textgreater{}    N1     N2     N3     N4     E1     E2     E3    }
\CommentTok{\#\textgreater{} N1  0.000                                          }
\CommentTok{\#\textgreater{} N2  0.016  0.000                                   }
\CommentTok{\#\textgreater{} N3 {-}0.015 {-}0.007  0.000                            }
\CommentTok{\#\textgreater{} N4 {-}0.002 {-}0.010  0.018  0.000                     }
\CommentTok{\#\textgreater{} E1 {-}0.042 {-}0.006 {-}0.062 {-}0.010  0.000              }
\CommentTok{\#\textgreater{} E2  0.005  0.028  0.006  0.053  0.006  0.000       }
\CommentTok{\#\textgreater{} E3  0.008  0.002 {-}0.007  0.007  0.001 {-}0.007  0.000}
\CommentTok{\#\textgreater{} E4 {-}0.013  0.004 {-}0.035  0.023 {-}0.027  0.010  0.014}
\CommentTok{\#\textgreater{}    E4    }
\CommentTok{\#\textgreater{} N1       }
\CommentTok{\#\textgreater{} N2       }
\CommentTok{\#\textgreater{} N3       }
\CommentTok{\#\textgreater{} N4       }
\CommentTok{\#\textgreater{} E1       }
\CommentTok{\#\textgreater{} E2       }
\CommentTok{\#\textgreater{} E3       }
\CommentTok{\#\textgreater{} E4  0.000}
\end{Highlighting}
\end{Shaded}

Per fare un esempio, calcoliamo la correlazione predetta dal modello tra le variabili \(Y_1\) e \(Y_2\):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lambda[}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{] }\SpecialCharTok{*}\NormalTok{ lambda[}\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{] }\SpecialCharTok{+}\NormalTok{ lambda[}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{] }\SpecialCharTok{*}\NormalTok{ lambda[}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{] }\SpecialCharTok{+}
\NormalTok{  lambda[}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{] }\SpecialCharTok{*}\NormalTok{ lambda[}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{] }\SpecialCharTok{*}\NormalTok{ Phi[}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{] }\SpecialCharTok{+}
\NormalTok{  lambda[}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{] }\SpecialCharTok{*}\NormalTok{ lambda[}\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{] }\SpecialCharTok{*}\NormalTok{ Phi[}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{]}
\CommentTok{\#\textgreater{} [1] 0.7508}
\end{Highlighting}
\end{Shaded}

Questo valore si avvicina al valore contenuto dell'elemento (1, 2) della matrice di correlazioni osservate:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{psychot\_cor\_mat[}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{]}
\CommentTok{\#\textgreater{} [1] 0.767}
\end{Highlighting}
\end{Shaded}

Usando le funzonalità di \texttt{lavaan} la matrice di correlazione predetta si ottiene con:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{fitted}\NormalTok{(fit2\_cfa)}\SpecialCharTok{$}\NormalTok{cov}
\CommentTok{\#\textgreater{}    N1     N2     N3     N4     E1     E2     E3    }
\CommentTok{\#\textgreater{} N1  0.996                                          }
\CommentTok{\#\textgreater{} N2  0.748  0.996                                   }
\CommentTok{\#\textgreater{} N3  0.743  0.713  0.996                            }
\CommentTok{\#\textgreater{} N4  0.777  0.745  0.741  0.996                     }
\CommentTok{\#\textgreater{} E1 {-}0.307 {-}0.295 {-}0.293 {-}0.306  0.996              }
\CommentTok{\#\textgreater{} E2 {-}0.320 {-}0.306 {-}0.305 {-}0.319  0.666  0.996       }
\CommentTok{\#\textgreater{} E3 {-}0.303 {-}0.290 {-}0.289 {-}0.302  0.630  0.656  0.996}
\CommentTok{\#\textgreater{} E4 {-}0.268 {-}0.257 {-}0.255 {-}0.267  0.558  0.580  0.550}
\CommentTok{\#\textgreater{}    E4    }
\CommentTok{\#\textgreater{} N1       }
\CommentTok{\#\textgreater{} N2       }
\CommentTok{\#\textgreater{} N3       }
\CommentTok{\#\textgreater{} N4       }
\CommentTok{\#\textgreater{} E1       }
\CommentTok{\#\textgreater{} E2       }
\CommentTok{\#\textgreater{} E3       }
\CommentTok{\#\textgreater{} E4  0.996}
\end{Highlighting}
\end{Shaded}

La matrice dei residui è

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{resid}\NormalTok{(fit2\_cfa)}\SpecialCharTok{$}\NormalTok{cov}
\CommentTok{\#\textgreater{}    N1     N2     N3     N4     E1     E2     E3    }
\CommentTok{\#\textgreater{} N1  0.000                                          }
\CommentTok{\#\textgreater{} N2  0.016  0.000                                   }
\CommentTok{\#\textgreater{} N3 {-}0.015 {-}0.007  0.000                            }
\CommentTok{\#\textgreater{} N4 {-}0.002 {-}0.010  0.018  0.000                     }
\CommentTok{\#\textgreater{} E1 {-}0.042 {-}0.006 {-}0.062 {-}0.010  0.000              }
\CommentTok{\#\textgreater{} E2  0.005  0.028  0.006  0.053  0.006  0.000       }
\CommentTok{\#\textgreater{} E3  0.008  0.002 {-}0.007  0.007  0.001 {-}0.007  0.000}
\CommentTok{\#\textgreater{} E4 {-}0.013  0.004 {-}0.035  0.023 {-}0.026  0.010  0.014}
\CommentTok{\#\textgreater{}    E4    }
\CommentTok{\#\textgreater{} N1       }
\CommentTok{\#\textgreater{} N2       }
\CommentTok{\#\textgreater{} N3       }
\CommentTok{\#\textgreater{} N4       }
\CommentTok{\#\textgreater{} E1       }
\CommentTok{\#\textgreater{} E2       }
\CommentTok{\#\textgreater{} E3       }
\CommentTok{\#\textgreater{} E4  0.000}
\end{Highlighting}
\end{Shaded}

La matrice dei residui standardizzati è

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{resid}\NormalTok{(fit2\_cfa, }\AttributeTok{type =} \StringTok{"standardized"}\NormalTok{)}\SpecialCharTok{$}\NormalTok{cov}
\CommentTok{\#\textgreater{}    N1     N2     N3     N4     E1     E2     E3    }
\CommentTok{\#\textgreater{} N1  0.000                                          }
\CommentTok{\#\textgreater{} N2  1.674  0.000                                   }
\CommentTok{\#\textgreater{} N3 {-}1.769 {-}0.569  0.000                            }
\CommentTok{\#\textgreater{} N4 {-}0.350 {-}1.152  1.746  0.000                     }
\CommentTok{\#\textgreater{} E1 {-}1.214 {-}0.161 {-}1.646 {-}0.294  0.000              }
\CommentTok{\#\textgreater{} E2  0.154  0.794  0.168  1.626  0.637  0.000       }
\CommentTok{\#\textgreater{} E3  0.219  0.062 {-}0.191  0.193  0.075 {-}0.693  0.000}
\CommentTok{\#\textgreater{} E4 {-}0.314  0.092 {-}0.824  0.552 {-}1.481  0.624  0.690}
\CommentTok{\#\textgreater{}    E4    }
\CommentTok{\#\textgreater{} N1       }
\CommentTok{\#\textgreater{} N2       }
\CommentTok{\#\textgreater{} N3       }
\CommentTok{\#\textgreater{} N4       }
\CommentTok{\#\textgreater{} E1       }
\CommentTok{\#\textgreater{} E2       }
\CommentTok{\#\textgreater{} E3       }
\CommentTok{\#\textgreater{} E4  0.000}
\end{Highlighting}
\end{Shaded}

\end{exercise}

\hypertarget{efa-con-lavaan}{%
\section{\texorpdfstring{EFA con \texttt{lavaan}}{EFA con lavaan}}\label{efa-con-lavaan}}

Una funzionalità sperimentale di \texttt{lavaan} (ancora non ufficiale) è quella che consente di svolgere l'analisi fattoriale esplorativa con la funzione \texttt{efa()}. Consideriamo nuovamente i dati di \citet{brown2015confirmatory}, ovvero otto misure di personalità raccolte su un campione di 250 pazienti che hanno concluso un programma di psicoterapia.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 1{-}factor model}
\NormalTok{f1 }\OtherTok{\textless{}{-}} \StringTok{\textquotesingle{}}
\StringTok{efa("efa")*f1 =\textasciitilde{} N1 + N2 + N3 + N4 + E1 + E2 + E3 + E4}
\StringTok{\textquotesingle{}}
\CommentTok{\# 2{-}factor model}
\NormalTok{f2 }\OtherTok{\textless{}{-}} \StringTok{\textquotesingle{}}
\StringTok{efa("efa")*f1 +}
\StringTok{efa("efa")*f2 =\textasciitilde{} N1 + N2 + N3 + N4 + E1 + E2 + E3 + E4}
\StringTok{\textquotesingle{}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{efa\_f1 }\OtherTok{\textless{}{-}}
  \FunctionTok{cfa}\NormalTok{(}
    \AttributeTok{model =}\NormalTok{ f1,}
    \AttributeTok{sample.cov =}\NormalTok{ psychot\_cor\_mat,}
    \AttributeTok{sample.nobs =} \DecValTok{250}\NormalTok{,}
    \AttributeTok{rotation =} \StringTok{"oblimin"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(}
\NormalTok{  efa\_f1,}
  \AttributeTok{fit.measures =} \ConstantTok{TRUE}\NormalTok{,}
  \AttributeTok{standardized =} \ConstantTok{TRUE}\NormalTok{,}
  \AttributeTok{rsquare =} \ConstantTok{TRUE}
\NormalTok{)}
\CommentTok{\#\textgreater{} lavaan 0.6{-}10 ended normally after 2 iterations}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}   Estimator                                         ML}
\CommentTok{\#\textgreater{}   Optimization method                           NLMINB}
\CommentTok{\#\textgreater{}   Number of model parameters                        16}
\CommentTok{\#\textgreater{}                                                       }
\CommentTok{\#\textgreater{}   Rotation method                      OBLIMIN OBLIQUE}
\CommentTok{\#\textgreater{}   Oblimin gamma                                      0}
\CommentTok{\#\textgreater{}   Rotation algorithm (rstarts)               GPA (100)}
\CommentTok{\#\textgreater{}   Standardized metric                             TRUE}
\CommentTok{\#\textgreater{}   Row weights                                     None}
\CommentTok{\#\textgreater{}                                                       }
\CommentTok{\#\textgreater{}   Number of observations                           250}
\CommentTok{\#\textgreater{}                                                       }
\CommentTok{\#\textgreater{} Model Test User Model:}
\CommentTok{\#\textgreater{}                                                       }
\CommentTok{\#\textgreater{}   Test statistic                               375.327}
\CommentTok{\#\textgreater{}   Degrees of freedom                                20}
\CommentTok{\#\textgreater{}   P{-}value (Chi{-}square)                           0.000}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Model Test Baseline Model:}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}   Test statistic                              1253.791}
\CommentTok{\#\textgreater{}   Degrees of freedom                                28}
\CommentTok{\#\textgreater{}   P{-}value                                        0.000}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} User Model versus Baseline Model:}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}   Comparative Fit Index (CFI)                    0.710}
\CommentTok{\#\textgreater{}   Tucker{-}Lewis Index (TLI)                       0.594}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Loglikelihood and Information Criteria:}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}   Loglikelihood user model (H0)              {-}2394.637}
\CommentTok{\#\textgreater{}   Loglikelihood unrestricted model (H1)      {-}2206.974}
\CommentTok{\#\textgreater{}                                                       }
\CommentTok{\#\textgreater{}   Akaike (AIC)                                4821.275}
\CommentTok{\#\textgreater{}   Bayesian (BIC)                              4877.618}
\CommentTok{\#\textgreater{}   Sample{-}size adjusted Bayesian (BIC)         4826.897}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Root Mean Square Error of Approximation:}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}   RMSEA                                          0.267}
\CommentTok{\#\textgreater{}   90 Percent confidence interval {-} lower         0.243}
\CommentTok{\#\textgreater{}   90 Percent confidence interval {-} upper         0.291}
\CommentTok{\#\textgreater{}   P{-}value RMSEA \textless{}= 0.05                          0.000}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Standardized Root Mean Square Residual:}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}   SRMR                                           0.187}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Parameter Estimates:}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}   Standard errors                             Standard}
\CommentTok{\#\textgreater{}   Information                                 Expected}
\CommentTok{\#\textgreater{}   Information saturated (h1) model          Structured}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Latent Variables:}
\CommentTok{\#\textgreater{}                    Estimate  Std.Err  z{-}value  P(\textgreater{}|z|)}
\CommentTok{\#\textgreater{}   f1 =\textasciitilde{} efa                                           }
\CommentTok{\#\textgreater{}     N1                0.879    0.051   17.333    0.000}
\CommentTok{\#\textgreater{}     N2                0.841    0.052   16.154    0.000}
\CommentTok{\#\textgreater{}     N3                0.841    0.052   16.175    0.000}
\CommentTok{\#\textgreater{}     N4                0.870    0.051   17.065    0.000}
\CommentTok{\#\textgreater{}     E1               {-}0.438    0.062   {-}7.041    0.000}
\CommentTok{\#\textgreater{}     E2               {-}0.398    0.063   {-}6.327    0.000}
\CommentTok{\#\textgreater{}     E3               {-}0.398    0.063   {-}6.342    0.000}
\CommentTok{\#\textgreater{}     E4               {-}0.364    0.063   {-}5.746    0.000}
\CommentTok{\#\textgreater{}    Std.lv  Std.all}
\CommentTok{\#\textgreater{}                   }
\CommentTok{\#\textgreater{}     0.879    0.880}
\CommentTok{\#\textgreater{}     0.841    0.842}
\CommentTok{\#\textgreater{}     0.841    0.843}
\CommentTok{\#\textgreater{}     0.870    0.872}
\CommentTok{\#\textgreater{}    {-}0.438   {-}0.439}
\CommentTok{\#\textgreater{}    {-}0.398   {-}0.398}
\CommentTok{\#\textgreater{}    {-}0.398   {-}0.399}
\CommentTok{\#\textgreater{}    {-}0.364   {-}0.364}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Variances:}
\CommentTok{\#\textgreater{}                    Estimate  Std.Err  z{-}value  P(\textgreater{}|z|)}
\CommentTok{\#\textgreater{}    .N1                0.224    0.028    7.915    0.000}
\CommentTok{\#\textgreater{}    .N2                0.289    0.033    8.880    0.000}
\CommentTok{\#\textgreater{}    .N3                0.288    0.032    8.866    0.000}
\CommentTok{\#\textgreater{}    .N4                0.239    0.029    8.174    0.000}
\CommentTok{\#\textgreater{}    .E1                0.804    0.073   10.963    0.000}
\CommentTok{\#\textgreater{}    .E2                0.838    0.076   11.008    0.000}
\CommentTok{\#\textgreater{}    .E3                0.837    0.076   11.007    0.000}
\CommentTok{\#\textgreater{}    .E4                0.864    0.078   11.041    0.000}
\CommentTok{\#\textgreater{}     f1                1.000                           }
\CommentTok{\#\textgreater{}    Std.lv  Std.all}
\CommentTok{\#\textgreater{}     0.224    0.225}
\CommentTok{\#\textgreater{}     0.289    0.290}
\CommentTok{\#\textgreater{}     0.288    0.289}
\CommentTok{\#\textgreater{}     0.239    0.240}
\CommentTok{\#\textgreater{}     0.804    0.807}
\CommentTok{\#\textgreater{}     0.838    0.841}
\CommentTok{\#\textgreater{}     0.837    0.841}
\CommentTok{\#\textgreater{}     0.864    0.867}
\CommentTok{\#\textgreater{}     1.000    1.000}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} R{-}Square:}
\CommentTok{\#\textgreater{}                    Estimate}
\CommentTok{\#\textgreater{}     N1                0.775}
\CommentTok{\#\textgreater{}     N2                0.710}
\CommentTok{\#\textgreater{}     N3                0.711}
\CommentTok{\#\textgreater{}     N4                0.760}
\CommentTok{\#\textgreater{}     E1                0.193}
\CommentTok{\#\textgreater{}     E2                0.159}
\CommentTok{\#\textgreater{}     E3                0.159}
\CommentTok{\#\textgreater{}     E4                0.133}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{efa\_f2 }\OtherTok{\textless{}{-}}
  \FunctionTok{cfa}\NormalTok{(}
    \AttributeTok{model =}\NormalTok{ f2,}
    \AttributeTok{sample.cov =}\NormalTok{ psychot\_cor\_mat,}
    \AttributeTok{sample.nobs =} \DecValTok{250}\NormalTok{,}
    \AttributeTok{rotation =} \StringTok{"oblimin"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(}
\NormalTok{  efa\_f2,}
  \AttributeTok{fit.measures =} \ConstantTok{TRUE}\NormalTok{,}
  \AttributeTok{standardized =} \ConstantTok{TRUE}\NormalTok{,}
  \AttributeTok{rsquare =} \ConstantTok{TRUE}
\NormalTok{)}
\CommentTok{\#\textgreater{} lavaan 0.6{-}10 ended normally after 1 iterations}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}   Estimator                                         ML}
\CommentTok{\#\textgreater{}   Optimization method                           NLMINB}
\CommentTok{\#\textgreater{}   Number of model parameters                        23}
\CommentTok{\#\textgreater{}                                                       }
\CommentTok{\#\textgreater{}   Rotation method                      OBLIMIN OBLIQUE}
\CommentTok{\#\textgreater{}   Oblimin gamma                                      0}
\CommentTok{\#\textgreater{}   Rotation algorithm (rstarts)               GPA (100)}
\CommentTok{\#\textgreater{}   Standardized metric                             TRUE}
\CommentTok{\#\textgreater{}   Row weights                                     None}
\CommentTok{\#\textgreater{}                                                       }
\CommentTok{\#\textgreater{}   Number of observations                           250}
\CommentTok{\#\textgreater{}                                                       }
\CommentTok{\#\textgreater{} Model Test User Model:}
\CommentTok{\#\textgreater{}                                                       }
\CommentTok{\#\textgreater{}   Test statistic                                 9.811}
\CommentTok{\#\textgreater{}   Degrees of freedom                                13}
\CommentTok{\#\textgreater{}   P{-}value (Chi{-}square)                           0.709}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Model Test Baseline Model:}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}   Test statistic                              1253.791}
\CommentTok{\#\textgreater{}   Degrees of freedom                                28}
\CommentTok{\#\textgreater{}   P{-}value                                        0.000}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} User Model versus Baseline Model:}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}   Comparative Fit Index (CFI)                    1.000}
\CommentTok{\#\textgreater{}   Tucker{-}Lewis Index (TLI)                       1.006}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Loglikelihood and Information Criteria:}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}   Loglikelihood user model (H0)              {-}2211.879}
\CommentTok{\#\textgreater{}   Loglikelihood unrestricted model (H1)      {-}2206.974}
\CommentTok{\#\textgreater{}                                                       }
\CommentTok{\#\textgreater{}   Akaike (AIC)                                4469.758}
\CommentTok{\#\textgreater{}   Bayesian (BIC)                              4550.752}
\CommentTok{\#\textgreater{}   Sample{-}size adjusted Bayesian (BIC)         4477.840}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Root Mean Square Error of Approximation:}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}   RMSEA                                          0.000}
\CommentTok{\#\textgreater{}   90 Percent confidence interval {-} lower         0.000}
\CommentTok{\#\textgreater{}   90 Percent confidence interval {-} upper         0.048}
\CommentTok{\#\textgreater{}   P{-}value RMSEA \textless{}= 0.05                          0.957}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Standardized Root Mean Square Residual:}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}   SRMR                                           0.010}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Parameter Estimates:}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}   Standard errors                             Standard}
\CommentTok{\#\textgreater{}   Information                                 Expected}
\CommentTok{\#\textgreater{}   Information saturated (h1) model          Structured}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Latent Variables:}
\CommentTok{\#\textgreater{}                    Estimate  Std.Err  z{-}value  P(\textgreater{}|z|)}
\CommentTok{\#\textgreater{}   f1 =\textasciitilde{} efa                                           }
\CommentTok{\#\textgreater{}     N1                0.874    0.053   16.592    0.000}
\CommentTok{\#\textgreater{}     N2                0.851    0.055   15.551    0.000}
\CommentTok{\#\textgreater{}     N3                0.826    0.054   15.179    0.000}
\CommentTok{\#\textgreater{}     N4                0.896    0.053   16.802    0.000}
\CommentTok{\#\textgreater{}     E1               {-}0.046    0.040   {-}1.138    0.255}
\CommentTok{\#\textgreater{}     E2                0.035    0.034    1.030    0.303}
\CommentTok{\#\textgreater{}     E3                0.000    0.040    0.010    0.992}
\CommentTok{\#\textgreater{}     E4               {-}0.006    0.049   {-}0.131    0.896}
\CommentTok{\#\textgreater{}   f2 =\textasciitilde{} efa                                           }
\CommentTok{\#\textgreater{}     N1               {-}0.017    0.032   {-}0.539    0.590}
\CommentTok{\#\textgreater{}     N2                0.011    0.035    0.322    0.748}
\CommentTok{\#\textgreater{}     N3               {-}0.035    0.036   {-}0.949    0.343}
\CommentTok{\#\textgreater{}     N4                0.031    0.031    0.994    0.320}
\CommentTok{\#\textgreater{}     E1                0.776    0.059   13.125    0.000}
\CommentTok{\#\textgreater{}     E2                0.854    0.058   14.677    0.000}
\CommentTok{\#\textgreater{}     E3                0.785    0.060   13.106    0.000}
\CommentTok{\#\textgreater{}     E4                0.695    0.063   10.955    0.000}
\CommentTok{\#\textgreater{}    Std.lv  Std.all}
\CommentTok{\#\textgreater{}                   }
\CommentTok{\#\textgreater{}     0.874    0.876}
\CommentTok{\#\textgreater{}     0.851    0.853}
\CommentTok{\#\textgreater{}     0.826    0.828}
\CommentTok{\#\textgreater{}     0.896    0.898}
\CommentTok{\#\textgreater{}    {-}0.046   {-}0.046}
\CommentTok{\#\textgreater{}     0.035    0.035}
\CommentTok{\#\textgreater{}     0.000    0.000}
\CommentTok{\#\textgreater{}    {-}0.006   {-}0.006}
\CommentTok{\#\textgreater{}                   }
\CommentTok{\#\textgreater{}    {-}0.017   {-}0.017}
\CommentTok{\#\textgreater{}     0.011    0.011}
\CommentTok{\#\textgreater{}    {-}0.035   {-}0.035}
\CommentTok{\#\textgreater{}     0.031    0.031}
\CommentTok{\#\textgreater{}     0.776    0.778}
\CommentTok{\#\textgreater{}     0.854    0.855}
\CommentTok{\#\textgreater{}     0.785    0.787}
\CommentTok{\#\textgreater{}     0.695    0.697}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Covariances:}
\CommentTok{\#\textgreater{}                    Estimate  Std.Err  z{-}value  P(\textgreater{}|z|)}
\CommentTok{\#\textgreater{}   f1 \textasciitilde{}\textasciitilde{}                                               }
\CommentTok{\#\textgreater{}     f2               {-}0.432    0.059   {-}7.345    0.000}
\CommentTok{\#\textgreater{}    Std.lv  Std.all}
\CommentTok{\#\textgreater{}                   }
\CommentTok{\#\textgreater{}    {-}0.432   {-}0.432}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Variances:}
\CommentTok{\#\textgreater{}                    Estimate  Std.Err  z{-}value  P(\textgreater{}|z|)}
\CommentTok{\#\textgreater{}    .N1                0.218    0.028    7.790    0.000}
\CommentTok{\#\textgreater{}    .N2                0.279    0.032    8.693    0.000}
\CommentTok{\#\textgreater{}    .N3                0.287    0.032    8.907    0.000}
\CommentTok{\#\textgreater{}    .N4                0.216    0.029    7.578    0.000}
\CommentTok{\#\textgreater{}    .E1                0.361    0.044    8.226    0.000}
\CommentTok{\#\textgreater{}    .E2                0.292    0.043    6.787    0.000}
\CommentTok{\#\textgreater{}    .E3                0.379    0.046    8.315    0.000}
\CommentTok{\#\textgreater{}    .E4                0.509    0.053    9.554    0.000}
\CommentTok{\#\textgreater{}     f1                1.000                           }
\CommentTok{\#\textgreater{}     f2                1.000                           }
\CommentTok{\#\textgreater{}    Std.lv  Std.all}
\CommentTok{\#\textgreater{}     0.218    0.219}
\CommentTok{\#\textgreater{}     0.279    0.280}
\CommentTok{\#\textgreater{}     0.287    0.289}
\CommentTok{\#\textgreater{}     0.216    0.217}
\CommentTok{\#\textgreater{}     0.361    0.362}
\CommentTok{\#\textgreater{}     0.292    0.293}
\CommentTok{\#\textgreater{}     0.379    0.381}
\CommentTok{\#\textgreater{}     0.509    0.511}
\CommentTok{\#\textgreater{}     1.000    1.000}
\CommentTok{\#\textgreater{}     1.000    1.000}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} R{-}Square:}
\CommentTok{\#\textgreater{}                    Estimate}
\CommentTok{\#\textgreater{}     N1                0.781}
\CommentTok{\#\textgreater{}     N2                0.720}
\CommentTok{\#\textgreater{}     N3                0.711}
\CommentTok{\#\textgreater{}     N4                0.783}
\CommentTok{\#\textgreater{}     E1                0.638}
\CommentTok{\#\textgreater{}     E2                0.707}
\CommentTok{\#\textgreater{}     E3                0.619}
\CommentTok{\#\textgreater{}     E4                0.489}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# define the fit measures}
\NormalTok{fit\_measures\_robust }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}
  \StringTok{"chisq"}\NormalTok{, }\StringTok{"df"}\NormalTok{, }\StringTok{"pvalue"}\NormalTok{,}
  \StringTok{"cfi"}\NormalTok{, }\StringTok{"rmsea"}\NormalTok{, }\StringTok{"srmr"}
\NormalTok{)}

\CommentTok{\# collect them for each model}
\FunctionTok{rbind}\NormalTok{(}
  \FunctionTok{fitmeasures}\NormalTok{(efa\_f1, fit\_measures\_robust),}
  \FunctionTok{fitmeasures}\NormalTok{(efa\_f2, fit\_measures\_robust)}
\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \CommentTok{\# wrangle}
  \FunctionTok{data.frame}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{chisq =} \FunctionTok{round}\NormalTok{(chisq, }\AttributeTok{digits =} \DecValTok{0}\NormalTok{),}
    \AttributeTok{df =} \FunctionTok{as.integer}\NormalTok{(df),}
    \AttributeTok{pvalue =} \FunctionTok{ifelse}\NormalTok{(pvalue }\SpecialCharTok{==} \DecValTok{0}\NormalTok{, }\StringTok{"\textless{} .001"}\NormalTok{, pvalue)}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate\_at}\NormalTok{(}\FunctionTok{vars}\NormalTok{(cfi}\SpecialCharTok{:}\NormalTok{srmr), }\SpecialCharTok{\textasciitilde{}} \FunctionTok{round}\NormalTok{(., }\AttributeTok{digits =} \DecValTok{3}\NormalTok{))}
\CommentTok{\#\textgreater{}   chisq df            pvalue  cfi rmsea  srmr}
\CommentTok{\#\textgreater{} 1   375 20            \textless{} .001 0.71 0.267 0.187}
\CommentTok{\#\textgreater{} 2    10 13 0.709310449320062 1.00 0.000 0.010}
\end{Highlighting}
\end{Shaded}

I risultati mostrano come la funzione \texttt{efa()} sia effettivamente in grado di distinguere in maniera chiara tra i due fattori. Il confronto tra modelli mostra la superiorità del modello a due fattori.

\hypertarget{ch:factor-scores}{%
\chapter{I punteggi fattoriali}\label{ch:factor-scores}}

Uno dei momenti più difficili nel processo di sviluppo di un test psicometrico è quello dell'interpretazione dei fattori. La verifica del livello di affidabilità rivela il grado di precisione delle misure ottenute ma non fornisce alcuna informazione sulla natura di ciò che si sta misurando. Non esistono specifiche indicazioni che guidino il lavoro interpretativo. Dipende, perciò, dalla capacità e dall'esperienza del ricercatore cogliere il significato comune delle variabili confluite in un fattore, attenendosi alla realtà delle singole variabili senza fornire interpretazioni fantasiose. È importante rendersi conto che sia la scelta del metodo di estrazione dei fattori, sia il problema del numero dei fattori da estrarre, sia la scelta del metodo con cui effettuare la rotazione, rendono molto arbitraria l'interpretazione della soluzione fattoriale.

I passaggi teorici necessari per interpretare una matrice fattoriale ruotata possono essere descritti nel modo seguente.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Si definisce un livello arbitrario per le saturazioni che ci indichi il limite oltre il quale non riteniamo le variabili sufficientemente importanti per caratterizzare quel determinato fattore. Solitamente si sceglie la soglia di .40. In casi particolari è possibile usare valori maggiori o minori di questo, a seconda che si abbia un numero ristretto o troppo ampio di variabili da interpretare.
\item
  Si ordinano le saturazioni delle variabili del fattore in ordine decrescente (in valore assoluto), fermandosi al livello prescelto.
\item
  Si scrive accanto ad ogni saturazione la denominazione della variabile corrispondente (o il testo dell'item).
\item
  Tenendo presente il dominio di indagine, le teorie di riferimento ed eventuali risultati precedenti, si cerca di stabilire quale sia il tratto, caratteristica, aspetto \ldots che queste variabili abbiano in comune, in modo da poter in modo da poter ``nominare'' il fattore che definisce questo tratto comune. In questo processo interpretativo gli item con le saturazioni maggiori contribuiscono in misura maggiore alla definizione del carattere comune del fattore e, viceversa, ciò che è stato individuato come tratto comune delle variabili deve comparire in maggior grado nelle variabili più sature.
\item
  Il segno negativo di una saturazione indica solamente un'opposizione rispetto alle saturazioni positive. Il tratto comune alle variabili dovrebbe essere pensato come un continuum che passa dalla sua massima presenza al suo opposto. Per procedere all'interpretazione conviene iniziare dalle variabili il cui segno è più frequente e considerarle come se fossero positive; di conseguenza, le altre (siano esse di segno positivo o negativo) devono essere considerate di segno opposto.
\item
  Nel caso in cui non si riesca a riscontrare nessun tratto comune alle variabili del fattore, si dovrà concludere che il fattore non è interpretabile e che le variabili sono state tra loro associate per un errore attribuibile o al campione o alla misurazione delle variabili stesse. Normalmente i ``primi'' fattori estratti sono facilmente interpretabili mentre gli ``ultimi'', soprattutto se ne sono stati estratti molti o se la matrice delle correlazioni iniziale fra le variabili contiene molti valori bassi, sono spesso difficilmente interpretabili o saturi di una sola variabile e quindi fattori specifici di quella variabile. In linea di massima se i fattori non interpretabili sono molti è meglio non considerare affatto i risultati dell'analisi fattoriale.
\end{enumerate}

\hypertarget{esempio-di-interpretazione}{%
\subsection{Esempio di interpretazione}\label{esempio-di-interpretazione}}

Il WISC-III (Wechsler Intelligence Scale For Children - III) valuta l'abilità intellettiva di soggetti dai 6 ai 16 anni e 11 mesi. I subtest sono stati selezionati per valutare diverse abilità mentali, che tutte insieme indicano l'abilità intellettiva generale del bambino. Alcuni gli richiedono un ragionamento astratto, altri si focalizzano sulla memoria, altri ancora richiedono certe abilità percettive e così via.

Si consideri la matrice di correlazione tra i subtest della scala WISC-III riportata dal manuale.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lower }\OtherTok{\textless{}{-}} \StringTok{"}
\StringTok{1}
\StringTok{.66      1}
\StringTok{.57 .55      1}
\StringTok{.70 .69 .54       1}
\StringTok{.56 .59 .47 .64      1}
\StringTok{.34 .34 .43 .35 .29      1}
\StringTok{.47 .45 .39 .45 .38 .25      1}
\StringTok{.21 .20 .27 .26 .25 .23 .18      1}
\StringTok{.40 .39 .35 .40 .35 .20 .37 .28      1}
\StringTok{.48 .49 .52 .46 .40 .32 .52 .27 .41      1}
\StringTok{.41 .42 .39 .41 .34 .26 .49 .24 .37 .61      1}
\StringTok{.35 .35 .41 .35 .34 .28 .33 .53 .36 .45 .38      1}
\StringTok{.18 .18 .22 .17 .17 .14 .24 .15 .23 .31 .29 .24     1}
\StringTok{"}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{wisc\_III\_cov }\OtherTok{\textless{}{-}} \FunctionTok{getCov}\NormalTok{(}
\NormalTok{  lower,}
  \AttributeTok{names =} \FunctionTok{c}\NormalTok{(}
    \StringTok{"INFO"}\NormalTok{, }\StringTok{"SIM"}\NormalTok{, }\StringTok{"ARITH"}\NormalTok{, }\StringTok{"VOC"}\NormalTok{, }\StringTok{"COMP"}\NormalTok{, }\StringTok{"DIGIT"}\NormalTok{, }\StringTok{"PICTCOM"}\NormalTok{,}
    \StringTok{"CODING"}\NormalTok{, }\StringTok{"PICTARG"}\NormalTok{, }\StringTok{"BLOCK"}\NormalTok{, }\StringTok{"OBJECT"}\NormalTok{, }\StringTok{"SYMBOL"}\NormalTok{, }\StringTok{"MAZES"}
\NormalTok{  )}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Eseguiamo l'analisi fattoriale con il metodo delle componenti principali e una rotazione Varimax:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{f\_pc }\OtherTok{\textless{}{-}}\NormalTok{ psych}\SpecialCharTok{::}\FunctionTok{principal}\NormalTok{(wisc\_III\_cov, }\AttributeTok{nfactors =} \DecValTok{3}\NormalTok{, }\AttributeTok{rotate =} \StringTok{"varimax"}\NormalTok{)}
\NormalTok{f\_pc}
\CommentTok{\#\textgreater{} Principal Components Analysis}
\CommentTok{\#\textgreater{} Call: psych::principal(r = wisc\_III\_cov, nfactors = 3, rotate = "varimax")}
\CommentTok{\#\textgreater{} Standardized loadings (pattern matrix) based upon correlation matrix}
\CommentTok{\#\textgreater{}           RC1  RC3  RC2   h2   u2 com}
\CommentTok{\#\textgreater{} INFO     0.80 0.25 0.09 0.72 0.28 1.2}
\CommentTok{\#\textgreater{} SIM      0.81 0.25 0.08 0.72 0.28 1.2}
\CommentTok{\#\textgreater{} ARITH    0.65 0.26 0.28 0.57 0.43 1.7}
\CommentTok{\#\textgreater{} VOC      0.83 0.19 0.13 0.75 0.25 1.2}
\CommentTok{\#\textgreater{} COMP     0.75 0.14 0.16 0.60 0.40 1.2}
\CommentTok{\#\textgreater{} DIGIT    0.45 0.06 0.36 0.34 0.66 2.0}
\CommentTok{\#\textgreater{} PICTCOM  0.43 0.61 0.02 0.56 0.44 1.8}
\CommentTok{\#\textgreater{} CODING   0.10 0.09 0.88 0.79 0.21 1.0}
\CommentTok{\#\textgreater{} PICTARG  0.34 0.45 0.27 0.39 0.61 2.6}
\CommentTok{\#\textgreater{} BLOCK    0.41 0.66 0.22 0.66 0.34 1.9}
\CommentTok{\#\textgreater{} OBJECT   0.31 0.71 0.14 0.62 0.38 1.5}
\CommentTok{\#\textgreater{} SYMBOL   0.23 0.32 0.74 0.70 0.30 1.6}
\CommentTok{\#\textgreater{} MAZES   {-}0.06 0.71 0.11 0.51 0.49 1.1}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}                        RC1  RC3  RC2}
\CommentTok{\#\textgreater{} SS loadings           3.80 2.37 1.74}
\CommentTok{\#\textgreater{} Proportion Var        0.29 0.18 0.13}
\CommentTok{\#\textgreater{} Cumulative Var        0.29 0.47 0.61}
\CommentTok{\#\textgreater{} Proportion Explained  0.48 0.30 0.22}
\CommentTok{\#\textgreater{} Cumulative Proportion 0.48 0.78 1.00}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Mean item complexity =  1.5}
\CommentTok{\#\textgreater{} Test of the hypothesis that 3 components are sufficient.}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} The root mean square of the residuals (RMSR) is  0.07 }
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Fit based upon off diagonal values = 0.97}
\end{Highlighting}
\end{Shaded}

Si noti che i primi cinque subtest possiedono saturazioni maggiori di \(0.6\) sul primo fattore. Dato che questi test sono tutti presentati verbalmente e richiedono delle risposte verbali, tale fattore può essere denominato \emph{Comprensione Verbale}.

I subtest ``Cifrario'' e ``Ricerca di simboli'' saturano sul secondo fattore. Entrambi i subtest misurano la velocità dei processi di codifica o ricerca. Questo fattore, dunque, può essere denominato \emph{Velocità di elaborazione}.

Infine, i subtest ``Completamento di figure,'' ``Disegno con i cubi,'' ``Riordinamento di storie figurate'' e ``Labirinti'' saturano sul terzo fattore. Tutti questi test condividono una componente geometrica o configurazionale: misurano infatti le abilità necessarie per la manipolazione o la disposizione di immagini, oggetti, blocchi. Questo fattore, dunque, può essere denominato \emph{Organizzazione percettiva}.

Nel caso di una rotazione ortogonale, la comunalità di ciascuna sottoscala è uguale alla somma dei coefficienti di impatto al quadrato della sottoscala nei fattori. Per le 13 sottoscale del WISC-III abbiamo dunque

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{h2 }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{13}\NormalTok{)}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\DecValTok{13}\NormalTok{) \{}
\NormalTok{  h2[i] }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(f\_pc}\SpecialCharTok{$}\NormalTok{loadings[i, ]}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\NormalTok{\}}
\FunctionTok{round}\NormalTok{(h2, }\DecValTok{2}\NormalTok{)}
\CommentTok{\#\textgreater{}  [1] 0.72 0.72 0.57 0.75 0.60 0.34 0.56 0.79 0.39 0.66}
\CommentTok{\#\textgreater{} [11] 0.62 0.70 0.51}
\end{Highlighting}
\end{Shaded}

Questi risultati replicano quelli riportati nel manuale del test WISC-III.

\hypertarget{punteggi-fattoriali}{%
\section{Punteggi fattoriali}\label{punteggi-fattoriali}}

Fino ad ora abbiamo considerato le strategie di costruzione del modello basate sulla stima e sull'interpretazione delle saturazioni fattoriali e delle comunalità. Questo è il primo passo nella costruzione del modello fattoriale. È però possibile compiere un passo ulteriore, ovvero quello della stima dei punteggi fattoriali (\emph{factor scores}) i quali risultano utili sia per interpretare i risultati dell'analisi fattoriale che per fare diagnostica. I punteggi fattoriali forniscono le previsioni dei livelli dei fattori latenti per ogni rispondente. Esistono vari metodi di stima dei punteggi fattoriali. Tra questi troviamo il metodo di Thomson basato sulla regressione e il metodo di Bartlett basato sulla massima verosimiglianza. Entrambi questi metodi sono implementati nel software .

\hypertarget{stima-dei-punteggi-fattoriali}{%
\subsection{Stima dei punteggi fattoriali}\label{stima-dei-punteggi-fattoriali}}

Si definiscono punteggi fattoriali i valori assunti dai fattori comuni (inosservabili) in corrispondenza delle osservazioni campionarie. Il metodo di Thomson stima i punteggi fattoriali in base all'approccio della regressione multipla, ovvero, impiegando la matrice delle correlazioni tra le variabili e la matrice di struttura (ovvero, la matrice delle correlazioni delle variabili con i fattori). Per ottenere le stime dei punteggi fattoriali con il metodo di Thomson è necessario specificare nella funzione \texttt{factanal()} l'opzione \texttt{scores\ =\ "regression"}.

\hypertarget{dimostrazione-di-thurstone}{%
\subsection{Dimostrazione di Thurstone}\label{dimostrazione-di-thurstone}}

Prima di descrivere il metodo della regressione, esaminiamo la dimostrazione che Thurstone (1947) ha fornito per illustrare il significato dei punteggi fattoriali (si veda Loehlin, 1987). L'idea è quella di esaminare la stima dei punteggi fattoriali in una situazione in cui i tali punteggi sono conosciuti, in maniera tale da potere controllare il risultato dell'analisi.

Si consideri un insieme di 1000 scatole di cui conosciamo le dimensioni \(x, y, z\):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}
\NormalTok{n }\OtherTok{\textless{}{-}} \FloatTok{1e3}
\NormalTok{x }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{100}\NormalTok{, }\FloatTok{1.5}\NormalTok{)}
\NormalTok{y }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{200}\NormalTok{, }\FloatTok{1.5}\NormalTok{)}
\NormalTok{z }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{300}\NormalTok{, }\FloatTok{1.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Il problema è quello di stimare le dimensioni delle scatole disponendo soltanto di una serie di misure indirette, corrotte dal rumore di misura. Thurstone (1947) utilizzò le seguenti trasformazioni delle dimensioni delle scatole (si veda Jennrich, 2007).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{s }\OtherTok{\textless{}{-}} \DecValTok{40}
\NormalTok{y1 }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(n, }\FunctionTok{mean}\NormalTok{(x), s)}
\NormalTok{y2 }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(n, }\FunctionTok{mean}\NormalTok{(y), s)}
\NormalTok{y3 }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(n, }\FunctionTok{mean}\NormalTok{(z), s)}
\NormalTok{y4 }\OtherTok{\textless{}{-}}\NormalTok{ x }\SpecialCharTok{*}\NormalTok{ y }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{0}\NormalTok{, s)}
\NormalTok{y5 }\OtherTok{\textless{}{-}}\NormalTok{ x }\SpecialCharTok{*}\NormalTok{ z }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{0}\NormalTok{, s)}
\NormalTok{y6 }\OtherTok{\textless{}{-}}\NormalTok{ y }\SpecialCharTok{*}\NormalTok{ z }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{0}\NormalTok{, s)}
\NormalTok{y7 }\OtherTok{\textless{}{-}}\NormalTok{ x}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{*}\NormalTok{ y }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{0}\NormalTok{, s)}
\NormalTok{y8 }\OtherTok{\textless{}{-}}\NormalTok{ x }\SpecialCharTok{*}\NormalTok{ y}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{0}\NormalTok{, s)}
\NormalTok{y9 }\OtherTok{\textless{}{-}}\NormalTok{ x}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{*}\NormalTok{ z }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{0}\NormalTok{, s)}
\NormalTok{y10 }\OtherTok{\textless{}{-}}\NormalTok{ x }\SpecialCharTok{*}\NormalTok{ z}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{0}\NormalTok{, s)}
\NormalTok{y11 }\OtherTok{\textless{}{-}}\NormalTok{ y}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{*}\NormalTok{ z }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{0}\NormalTok{, s)}
\NormalTok{y12 }\OtherTok{\textless{}{-}}\NormalTok{ y }\SpecialCharTok{*}\NormalTok{ z}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{0}\NormalTok{, s)}
\NormalTok{y13 }\OtherTok{\textless{}{-}}\NormalTok{ y}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{*}\NormalTok{ z }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{0}\NormalTok{, s)}
\NormalTok{y14 }\OtherTok{\textless{}{-}}\NormalTok{ y }\SpecialCharTok{*}\NormalTok{ z}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{0}\NormalTok{, s)}
\NormalTok{y15 }\OtherTok{\textless{}{-}}\NormalTok{ x }\SpecialCharTok{/}\NormalTok{ y }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{0}\NormalTok{, s)}
\NormalTok{y16 }\OtherTok{\textless{}{-}}\NormalTok{ y }\SpecialCharTok{/}\NormalTok{ x }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{0}\NormalTok{, s)}
\NormalTok{y17 }\OtherTok{\textless{}{-}}\NormalTok{ x }\SpecialCharTok{/}\NormalTok{ z }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{0}\NormalTok{, s)}
\NormalTok{y18 }\OtherTok{\textless{}{-}}\NormalTok{ z }\SpecialCharTok{/}\NormalTok{ x }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{0}\NormalTok{, s)}
\NormalTok{y19 }\OtherTok{\textless{}{-}}\NormalTok{ y }\SpecialCharTok{/}\NormalTok{ z }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{0}\NormalTok{, s)}
\NormalTok{y20 }\OtherTok{\textless{}{-}}\NormalTok{ z }\SpecialCharTok{/}\NormalTok{ y }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{0}\NormalTok{, s)}
\NormalTok{y21 }\OtherTok{\textless{}{-}} \DecValTok{2} \SpecialCharTok{*}\NormalTok{ x }\SpecialCharTok{+} \DecValTok{2} \SpecialCharTok{*}\NormalTok{ y }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{0}\NormalTok{, s)}
\NormalTok{y22 }\OtherTok{\textless{}{-}} \DecValTok{2} \SpecialCharTok{*}\NormalTok{ x }\SpecialCharTok{+} \DecValTok{2} \SpecialCharTok{*}\NormalTok{ z }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{0}\NormalTok{, s)}
\NormalTok{y23 }\OtherTok{\textless{}{-}} \DecValTok{2} \SpecialCharTok{*}\NormalTok{ y }\SpecialCharTok{+} \DecValTok{2} \SpecialCharTok{*}\NormalTok{ z }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{0}\NormalTok{, s)}
\end{Highlighting}
\end{Shaded}

Eseguiamo l'analisi fattoriale con una soluzione a tre fattori sui dati così creati.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Y }\OtherTok{\textless{}{-}} \FunctionTok{cbind}\NormalTok{(}
\NormalTok{  y1, y2, y3, y4, y5, y6, y7, y8, y9,}
\NormalTok{  y10, y11, y12, y13, y14, y15, y16,}
\NormalTok{  y17, y18, y19, y20, y21, y22, y23}
\NormalTok{)}

\NormalTok{fa }\OtherTok{\textless{}{-}} \FunctionTok{factanal}\NormalTok{(}
\NormalTok{  Y,}
  \AttributeTok{factors =} \DecValTok{3}\NormalTok{,}
  \AttributeTok{scores =} \StringTok{"regression"}\NormalTok{,}
  \AttributeTok{lower =} \FloatTok{0.01}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

L'opzione \texttt{scores\ =\ "regression"} richiede il calcolo dei punteggi fattoriali con il metodo della regressione. Nel caso di una rotazione Varimax (default della funzione \texttt{factanal()}), i punteggi fattoriali risultano ovviamente incorrelati:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cor}\NormalTok{(}
  \FunctionTok{cbind}\NormalTok{(fa}\SpecialCharTok{$}\NormalTok{scores[, }\DecValTok{1}\NormalTok{], fa}\SpecialCharTok{$}\NormalTok{scores[, }\DecValTok{2}\NormalTok{], fa}\SpecialCharTok{$}\NormalTok{scores[, }\DecValTok{3}\NormalTok{])}
\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{round}\NormalTok{(}\DecValTok{3}\NormalTok{)}
\CommentTok{\#\textgreater{}        [,1]  [,2]   [,3]}
\CommentTok{\#\textgreater{} [1,]  1.000 0.002 {-}0.001}
\CommentTok{\#\textgreater{} [2,]  0.002 1.000  0.005}
\CommentTok{\#\textgreater{} [3,] {-}0.001 0.005  1.000}
\end{Highlighting}
\end{Shaded}

Generiamo ora i diagrammi di dispersione che mettono in relazione le dimensioni originarie delle scatole (\(x, y, z\)) con i punteggi fattoriali sui tre fattori. Se l'analisi ha successo, ci aspettiamo un'alta correlazione tra i punteggi fattoriali di ogni fattore e una sola delle dimensioni delle scatole \(x\), \(y\), \(z\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p1 }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(x, }\AttributeTok{fs1 =}\NormalTok{ fa}\SpecialCharTok{$}\NormalTok{scores[, }\DecValTok{1}\NormalTok{]) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(x, fs1)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{alpha =} \FloatTok{0.2}\NormalTok{)}
\NormalTok{p2 }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(y, }\AttributeTok{fs1 =}\NormalTok{ fa}\SpecialCharTok{$}\NormalTok{scores[, }\DecValTok{1}\NormalTok{]) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(y, fs1)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{alpha =} \FloatTok{0.2}\NormalTok{)}
\NormalTok{p3 }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(z, }\AttributeTok{fs1 =}\NormalTok{ fa}\SpecialCharTok{$}\NormalTok{scores[, }\DecValTok{1}\NormalTok{]) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(z, fs1)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{alpha =} \FloatTok{0.2}\NormalTok{)}

\NormalTok{p4 }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(x, }\AttributeTok{fs2 =}\NormalTok{ fa}\SpecialCharTok{$}\NormalTok{scores[, }\DecValTok{2}\NormalTok{]) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(x, fs2)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{alpha =} \FloatTok{0.2}\NormalTok{)}
\NormalTok{p5 }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(y, }\AttributeTok{fs2 =}\NormalTok{ fa}\SpecialCharTok{$}\NormalTok{scores[, }\DecValTok{2}\NormalTok{]) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(y, fs2)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{alpha =} \FloatTok{0.2}\NormalTok{)}
\NormalTok{p6 }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(z, }\AttributeTok{fs2 =}\NormalTok{ fa}\SpecialCharTok{$}\NormalTok{scores[, }\DecValTok{2}\NormalTok{]) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(z, fs2)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{alpha =} \FloatTok{0.2}\NormalTok{)}

\NormalTok{p7 }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(x, }\AttributeTok{fs3 =}\NormalTok{ fa}\SpecialCharTok{$}\NormalTok{scores[, }\DecValTok{3}\NormalTok{]) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(x, fs3)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{alpha =} \FloatTok{0.2}\NormalTok{)}
\NormalTok{p8 }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(y, }\AttributeTok{fs3 =}\NormalTok{ fa}\SpecialCharTok{$}\NormalTok{scores[, }\DecValTok{3}\NormalTok{]) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(y, fs3)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{alpha =} \FloatTok{0.2}\NormalTok{)}
\NormalTok{p9 }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(z, }\AttributeTok{fs3 =}\NormalTok{ fa}\SpecialCharTok{$}\NormalTok{scores[, }\DecValTok{3}\NormalTok{]) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(z, fs3)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{alpha =} \FloatTok{0.2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(p1 }\SpecialCharTok{|}\NormalTok{ p2 }\SpecialCharTok{|}\NormalTok{ p3) }\SpecialCharTok{/}
\NormalTok{  (p4 }\SpecialCharTok{|}\NormalTok{ p5 }\SpecialCharTok{|}\NormalTok{ p6) }\SpecialCharTok{/}
\NormalTok{  (p7 }\SpecialCharTok{|}\NormalTok{ p8 }\SpecialCharTok{|}\NormalTok{ p9)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{cfa_book_files/figure-latex/unnamed-chunk-154-1} \end{center}

I risultati riportati nella figura confermano le aspettative.

Il metodo della regressione pone il problema della stima dei punteggi fattoriali nei termini di una ideale regressione di ogni fattore rispetto a tutte le variabili osservate. Per il fattore \(j\)-esimo, si può scrivere la seguente equazione:

\[
\begin{aligned}
F_j =& \beta_{1j}y_1 + \dots + \beta_{pm}y_p + \varepsilon_j
\end{aligned}
\]

dove \(F_j\) sono i punteggi fattoriali e \(y\) sono le variabili osservate standardizzate \((Y-\bar{Y})/s\). In forma matriciale, il modello diventa

\[
\textbf{F} = \textbf{y} \textbf{B} +
\boldsymbol{\varepsilon}
\]

I coefficienti parziali di regressione \textbf{B} sono ignoti. Tuttavia, possono essere calcolati utilizzando i metodi della regressione lineare. Nel modello di regressione, infatti, i coefficienti dei minimi quadrati possono essere calcolati utilizzando due matrici di correlazioni: la matrice \(\textbf{R}_{xx}\) (le correlazioni tra le variabili \(X\)) e la matrice \(\textbf{R}_{xy}\) (le correlazioni tra le variabili \(X\) e la variabile \(Y\):

\[
\hat{\textbf{B}} = \textbf{R}_{xx}^{-1}\textbf{R}_{xy}
\]

Nel caso dell'analisi fattoriale, \(\textbf{R}_{xx}\) corrisponde alla matrice delle correlazioni tra le variabili osservate e \(\textbf{R}_{xy}\) corrisponde alla matrice di struttura (la matrice delle correlazioni tra le variabili osservate e i fattori). Se i fattori sono ortogonali, la matrice di struttura coincide con la matrice dei pesi fattoriali \(\hat{\boldsymbol{\Lambda}}\).

I coefficienti \textbf{B} dell'equazione precedente possono dunque essere trovati nel modo seguente:

\begin{equation}
\hat{\textbf{B}} = \textbf{R}_{yy}^{-1}\textbf{R}_{xf}=
\textbf{R}^{-1}\hat{\boldsymbol{\Lambda}}
\end{equation}

Una volta stimati i coefficienti \(\hat{\textbf{B}}\), i punteggi fattoriali si calcolano allo stesso modo dei punteggi teorici del modello di regressione:

\begin{equation}
\hat{\textbf{F}} = \textbf{y} \hat{\textbf{B}} = \textbf{y}
\textbf{R}^{-1}\hat{\boldsymbol{\Lambda}},
\end{equation}

dove \(\textbf{y}\) è la matrice delle variabili osservate standardizzate \((Y-\bar{Y})/s\).

\hypertarget{ch:path_analysis}{%
\chapter{Path Analysis}\label{ch:path_analysis}}

La \emph{path analysis} è un metodo per decomporre la correlazione (o la covarianza) in componenti differenti al fine di studiare i processi causali sottostanti. La \emph{path analysis} comprende due parti principali: la rappresentazione grafica delle interrelazioni esistenti tra le variabili e la scomposizione delle correlazioni (o covarianze) nei termini dei parametri del modello.

\hypertarget{path-diagram}{%
\section{Path diagram}\label{path-diagram}}

Il path diagram fornisce una rappresentazione grafica delle relazioni esistenti tra le variabili oggetto di interesse. In tale diagramma, le variabili non osservate o latenti sono racchiuse in un cerchio o ellisse; le variabili osservate sono racchiuse in un quadrato o rettangolo. Due classi di variabili vengono rappresentate in un path diagram: quelle che non ricevono effetti causali da altre variabili e quelle che li ricevono. Una variabile \emph{esogena} (cioè esterna) svolge sempre e soltanto funzione di variabile indipendente, ovvero di variabile che causa un effetto. Una variabile \emph{endogena} (cioè interna) può essere effetto di alcune variabili e contemporaneamente causa per altre, oppure può svolgere solo il ruolo di variabile dipendente. Le fonti causali delle variabili endogene sono interne al path diagram; le fonti causali delle variabili esogene sono esterne al path diagram. La distinzione tra variabili esogene e endogene ha delle ovvie assonanze con la distinzione tra variabili indipendenti e dipendenti propria dei modelli lineari.

Le frecce che connettono le variabili nel diagramma denotano nessi causali o mere associazioni. Una freccia orientata rappresenta un nesso causale tra le variabili implicate: la variabile che riceve la freccia dipende dalla variabile da cui parte la freccia. Una freccia curva a due direzioni indica, invece, un'associazione non causale tra due variabili. Il fatto che due variabili non siano collegate nel diagramma equivale ad assumere che tali variabili siano incorrelate. Un esempio è fornito nella Figura \ref{fig:path01} la quale rende esplicite le relazioni tra tre variabili latenti e nove variabili manifeste.

\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{images/path_01} 

}

\caption{Esempio di path diagram.}\label{fig:path01}
\end{figure}

\hypertarget{path-analysis-e-regressione-multipla}{%
\section{Path analysis e regressione multipla}\label{path-analysis-e-regressione-multipla}}

Vi è una stretta relazione tra path analysis e regressione multipla, tanto che la regressione può essere considerata un caso particolare di path analysis. Per semplicità, si supponga che le variabili siano state standardizzate, anche se la stessa analisi può essere condotta per variabili grezze. Il path diagram mostra la relazione tra tutte le variabili, comprendendo anche i fattori di disturbo, e fornisce dunque la rappresentazione grafica di un sistema di equazioni simultanee. Nel caso di due regressori, il modello di regressione multipla può essere rappresentato tramite il path diagram riportato nella Figura \ref{fig:path02}.

\begin{figure}

{\centering \includegraphics[width=0.55\linewidth]{images/path_02} 

}

\caption{Path diagram per il modello di regressione multipla con due regressori.}\label{fig:path02}
\end{figure}

I coefficienti di percorso associati alle frecce orientate esprimono la portata del nesso causale e corrispondono ai pesi beta (ovvero ai coefficienti parziali di regressione standardizzati). Le frecce non orientate esprimono la portata della pura associazione tra variabili e dunque corrispondono alle correlazioni.

Nel caso di due variabili esogene \(x_1\) e \(x_2\), il modello di regressione diventa

\[y = b_{1} x_1 + b_{2} x_2 + 1 \cdot e\]

dove \(y\) è la variabile endogena ed \(e\) è il fattore di disturbo. Tale modello di regressione può essere rappresentato graficamente come indicato nella figura precedente.

Nella figura, le frecce dritte indicano un'influenza causale dalla variabile da cui parte la freccia a quella a cui la freccia arriva. A tali frecce dritte sono associati i coefficienti di percorso \(b_1\) e \(b_2\) (ovvero i pesi beta). Il coefficiente 1 rappresenta l'effetto del fattore di disturbo \(e\) sulla variabile endogena \(y\), implicito nelle equazioni e reso esplicito nella figura.

Si noti che si hanno tante equazioni quante sono le variabili endogene. Nel caso presente, c'è un'unica equazione in quanto vi è una sola variabile endogena (ovvero la \(y\), le cui cause sono interne al path diagram). All'interno di ciascuna equazione, inoltre, ci saranno tanti termini quante sono le frecce dritte che puntano verso la variabile endogena. Nell'esempio, ci sono tre termini, uno per ciascun freccia dritta.

\hypertarget{effetti-diretti-e-indiretti}{%
\section{Effetti diretti e indiretti}\label{effetti-diretti-e-indiretti}}

La path analysis fornisce un metodo per distinguere tra i diversi tipi di effetti che influenzano le variabili: l'effetto diretto, l'effetto indiretto e l'effetto totale. Gli effetti diretti sono quelli non mediati da altre variabili. Gli effetti indiretti operano attraverso l'intervento di almeno una variabile. L'effetto totale è la somma di tutti gli effetti diretti e indiretti.

Nella Figura \ref{fig:path03} la variable \(y_1\) ha un effetto diretto sulla \(y_2\). La variabile \(y_1\) ha un effetto indiretto sulla \(y_3\) in quanto non c'è una freccia causale che colleghi direttamente la variabile \(y_1\) alla \(y_3\). La variabile \(y_1\) è una variabile esogena e le varibili \(y_2\) e \(y_3\) sono variabili endogene.

\begin{figure}

{\centering \includegraphics[width=0.4\linewidth]{images/path_03} 

}

\caption{Path diagram per una relazione a catena.}\label{fig:path03}
\end{figure}

Nella Figura \ref{fig:path03}, la variabile \(x_1\) ha un effetto diretto sulla \(y\), ma anche un effetto indiretto sulla \(y\) derivante dalla correlazione tra \(x_1\) e \(x_2\). In un path diagram, l'effetto diretto è rappresentato da una freccia dritta (es., \(b_{1}\)). L'effetto indiretto tra due variabili è rappresentato da un percorso composto che include una o più frecce dritte e non più di una linea curva -- per es., \(s_{12} b_{2}\).

\hypertarget{le-regole-di-wright}{%
\section{Le regole di Wright}\label{le-regole-di-wright}}

Lo scopo della path analysis è quello di decomporre la correlazione (o la covarianza) nei termini della somma di tutti i percorsi (diretti e indiretti) che legano le due variabili tramite i coefficienti detti \emph{path coefficients}. Usando il path diagram, Sewall Wright (1921, 1934) enunciò le regole che, attraverso le cosiddette \emph{tracing rules}, legano le correlazioni (o covarianze) delle variabili ai parametri del modello. Le tracing rules possono essere espresse nei termini seguenti:

\begin{itemize}
\tightlist
\item
  è possibile procedere prima all'indietro lungo una freccia e poi in avanti, seguendo la direzione di una freccia, ma non si può andare prima avanti e poi tornare indietro;
\item
  un percorso composto non deve transitare due volte per la stessa variabile (non devono esserci loop);
\item
  un percorso non può comprendere più di una linea curva.
\end{itemize}

Si chiama ``percorso'' il tracciato che unisce due variabili; è costituito da sequenze di frecce direzionali e di curve non direzionali. A ciascun percorso legittimo (ovvero, che soddisfa le regole di Wright) viene assegnato un valore numerico pari al prodotto dei coefficienti incontrati sul percorso medesimo. I coefficienti di percorso possono essere o coefficienti parziali di regressione standardizzati, se il legame ha una direzione, oppure coefficienti di correlazione, se il legame è bidirezionale.

\hypertarget{scomposizione-delle-correlazioni-covarianze}{%
\subsection{Scomposizione delle correlazioni (covarianze)}\label{scomposizione-delle-correlazioni-covarianze}}

Il principio di base è stato espresso da Sewall Wright (1934) nel modo seguente: ``Any correlation between variables in a network of sequential relations can be analyzed into contributions from all the paths (direct or through common factors) by which the two variables are connected, such that the value of each contribution is the product of the coefficients pertaining to the elementary paths. If residual correlations are present (represented by bidirectional arrows) one (but never more than one) of the coefficients thus multiplied together to give the contribution of the connecting path, may be a correlation coefficient. The others are all path coefficients.''

Possiamo così enunciare la regola di scomposizione della correlazione.

\begin{definition}
La correlazione fra due variabili può essere decomposta in tanti addendi quanto sono i percorsi che le collegano; ogni addendo è dato dal prodotto dei coefficienti incontrati sul percorso.
\end{definition}

Si consideri il diagramma rappresesentato nella Figura \ref{fig:path02}. La variabile endogena è la \(y\). Le variabili esogene, correlate tra loro, sono \(x_1\) e \(x_2\).

Il diagramma di percorso corrisponde alla seguente equazione:

\[y = 0.50 x_1 + 0.40 x_2 + e\]

dove le variabili \(x_1\) e \(x_2\) sono incorrelate con \(e\).

La correlazione tra \(y\) e \(x_1\) è uguale alla somma dell'effetto diretto che \(x_1\) esercita sulla \(y\) e dell'effetto indiretto che \(x_1\) esercita sulla \(y\) tramite la correlazione con \(x_2\). In base alle regole di Wright, \(x_1\) e \(y\) risultano collegate da due percorsi legittimi: il percorso costituito dalla freccia dritta \(x_1 \rightarrow  y\); il percorso composto dalla freccia dritta \(x_2 \rightarrow  y\) e dalla curva non direzionale \(x_1 \leftrightarrow x_2\). Il valore numerico del primo percorso è \(0.50\). Il valore numerico del secondo percorso è \(0.50\times 0.40\). La correlazione tra le variabili \(x_1\) e \(y\) è dunque uguale alla somma dei valori numerici dei due percorsi legittimi che legano \(x_1\) alla \(y\):

\begin{equation}
\begin{aligned}
  r_{x_1,y} &= \beta_{y,x_1} + r_{x_1,x_2} \beta_{y,x_2}\notag\\
  &=   0.50 + 0.50 \times 0.40 = 0.70.\notag
\end{aligned}
\end{equation}

La correlazione tra \(x_2\) e \(y\) è invece uguale a:

\begin{equation}
\begin{aligned}
  r_{yx_2} &=\beta_{yx_2} + r_{x_1x_2} \beta_{yx_1}\notag\\
  &= 0.40 + 0.50 \times 0.50 = 0.65.\notag
\end{aligned}
\end{equation}

\hypertarget{scomposizione-della-varianza}{%
\subsection{Scomposizione della varianza}\label{scomposizione-della-varianza}}

La varianza di una variabile endogena si decompone in una quota di varianza spiegata dalle variabili agenti causalmente su di essa e in una quota di varianza non spiegata.

\begin{definition}
La varianza spiegata è data dalla somma di tanti addendi quanti sono i percorsi che consentono di collegare la variabile a se stessa rispettando le tracing rules di Wright.
\end{definition}

Facendo riferimento alla Figura \ref{fig:path02}, si possono individuare quattro percorsi legittimi che collegano \(y\) a se stessa:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(0.50 \times 1.00 \times 0.50\),
\item
  \(0.40 \times 1.00 \times 0.40\),
\item
  \(0.50 \times 0.50 \times 0.40\),
\item
  \(0.40 \times 0.50 \times 0.50\).
\end{enumerate}

La varianza della variabile endogena \(y\) che viene spiegata dalle variabili esogene \(x_1\) e \(x_2\) è dunque uguale a \[0.25 + 0.16  + 0.10 + 0.10= 0.61.\] Inoltre, dato che le variabili rappresentate nel diagramma sono standardizzate, la varianza complessiva della \(y\) è uguale a 1.00. La varianza della \(y\) non spiegata dalle variabili \(x_1\) e \(x_2\) è quindi uguale a \[1-0.61 = 0.39.\]

\hypertarget{sec:how_compute_path_coef}{%
\section{Come calcolare i coefficienti di percorso?}\label{sec:how_compute_path_coef}}

Data una matrice di correlazione, i coefficienti di percorso possono essere calcolati risolvendo un sistema di equazioni simultanee. Si supponga che, per le tre variabili della figura precedente, vi sia la seguente matrice di correlazione:

\begin{longtable}[]{@{}lccc@{}}
\toprule
\endhead
& \(y\) & \(x_1\) & \(x_2\) \\
\(y\) & 1.00 & & \\
\(x_1\) & 0.70 & 1.00 & \\
\(x_2\) & 0.65 & 0.50 & 1.00 \\
\bottomrule
\end{longtable}

Esprimendo le tre correlazioni nei termini dei coefficienti del path diagram otteniamo:

\begin{equation} 
\begin{cases} 
r_{x_1x_2} &= 0.50\\ 
r_{yx_2} &= \beta_{yx_2} + 0.50 \beta_{yx_1} = 0.65\\ 
r_{x_1y} &= \beta_{yx_1} +   0.50 \beta_{yx_2} = 0.70
\end{cases}
\end{equation}

Risolvendo il sistema di equazioni simultanee, si ottengono i valori dei coefficienti di percorso:

\begin{equation}
\begin{aligned}
\beta_{yx_1} &= 0.50\notag\\ 
\beta_{yx_2} &= 0.40\notag
\end{aligned}
\end{equation}

\hypertarget{path-analysis-e-software}{%
\section{Path analysis e software}\label{path-analysis-e-software}}

Vengono simulate 100 osservazioni su tre variabili. Imponendo un effetto causale diretto delle variabili \(x_1\) e \(x_2\) sulla \(y\) e una correlazione \(> 0\) tra le variabili \(x_1\) e \(x_2\), otteniamo i seguenti dati:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{3}\NormalTok{)}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{100}
\NormalTok{x1 }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{100}\NormalTok{, }\DecValTok{9}\NormalTok{)}
\NormalTok{x2 }\OtherTok{\textless{}{-}}\NormalTok{ x1 }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{0}\NormalTok{, }\DecValTok{10}\NormalTok{)}
\FunctionTok{cor}\NormalTok{(x1, x2)}
\CommentTok{\#\textgreater{} [1] 0.5346}
\NormalTok{y }\OtherTok{\textless{}{-}} \DecValTok{10} \SpecialCharTok{+} \DecValTok{3} \SpecialCharTok{*}\NormalTok{ x1 }\SpecialCharTok{+} \FloatTok{1.5} \SpecialCharTok{*}\NormalTok{ x2 }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{0}\NormalTok{, }\DecValTok{15}\NormalTok{)}
\NormalTok{dd }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(y, x1, x2)}
\FunctionTok{print}\NormalTok{(}\FunctionTok{cor}\NormalTok{(dd), }\DecValTok{3}\NormalTok{)}
\CommentTok{\#\textgreater{}        y    x1    x2}
\CommentTok{\#\textgreater{} y  1.000 0.831 0.786}
\CommentTok{\#\textgreater{} x1 0.831 1.000 0.535}
\CommentTok{\#\textgreater{} x2 0.786 0.535 1.000}
\NormalTok{lower }\OtherTok{\textless{}{-}} \StringTok{"}
\StringTok{ 1}
\StringTok{ .831 1}
\StringTok{ .786 .535 1}
\StringTok{"}
\FunctionTok{library}\NormalTok{(}\StringTok{"lavaan"}\NormalTok{)}
\NormalTok{dat.cov }\OtherTok{\textless{}{-}} \FunctionTok{getCov}\NormalTok{(lower, }\AttributeTok{names =} \FunctionTok{c}\NormalTok{(}\StringTok{"y"}\NormalTok{, }\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{))}
\NormalTok{dat.cov}
\CommentTok{\#\textgreater{}        y    x1    x2}
\CommentTok{\#\textgreater{} y  1.000 0.831 0.786}
\CommentTok{\#\textgreater{} x1 0.831 1.000 0.535}
\CommentTok{\#\textgreater{} x2 0.786 0.535 1.000}
\end{Highlighting}
\end{Shaded}

Data una matrice di correlazioni e data la specificazione delle relazioni tra le variabili, la funzione \texttt{sem()} contenuta nel pacchetto \texttt{lavaan} consente di stimare i coefficienti di percorso. Le relazioni tra le variabili sono speficicate con la sintassi descritta nel manuale.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# the model}
\NormalTok{mr.model }\OtherTok{\textless{}{-}} \StringTok{"y \textasciitilde{} x1 + x2"}
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{sem}\NormalTok{(mr.model, }\AttributeTok{sample.cov =}\NormalTok{ dat.cov, }\AttributeTok{sample.nobs =}\NormalTok{ n)}
\FunctionTok{summary}\NormalTok{(fit, }\AttributeTok{standardized =} \ConstantTok{TRUE}\NormalTok{)}
\CommentTok{\#\textgreater{} lavaan 0.6{-}10 ended normally after 1 iterations}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}   Estimator                                         ML}
\CommentTok{\#\textgreater{}   Optimization method                           NLMINB}
\CommentTok{\#\textgreater{}   Number of model parameters                         3}
\CommentTok{\#\textgreater{}                                                       }
\CommentTok{\#\textgreater{}   Number of observations                           100}
\CommentTok{\#\textgreater{}                                                       }
\CommentTok{\#\textgreater{} Model Test User Model:}
\CommentTok{\#\textgreater{}                                                       }
\CommentTok{\#\textgreater{}   Test statistic                                 0.000}
\CommentTok{\#\textgreater{}   Degrees of freedom                                 0}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Parameter Estimates:}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}   Standard errors                             Standard}
\CommentTok{\#\textgreater{}   Information                                 Expected}
\CommentTok{\#\textgreater{}   Information saturated (h1) model          Structured}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Regressions:}
\CommentTok{\#\textgreater{}                    Estimate  Std.Err  z{-}value  P(\textgreater{}|z|)}
\CommentTok{\#\textgreater{}   y \textasciitilde{}                                                 }
\CommentTok{\#\textgreater{}     x1                0.575    0.045   12.710    0.000}
\CommentTok{\#\textgreater{}     x2                0.478    0.045   10.571    0.000}
\CommentTok{\#\textgreater{}    Std.lv  Std.all}
\CommentTok{\#\textgreater{}                   }
\CommentTok{\#\textgreater{}     0.575    0.575}
\CommentTok{\#\textgreater{}     0.478    0.478}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Variances:}
\CommentTok{\#\textgreater{}                    Estimate  Std.Err  z{-}value  P(\textgreater{}|z|)}
\CommentTok{\#\textgreater{}    .y                 0.145    0.020    7.071    0.000}
\CommentTok{\#\textgreater{}    Std.lv  Std.all}
\CommentTok{\#\textgreater{}     0.145    0.146}
\FunctionTok{summary}\NormalTok{(}\FunctionTok{lm}\NormalTok{(}\FunctionTok{scale}\NormalTok{(y) }\SpecialCharTok{\textasciitilde{}} \FunctionTok{scale}\NormalTok{(x1) }\SpecialCharTok{+} \FunctionTok{scale}\NormalTok{(x2)))}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Call:}
\CommentTok{\#\textgreater{} lm(formula = scale(y) \textasciitilde{} scale(x1) + scale(x2))}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Residuals:}
\CommentTok{\#\textgreater{}     Min      1Q  Median      3Q     Max }
\CommentTok{\#\textgreater{} {-}0.8720 {-}0.2462  0.0163  0.2571  0.9038 }
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Coefficients:}
\CommentTok{\#\textgreater{}              Estimate Std. Error t value Pr(\textgreater{}|t|)    }
\CommentTok{\#\textgreater{} (Intercept) {-}7.47e{-}16   3.87e{-}02     0.0        1    }
\CommentTok{\#\textgreater{} scale(x1)    5.75e{-}01   4.60e{-}02    12.5   \textless{}2e{-}16 ***}
\CommentTok{\#\textgreater{} scale(x2)    4.79e{-}01   4.60e{-}02    10.4   \textless{}2e{-}16 ***}
\CommentTok{\#\textgreater{} {-}{-}{-}}
\CommentTok{\#\textgreater{} Signif. codes:  }
\CommentTok{\#\textgreater{} 0 \textquotesingle{}***\textquotesingle{} 0.001 \textquotesingle{}**\textquotesingle{} 0.01 \textquotesingle{}*\textquotesingle{} 0.05 \textquotesingle{}.\textquotesingle{} 0.1 \textquotesingle{} \textquotesingle{} 1}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Residual standard error: 0.387 on 97 degrees of freedom}
\CommentTok{\#\textgreater{} Multiple R{-}squared:  0.853,  Adjusted R{-}squared:  0.85 }
\CommentTok{\#\textgreater{} F{-}statistic:  283 on 2 and 97 DF,  p{-}value: \textless{}2e{-}16}
\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ .}\DecValTok{145}
\CommentTok{\#\textgreater{} [1] 0.855}
\end{Highlighting}
\end{Shaded}

Consideriamo nuovamente la seguente matrice di correlazioni:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lower }\OtherTok{\textless{}{-}} \StringTok{"}
\StringTok{  1}
\StringTok{  .70 1}
\StringTok{  .65 .50 1}
\StringTok{"}
\end{Highlighting}
\end{Shaded}

Converto tali dati in una matrice simmetrica.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dat.cov }\OtherTok{\textless{}{-}} \FunctionTok{getCov}\NormalTok{(lower, }\AttributeTok{names =} \FunctionTok{c}\NormalTok{(}\StringTok{"y"}\NormalTok{, }\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{))}
\NormalTok{dat.cov}
\CommentTok{\#\textgreater{}       y  x1   x2}
\CommentTok{\#\textgreater{} y  1.00 0.7 0.65}
\CommentTok{\#\textgreater{} x1 0.70 1.0 0.50}
\CommentTok{\#\textgreater{} x2 0.65 0.5 1.00}
\end{Highlighting}
\end{Shaded}

Specifico il modello:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mr\_model }\OtherTok{\textless{}{-}} \StringTok{"y \textasciitilde{} x1 + x2"}
\end{Highlighting}
\end{Shaded}

Adatto il modello ai dati:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{sem}\NormalTok{(mr\_model, }\AttributeTok{sample.cov =}\NormalTok{ dat.cov, }\AttributeTok{sample.nobs =}\NormalTok{ n)}
\end{Highlighting}
\end{Shaded}

Esamino i risultati:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(fit, }\AttributeTok{standardized =} \ConstantTok{TRUE}\NormalTok{)}
\CommentTok{\#\textgreater{} lavaan 0.6{-}10 ended normally after 1 iterations}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}   Estimator                                         ML}
\CommentTok{\#\textgreater{}   Optimization method                           NLMINB}
\CommentTok{\#\textgreater{}   Number of model parameters                         3}
\CommentTok{\#\textgreater{}                                                       }
\CommentTok{\#\textgreater{}   Number of observations                           100}
\CommentTok{\#\textgreater{}                                                       }
\CommentTok{\#\textgreater{} Model Test User Model:}
\CommentTok{\#\textgreater{}                                                       }
\CommentTok{\#\textgreater{}   Test statistic                                 0.000}
\CommentTok{\#\textgreater{}   Degrees of freedom                                 0}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Parameter Estimates:}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}   Standard errors                             Standard}
\CommentTok{\#\textgreater{}   Information                                 Expected}
\CommentTok{\#\textgreater{}   Information saturated (h1) model          Structured}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Regressions:}
\CommentTok{\#\textgreater{}                    Estimate  Std.Err  z{-}value  P(\textgreater{}|z|)}
\CommentTok{\#\textgreater{}   y \textasciitilde{}                                                 }
\CommentTok{\#\textgreater{}     x1                0.500    0.072    6.934    0.000}
\CommentTok{\#\textgreater{}     x2                0.400    0.072    5.547    0.000}
\CommentTok{\#\textgreater{}    Std.lv  Std.all}
\CommentTok{\#\textgreater{}                   }
\CommentTok{\#\textgreater{}     0.500    0.500}
\CommentTok{\#\textgreater{}     0.400    0.400}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Variances:}
\CommentTok{\#\textgreater{}                    Estimate  Std.Err  z{-}value  P(\textgreater{}|z|)}
\CommentTok{\#\textgreater{}    .y                 0.386    0.055    7.071    0.000}
\CommentTok{\#\textgreater{}    Std.lv  Std.all}
\CommentTok{\#\textgreater{}     0.386    0.390}
\end{Highlighting}
\end{Shaded}

Con la funzione \texttt{sem()} del pacchetto \texttt{lavaan} abbiamo dunque replicato i risultati ottenuti in precedenza. Il valore \(0.386\) rappresenta la quota di varianza della \(y\) non spiegata dalle variabili esogene.

\hypertarget{oltre-la-regressione-multipla}{%
\section{Oltre la regressione multipla}\label{oltre-la-regressione-multipla}}

In generale, lo psicologo ha a che fare con diagrammi di percorso nei quali sono presenti variabili non osservabili (latenti) e quindi l'approccio della regressione multipla non può essere applicato. È necessario invece descrivere il diagramma di percorso mediante un insieme di equazioni strutturali, definendo un numero di equazioni almeno altrettanto grande quanto il numero delle incognite. Tale soluzione viene solitamente fornita da un software. Consideriamo di seguito alcuni esempi in cui vengono applicate le regole di Wright per diagrammi di percorso che non possono essere descritti nei termini di un modello di regressione multipla. Un esempio di path diagram che non si riduce al modello di regressione multipla è quello fornito nella Figura \ref{fig:path01}.

La path analysis è anche usata in quel campo della psicologia interessato alla misurazione dei costrutti psicologici quali i tratti della personalità, le capacità cognitive e i disturbi psicopatologici. Questa è la ragione per cui la discutiamo qui.

\hypertarget{ch:cronbach}{%
\chapter{Attendibilità e modello fattoriale}\label{ch:cronbach}}

McDonald (2013) mostra come la teoria classica dei test possa essere messa in relazione con il modello dell'analisi fattoriale. La figura \ref{fig:factmod1} descrive nei termini del modello fattoriale la relazione che intercorre tra i punteggi \(Y\) ottenuti dalla somministrazione di un test con cinque item e i punteggi veri.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{images/factmod1} 

}

\caption{Modello fattoriale che mette in relazione i punteggi osservati e i punteggi veri.}\label{fig:factmod1}
\end{figure}

Il metodo delle forme parallele proposto dalla teoria classica dei test fornisce una risposta solo in parte soddisfacente al problema della stima del coefficiente di attendibilità. Ricordiamo che il metodo delle forme parallele consiste nel somministrare due questionari \(X\) e \(X^\prime\), espressione dello stesso costrutto, nella stessa occasione allo stesso campione di soggetti. In tali circostanze \(\rho^2_{XT} = \rho_{XX^\prime}\). Affinché la relazione definita dall'equazione precedente sia vera, le due forme del test devono essere parallele, nel senso descritto della teoria classica dei test. In pratica, però, è impossibile somministrare lo stesso test due volte agli stessi rispondenti \emph{nelle medesime condizioni}. È dunque necessario basare la stima del coefficiente di attendibilità sui dati acquisiti mediante un'unica somministrazione del test.

Vi sono vari metodi per la stima dell'attendibilità nel caso di un'unica somministrazione di un test. Considereremo qui tre metodi che possono essere applicati mediante l'utilizzo dell'analisi fattoriale: l'\(\alpha\) di Cronbach, l'\(\omega\) di McDonald e il metodo di Spearman-Brown. Il coefficiente \(\alpha\) è la misura più utilizzata per la stima dell'attendibilità quale coerenza interna, o omogeneità. Vedremo come tale indice costituisca il limite inferiore dell'attendibilità di un test, se alcune assunzioni sono soddisfatte, mentre risulta uno stimatore distorto dell'attendibilità se le assunzioni che descriveremo risultano violate.

Per discutere i diversi metodi di stima dell'attendibilità quale coerenza interna è prima necessario distinguere tra tre diverse forme che il modello mono-fattoriale può assumere. Queste tre forme sono quelle del modello con indicatori congenerici, \(\tau\)-equivalenti e paralleli.

\hypertarget{modello-fattoriale-e-ctt}{%
\section{Modello fattoriale e CTT}\label{modello-fattoriale-e-ctt}}

Sia \(X_1, X_2, \dots, X_p\), con \(p>2\), un insieme di item osservati. I punteggi ottenuti su tali item sono costituiti da una componente di punteggio vero e da una componente d'errore:

\begin{equation}
\begin{aligned}
X_1 &=T_1+E_1,\notag\\ 
X_2 &=T_2+E_2,\notag\\ 
&\dots\notag\\ 
X_p &=T_p+E_p.\notag
\end{aligned}
\end{equation}

Seguendo McDonald (1999), tale scomposizione in una componente vera e in una componente d'errore può essere espressa nei termini dei parametri del modello fattoriale. L'espressione \(X_i = T_i + E_i\) può infatti essere riscritta come

\[
X_i = \lambda_i \xi + \delta_i, \quad{i=1, \dots, p},
\]

dove \(X_i\) denota il punteggio osservato per l'item \(i\)-esimo, \(\lambda_i\) è il peso fattoriale \(i\)-esimo, \(\xi\) è il fattore comune e \(\delta_i\) è la componente erratica del punteggio osservato \(i\)-esimo. Valgono le assunzioni del modello monofattoriale. Ovvero, si assume che \(\xi\) e \(\delta_i\) siano incorrelati per ciascun item \(i\)-esimo e che \(\delta_i\) e \(\delta_k\) siano incorrelati per ciascuna coppia \(i \neq k\).

\hypertarget{classi-di-modelli}{%
\section{Classi di modelli}\label{classi-di-modelli}}

Si possono distinguere tre importanti casi del modello mono-fattoriale:

\begin{itemize}
\tightlist
\item
  il modello con indicatori congenerici,
\item
  il modello con indicatori \(\tau\)-equivalenti,
\item
  il modello con indicatori paralleli.
\end{itemize}

Il modello con indicatori congenerici rappresenta il caso più generale, mentre gli indicatori \(\tau\)-equivalenti e paralleli sono casi particolari, ovvero impongono restrizioni al modello con indicatori congenerici.

\hypertarget{indicatori-congenerici}{%
\subsection{Indicatori congenerici}\label{indicatori-congenerici}}

Indicatori \emph{congenerici} misurano lo stesso costrutto, ma non necessariamente nella stessa misura. Nel caso di indicatori congenerici, nel modello mono-fattoriale non viene imposto alcun vincolo né sulle saturazioni fattoriali né sulle specificità:

\[
\lambda_1\neq \lambda_2 \neq \dots\neq \lambda_p,
\]

\[
\psi_{11}\neq \psi_{22} \neq \dots\neq \psi_{pp}.
\]

Il modello mono-fattoriale con indicatori congenerici è dunque

\begin{equation}
X_i = \lambda_i \xi + \delta_i.
\label{eq:mod-tau-eq}
\end{equation}

Dalle assunzioni precedenti possiamo derivare la matrice \(\boldsymbol{\Sigma}\) riprodotta in base al modello congenerico la quale risulta essere uguale a

\[
\boldsymbol{\Sigma}=\left[
      \begin{array}{ c c c c }
        \sigma_{11} & \sigma_{12} & \dots & \sigma_{1p}, \\
        \sigma_{21} & \sigma_{22} & \dots & \sigma_{2p}. \\
        \vdots & \vdots & & \vdots\\
        \sigma_{p1} & \sigma_{p2} & \dots & \sigma_{pp} 
      \end{array} 
    \right].
\]

Si noti come tutte le varianze e tutte le covarianze siano tra loro diverse.

\hypertarget{indicatori-tau-equivalenti}{%
\subsection{Indicatori tau-equivalenti}\label{indicatori-tau-equivalenti}}

Nel caso di indicatori \(\tau\)-equivalenti, si ha che

\[
\lambda_1=\lambda_2=\dots=\lambda_p=\lambda,
\]

\[
\psi_{11}\neq \psi_{22} \neq \dots\neq \psi_{pp}.
\]

Il modello monofattoriale con indicatori \(\tau\)-equivalenti diventa dunque

\begin{equation}
X_i = \lambda \xi + \delta_i, 
\label{eq:mod-tau-eq}
\end{equation}

ovvero

\begin{equation}
X_i = \tau + \delta_i,
\label{eq:mod-tau-eq-b}
\end{equation}

dove \(\tau=\lambda \xi\) è l'attributo comune scalato nell'unità di misura dell'indicatore. Secondo il modello \eqref{eq:mod-tau-eq}, tutte le \(p(p-1)\) covarianze tra gli item del test devono essere uguali, ovvero

\begin{equation}
\sigma_{ik} = \lambda^2=\sigma^2_T,
\label{eq:cov-tau-eq}
\end{equation}

per \(i\neq k\). Gli elementi sulla diagonale principale della matrice di varianze e covarianze saranno invece

\begin{equation}
\sigma_{ii} = \lambda^2 + \psi_{ii} =\sigma^2_T + \psi_{ii}.
\label{eq:var-tau}
\end{equation}

La matrice \(\boldsymbol{\Sigma}\) riprodotta in base al modello \(\tau\)-equivalente è dunque uguale a

\begin{equation}
\boldsymbol{\Sigma}=\left[
      \begin{array}{ c c c c }
        \sigma_{T}^2 + \psi_{11} & \sigma_{T}^2 & \dots & \sigma_{T}^2 \\
        \sigma_{T}^2 & \sigma_{T}^2 + \psi_{22} & \dots & \sigma_{T}^2 \\
        \vdots & \vdots & & \vdots\\
        \sigma_{T}^2 & \sigma_{T}^2 & \dots & \sigma_{T}^2 + \psi_{pp} 
      \end{array} 
    \right].
\label{eq:sigma-tau-eq}
\end{equation}

Tutte le covarianze sono uguali, mentre le varianze sono tra loro diverse.

\hypertarget{indicatori-paralleli}{%
\subsection{Indicatori paralleli}\label{indicatori-paralleli}}

Nel caso di indicatori paralleli si ha che

\[
\lambda_1=\lambda_2=\dots=\lambda_p=\lambda,
\] \[
\psi_{11}=\psi_{22}=\dots=\psi_{pp}=\psi.
\]

Il modello costituito da indicatori paralleli impone dunque un'ulteriore restrizione che riguarda le varianze degli item, ovvero:

\[
\sigma_{ii} = \lambda^2 + \psi =\sigma^2_T + \sigma^2.
\]

La struttura di varianze e covarianze imposta dal modello per indicatori paralleli è dunque tale da richiedere l'uguaglianza tra tutte le covarianze tra gli item e l'uguaglianza tra tutte le varianze degli item. La matrice \(\boldsymbol{\Sigma}\) riprodotta in base al modello con indicatori paralleli è dunque uguale a

\[
\boldsymbol{\Sigma}=\left[
      \begin{array}{ c c c c }
        \sigma_{T}^2 + \sigma^2 & \sigma_{T}^2 & \dots & \sigma_{T}^2 \\
        \sigma_{T}^2 & \sigma_{T}^2 + \sigma^2 & \dots & \sigma_{T}^2 \\
        \vdots & \vdots & & \vdots\\
        \sigma_{T}^2 & \sigma_{T}^2 & \dots & \sigma_{T}^2 +\sigma^2 \notag
      \end{array} 
    \right].
\]

\hypertarget{indicatori-strettamente-paralleli}{%
\subsection{Indicatori strettamente paralleli}\label{indicatori-strettamente-paralleli}}

L'aggiunta di un ulteriore vincolo a quelli definiti dal modello costituito da indicatori paralleli, ovvero quello dell'eguaglianza delle medie, definisce gli indicatori detti \emph{strettamente paralleli} (McDonald, 1999).

\hypertarget{metodo-dei-minimi-quadrati-non-pesati}{%
\section{Metodo dei minimi quadrati non pesati}\label{metodo-dei-minimi-quadrati-non-pesati}}

Nel modello uni-fattoriale, la varianza di ciascun indicatore viene scomposta nella somma di due componenti: la componente \(\sigma^2_T\) dovuta all'effetto del fattore latente comune e la componente \(\psi\) dovuta all'effetto del fattore specifico. McDonald (2013) illustra come sia possibile stimare tali componenti dai dati osservati. Tali stime vengono poi utilizzate per calcolare la coerenza interna del test tramite le formule degli indici \(\alpha\) di Cronbach e \(\omega\) di McDonald.

In precedenza abbiamo visto come la varianza del punteggio vero sia uguale alla covarianza tra due forme parallele dello stesso test: \(\sigma^2_T = \sigma_{XX^\prime}\). Se gli indicatori sono \(\tau\)-equivalenti, la matrice la matrice \(\boldsymbol{\Sigma}\) riprodotta dal modello è uguale a

\[
\boldsymbol{\Sigma}=\left[
      \begin{array}{ c c c c }
        \sigma_{T}^2 + \psi_{11} & \sigma_{T}^2 & \dots & \sigma_{T}^2 \\
        \sigma_{T}^2 & \sigma_{T}^2 + \psi_{22} & \dots & \sigma_{T}^2 \\
        \vdots & \vdots & & \vdots\\
        \sigma_{T}^2 & \sigma_{T}^2 & \dots & \sigma_{T}^2 + \psi_{pp} \notag
      \end{array}
    \right],
\]

ovvero, tutte le covarianze sono tra loro uguali. Nel caso di indicatori \(\tau\)-equivalenti, dunque, una stima \(\hat{\sigma}^2_T\) di \(\sigma^2_T\) è data dalla media delle covarianze della matrice \textbf{S}:

\begin{equation}
\hat{\sigma}_T^2 = \frac{1}{p(p-1)} \sideset{}{} {\sum \sum}_{i \neq k} s_{ik}.
\label{eq:sigma-t}
\end{equation}

Tale medoto di stima di \(\sigma^2_T\) viene chiamato ``metodo dei minimi quadrati non pesati'' (McDonald, 2013).

Inoltre, nel caso di indicatori \(\tau\)-equivalenti, la stima di \(\psi_{ii}\) nella \eqref{eq:var-tau} è data da

\[
\hat{\psi}_{ii }= s_{ii} - \hat{\sigma}_T^2,
\]

per ciascun item.

Nel caso di \emph{indicatori paralleli}, la stima di \(\sigma^2_T\) è ancora data dalla \eqref{eq:sigma-t}, ovvero dalla media delle covarianze della matrice \(\boldsymbol{\Sigma}\). La stima del valore costante \(\psi\) è invece data da

\begin{equation}
\hat{\psi} = \frac{1}{p} \sum_i (s_{ii} - \hat{\sigma}_T^2)
\label{eq:psi-par-st}
\end{equation}

\hypertarget{varianza-del-punteggio-totale-di-un-test}{%
\section{Varianza del punteggio totale di un test}\label{varianza-del-punteggio-totale-di-un-test}}

Il punteggio totale \(Y\) di un test omogeneo è uguale alla somma dei punteggi \(X_i\) sui \(p\) item di cui è composto il test: \(Y = \sum_{i=1}^p X_i.\) Poniamoci ora il problema di descrivere la varianza del punteggio totale del test nei termini dei parametri del modello uni-fattoriale. Nel caso di un modello congenerico ad un fattore comune, la varianza del punteggio totale \(Y\) del test può essere scomposta in due componenti: il quadrato della somma delle saturazioni fattoriali, corrispondentente alla varianza attribuibile al punteggio vero (ovvero la quota di varianza derivante dall'attributo di cui gli item sono indicatori) e la somma delle varianze specifiche dei \(p\) indicatori, corrispondente alla varianza degli errori della misura del punteggio totale del test, ovvero

\begin{equation}
 \V(Y) = \left( \sum_i \lambda_i\right)^2 + \sum_i \psi_{ii}
  \label{eq:var-y}
\end{equation}

\begin{proof}
Per un modello congenerico, la varianza del punteggio totale \(Y\) è uguale a:

\begin{equation}
\begin{aligned}
  \V(Y) &= \V\left[ \sum_i  \left(\lambda_i \xi + \delta_i\right)  \right]\notag\\
  &= \V\left[  (\lambda_1 \xi + \delta_1) + (\lambda_2 \xi + \delta_2) + \dots +  (\lambda_p \xi + \delta_p)  \right]\notag\\
  &= \V\left[ \left( \sum_i \lambda_i\right) \xi + \sum_i \delta_i\right]\notag\\
  &=  \left(\sum_i \lambda_i\right)^2 \underbrace{\V(\xi)}_{=1} +  \sum_i  \V(\delta_i)\notag\\
  &= \left(\sum_i \lambda_i\right)^2 + \sum_i \psi_{ii}.\notag
\end{aligned}
\end{equation}
\end{proof}

\hypertarget{stima-dellattendibilituxe0}{%
\section{Stima dell'attendibilità}\label{stima-dellattendibilituxe0}}

\hypertarget{coefficiente-omega}{%
\subsection{Coefficiente omega}\label{coefficiente-omega}}

Avendo scomposto la varianza del punteggio totale di un test come indicato nella \eqref{eq:var-y}

\[
\V(Y) = \left( \sum_i \lambda_i\right)^2 + \sum_i \psi_{ii}.
\]

McDonald (1999) definisce il coefficiente di attendibilità \(\omega\) come il rapporto tra la varianza ``vera'' (attribuibile all'attributo comune) e la varianza totale. Nei termini dei parametri del modello uni-fattoriale, il coefficiente \(\omega\) diventa:

\begin{equation}
\begin{aligned}
\omega &= \frac{\left( \sum_{i=1}^p \lambda_i \right)^2}{\sigma_Y^2} \notag\\
&= \frac{\left( \sum_{i=1}^p \lambda_i \right)^2}{\left( \sum_{i=1}^p \lambda_i \right)^2  + \sum_{i=1}^p \psi_{ii}}
\end{aligned}
\label{eq:omega}
\end{equation}

Il coefficiente \(\omega\) consente dunque di stimare il coefficiente di attendibilità nei termini dei parametri del modello fattoriale congenerico, utilizzando i dati ottenuti in un'unica somministrazione del test.

\hypertarget{un-esempio-concreto}{%
\subsubsection{Un esempio concreto}\label{un-esempio-concreto}}

Per illustrare la procedura per il calcolo del coefficiente \(\omega\), McDonald (1999) utilizza i dati derivanti dalla somministrazione del test \emph{Satisfaction With Life Scale} (SWLS) a 215 rispondenti. Tale test è costituito da 14 item ma, per semplificare la discussione, McDonald ne utilizza solo 5.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{SWLS }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}
  \FunctionTok{c}\NormalTok{(}
    \FloatTok{2.565}\NormalTok{, }\FloatTok{1.424}\NormalTok{, }\FloatTok{1.481}\NormalTok{, }\FloatTok{1.328}\NormalTok{, }\FloatTok{1.529}\NormalTok{,}
    \FloatTok{1.424}\NormalTok{, }\FloatTok{2.493}\NormalTok{, }\FloatTok{1.267}\NormalTok{, }\FloatTok{1.051}\NormalTok{, }\FloatTok{1.308}\NormalTok{,}
    \FloatTok{1.481}\NormalTok{, }\FloatTok{1.267}\NormalTok{, }\FloatTok{2.462}\NormalTok{, }\FloatTok{1.093}\NormalTok{, }\FloatTok{1.360}\NormalTok{,}
    \FloatTok{1.328}\NormalTok{, }\FloatTok{1.051}\NormalTok{, }\FloatTok{1.093}\NormalTok{, }\FloatTok{2.769}\NormalTok{, }\FloatTok{1.128}\NormalTok{,}
    \FloatTok{1.529}\NormalTok{, }\FloatTok{1.308}\NormalTok{, }\FloatTok{1.360}\NormalTok{, }\FloatTok{1.128}\NormalTok{, }\FloatTok{3.355}
\NormalTok{  ),}
  \AttributeTok{ncol =} \DecValTok{5}\NormalTok{, }\AttributeTok{byrow =} \ConstantTok{TRUE}
\NormalTok{)}
\NormalTok{SWLS}
\CommentTok{\#\textgreater{}       [,1]  [,2]  [,3]  [,4]  [,5]}
\CommentTok{\#\textgreater{} [1,] 2.565 1.424 1.481 1.328 1.529}
\CommentTok{\#\textgreater{} [2,] 1.424 2.493 1.267 1.051 1.308}
\CommentTok{\#\textgreater{} [3,] 1.481 1.267 2.462 1.093 1.360}
\CommentTok{\#\textgreater{} [4,] 1.328 1.051 1.093 2.769 1.128}
\CommentTok{\#\textgreater{} [5,] 1.529 1.308 1.360 1.128 3.355}
\end{Highlighting}
\end{Shaded}

Eseguiamo l'analisi fattoriale con il metodo della massima verosimiglianza:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fa }\OtherTok{\textless{}{-}} \FunctionTok{factanal}\NormalTok{(}\AttributeTok{covmat =}\NormalTok{ SWLS, }\AttributeTok{factors =} \DecValTok{1}\NormalTok{, }\AttributeTok{n.obs =} \DecValTok{215}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Le saturazioni fattoriali sono:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fa}\SpecialCharTok{$}\NormalTok{load}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Loadings:}
\CommentTok{\#\textgreater{}      Factor1}
\CommentTok{\#\textgreater{} [1,] 0.817  }
\CommentTok{\#\textgreater{} [2,] 0.694  }
\CommentTok{\#\textgreater{} [3,] 0.726  }
\CommentTok{\#\textgreater{} [4,] 0.591  }
\CommentTok{\#\textgreater{} [5,] 0.643  }
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}                Factor1}
\CommentTok{\#\textgreater{} SS loadings      2.438}
\CommentTok{\#\textgreater{} Proportion Var   0.488}
\end{Highlighting}
\end{Shaded}

Le specificità sono uguali a

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fa}\SpecialCharTok{$}\NormalTok{uniq}
\CommentTok{\#\textgreater{} [1] 0.3330 0.5182 0.4732 0.6512 0.5867}
\end{Highlighting}
\end{Shaded}

Il coefficiente \(\omega\)

\[
\omega = \frac{\left( \sum_{i=1}^p \lambda_i \right)^2}{\left( \sum_{i=1}^p \lambda_i \right)^2  + \sum_{i=1}^p \psi_{ii}}
\]

può essere calcolato nel modo seguente:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\FunctionTok{sum}\NormalTok{(fa}\SpecialCharTok{$}\NormalTok{load))}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{/}\NormalTok{ (}\FunctionTok{sum}\NormalTok{((fa}\SpecialCharTok{$}\NormalTok{load))}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{+} \FunctionTok{sum}\NormalTok{(fa}\SpecialCharTok{$}\NormalTok{uniq))}
\CommentTok{\#\textgreater{} [1] 0.8245}
\end{Highlighting}
\end{Shaded}

Nel caso presente, il coefficiente di attendibilità \(\omega=0.82\) ci dice che l'\(82\)\% della varianza del punteggio totale \(Y\) del test viene spiegato dal fattore comune latente.

\hypertarget{coefficiente-omega-e-assunzioni-della-teoria-classica-dei-test}{%
\subsubsection{\texorpdfstring{Coefficiente \(\omega\) e assunzioni della teoria classica dei test}{Coefficiente \textbackslash omega e assunzioni della teoria classica dei test}}\label{coefficiente-omega-e-assunzioni-della-teoria-classica-dei-test}}

Il calcolo di \(\omega\) è basato sull'assunzione (tipica della teoria classica dei test) che \(\psi_{ik}=0\) per \(i\neq k\). Tale assunzione però potrebbe non essere soddisfatta nel caso di dati empirici. In tal caso, come indicato da Bollen (1980), la \eqref{eq:omega} diventa

\begin{equation}
 \omega = \frac{\left( \sum_{i=1}^p \lambda_i \right)^2}{\left( \sum_{i=1}^p \lambda_i \right)^2  + \sum_{i=1}^p \psi_{ii} + \sum_{i, k, i\neq k}^p \psi_{ik}}.
 \label{eq:omega2}
 \end{equation}

L'appropriatezza dell'assunzione dell'incorrelazione dei fattori specifici può essere verificata mediante un'analisi fattoriale confermativa. Se vi sono molte coppie di fattori specifici correlati, allora può essere necessario introdurre nel modello dei fattori aggiuntivi che rendano conto di queste covarianze. In questo caso, la scala non sarà più unidimensionale: la presenza di più fattori indica la presenza di più sottoscale. Il problema presentato sopra, tuttavia, non sempre può essere risolto individuando delle sottoscale perché, anche in tal caso, possono rimanere delle covarianze tra i fattori specifici che non sono spiegate dai fattori che individuano le sottoscale. In questi casi, per calcolare \(\omega\) sarà necessario utilizzare la \eqref{eq:omega2}.

McDonald (1999) attribuisce al coefficiente \(\omega\) le seguenti interpretazioni: \(\omega\) è uguale al quadrato della correlazione tra la \(Y\) e il fattore comune \(\xi\) o, in maniera equivalente, tra la \(Y\) e il punteggio vero (in base alla definizione di attendibilità: \(\rho_{XT}^2=\sigma^2_{\tau}/\sigma^2_X\)); \(\omega\) è uguale alla correlazione tra due test \(Y\) e \(Y'\) aventi la stessa somma (o media) delle saturazioni nel modello ad un fattore e la stessa somma (o media) delle varianze specifiche nel modello ad un fattore; \(\omega\) è uguale al quadrato della correlazione tra il punteggio totale di \(p\) item e il punteggio medio di un insieme infinito di item di un dominio omogeneo di cui i \(p\) item costituisciono un sottoinsieme.

\hypertarget{coefficiente-alpha-di-cronbach}{%
\subsection{\texorpdfstring{Coefficiente \(\alpha\) di Cronbach}{Coefficiente \textbackslash alpha di Cronbach}}\label{coefficiente-alpha-di-cronbach}}

Il coefficiente \(\omega\) consente di stimare il coefficiente di attendibilità nel caso di un modello monofattoriale congenerico. Invece, il coefficiente \(\alpha\) fornisce una stima del coefficiente di attendibilità nel caso di un modello con indicatori \(\tau\)-equivalenti.

Se \(p\) item soddisfano il modello di \(\tau\)-equivalenza, la varianza di ciascun item può essere scomposta in una componente attribuibile al valore vero e in una componente d'errore, come indicato nella \eqref{eq:var-tau}, ovvero, \(\sigma_{ii} = \lambda^2 + \psi_{ii} =\sigma^2_T + \sigma^2_i\). In base al principio di \(\tau\)-equivalenza, le varianze e covarianze riprodotte dal modello uni-fattoriale hanno le caratteristiche descritte nella matrice \eqref{eq:sigma-tau-eq}. Dato che tutti gli item hanno la stessa saturazione fattoriale \(\lambda\), la formula per il calcolo del coefficiente \(\omega\) si riduce a

\[
\omega = \frac{\left( \sum_i \lambda_i \right)^2}{\left( \sum_i
    \lambda_i \right)^2  + \sum_i \psi_{ii}} = \frac{p^2 \lambda^2}{\sigma^2_Y} = \frac{p^2 \sigma_T^2}{\sigma_Y^2}
\]

dove \(Y\) è il punteggio totale del test.

Usando il metodo dei minimi quadrati non pesati, una stima di \(\omega\) può essere ottenuta nel modo seguente:

\begin{equation}
\hat{\omega} = \frac{p^2 \hat{\sigma}_T^2}{s_Y^2}
\label{eq:omega-firt-part}
\end{equation}

dove una stima di \(\sigma_T^2\) viene fornita dalla \eqref{eq:sigma-t}, ovvero

\begin{equation}
\hat{\sigma}_T^2 = \frac{1}{p(p-1)} \sideset{}{} {\sum \sum}_{i \neq k} s_{ik}
\label{eq:hat-sigma-tau2}
\end{equation}

Inserendo la \eqref{eq:hat-sigma-tau2} nella \eqref{eq:omega-firt-part}, otteniamo

\begin{equation}
\hat{\omega} = \frac{p}{p-1}\frac{\sideset{}{} {\sum \sum}_{i \neq k} s_{ik}}{s_Y^2}
\end{equation}

In conclusione, nel caso di indicatori \(\tau\)-eqivalenti, una stima del coefficiente \(\omega\) è data da

\begin{equation}
\begin{aligned}
\hat{\omega}
%&= \frac{p}{p-1}\frac{\sideset{}{} {\sum \sum}_{i \neq k} s_{ik}}{s_Y^2} \notag\\
 = \frac{p}{p-1}\left(1-\frac{\sum_i s_{ii}}{s_Y^2}\right)
\label{eq:alpha-camp}
\end{aligned}
\end{equation}

La stima dell'attendibilità fornita dalla \eqref{eq:alpha-camp} trova il suo corrispettivo per i valori della popolazione nell'equazione seguente:

\begin{equation}
\begin{aligned}
\alpha &= \frac{p}{p-1}\left(1-\frac{\sum_{i=1}^p \sigma_{ii}}{\sigma_Y^2}\right)
&= \frac{p}{p-1}\frac{\sum_{i\neq k}^p \mbox{Cov}(X_i, X_k)}{\V(Y)}
\label{eq:alpha-pop}
\end{aligned}
\end{equation}

La \eqref{eq:alpha-pop} definisce quello che è conosciuto come il coefficiente \(\alpha\).

Il coefficiente \(\alpha\) fu scoperto da Guttman nel 1945 e incorrettamente attribuito a Cronbach. Viene spesso chiamato coefficiente \(\alpha\) di Guttman-Cronbach, o G-C \(\alpha\).

Se gli indicatori soddisfano i requisiti del modello di \(\tau\)-equivalenza, i coefficienti \(\alpha\) e \(\omega\) sono uguali. Se il modello di \(\tau\)-equivalenza è appropriato, il coefficiente \(\alpha\) fornisce un limite inferiore del coefficiente \(\omega\) (ovvero, fornisce una sottostima di \(\omega\)): \(\omega \geq \alpha\). A causa del fatto che fornisce una stima conservativa del coefficiente di attendibilità, \(\alpha\) viene preferito ad \(\omega\) da alcuni ricercatori. Si noti però che \(\alpha\) possiede tale carattere conservativo solo nel caso in cui le assunzioni del modello \(\tau\)-equivalente siano soddisfatte.

\hypertarget{un-esempio-concreto-1}{%
\subsubsection{Un esempio concreto}\label{un-esempio-concreto-1}}

consideriamo nuovamente la matrice di varianze e covarianze SWLS. Il coefficiente \(\alpha\) si calcola usando la \eqref{eq:alpha-camp} e, per i dati presenti, risulta essere uguale a

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p }\OtherTok{\textless{}{-}} \DecValTok{5}
\NormalTok{alpha }\OtherTok{\textless{}{-}}\NormalTok{ (p }\SpecialCharTok{/}\NormalTok{ (p }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)) }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{tr}\NormalTok{(SWLS) }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(SWLS))}
\NormalTok{alpha}
\CommentTok{\#\textgreater{} [1] 0.8191}
\end{Highlighting}
\end{Shaded}

Lo stesso risultato si ottiene utilizzando la funzione \texttt{alpha()} contenuta nel pacchetto \texttt{psych}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{alpha}\NormalTok{(SWLS)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Reliability analysis   }
\CommentTok{\#\textgreater{} Call: alpha(x = SWLS)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}   raw\_alpha std.alpha G6(smc) average\_r S/N median\_r}
\CommentTok{\#\textgreater{}       0.82      0.82    0.79      0.48 4.6     0.49}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}     95\% confidence boundaries }
\CommentTok{\#\textgreater{}       lower alpha upper}
\CommentTok{\#\textgreater{} Feldt  0.33  0.82  0.98}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}  Reliability if an item is dropped:}
\CommentTok{\#\textgreater{}    raw\_alpha std.alpha G6(smc) average\_r S/N  var.r}
\CommentTok{\#\textgreater{} V1      0.75      0.76    0.70      0.44 3.1 0.0027}
\CommentTok{\#\textgreater{} V2      0.78      0.79    0.74      0.48 3.7 0.0060}
\CommentTok{\#\textgreater{} V3      0.78      0.78    0.73      0.47 3.5 0.0055}
\CommentTok{\#\textgreater{} V4      0.81      0.81    0.77      0.52 4.3 0.0027}
\CommentTok{\#\textgreater{} V5      0.80      0.80    0.75      0.50 3.9 0.0057}
\CommentTok{\#\textgreater{}    med.r}
\CommentTok{\#\textgreater{} V1  0.44}
\CommentTok{\#\textgreater{} V2  0.49}
\CommentTok{\#\textgreater{} V3  0.48}
\CommentTok{\#\textgreater{} V4  0.52}
\CommentTok{\#\textgreater{} V5  0.50}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}  Item statistics }
\CommentTok{\#\textgreater{}       r r.cor r.drop}
\CommentTok{\#\textgreater{} V1 0.83  0.79   0.71}
\CommentTok{\#\textgreater{} V2 0.77  0.68   0.62}
\CommentTok{\#\textgreater{} V3 0.78  0.71   0.64}
\CommentTok{\#\textgreater{} V4 0.70  0.58   0.53}
\CommentTok{\#\textgreater{} V5 0.74  0.63   0.57}
\end{Highlighting}
\end{Shaded}

\hypertarget{sec:violazione_tau}{%
\subsubsection{Violazione dell'assunto di tau-equivalenza}\label{sec:violazione_tau}}

Il coefficiente \(\alpha\), la misura di attendibilità maggiormente usata in psicometria, è basato sull'\emph{assuzione che il modello di misurazione sia \(\tau\)-equivalente}. Come indicato sopra, se tale assunzione è soddisfatta, \(\alpha\) fornisce un limite inferiore dell'attendibilità del test. Nei casi in cui tale assunzione venga violata, però, \(\alpha\) può perdere tale carattere conservativo e può fornire una \emph{sovrastima} dell'attendibilità del test (Sijtsma, 2009).

NKano e Azuma (2003) riportano i risultati di una simulazione che mette in evidenza le conseguenze che risultano dalla violazione dell'assunzione di incorrelazione tra le componenti specifiche del modello monofattoriale. Questi autori trovano che, quando il principio dell'incorrelazione dei fattori specifici è violato, allora le stime dell'attendibilità ottenute mediante il coefficiente \(\alpha\) sono affette da un errore sistematico. Tale errore sistematico aumenta all'aumentare del numero di coppie di fattori specifici che risultano tra loro correlati. In queste circostanze, dunque, il coefficiente \(\alpha\) non fornisce più una stima conservativa dell'attendibilità.

In conclusione, il coefficiente \(\omega\) fornisce una stima adeguata dell'attendibilità nel caso di un modello di misurazione congenerico. L'utilizzo del coefficiente \(\alpha\) per la stima dell'attendibilità richiede un modello di misurazione \(\tau\)-equivalente. L'esistenza di fattori specifici correlati invalida sia il coefficiente \(\alpha\), sia il coefficiente \(\omega\) calcolato in base alla \eqref{eq:omega}. In tali circostanze l'attendibilità deve essere stimata utilizzando una diversa equazione (Kano \& Azuma, 2003; Komaroff, 1997).

Questa discussione mette in evidenza un aspetto importante: il coefficiente \(\alpha\) fornisce una stima conservativa dell'attendibilità di un test solo se le variabili osservate sono associate alle variabili latenti come indicato dal modello di misurazione \(\tau\)-equivalente. Se le assunzioni del modello \(\tau\)-equivalente sono violate (per esempio, l'assunzione dell'incorrelazione degli errori), allora \(\alpha\) porta ad una sovrastima stima dell'attendibilità del test.

Sijtsma (2009), tra gli altri, sconsiglia l'uso di \(\alpha\) per la stima dell'attendibilità del test in quanto, nelle applicazioni reali, \emph{le assunzioni di \(\tau\)-equivalenza e dell'incorrelazione degli errori risultano spesso violate}. La violazione dell'assunzione di \(\tau\)-equivalenza porta ad una stima conservativa dell'attendibilità, mentre la violazione dell'assunzione dell'incorrelazione degli errori porta ad una stima liberale dell'attendibilità. In entrambi i casi, l'errore sistematico può essere sostanziale.

Un secondo problema è che \(\alpha\) viene spesso preso quale misura della ``struttura interna'' di un test e quindi come evidenza che gli item del test ``misurino la stessa cosa.'' Tale interpretazione di \(\alpha\) è sbagliata, in quanto \(\alpha\) non fornisce alcuna informazione a questo proposito. Non è semplice fornire ad \(\alpha\) una chiara interpretazione, anche nel caso in cui siano soddisfatte le assunzioni del modello di misurazione su cui si basa.

\hypertarget{la-formula-profetica-di-spearman-brown}{%
\subsection{La formula ``profetica'' di Spearman-Brown}\label{la-formula-profetica-di-spearman-brown}}

L'attendibilità può essere stimata mediante il coefficiente \(\omega\) se il modello di misurazione è congenerico e tramite il coefficiente \(\alpha\), se il modello di misurazione è \(\tau\)-equivalente. Chiediamoci ora come possa essere misurata l'attendibilità nel caso di un modello di misurazione costituito da indicatori paralleli.

Si considerino \(p\) item paralleli, tali per cui \(\lambda_1=\lambda_2=\dots=\lambda_p=\lambda\) e \(\psi_{11}=\psi_{22}=\dots=\psi_{pp}=\psi\). In tal caso, la quota di varianza del punteggio totale del test che viene spiegata dalla variabile latente è uguale a

\[
\left(\sum_i \lambda_i \right)^2 = (p \lambda)^2 = p^2 \lambda^2.
\]

L'attendibilità di un singolo item è data da

\[
\rho_1 = \frac{\lambda^2}{\lambda^2 + \psi} = \frac{\sigma_T^2}{\sigma_T^2+ \sigma_E^2}.
\]

Per \(p\) item paralleli abbiamo

\begin{equation}
\begin{aligned}
  \rho_p &= \frac{p^2 \lambda^2}{p^2 \lambda^2 + p \psi} \notag\\
         &= \frac{p^2 \lambda^2}{ p (p \lambda^2 + \psi)} \notag\\
         &= \frac{p \lambda^2}{ p \lambda^2 + \psi} \notag\\
         &= \frac{p \lambda^2}{(p-1) \lambda^2 + (\lambda^2 + \psi)} \notag
\end{aligned}
\end{equation}

ovvero,

\begin{equation}
\begin{aligned}
  \rho_p &= \frac{p \frac{\lambda^2}{\lambda^2+\psi}}{(p-1) \frac{\lambda^2}{\lambda^2+\psi} + \frac{\lambda^2 + \psi}{\lambda^2+\psi}} \notag\\
  &= \frac{p \rho_1}{(p-1)\rho_1 + 1},
\end{aligned}
\label{eq:spearman-brown-der}
\end{equation}

ricordando che l'attendibilità di ciascun singolo item è \(\rho_1 = \frac{\lambda^2}{\lambda^2 + \psi}\).

La \eqref{eq:spearman-brown-der} esprime l'attendibilità di un test costituito da \(p\) item paralleli nei termini dell'attendibilità di un solo item ed è tradizionalmente conosciuta come la formula di Spearman-Brown (\emph{Spearman-Brown prophecy formula}). Nel caso di item paralleli si ha che

\[
\omega=\alpha=\rho_p.
\]

\hypertarget{un-esempio-concreto-2}{%
\subsubsection{Un esempio concreto}\label{un-esempio-concreto-2}}

Poniamoci ora il problema di calcolare l'attendibilità del test SWLS ipotizzando che gli item siano paralleli e utilizzando la formula di Spearman-Brown. La matrice di correlazione è:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{R }\OtherTok{\textless{}{-}} \FunctionTok{cov2cor}\NormalTok{(SWLS)}
\FunctionTok{round}\NormalTok{(R, }\DecValTok{3}\NormalTok{)}
\CommentTok{\#\textgreater{}       [,1]  [,2]  [,3]  [,4]  [,5]}
\CommentTok{\#\textgreater{} [1,] 1.000 0.563 0.589 0.498 0.521}
\CommentTok{\#\textgreater{} [2,] 0.563 1.000 0.511 0.400 0.452}
\CommentTok{\#\textgreater{} [3,] 0.589 0.511 1.000 0.419 0.473}
\CommentTok{\#\textgreater{} [4,] 0.498 0.400 0.419 1.000 0.370}
\CommentTok{\#\textgreater{} [5,] 0.521 0.452 0.473 0.370 1.000}
\end{Highlighting}
\end{Shaded}

Seguendo McDonald (1999), supponiamo di calcolare l'attendibilità di un singolo item (\(\rho_1\)) come la correlazione media tra gli item:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rr }\OtherTok{\textless{}{-}} \ConstantTok{NULL}
\NormalTok{k }\OtherTok{\textless{}{-}} \DecValTok{1}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{p) \{}
  \ControlFlowTok{for}\NormalTok{ (j }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{p) \{}
    \ControlFlowTok{if}\NormalTok{ (j }\SpecialCharTok{!=}\NormalTok{ i) \{}
\NormalTok{      rr[k] }\OtherTok{\textless{}{-}}\NormalTok{ R[i, j]}
\NormalTok{    \}}
\NormalTok{    k }\OtherTok{\textless{}{-}}\NormalTok{ k }\SpecialCharTok{+} \DecValTok{1}
\NormalTok{  \}}
\NormalTok{\}}
\NormalTok{ro\_1 }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(rr, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{ro\_1}
\CommentTok{\#\textgreater{} [1] 0.4798}
\end{Highlighting}
\end{Shaded}

Applicando la formula di Spearman-Brown, la stima dell'attendibilità del test diventa pari a

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(p }\SpecialCharTok{*}\NormalTok{ ro\_1) }\SpecialCharTok{/}\NormalTok{ ((p }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ ro\_1 }\SpecialCharTok{+} \DecValTok{1}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 0.8218}
\end{Highlighting}
\end{Shaded}

\hypertarget{attenuazione-1}{%
\subsubsection{Attenuazione}\label{attenuazione-1}}

All'aumentare dell'errore di misurazione, la correlazione tra due variabili tende a diminuire. L'errore di misurazione, dunque, ``maschera'' l'associazione esistente tra le variabili. Tale fenomeno va sotto il nome di \emph{attenuazione}.

Lord e Novick (1967) notano che, volendo determinare la relazione esistente tra due costrutti, uno psicologo può costruire opportune scale per misurarli. Se la relazione tra queste scale è lineare, allora il grado di associazione tra le scale può essere misurato dal coefficiente di correlazione. Le scale, però, contengono una componente di errore e, quindi, la correlazione empirica tra le due scale assume un valore minore della ``reale'' correlazione tra i costrutti. In tali circostanze, possono essere usate opportune formule per stimare il valore della correlazione disattenuata tra i tratti latenti.

Si può dimostrare che la correlazione tra i punteggi veri di due costrutti, \(T_y\) e \(T_y\), può essere espressa nei termini della correlazione \(\rho_{XY}\) tra i punteggi osservati \(X\) e \(Y\), e nei termini dei coefficienti di attenibilità \(\rho_{XX^\prime}\), \(\rho_{YY^\prime}\) dei due test:

\begin{equation}
\rho(T_X, T_Y)  = \frac{\rho_{XY}}{\sqrt{\rho_{XX^\prime} \rho_{YY^\prime}}}
\label{eq:3-9-6}
\end{equation}

Inoltre, può essere dimostrato che la correlazione tra i punteggi di un test e i punteggi veri di un secondo test può essere espressa nei termini delle correlazioni tra i punteggi osservati dei due test e del coefficiente di attendibilità del secondo test:

\begin{equation}
\rho(X, T_Y)  = \frac{\rho_{XY}}{\sqrt{\rho_{YY^\prime}}}.
\label{eq:3-9-7}
\end{equation}

\hypertarget{correlazioni-disattenuate}{%
\subsubsection{Correlazioni disattenuate}\label{correlazioni-disattenuate}}

Le \eqref{eq:3-9-6} e \eqref{eq:3-9-7} consentono di calcolare le cosiddette \emph{correlazioni disattenuate}. L'idea è che le correlazioni tra i punteggi veri di due test sono sottostimate dalle correlazioni tra i punteggi osservati dei test, a causa dell'errore di misura. Se le attendibilità dei test sono conosciute, le \eqref{eq:3-9-6} e \eqref{eq:3-9-7} possono essere usate per stimare le correlazioni tra i corrispondenti punteggi veri. La teoria dell'attenuazione costituisce un'ulteriore applicazione del coefficiente di attendibilità nell'ambito della teoria classica dei test.

Le correlazioni disattenuate sono state usate già a partire dal 1904 da Spearman. Nell'esempio di Spearman, \(X\) era una misura di discriminazione dell'altezza di un suono (\emph{pitch discrimination}) e \(Y\) era una misura di intelligenza fornita da un insegnante. La correlazione tra queste due misure era \(\hat{\rho}_{XY}=0.38\). Le attendibilità delle due misure erano pari a, rispettivamente, \(\hat{\rho}_{XX'}= 0.25\) e \(\hat{\rho}_{YY'}= 0.55\). In base alla \eqref{eq:3-9-7}

\[
\rho(X, T_Y)  = \frac{\rho_{XY}}{\sqrt{\rho_{YY^\prime}}}
\]

la correlazione predetta tra i valori veri di pitch discrimination e i valori empirici dell'intelligenza è

\[
\hat{\rho}(X, T_Y)  =\frac{0.38}{\sqrt{0.25}}=0.76.
\]

In base alla \eqref{eq:3-9-6}

\[\rho(T_X, T_Y)  = \frac{\rho_{XY}}{\sqrt{\rho_{XX'} \rho_{YY'}}}\]

la correlazione tra i valori veri di pitch discrimination e i valori veri dell'intelligenza è

\[\hat{\rho}(T_X, T_Y)  =\frac{0.38}{\sqrt{0.25 \times 0.55}}=1.025.\]

Si noti come i limiti di questa procedura emergano già dall'esempio fornito da Spearman: le correlazioni disattenuate possono facilmente produrre una sovrastima.

Questa formula originò una controversia tra Charles Spearman e Karl Pearson. In un suo articolo del 1904 (lo stesso anno dei famosi articoli di Spearman), Pearson riportò diverse correlazioni nell'intorno di 0.5 che riguardavano la misurazione empirica di caratteristiche quali la vivacità e l'introspezione. Spearman criticò l'articolo di Pearson affermando che le osservazioni probabilmente contenevano un sostanziale errore di misurazione, il che determinava il fatto che fossero così basse. Le corrispondenti correlazioni disattenuate erano, secondo Spearman, probabilmente molto più alte. Tale critica venne del tutto ignorata da Pearson sulla base del fatto che la formula di Spearman poteva condurre a correlazioni maggiori di uno. Inoltre, Pearson non accettava i riferimenti a quantità inosservabili. Spearman, d'altra parte, eseguì diversi studi su variabili psicologiche alle quali applicò la sua formula per le correlazioni disattenuate. In molti casi, trovò che le correlazioni disattenuate erano vicine ad uno. Questo suggeriva che tali variabili psicologiche erano indicatori dello stesso fenomeno. Queste considerazioni spinsero Spearman a procedere in questa direzione, giungendo ad inventare l'analisi fattoriale così com'è riportata nell'articolo del 1904 \emph{``General intelligence'', objectively determined and measured}.

McDonald (1999) afferma che le correlazioni disattenuate devono essere usate con cautela. Un metodo migliore per calcolare le correlazioni tra le variabili latenti (ovvero, le correlazioni non ``inquinate'' dagli errori di misura) è quello di costruire un modello di equazioni strutturali nel quale diverse ipotesi possono essere direttamente verificate, compresa quella della correlazione tra le variabili latenti.

\hypertarget{attendibilituxe0-e-scala-di-misura}{%
\section{Attendibilità e scala di misura}\label{attendibilituxe0-e-scala-di-misura}}

McDonald (2013) fa notare che i coefficienti \(\omega\) e \(\alpha\), ma non il coefficiente di Spearman-Brown, dipendono dalla scala di misura degli item. Stimare \(\omega\) utilizzando una matrice di correlazione anziché una matrice di varianze e di covarianze è equivalente a stimare il coefficiente di attendibilità di una somma di item standardizzati. Il risultato ottenuto mediante \(\omega\) e \(\alpha\) non si generalizza però al caso in cui si voglia valutare l'attendibilità del punteggio totale di un test calcolato sui valori grezzi degli item.

Il modello ad un fattore comune non dipende dall'unità di misura degli indicatori e può essere adattato sia ad una matrice di correlazione sia ad una matrice di varianze e di covarianze. Il calcolo dei coefficienti \(\omega\) e \(\alpha\), invece, deve essere fatto sulla soluzione trovata utilizzando una matrice di varianze e di covarianze.

\hypertarget{quale-indice-usare}{%
\section{Quale indice usare?}\label{quale-indice-usare}}

L'indice di attendibilità più diffuso in letteratura è il coefficiente \(\alpha\) di Cronbach. Affinché \(\alpha\) fornisca una stima dell'attendibilità del test, però, gli item devono essere \(\tau\)-equivalenti. Il modello di \(\tau\)-equivalenza richiede l'unidimensionalità del tratto latente. In pratica, tale assunzione viene spesso violata, dato che la maggior parte dei test, oltre ad un fattore generale, misurano anche altri fattori. Anche nel caso di un test unidimensionale, le comunalità degli item non sono mai uguali tra loro, violando così l'assunzione di \(\tau\)-equivalenza. In tali circostanze, se risulta soddisfatta l'assunzione di incorrelazione degli errori, il coefficiente \(\alpha\) sottostima l'attendibilità del test. Se invece l'assunzione di incorrelazione degli errori non risulta soddisfatta, allora il coefficiente \(\alpha\) sovrastima l'attendibilità del test. Per tali ragioni, l'utilità del coefficiente \(\alpha\) di Cronbach è molto limitata e, in generale, è preferibile usare il coefficiente \(\omega\) (McDonald, 1999). Altre alternative sono gli indici \(glb\) (\emph{Greatest Lower Bound}; si veda, ad esempio, Ten Berge e Sočan, 2004) e \(\beta\) (Revelle, 1979).

\hypertarget{ch:cfa-cong-parall}{%
\chapter{CFA: confronto tra modelli}\label{ch:cfa-cong-parall}}

In un modello CFA, i parametri possono essere stimati senza vincoli, possono essere fissi o possono essre stimati sulla base di alcuni vincoli. Un parametro libero è sconosciuto e il ricercatore consente all'algoritmo di stima di trovare il suo valore ottimale che, insime agli altri parametri del modello, riduce al minimo le differenze tra le matrici di varianze-covarianze osservate e quelle predette dal modello. Un parametro fisso è pre-specificato dal ricercatore ad un valore specifico, più comunemente 1.0 (ad esempio, per definire la metrica di una variabile latente) o 0 (ad esempio, l'assenza di saturazionoi fattoriali o di covarianze di errore). Come per un parametro libero, anche un parametro vincolato è sconosciuto; tuttavia, un tale parametro non può assumere un valore qualsiasi, ma deve rispettare le restrizioni su suoi valori che il ricercatore ha imposto. I vincoli più comuni sono i vincoli di uguaglianza, in cui i parametri non standardizzati devono assumere valori uguali (ad esempio, in diversi gruppi).

Consideriamo un esempio discusso da \citet{brown2015confirmatory}. Viene qui considerato un set di dati in cui le prime tre misure osservate (X1, X2, X3) sono indicatori di un costrutto latente corrispondente alla Memoria uditiva e il secondo insieme di misure (X4, X5, X6) sono indicatori di un altro costrutto latente, Memoria visiva. Le tre misure usate quali indicatori del costrutto di memoria uditiva sono: X1 = memoria logica, X2 = associazione verbale a coppie, X3 = liste di parole; le tre misure usate come indicatori del costrutto di memoria visiva sono: X4 = immagini di facce, X5 = foto di famiglia, X6 = generiche riproduzioni visive. I dati sono i seguenti:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sds }\OtherTok{\textless{}{-}} \StringTok{"2.610  2.660  2.590  1.940  2.030  2.050"}

\NormalTok{cors }\OtherTok{\textless{}{-}} \StringTok{"}
\StringTok{  1.000}
\StringTok{  0.661  1.000}
\StringTok{  0.630  0.643  1.000}
\StringTok{  0.270  0.300  0.268  1.000}
\StringTok{  0.297  0.265  0.225  0.805  1.000}
\StringTok{  0.290  0.287  0.248  0.796  0.779  1.000"}

\NormalTok{covs }\OtherTok{\textless{}{-}} \FunctionTok{getCov}\NormalTok{(cors, }\AttributeTok{sds =}\NormalTok{ sds, }\AttributeTok{names =} \FunctionTok{paste}\NormalTok{(}\StringTok{"x"}\NormalTok{, }\DecValTok{1}\SpecialCharTok{:}\DecValTok{6}\NormalTok{, }\AttributeTok{sep =} \StringTok{""}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Adattiamo i cinque modelli discussi da \citet{brown2015confirmatory}.

\hypertarget{modello-congenerico}{%
\section{Modello congenerico}\label{modello-congenerico}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model.congeneric }\OtherTok{\textless{}{-}} \StringTok{"}
\StringTok{  auditorymemory =\textasciitilde{} x1 + x2 + x3}
\StringTok{  visualmemory   =\textasciitilde{} x4 + x5 + x6}
\StringTok{"}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit.congeneric }\OtherTok{\textless{}{-}} \FunctionTok{cfa}\NormalTok{(}
\NormalTok{  model.congeneric,}
  \AttributeTok{sample.cov =}\NormalTok{ covs,}
  \AttributeTok{sample.nobs =} \DecValTok{200}\NormalTok{,}
  \AttributeTok{std.lv =} \ConstantTok{TRUE}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

L'output (qui non fornito) si ottiene con:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(}
\NormalTok{  fit.congeneric,}
  \AttributeTok{fit.measures =} \ConstantTok{TRUE}\NormalTok{,}
  \AttributeTok{standardized =} \ConstantTok{TRUE}\NormalTok{,}
  \AttributeTok{rsquare =} \ConstantTok{TRUE}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{modello-tau-equivalente}{%
\section{Modello tau-equivalente}\label{modello-tau-equivalente}}

Solo memoria auditiva:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model.tau.a }\OtherTok{\textless{}{-}} \StringTok{"}
\StringTok{  auditorymemory =\textasciitilde{} x1 + v1*x1 + v1*x2 + v1*x3}
\StringTok{  visualmemory   =\textasciitilde{} x4 + x5 + x6}
\StringTok{"}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit.tau.a }\OtherTok{\textless{}{-}} \FunctionTok{cfa}\NormalTok{(}
\NormalTok{  model.tau.a,}
  \AttributeTok{sample.cov =}\NormalTok{ covs,}
  \AttributeTok{sample.nobs =} \DecValTok{200}\NormalTok{,}
  \AttributeTok{std.lv =} \ConstantTok{TRUE}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Memoria auditiva e visiva:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model.tau.av }\OtherTok{\textless{}{-}} \StringTok{"}
\StringTok{  auditorymemory =\textasciitilde{} x1 + v1*x1 + v1*x2 + v1*x3}
\StringTok{  visualmemory   =\textasciitilde{} x4 + v2*x4 + v2*x5 + v2*x6}
\StringTok{"}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit.tau.av }\OtherTok{\textless{}{-}} \FunctionTok{cfa}\NormalTok{(}
\NormalTok{  model.tau.av,}
  \AttributeTok{sample.cov =}\NormalTok{ covs,}
  \AttributeTok{sample.nobs =} \DecValTok{200}\NormalTok{,}
  \AttributeTok{std.lv =} \ConstantTok{TRUE}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{modello-parallelo}{%
\section{Modello parallelo}\label{modello-parallelo}}

Solo memoria auditiva:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model.parallel.a }\OtherTok{\textless{}{-}} \StringTok{"}
\StringTok{  auditorymemory =\textasciitilde{} x1 + v1*x1 + v1*x2 + v1*x3}
\StringTok{  visualmemory   =\textasciitilde{} x4 + v2*x4 + v2*x5 + v2*x6}
\StringTok{  x1 \textasciitilde{}\textasciitilde{} v3 * x1}
\StringTok{  x2 \textasciitilde{}\textasciitilde{} v3 * x2}
\StringTok{  x3 \textasciitilde{}\textasciitilde{} v3 * x3}
\StringTok{"}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit.parallel.a }\OtherTok{\textless{}{-}} \FunctionTok{cfa}\NormalTok{(}
\NormalTok{  model.parallel.a,}
  \AttributeTok{sample.cov =}\NormalTok{ covs,}
  \AttributeTok{sample.nobs =} \DecValTok{200}\NormalTok{,}
  \AttributeTok{std.lv =} \ConstantTok{TRUE}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Memoria auditiva e visiva:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model.parallel.av }\OtherTok{\textless{}{-}} \StringTok{"}
\StringTok{  auditorymemory =\textasciitilde{} x1 + v1*x1 + v1*x2 + v1*x3}
\StringTok{  visualmemory   =\textasciitilde{} x4 + v2*x4 + v2*x5 + v2*x6}
\StringTok{  x1 \textasciitilde{}\textasciitilde{} v3 * x1}
\StringTok{  x2 \textasciitilde{}\textasciitilde{} v3 * x2}
\StringTok{  x3 \textasciitilde{}\textasciitilde{} v3 * x3}

\StringTok{  x4 \textasciitilde{}\textasciitilde{} v4 * x4}
\StringTok{  x5 \textasciitilde{}\textasciitilde{} v4 * x5}
\StringTok{  x6 \textasciitilde{}\textasciitilde{} v4 * x6}
\StringTok{"}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit.parallel.av }\OtherTok{\textless{}{-}} \FunctionTok{cfa}\NormalTok{(}
\NormalTok{  model.parallel.av,}
  \AttributeTok{sample.cov =}\NormalTok{ covs,}
  \AttributeTok{sample.nobs =} \DecValTok{200}\NormalTok{,}
  \AttributeTok{std.lv =} \ConstantTok{TRUE}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{il-test-del-chi2}{%
\section{\texorpdfstring{Il test del \(\chi^2\)}{Il test del \textbackslash chi\^{}2}}\label{il-test-del-chi2}}

Il confronto tra modelli nidificati procede attraverso il test \(\chi^2\). Tale test si basa su una proprietà delle variabili casuali distribuite come \(\chi^2\): la differenza tra due v.c. \(X_1\) e \(X_2\) che seguono la distribuzione \(\chi^2\), rispettivamente con \(\nu_1\) e \(\nu_2\), con \(\nu_1 > \nu_2\), è una variabile causale che segue la distribuzione \(\chi^2\) con gradi di libertà pari a \(\nu_1 - \nu_2\).

Un modello nidificato è un modello che impone dei vincoli sui parametri del modello di partenza. L'imposizione di vincoli sui parametri ha la conseguenza che vi sarà un numero minore di parametri da stimare. Il confronto tra i modelli si esegue valutando in maniera relativa la bontà di adattamento di ciascun modello per mezzo della statistica chi-quadrato. La statistica così calcolata avrà un numero di gradi di libertà uguale alla differenza tra i gradi di libertà dei due modelli.

Nel caso dell'esempio in dicussione, abbiamo

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{anova}\NormalTok{(}
\NormalTok{  fit.congeneric,}
\NormalTok{  fit.tau.a,}
\NormalTok{  fit.tau.av,}
\NormalTok{  fit.parallel.a,}
\NormalTok{  fit.parallel.av,}
  \AttributeTok{test =} \StringTok{"chisq"}
\NormalTok{)}
\CommentTok{\#\textgreater{} Chi{-}Squared Difference Test}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}                 Df  AIC  BIC Chisq Chisq diff Df diff}
\CommentTok{\#\textgreater{} fit.congeneric   8 4702 4745  4.88                   }
\CommentTok{\#\textgreater{} fit.tau.a       10 4699 4735  5.66       0.78       2}
\CommentTok{\#\textgreater{} fit.tau.av      12 4695 4725  5.88       0.22       2}
\CommentTok{\#\textgreater{} fit.parallel.a  14 4691 4714  5.98       0.10       2}
\CommentTok{\#\textgreater{} fit.parallel.av 16 4690 4707  9.28       3.30       2}
\CommentTok{\#\textgreater{}                 Pr(\textgreater{}Chisq)}
\CommentTok{\#\textgreater{} fit.congeneric            }
\CommentTok{\#\textgreater{} fit.tau.a             0.68}
\CommentTok{\#\textgreater{} fit.tau.av            0.90}
\CommentTok{\#\textgreater{} fit.parallel.a        0.95}
\CommentTok{\#\textgreater{} fit.parallel.av       0.19}
\end{Highlighting}
\end{Shaded}

I test precedenti indicano come non vi sia una perdita di adattamento passando dal modello congenerico al modello più restrittivo (ovvero, il modello parallelo per entrambi i fattori). Per questi dati, dunque, può essere adottato il modello più semplice, cioè il modello parallelo.

\hypertarget{part-costruzione-di-strumenti-psicometrici}{%
\part{Costruzione di strumenti psicometrici}\label{part-costruzione-di-strumenti-psicometrici}}

\hypertarget{ch:problema}{%
\chapter{Tipologie dei test psicometrici}\label{ch:problema}}

Prima di iniziare lo sviluppo di un test psicometrico, il ricercatore deve decidere quale tipologia di strumento sia più utile per affrontare il problema che ha di fronte. Possiamo infatti distinguere tra test orientati al criterio e test riferiti alla norma.

\hypertarget{test-orientati-al-criterio}{%
\subsection{Test orientati al criterio}\label{test-orientati-al-criterio}}

I test orientati al criterio hanno quale scopo il confronto fra gruppi precostituiti di individui. Gli item del test vengono selezionati in base alla loro capacità empirica di discriminare fra gruppi criterio, ad esempio, malati/sani, bocciati/promossi, schizofrenici/depressi. I test orientati al criterio sono costruiti utilizzando metodi empirici e non teorici. Al vantaggio di una chiara utilità pratica si accompagna il grande svantaggio di identificare fattori aventi una scarsa validità di costrutto, i quali risultano inutili per la comprensione dei processi psicologici.

Il processo di sviluppo della scala è semplice, in quanto si devono selezionare gli item che mostrano punteggi differenti in gruppi-criterio noti. Se i gruppi criterio possono essere individuati con chiarezza è sempre teoricamente possibile sviluppare test in grado di discriminarli.

Tuttavia, non sempre i gruppi possono essere definiti in modo attendibile; oppure, la definizione dei gruppi criterio potrebbe avere senso solo all'interno di una teoria, ma non sia generalizzabile ad altre tradizioni teoriche. In questo caso, il test rischia di essere eccessivamente specifico, dimostrandosi utile solo nelle condizioni per cui è stato sviluppato, ma con scarsa capacità di potere essere utilizzato in condizioni diverse.

Lo svantaggio principale dei test orientati al criterio è che il significato psicologico dei punteggi è ignoto. Non avendo una teoria sulle variabili psicologiche che distinguono due gruppi, un buon test discriminante non ci aiuta a capire perché tali gruppi siano diversi. Non è possibile sapere quanti costrutti siano coinvolti nella determinazione di un punteggio. Inoltre, due punteggi uguali non implicano la presenza dei medesime meccanismi psicologici. Date queste ambiguità, utilizzando questi test non è possibile neppure aumentare le nostre conoscenze in maniera incrementale.

Il problema maggiore per lo sviluppo di questi strumenti è la definizione del criterio: qual è la variabile numerica che discrimina nella maniera maggiore tra i gruppi in esame (malati/sani)?

La batteria di item iniziale deve essere sufficientemente grande e non è necessario che gli item abbiano validità di contenuto o validità di facciata. In generale, la batteria di item deve essere più grande di quelle usate per il metodo fattoriale o di analisi degli item: mancando criteri teorici per la scelta degli item, la scelta iniziale degli item è molto arbitraria ed è dunque necessario partire da un numero molto elevato di item. Ciò è meno vero quando gli item hanno una certa validità di facciata o di contenuto. In seguito, semplicemente si selezionano gli item che discriminano efficacemente fra i gruppi, o gli item fortemente associati con il punteggio criterio. È necessario poi replicare su un diverso campione la capacità discriminativa degli item selezionati.

\hypertarget{test-basati-sulla-norma}{%
\subsection{Test basati sulla norma}\label{test-basati-sulla-norma}}

Le misure riferite ad una norma indicano la posizione del rispondente in riferimento alla distribuzione di punteggi ottenuti nello stesso test da un campione di grandi dimensioni e rappresentativo della popolazione di riferimento. La maggioranza dei test di personalità, attitudinali e cognitivi sono test basati sulla norma.

La metrica utilizzata per tale confronto può avere caratteristiche diverse. I punteggi standardizzati (con media \(0\) e varianza unitaria) calcolati rispetto al gruppo di riferimento sono spesso convertiti in una scala diversa, per esempio aventi media pari a \(500\) e deviazione standard di \(100\) (punteggi SAT), o aventi media pari a \(100\) e deviazione standard di \(15\) (es. punteggi WAIS-VI). È facile operare tale trasformazione. Il punteggio \(Y\) di un rispondente può essere trasformato nel modo seguente in un punteggio standard \(X_i\), avente una media target pari a \(\mu_s\) e una deviazione standard \(\sigma_s\)

\[X_i = \mu_s + z_i \sigma_s\notag\]

dove \(z\) è il punteggio standardizzato \(z=\frac{Y-\bar{Y}}{s_Y}\).

\hypertarget{variabili-latenti-e-sviluppo-di-uno-strumento-psicometrico}{%
\section{Variabili latenti e sviluppo di uno strumento psicometrico}\label{variabili-latenti-e-sviluppo-di-uno-strumento-psicometrico}}

Quando uno psicologo sviluppa una scala di misura è meno interessato agli item della scala che ai costrutti che si intendono misurare: ``Scale items are usually a means to the end of construct assessment \ldots they are necessary because many constructs cannot be assessed directly'' (p.~2). Dato che non sono osservabili direttamente, i costrutti sono detti \emph{variabili latenti}. I costrutti sono interpretati come le cause (non visibili) che fanno in modo che gli item assumano un determinato valore per un determinato rispondente in un certo momento del tempo. Mentre alcune variabili, quali l'altezza, il peso, il battito cardiaco, la temperatura, possono essere misurate direttamente, i costrutti psicologici, quali l'ansia, la personalità, la qualità della vita, possono solo essere misurati indirettamente esaminando gli effetti che hanno sugli indicatori osservabili del costrutto. Gli item che vengono misurati tramite uno strumento sono gli indicatori osservati o empirici degli attributi del costrutto. Il dolore, ad esempio, è un costrutto psicologico non direttamente osservabile. Tuttavia, al dolore sono associati molteplici indicatori che sono direttamente osservabili, quali il pallore, la sudorazione profusa, ecc.

Allo scopo di misurare le variabili latenti del costrutto di interesse, lo psicologo deve identificare gli indicatori empirici del costrutto che possono essere direttamente osservabili. L'identificazione di tali indicatori empirici avviene attraverso (1) la chiarificazione del costrutto di interesse, (2) l'operazionalizzazione del costrutto, (3) la rassegna della letteratura rilevante, (4) l'analisi concettuale del costrutto.

\hypertarget{chiarificazione-del-costrutto-di-interesse}{%
\subsection{Chiarificazione del costrutto di interesse}\label{chiarificazione-del-costrutto-di-interesse}}

Vi sono diverse domande a cui lo psicologo deve rispondere prima di iniziare la selezione degli item, altrimenti rischia di produrre uno strumento con una scarsa validità di costrutto.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Qual è lo scopo dello strumento? Che cosa lo strumento dovrà misurare?
\item
  Quali altri costrutti sono associati al costrutto di interesse? In che misura essi si distinguono dal costrutto di interesse? A tali domande non è semplice dare una risposta se il costrutto di interesse è complesso e astratto.
\item
  Lo strumento da costruire intende misurare le caratteristiche generali del costrutto di interesse, o intende focalizzarsi su alcuni specifici aspetti del costrutto?
\end{enumerate}

\begin{example}
Watson et al.~(2007) si sono posti il problema di costruire uno strumento atto misurare la depressione superando i limiti degli strumenti già esistenti, quali il Beck Depression Inventory---II (BDI--II; Beck, Steer, \& Brown, 1996) e il Center for Epidemiological Studies Depression Scale (CES--D; Radloff, 1977). La scala costruita dagli autori prende il nome di Inventory of Depression and Anxiety Symptoms (IDAS).

Per rispondere alla prima domanda, Watson et al.~(2007) fanno notare che gli strumenti esistenti comprendono contenuti non specifici, ovvero non direttamente associati alla depressione. Infatti, sia il BDI-2 sia il CES--D contengono item che fanno riferimento a vari tipi di ansia. Di conseguenza, la validità discriminante di questi strumenti risulta compromessa. Inoltre, gli strumenti esistenti non contengono item che coprono tutto il dominio del costrutto della depressione maggiore, così come specificato dal Diagnostic and Statistical Manual of Mental Disorders (4th ed.). Infine, un'altra limitazione degli strumenti esistenti è il fatto che essi sono stati creati per produrre un singolo item della severità dei sintomi e quindi ignorano l'eterogeneità e la multidimensionalità del fenomeno depressivo. Questo si riflette sul fatto che gli strumenti esistenti manifestano una struttura fattoriale poco chiara, nel senso che autori diverse hanno trovato soluzioni fattoriali diverse. Lo strumento che Watson et al.~(2007) intendono sviluppare vuole superare queste difficoltà costruendo una scale che direttamente rifletta, in ciascuna delle sue sottoscale, gli aspetti distintivi della depressione, a differenza di quanto accade per gli strumenti BDI--II e CES--D.

Per rispondere alla seconda domanda, Watson et al.~(2007) fanno notare come la depressione sia inserita in una rete nomologica di costrutti che include, in primo luogo, l'ansia. Diversamente dagli strumenti già esistenti, BDI--II e CES--D, Watson et al.~(2007) si propongono espliciatamente di creare scale che riflettano gli aspetti specifici della depressione, distinti dall'ansia. Per fare questo, Watson et al. (2007) iniziano con il considerare un ampio insieme di item che rappresentano sintomi associati all'ansia. In questo modo viene perseguito l'obiettivo, all'interno dello strumento, di esaminare la relazione tra i sintomi d'ansia e quelli della depressione in modo da creare scale distinte per tali dimensioni così da aumentare a validità discriminante dello strumento.

Per rispondere alla terza domanda, Watson et al.~(2007) affermano di volere sviluppare uno strumento che, nel suo punteggio generale, rifletta le caratteristiche generali della depressione mentre, quando vengono considerate le varie sottoscale che lo costituiscono, consente di misurare con precisione ciascuna delle dimensioni del costrutto esaminato.
\end{example}

\hypertarget{operazionalizzazione-del-costrutto-di-interesse}{%
\subsection{Operazionalizzazione del costrutto di interesse}\label{operazionalizzazione-del-costrutto-di-interesse}}

La definizione concettuale fornisce il significato teorico generale del costrutto. L'operazionalizzazione è invece una definizione del costrutto che ne consenta la misurazione (Vogt, 1993). Gli indicatori osservabili o empirici sono il prodotto finale di tale processo di operazionalizzazione (Keck, 1998) e diventano gli item dello strumento. Se il costrutto di interesse è stato sviluppato all'interno di un approccio teorico ben articolato, allora diventa più semplice stabilire quali siano le dimensioni che caratterizzano il costrutto, in che modo esse si possano manifestare, e in che modo possano essere misurate. Tuttavia, molti costrutti psicologici vengono spesso caratterizzati in maniera diversa da approcci teorici differenti.

\begin{example}
Per chiarire il costrutto di depressione, Watson et al.~(2007) fanno riferimento al DSM--IV il quale elenca nove criteri sintomatici per un episodio depressivo maggiore: (1) umore depresso per la maggior parte del giorno, quasi ogni giorno, come riportato dal soggetto o come osservato dagli altri, (2) marcata diminuzione di interesse o piacere per tutte, o quasi tutte, le attività per la maggior parte del giorno, quasi ogni giorno (come riportato dal soggetto o come osservato dagli altri), (3) significativa perdita di peso, senza essere a dieta, o aumento di peso, oppure diminuzione o aumento dell'appetito quasi ogni giorno, (4) insonnia o ipersonnia quasi ogni giorno, (5) agitazione o rallentamento psicomotorio quasi ogni giorno (osservabile dagli altri, non semplicemente sentimenti soggettivi di essere irrequieto o rallentato), (6) faticabilità o mancanza di energia quasi ogni giorno, (7) sentimenti di autosvalutazione o di colpa eccessivi o inappropriati (che possono essere deliranti), quasi ogni giorno, (8) ridotta capacità di pensare o di concentrarsi, o indecisione, quasi ogni giorno (come impressione soggettiva o osservata dagli altri), (9) pensieri ricorrenti di morte, ricorrente ideazione suicidaria senza un piano specifico, o un tentativo di suicidio, o l'ideazione di un piano specifico per commettere suicidio.

Per massimizzare l'utilità dell'IDAS, Watson et al.~(2007) includono item molteplici per ciascuno dei nove criteri sintomatici per un episodio depressivo maggiore. Allo scopo di assicurare che un numero sufficiente di indicatori venga incluso nello strumento per ciascuna di queste dimensioni potenziali, nell'insieme di item preso in considerazione inizialmente, Watson et al.~(2007) organizzano gli item potenziali in gruppi chiamati \emph{homogeneous item composites} (HIC). Essi fanno comunque notare come la costruzione di questi HIC non forza l'emergenza di un corrispondente fattore, ma soltanto consente di campionare tutto il dominio potenziale del costrutto.
\end{example}

\hypertarget{rassegna-della-letteratura-rilevante}{%
\subsection{Rassegna della letteratura rilevante}\label{rassegna-della-letteratura-rilevante}}

È importante per lo psicologo conoscere la maggior parte possibile della letteratura rilevante prima di iniziare il processo di costruzione di un nuovo strumento. Una sistematica rassegna della letteratura consente allo psicologo di valutare e organizzare i risultati empirici provenienti da fonti diverse che sono utili per individuare i potenziali indicatori empirici del costrutto. La rassegna della letteratura consente di sintetizzare le scoperte in un campo di ricerca, mette in evidenza gli aspetti metodologici associati al costrutto di interesse, chiarisce quali siano gli approcci teorici all'interno dei quali il costrutto è stato discusso e consente di mettere in evidenza, quando è opportuno, la ``dimensione dell'effetto'' attraverso le meta-analisi.

\begin{example}
Nel caso dell'articolo di Watson et al.~(2007), gran parte dell'introduzione è dedicata alla rassegna della letteratura che viene discussa allo scopo di mettere in evidenza i limiti degli strumenti esistenti, considerare quali sono le caratteristiche degli item utilizzati, mettere in relazione gli indicatori utilizzati dagli strumenti esistenti con gli approcci teorici disponibili in relazione alla depressione e all'ansia, discutere le soluzioni fattoriali che sono state ottenute dai dati raccolti tramite gli strumenti esistenti, considerare quali aree di contenuto del costrutto non sono state adeguatamente indagate dagli strumenti esistenti.
\end{example}

\hypertarget{analisi-concettuale-del-costrutto}{%
\subsection{Analisi concettuale del costrutto}\label{analisi-concettuale-del-costrutto}}

L'analisi concettuale del costrutto è un altro metodo che può essere usato per determinare gli indicatori empirici del costrutto di interesse.

È necessario stabilire quali siano gli attributi del costrutto di interesse, includendo la specificazione degli antecedenti e delle conseguenze che derivano da esso. Si devono identificare tutti gli usi che, nella letteratura specialistica, sono stati fatti del costrutto in esame. Infine, è necessario elencare tutti gli indicatori empirici che siano mai stati utilizzati per il costrutto esaminato.

\begin{example}
Allo scopo di campionare efficacemente l'intero dominio del costrutto, Watson et al.~(2007) hanno definito 20 HIC: Depressed Mood, Loss of Interest or Pleasure, Appetite Disturbance, Sleep Disturbance, Psychomotor Problems, Fatigue/Anergia, Worthlessness/Guilt, Cognitive Problems, Suicidal Ideation, Hopelessness, Melancholic Depression, Angry/Irritable Mood, High Energy/High Positive Affect, Anxious Mood, Worry, Panic, Agoraphobia, Social Anxiety, Traumatic Intrusions, Obsessive-Compulsive Symptoms.

Tredici HIC (per un totale di 117 item) raggruppavano gli indicatori rilevanti per la depressione. Tra questi, nove HICs (per un totale di 79 items) facevano riferimento ai sintomi di base della depressione maggiore così come descritta nel DSM--IV (depressed mood, loss of interest or pleasure, appetite disturbance, sleep disturbance, psychomotor problems, fatigue/anergia, worthlessness and guilt, cognitive problems, suicidal ideation). I quattro rimanenti HIC facevano riferimento alla presenza di sintomi della Hopelessness (Abramson, Metalsky, \& Alloy, 1989), ai sintomi specifici della depressione malinconica (Joiner et al., 2005), allo stato d'animo di rabbia/irritabilità (il quale rappresenta una forma alternativa di depressione tra gli adolescenti; DSM--IV, American Psychiatric Association, 1994, p.~327), e infine ad indicatori di energia e affetto positivo (i quali sono stati specificamente associati alla depressione; Mineka et al., 1998).

Gli altri sette HIC (per un totale di 63 item) sono stati introdotti per valutare sintomi associati all'ansia. Essi sono stati raggruppati nei termini dello stato d'animo ansioso, della worry, del panico, dell'agorafobia, dell'ansia sociale e delle intrusioni traumatiche associate al PTSD.
\end{example}

\hypertarget{metodi-di-ricerca-qualitativi}{%
\subsection{Metodi di ricerca qualitativi}\label{metodi-di-ricerca-qualitativi}}

Metodi di ricerca qualitativi posso anche essere usati allo scopo di identificare i potenziali indicatori empirici del costrutto. In particolare, possono essere usati i metodi della ricerca fenomenologica, dell'indagine naturalistica, i focus group e lo studio del caso singolo.

L'indagine fenomenologica is pone l'obiettivo di descrivere il costrutto dal punto di vista di chi fa di esperienza di esso (Carpenter, 1999). Utili a questo proposito sono ovviamente le descrizioni che i soggetti forniscono della propria esperienza.

Nell'indagine naturalistica, lo psicologo osserva le conseguenze del costrutto così come si manifestano nel mondo naturale. Uno strumento possibile di raccolta dati è l'intervista con il paziente.

Il focus group, originariamente sviluppato in ambito economico per ottenere opinioni su un determinato prodotto (Morse \& Field, 1995), ha le caratteristiche di `a semi-structured group session, moderated by a group leader, held in an informal setting with the purpose of collecting information on a designated topic'' (Carry, 1994, p.~226).

Un'altra possibile fonte di informazioni è costituita dagli studi sul caso singolo.

\hypertarget{lo-sviluppo-dello-strumento}{%
\section{Lo sviluppo dello strumento}\label{lo-sviluppo-dello-strumento}}

Una volta selezionati gli indicatori empirici del costrutto, deve essere scelta una modalità di presentazione che consenta la raccolta efficiente dei dati. Ciascuno strumento può essere descritto in base a sei caratteristiche: (1) formato, (2) composizione tipografica, (3) istruzioni ai soggetti, (4) la costruzione degli item, (5) formato di risposta, e (6) numero di item.

\hypertarget{formato}{%
\subsection{Formato}\label{formato}}

I formati di scala più usati sono lo scaling Thurstoniano, lo scaling di Guttman, le scale a differenziale semantico, le scale di valutazione grafica, semantic differential scales, graphic rating scales, le scale visive di tipo analogico (visual analog scales) e le scale Likert. Ci concentriamo qui sulle scale Likert per la loro importanza nei test psicometrici basati sull'analisi fattoriale.

\hypertarget{scala-likert}{%
\subsubsection{Scala Likert}\label{scala-likert}}

Sviluppata nel 1932 da Rensis Likert per misurare gli atteggiamenti, una scala Likert è una scala ordinale usata dai rispondenti per valutare il grado di accordo o disaccordo con l'affermazione che viene loro proposta. Di solito le alternative di risposta sono cinque o sette, da ``molto d'accordo'' a ``fortemente contrario.''

Essendo una scala ordinale, le risposte possono essere ordinate, ma le distanze tra i livelli della scala non sono quantificabili. Quindi le distanze tra i livelli ``sempre,'' ``spesso'' e ``talvolta'' non sono necessariamente uguali. In altri termini, non possiamo assumere che le differenze tra i livelli di risposta siano equidistanti anche se le differenze tra i valori numerici assegnati ai livelli della scala lo sono.

C'è una lunga controversia sulla possibilità di trattare i valori numerici di una scala ordinale come se essi provenissero da una scala ad intervalli. In altri termini, ci si è chiesti se sia appropriato usare statistiche descrittive quali la media e la deviazione standard per i dati a questo livello di scala, e ci si è chiesti se sia appropriato usare i test parametrici per dati a livello di scala Likert. È risaputo che i test non parametrici, i quali non fanno assunzioni sulla forma della distribuzione della popolazione da cui abbiamo campionato i dati, hanno una potenza statistica nettamente inferiore ai test parametrici. Inoltre, concetti quali quelli di media e varianza non hanno senso se i livelli di una scala Likert non vengono considerati a livello di scala ad intervalli. Per queste ragioni alcuni autori ritengono problematico non potere trattare i dati provenienti da scale di tipo Likert come se fossero a livello di scala ad intervalli.

È stato risposto a tali difficoltà che sufficienti evidenze mostrano come risulti giustificato trattare i dati a livello di scala Likert come se fossero a livello di scala ad intervalli quando la numerosità campionaria è sufficientemente grande e quando i dati si distribuiscono in maniera approssimativamente normale. Altri autori (es. Jöreskog \& Sörbom, 1996) ritengono invece che le scale tipo Likert vadano considerate in ogni caso come ordinali, e debbano essere analizzate di conseguenza. Nel caso dell'analisi fattoriale e dei modelli di equazioni strutturali questo significa semplicemente che l'analisi si deve basare sul calcolo delle correlazioni policoriche.

In conclusione, la procedura che sta alla base delle scale Likert consiste nella somma dei punti attribuiti ad ogni singola domanda. I vantaggi della scala Likert consistono nella sua semplicità e applicabilità, mentre i suoi svantaggi sono il fatto che i suoi elementi vengono trattati come scale cardinali pur essendo ordinali e il fatto che il punteggio finale non rappresenta una variabile cardinale.

\hypertarget{composizione-tipografica}{%
\subsection{Composizione tipografica}\label{composizione-tipografica}}

Criteri da considerare nella formattazione tipografica del test di un test psicometrico sono la facilità di lettura, la chiarezza e l'organizzazione. La formattazione dovrebbe tenere in considerazione l'età dei rispondenti e la potenziale difficoltà di lettura.

\hypertarget{istruzioni-ai-soggetti}{%
\subsection{Istruzioni ai soggetti}\label{istruzioni-ai-soggetti}}

Le istruzioni devono essere chiare e concise. Oltre ad illustrare la consegna, esse forniscono una cornice di riferimento che deve essere comune a tutti i rispondenti. Le istruzioni seguono un formato simile al seguente:

Lo studio ha come obiettivo generale \ldots{} In particolare, con la ricerca che qui presentiamo, si intendono ottenere dati relativi a \ldots{} Nel caso tu decida di partecipare allo studio, questa ricerca prevede l'attuazione dei seguenti trattamenti \ldots{} La ricerca durerà \ldots{} e vi parteciperanno \ldots{} individui. Dalla partecipazione a questa ricerca sono prevedibili i seguenti benefici \ldots{} La partecipazione allo studio non comporta alcun rischio. Sei del tutto libero/a di non partecipare allo studio. La tua adesione a questo programma di ricerca è completamente volontaria e potrà essere ritirata in qualsiasi momento.

Ai sensi del Decreto Legislativo 30 giugno 2003 n.~196 in materia di protezione dei dati personali, tratteranno i tuoi dati esclusivamente in funzione della realizzazione dello studio. Lo psicologo che ti seguirà nello studio ti identificherà con un codice: i dati che ti riguardano raccolti nel corso dello studio, ad eccezione del nominativo, saranno registrati, elaborati e conservati unitamente a tale codice, alla data di nascita, al genere. Soltanto il supervisore del progetto di ricerca potrà collegare questo codice al tuo nominativo. I dati, trattati mediante strumenti anche elettronici, saranno diffusi solo in forma rigorosamente anonima, ad esempio attraverso pubblicazioni scientifiche, statistiche e convegni scientifici. La tua partecipazione allo studio implica che il gruppo di ricerca che organizza lo studio e il Comitato etico potranno conoscere i dati che ti riguardano solo attraverso modalità tali da garantire la riservatezza della tua identità.

Potrai esercitare i diritti di cui all'art. 7 del Codice in materia di protezione dei Dati Personali (es. accedere ai tuoi dati personali, integrarli, aggiornarli, rettificarli, opporsi al loro trattamento per motivi legittimi, ecc.) rivolgendoti direttamente al responsabile della ricerca. Potrai interrompere in ogni momento e senza fornire alcuna giustificazione la tua partecipazione allo studio: in tal caso, i dati raccolti verranno distrutti.

Se lo richiederai, alla fine dello studio potranno esserti comunicati i risultati ottenuti in generale e, in particolare, quelli che ti riguardano. Per ulteriori informazioni e comunicazioni durante la ricerca puoi rivolgerti a \ldots{}

Potrai segnalare qualsiasi fatto che riterrai opportuno evidenziare, relativamente alla ricerca che ti riguarda, al Comitato Etico dell'Università degli Studi di Firenze. La segnalazione dovrà essere inoltrata all'attenzione di \ldots{}

È inoltre necessario che i partecipanti completino una dichiarazione di assenso (consenso informato). Ad esempio:

Io sottoscritto \ldots{} dichiaro di aver ricevuto dal Dottor \ldots{} esaurienti spiegazioni in merito alla richiesta di partecipazione alla ricerca in oggetto, secondo quanto riportato nella scheda informativa qui allegata, copia della quale mi è stata prima d'ora consegnata (indicare data e ora della consegna).

Dichiaro altresì di aver potuto discutere tali spiegazioni, porre tutte le domande che ho ritenuto necessarie e di aver ricevuto risposte soddisfacenti, come pure di aver avuto la possibilità di informarmi in merito ai particolari dello studio con persona di mia fiducia.

Accetto dunque liberamente di partecipare alla ricerca, avendo compreso completamente il significato della richiesta e i rischi e benefici che possono derivare da questa partecipazione. Acconsento al trattamento dei miei dati personali per gli scopi della ricerca nei limiti e con le modalità indicate nell'informativa fornitami con il presente documento.

Sono stato informato/a, inoltre, del mio diritto ad avere libero accesso alla documentazione relativa alla ricerca ed alla valutazione espressa dal Comitato Etico dell'Università degli Studi di Firenze.

\hypertarget{la-costruzione-degli-item}{%
\subsection{La costruzione degli item}\label{la-costruzione-degli-item}}

La scelta di item tecnicamente adeguati sul piano strutturale e linguistico non è un problema statistico. La formulazione verbale degli item è molto importante in quanto essa contribuisce all'errore di misura. Per ridurre gli errori di misura, gli item devono essere formulati nella forma più chiara e meno ambigua possibile. È ovviamente necessario impiegare contenuti coerenti con la definizione del costrutto, ma non ci sono regole semplici per generare item che fanno emergere il costrutto che si cerca di misurare. Vanno certamente evitati contenuti che inducano atteggiamenti difensive e/o ostili nei rispondenti. La formulazione verbale deve inoltre essere appropriata al livello di scolarità dei rispondenti. Pett, Lackey e Sullivan (2003) forniscono le raccomandazioni seguenti.

\begin{itemize}
\tightlist
\item
  Evitare affermazioni che si riferiscono al passato a meno che il costrutto faccia direttamente riferimento al passato.
\item
  Evitare affermazioni fattuali. Evitare affermazioni su cui quasi tutti (o quasi nessuno) sono d'accordo.
\item
  Evitare l'uso di pronomi personali con un significato ambiguo.
\item
  Selezionare item che potenzialmente possano coprire l'intera gamma delle possibili risposte concernenti il costrutto di interesse.
\item
  Se viene fatto riferimento ad argomenti sensibili, la formulazione verbale deve essere la più neutra possibile.
\item
  Utilizzare un linguaggio chiaro, semplice, diretto. Utilizzare frasi corte, altrimenti non ne è chiaro il senso.
\item
  Evitare affermazioni ambigue o interpretabili in più modi.
\item
  Evitare formulazioni sintattiche complesse.
\item
  Evitare l'uso di parole a bassa frequenza o l'uso di una terminologia che potrebbe non essere capita dai rispondenti.
\item
  Disporre gli item aventi un contenuto sensibile verso la fine dello strumento.
\item
  Fare riferimento a comportamenti specifici e non generali.
\item
  Evitare la duplicazione delle domande.
\end{itemize}

\hypertarget{desiderabilituxe0-sociale}{%
\subsubsection{Desiderabilità sociale}\label{desiderabilituxe0-sociale}}

Quando si sviluppa lo strumento è necessario tenere in considerazione il fatto che i rispondenti tendono a fornire risposte socialmente desiderabili piuttosto che risposte veritiere (Rosenthal \& Rosnow, 1991; Waltz et al., 1991). La Desiderabilità sociale non soltanto introduce dei bias nello strumento ma può anche comprometterne la validità.

La Desiderabilità Sociale si riferisce al bisogno provato da alcuni individui di approvazione sociale e accettazione, e alla credenza di poterle ottenere attraverso comportamenti appropriati e culturalmente accettati (Marlowe \& Crowne, 1961). La Desiderabilità Sociale consiste nella tendenza a fornire risposte molto positive quando vengono poste domande su di sé, con l'obiettivo di risultare positivamente agli occhi dell'altro. Marlowe e Crowne (1960) hanno proposto la scala di valutazione MC-SCS (Marlowe-Crowne Social Desirability Scale), largamente utilizzata per indagare questo costrutto. Un'altra scala di valutazione molto utilizzata è la BIDR (Balanced Inventory of Desirable Responding, 1991) proposta da Paulhus: tale scala contiene 40 item, volti a rilevare la gestione delle impressioni e l'autoinganno.

\hypertarget{item-marker}{%
\subsubsection{Item marker}\label{item-marker}}

Quando si anticipa la presenza di più costrutti latenti, è utile utilizzare nell'insieme degli item alcuni item marker, ovvero item che correlano molto con un solo fattore e pochissimo con altri. Questo facilità l'interpretazione dei fattori. I marker consentono infatti di attribuire ai fattori un nome (etichetta) coerente con l'area semantica cui i maker fanno riferimento.

\hypertarget{campionamento-del-dominio}{%
\subsubsection{Campionamento del dominio}\label{campionamento-del-dominio}}

Il campionamento del dominio può essere inteso sia come campionamento del contenuto o come campionamento del comportamento. L'adeguatezza del campionamento del contenuto riguarda il fatto che l'insieme degli item sia o meno in grado di rappresentare il dominio di contenuto di interesse. Questa caratteristica è un indice dell'adeguatezza del test nel misurare ciò che intende misurare e dovrebbe garantire che le risposte agli item possano rappresentare una stima della quantità di costrutto posseduta dal rispondente.

Il campionamento del comportamento riguarda invece il grado in cui le risposte a un test costituiscono un campione adeguato dei comportamenti che il test intende misurare. In questo caso ci si chiede se il test riflette i comportamenti che intende valutare e possiede dunque un valore descrittivo del comportamento del rispondente.

Un item mal formulato determina una distorsione delle risposte e non può essere considerato rappresentativo di nessun dominio di contenuto né di nessun universo di comportamenti.

Per la generazione iniziale degli item è molto importante considerare il parere della popolazione target e degli esperti. Interviste accuratamente strutturate e a risposta aperta con esperti o potenziali soggetti permettono non solo di verificare che gli item siano rappresentativi o rilevanti per il costrutto, ma anche che siano formulati correttamente. Questo processo può anche suggerire sfaccettature ulteriori rispetto a quelle progettate inizialmente e la necessità di raffinare il costrutto. Nello sviluppo di un test è molto utile ascoltare il parere di persone inserite nel contesto applicativo del test anche per sapere qual è la terminologia specifica da utilizzare nella formulazione degli item, o se gli item sono chiari, o se la scala di risposta è di facile compilazione.

È anche utile rivolgersi a giudici esterni aventi una conoscenza approfondita del dominio di contenuto per ottenere una prospettiva esterna e autorevole che aiuti nell'individuazione degli item da eliminare e di quelli che richiedono un raffinamento.

Gli item di un test dovrebbero essere distribuiti in modo che riflettano la relativa importanza delle varie sfaccettature del costrutto target (Nunnally \& Bernstein, 1994). Se gli item per una certa sfaccettatura sono troppi o troppo pochi, i punteggi e le inferenze ottenute da questi punteggi saranno distorte.

\hypertarget{numero-delle-opzioni-di-risposta}{%
\section{Numero delle opzioni di risposta}\label{numero-delle-opzioni-di-risposta}}

Un item è costituito da due parti: l'item stem, cioè il testo che contiene la domanda o l'affermazione da valutare e le alternative di risposta.

In una scala di tipo Likert, le categorie di risposta si dicono a parziale autonomia semantica, ovvero sono tali per cui le modalità di risposta devono essere confrontate con le altre affinché il rispondente sia in grado di stabilire il loro valore. A ciascuna modalità di risposta viene attribuito un punteggio (4, 3, 2, 1 oppure 3, 2, 1, 0), e la somma (o media) dei punteggi alle risposte di ciascun individuo sull'intera batteria rappresenta la posizione dell'individuo sul concetto indagato.

Per esempio,

\[\text{Fortemente d'accordo} \quad 7\quad 6 \quad 5 \quad 4 \quad 3 \quad 2 \quad 1 \quad \text{Fortemente in disaccordo}\] oppure,

\[\text{Molto} \quad \text{Abbastanza}\quad \text{Poco} \quad \text{Per niente}\]

Il numero ottimale delle opzioni di risposta è stato dibattuto a lungo. Per esempio, Schutz e Rucker (1975) hanno trovato che ``the number of available response categories does not materially affect the cognitive structure derived from the results'' (p.~323), il che suggerisce che il numero di opzioni di risposta ha poco effetto sui risultati ottenuti. Tale conclusione, tuttavia, è stata contraddetta da altri ricercatori. Per esempio, Garner (1960) ha suggerito risultati massimamente informativi si ottengono utilizzando più di 20 opzioni di risposta. D'altra parte, Green e Rao (1970), hanno trovato che i risultati migliori si ottengono con sei o sette alternative di risposta, con un guadagno molto piccolo all'aumentare delle categorie di risposta al di là di sette. In un articolo molto citato, Preston e Colman (2000) hanno esaminato le risposte fornite da un campione di rispondenti variando il numero di opzioni di risposta pari a 2, 3, \ldots, 11, e 101. Dopo avere calcolato l'attendibilità test-retest e la validità dello strumento, oltre al potere discriminante degli item, hanno concluso che le scale a 2, 3 e 4 passi hanno prestazioni piuttosto basse, avendo gli indici calcolati valori molto maggiori per le scale di risposta con un numero maggiore di opzioni di risposta. In particolare, i risultati dello studio suggeriscono che scale di valutazione con 7, 9 o 10 opzioni di risposta sono da preferire rispetto ad altri numeri di alternative di risposta.

Oltre alle scale Likert è possibile usare le risposte auto-ancoranti, ovvero quelle in cui gli item prevedono solo due aggettivi di risposta, estremi (per esempio, ``per niente'' e ``molto''), legati da un segmento continuo in cui il rispondente deve scegliere la propria posizione. Un esempio è la Visual Analogue Scale usata nella misura dell'umore. Tali scale sono molto più rare delle scale Likert.

\hypertarget{item-a-codifica-inversa}{%
\subsection{Item a codifica inversa}\label{item-a-codifica-inversa}}

Alcuni item correlano fortemente in maniera negativa con gli altri item e con il punteggio totale del test. Tali item richiedono una codifica inversa. Ad esempio, due item del questionario S.T.A.I per la valutazione dell'ansia sono codificati nel modo seguente.

``Sono preoccupata.''

\[\text{Per nulla} \quad \text{Un po'}\quad \text{Abbastanza} \quad \text{Moltissimo}\]

con valori 1, 2, 3 e 4, rispettivamente.

``Mi sento bene.''

\[\text{Per nulla} \quad \text{Un po'}\quad \text{Abbastanza} \quad \text{Moltissimo}\]

con valori 4, 3, 2, e 1, rispettivamente.

In ambito psicometrico si è soliti ritenere che due proprietà contrarie giacciano sullo stesso continuum latente. Nella costruzione di un test psicologico viene dunque consigliato di utilizzare sia item con contenuto orientato nella direzione del costrutto (per cui punteggi alti nell'item sono il riflesso di un alto livello del costrutto) sia nella direzione opposta (per cui punteggi alti nell'item sono il riflesso di un basso livello del costrutto). Nel primo caso si parla di \emph{straight item}, nel secondo di \emph{reverse item}. Lo scopo centrale degli item reverse è quello di contrastare l'acquiescenza, ovvero di rallentare il soggetto nella compilazione del test, evitando di rispondere in maniera automatica, così da prestare maggiore attenzione al contenuto degli item.

\hypertarget{numero-di-item}{%
\section{Numero di item}\label{numero-di-item}}

Un test psicometrico, oltre ad essere valido, deve minimizzare l'errore di misura. L'attendibilità di uno strumento sia dall'attendibilità di ciascun item, sia dal numero di item che lo compongono. Tratteremo di questo argomento in un capitolo successivo.

Kline (1986) suggerisce di costruire un numero di item almeno doppio del numero di item che andranno a costituire il test finale. La lunghezza del test dipende dal suo scopo. Un Test di valutazione delle abilità per la scuola primaria non deve richiedere più di trenta minuti per essere completato, altrimenti la fatica e la noia finiscono per distorcere i risultati dello strumento. Lo stesso si può dire per un test di personalità per soggetti adulti. Idealmente, un test dovrebbe essere il più breve possibile, a patto di raggiungere un livello adeguato di validità. Come regola euristica, Kline (1986) suggerisce la soglia di almeno 50 item nella forma finale del test.

\hypertarget{numero-di-soggetti}{%
\section{Numero di soggetti}\label{numero-di-soggetti}}

Vi è poco accordo su quale sia la grandezza del campione necessaria per lo svolgimento dell'analisi fattoriale. Nunnally (1978) ha suggerito che il campione deve essere costituito da almeno 10 soggetti per ciascun item. Comrey e Lee (1992) hanno fornito le seguenti indicazioni: 50---very poor, 100---poor, 200---fair, 300---good, 500---very good, 1,000 or more---excellent. Secondo altri autori ``as a general rule of thumb, it is comforting to have at least 300 cases for factor analysis'' (Tabachnick e Fidell, 2001).

\hypertarget{ch:val_matrici}{%
\chapter{Valutazione della matrice di correlazione}\label{ch:val_matrici}}

L'analisi fattoriale, essendo una tecnica di analisi multivariata, richiede la comprensione di almeno alcuni concetti di base dell'algebra matriciale. A livello minimale è necessario capire che cosa sono i vettori e le matrici, che cosa è il determinante di una matrice, e in che modo possano essere eseguite le operazioni algebriche su vettori e matrici (si veda l'Appendice).

Dopo avere padroneggiato gli aspetti di base dell'algebra matriciale, possiamo valutare il determinante della matrice da fattorializzare: se il determinante è nullo non si può fare l'analisi. Se invece il determinante non è nullo, ci possiamo chiedere se le correlazioni campionarie siano sufficientemente grandi da giustificare l'analisi fattoriale. Se le correlazioni tra gli item sono di modesta entità, allora la soluzione fornita dall'analisi fattoriale non consentirà una descrizione parsimoniosa delle informazioni contenute nella matrice delle correlazioni. Per rispondere a questa domanda si ricorre all'ispezione visiva della matrice di correlazione e si possono svolgere due test: il test della sfericità di Bartlett e il Kaiser-Meyer-Olkin test.

\hypertarget{ispezione-visiva-della-matrice-di-correlazione}{%
\section{Ispezione visiva della matrice di correlazione}\label{ispezione-visiva-della-matrice-di-correlazione}}

L'ispezione visiva della matrice di correlazione viene effettuata per vedere che vi siano blocchi di correlazioni alte fra loro e basse con le alte.

\hypertarget{sfericituxe0-di-bartlett}{%
\section{Sfericità di Bartlett}\label{sfericituxe0-di-bartlett}}

Il test della sfericità di Bartlett verifica l'ipotesi \(H_0 : \boldsymbol{R} = \boldsymbol{I}\) (ovvero che gli item siano tra loro incorrelati) tramite la formula:

\[\chi^2 = -\bigg[n -1 -\frac{1}{6} (2p +5)\bigg] \ln |\boldsymbol{R}|,\]

in cui \(n\) è il numero dei soggetti, \(p\) il numero delle variabili e \(|\boldsymbol{R}|\) il determinante della matrice di correlazione. La statistica del test della sfericità di Bartlett si distribuisce come \(\chi^2\) con \(p(p - 1)/2\) gradi di libertà. Se il risultato del test è significativo (ovvero, se il valore della statistica test è sufficientemente grande), significa che \(\boldsymbol{R}\) ha correlazioni sufficientemente elevate da non essere paragonabili a 0; se è non significativo le correlazioni sono basse e non si distinguono da 0. Il limite di questo test è che dipende dal numero delle variabili e dalla numerosità del campione, quindi tende ad essere significativo all'aumentare del campione e del numero delle variabili anche se ci sono correlazioni basse.

\hypertarget{test-di-adeguatezza-campionaria-di-kaiser-meyer-olkin}{%
\section{Test di adeguatezza campionaria di Kaiser-Meyer-Olkin}\label{test-di-adeguatezza-campionaria-di-kaiser-meyer-olkin}}

Henry Kaiser (1970) ha introdotto una misura di adeguatezza campionaria per le matrici sottoposte ad analisi fattoriale. In seguito, Kaiser and Rice (1974) hanno modificato questo indice che da allora è conosciuto come l'indice Kaiser-Meyer-Olkin (KMO). Il test di adeguatezza campionaria KMO è dato da

\[\text{KMO} = \frac{\sum_i\sum_j r^2_{ij}}{\sum_i\sum_j r^2_{ij} +\sum_i\sum_jp^2_{ij}},\]

dove \(r_{ij}\) sono le correlazioni osservate e \(p_{ij}\) sono le correlazioni parzializzate su tutte le altre. Se le correlazioni parzializzate sono piccole, KMO tende a 1. Secondo Kaiser (1970), se KMO \textgreater{} 0.90, l'adeguatezza campionaria è eccellente, fra .80 e .90 è buona, fra .70 e .80 è accettabile, fra .60 e .70 è mediocre, se è inferiore a .60 è meglio non fare l'analisi.

\hypertarget{matrice-anti-immagine}{%
\subsection{Matrice anti-immagine}\label{matrice-anti-immagine}}

La matrice delle correlazioni parzializzate riporta il valore di ogni correlazione dopo aver eliminato il contributo di tutte le altre variabili non implicate. Una correlazione parzializzata alta significa che due variabili sono molto correlate fra loro, ma non hanno legami con nessun altra variabile. L'analisi fattoriale richiede invece che ci siano più di due variabili per fattore. La matrice anti-immagine contiene i complementi a 1 della correlazione parzializzata fra due variabili rispetto a tutte e altre. Valori alti indicano correlazioni parziali basse e viceversa.

\hypertarget{ch:estrazione}{%
\chapter{L'estrazione dei fattori}\label{ch:estrazione}}

\hypertarget{motivazione}{%
\section*{Motivazione}\label{motivazione}}


Lo scopo dell'analisi fattoriale è quello di descrivere in maniera parsimoniosa le relazioni che intercorrono tra un grande numero di item. Ci si chiede se è possibile identificare un piccolo numero di variabili latenti che, quando vengono controllate, rendono uguali a zero le correlazioni parziali tra gli item. Abbiamo visto nel capitolo precedente come sia possibile determinare il numero dei fattori comuni. Chiediamoci ora come sia possibile stimare le saturazioni fattoriali che corrispondono alle correlazioni (o covarianze) tra gli item e i fattori.

In termini matriciali, il modello multifattoriale si scrive

\[
\boldsymbol{\Sigma} =\boldsymbol{\Lambda} \boldsymbol{\Phi} \boldsymbol{\Lambda}^{\mathsf{T}} + \boldsymbol{\Psi} 
\]

dove \(\boldsymbol{\Phi}\) è la matrice di ordine \(m \times m\) di varianze e covarianze tra i fattori comuni e \(\boldsymbol{\Psi}\) è una matrice diagonale di ordine \(p\) con le unicità delle variabili. Poniamoci ora il problema di stimare \(\boldsymbol{\Lambda}\).

\hypertarget{metodo-delle-componenti-principali}{%
\section{Metodo delle componenti principali}\label{metodo-delle-componenti-principali}}

L'analisi fattoriale eseguita mediante il metodo delle componenti principali, nonostante il nome, non è un'analisi delle componenti principali. Il metodo delle componenti principali costituisce invece un'applicazione del teorema di scomposizione spettrale di una matrice. Il \emph{teorema spettrale} afferma che ``data la matrice simmetrica \(\textbf{S}_{p \times p}\), è sempre possibile trovare una matrice \(\textbf{C}_{p \times p}\) ortogonale tale che

\[
\textbf{S} = \textbf{C}\textbf{D}\textbf{C}^{\mathsf{T}}
\] con \textbf{D} diagonale.'' Il teorema specifica inoltre che gli elementi presenti sulla diagonale di \textbf{D} sono gli autovalori di \textbf{S}, mentre le colonne di \textbf{C} rappresentano i rispettivi autovettori normalizzati associati agli autovalori di \textbf{S}.

Facciamo un esempio numerico utilizzando i dati discussi da Rencher(2002). Brown, Williams e Barlow (1984) hanno raccolto le valutazioni di una ragazza dodicenne relativamente a sette persone di sua conoscenza. Ciascuna persona veniva valutata su una scala a nove punti rispetto a cinque variabili: \emph{kind}, \emph{intelligent}, \emph{happy}, \emph{likeable} e \emph{just}. La matrice di correlazione per tali variabili è riportata di seguito:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{R }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{c}\NormalTok{(}
  \FloatTok{1.000}\NormalTok{, .}\DecValTok{296}\NormalTok{, .}\DecValTok{881}\NormalTok{, .}\DecValTok{995}\NormalTok{, .}\DecValTok{545}\NormalTok{,}
\NormalTok{  .}\DecValTok{296}\NormalTok{, }\FloatTok{1.000}\NormalTok{, }\SpecialCharTok{{-}}\NormalTok{.}\DecValTok{022}\NormalTok{, .}\DecValTok{326}\NormalTok{, .}\DecValTok{837}\NormalTok{,}
\NormalTok{  .}\DecValTok{881}\NormalTok{, }\SpecialCharTok{{-}}\NormalTok{.}\DecValTok{022}\NormalTok{, }\FloatTok{1.000}\NormalTok{, .}\DecValTok{867}\NormalTok{, .}\DecValTok{130}\NormalTok{,}
\NormalTok{  .}\DecValTok{995}\NormalTok{, .}\DecValTok{326}\NormalTok{, .}\DecValTok{867}\NormalTok{, }\FloatTok{1.000}\NormalTok{, .}\DecValTok{544}\NormalTok{,}
\NormalTok{  .}\DecValTok{545}\NormalTok{, .}\DecValTok{837}\NormalTok{, .}\DecValTok{130}\NormalTok{, .}\DecValTok{544}\NormalTok{, }\FloatTok{1.000}
\NormalTok{),}
\AttributeTok{ncol =} \DecValTok{5}\NormalTok{, }\AttributeTok{byrow =}\NormalTok{ T, }\AttributeTok{dimnames =} \FunctionTok{list}\NormalTok{(}
  \FunctionTok{c}\NormalTok{(}\StringTok{"K"}\NormalTok{, }\StringTok{"I"}\NormalTok{, }\StringTok{"H"}\NormalTok{, }\StringTok{"L"}\NormalTok{, }\StringTok{"J"}\NormalTok{),}
  \FunctionTok{c}\NormalTok{(}\StringTok{"K"}\NormalTok{, }\StringTok{"I"}\NormalTok{, }\StringTok{"H"}\NormalTok{, }\StringTok{"L"}\NormalTok{, }\StringTok{"J"}\NormalTok{)}
\NormalTok{)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Gli autovalori e gli autovettori si calcolano con la funzione \texttt{eigen()}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{e }\OtherTok{\textless{}{-}} \FunctionTok{eigen}\NormalTok{(R)}
\FunctionTok{print}\NormalTok{(e, }\DecValTok{3}\NormalTok{)}
\CommentTok{\#\textgreater{} eigen() decomposition}
\CommentTok{\#\textgreater{} $values}
\CommentTok{\#\textgreater{} [1] 3.263377 1.538382 0.167969 0.030030 0.000242}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} $vectors}
\CommentTok{\#\textgreater{}        [,1]   [,2]    [,3]   [,4]   [,5]}
\CommentTok{\#\textgreater{} [1,] {-}0.537 {-}0.186 {-}0.1899 {-}0.125  0.791}
\CommentTok{\#\textgreater{} [2,] {-}0.287  0.651  0.6849 {-}0.120  0.103}
\CommentTok{\#\textgreater{} [3,] {-}0.434 {-}0.474  0.4069  0.614 {-}0.212}
\CommentTok{\#\textgreater{} [4,] {-}0.537 {-}0.169 {-}0.0953 {-}0.629 {-}0.527}
\CommentTok{\#\textgreater{} [5,] {-}0.390  0.538 {-}0.5658  0.444 {-}0.204}
\end{Highlighting}
\end{Shaded}

Come indicato in precedenza, la matrice \textbf{R} può essere espressa come \(\textbf{R} = \textbf{C}\textbf{D}\textbf{C}^{\ensuremath{\mathsf{T}}}\):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{e}\SpecialCharTok{$}\NormalTok{vectors }\SpecialCharTok{\%*\%} \FunctionTok{diag}\NormalTok{(e}\SpecialCharTok{$}\NormalTok{values) }\SpecialCharTok{\%*\%} \FunctionTok{t}\NormalTok{(e}\SpecialCharTok{$}\NormalTok{vectors)}
\CommentTok{\#\textgreater{}       [,1]   [,2]   [,3]  [,4]  [,5]}
\CommentTok{\#\textgreater{} [1,] 1.000  0.296  0.881 0.995 0.545}
\CommentTok{\#\textgreater{} [2,] 0.296  1.000 {-}0.022 0.326 0.837}
\CommentTok{\#\textgreater{} [3,] 0.881 {-}0.022  1.000 0.867 0.130}
\CommentTok{\#\textgreater{} [4,] 0.995  0.326  0.867 1.000 0.544}
\CommentTok{\#\textgreater{} [5,] 0.545  0.837  0.130 0.544 1.000}
\end{Highlighting}
\end{Shaded}

Esaminiamo ora gli autovalori. I primi due autovalori spiegano da soli il 96\% della varianza campionaria:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(e}\SpecialCharTok{$}\NormalTok{values[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{+}\NormalTok{ e}\SpecialCharTok{$}\NormalTok{values[}\DecValTok{2}\NormalTok{]) }\SpecialCharTok{/} \DecValTok{5}
\CommentTok{\#\textgreater{} [1] 0.9604}
\end{Highlighting}
\end{Shaded}

Usando i primi due autovalori e i primi due autovettori sarà dunque possibile riprodurre in maniera soddisfacente la matrice \textbf{R} operando nel contempo una riduzione di dimensionalità dei dati.

Per fattorizzare \(\textbf{R} = \textbf{C}\textbf{D}\textbf{C}^{\ensuremath{\mathsf{T}}}\) nella forma \(\hat{\boldsymbol{\Lambda}} \hat{\boldsymbol{\Lambda}}^{\ensuremath{\mathsf{T}}}\) iniziamo a scrivere

\[\textbf{D}= \textbf{D}^{1/2} \textbf{D}^{1/2}\]

dove

\[
\textbf{D}^{1/2} = 
\left[
  \begin{array}{ c c c c }
     \sqrt{\theta_1} & 0 & \dots & 0 \\
     0 & \sqrt{\theta_2} & \dots & 0 \\
     \dots & \dots & & \dots \\
     0 & 0 & \dots &  \sqrt{\theta_p}
  \end{array} 
\right]
\]

Viene qui usata la notazione \(\theta\) per denotare gli autovalori anziché il tradizionale \(\lambda\) per evitare la confusione con la notazione \(\lambda_{jl}\) usata per le saturazioni fattoriali. In questo modo, possiamo scrivere

\begin{equation}
\begin{aligned}
\textbf{R} &= \textbf{C}\textbf{D}\textbf{C}^{\mathsf{T}}\notag\\
&= \textbf{C}\textbf{D}^{1/2}\textbf{D}^{1/2}\textbf{C}^{\mathsf{T}}\notag\\
&= (\textbf{C}\textbf{D}^{1/2}) (\textbf{C}\textbf{D}^{1/2})^{\mathsf{T}}
\end{aligned}
\end{equation}

Non possiamo però limiarci a definire \(\hat{\boldsymbol{\Lambda}}=\textbf{C}\textbf{D}^{1/2}\) in quanto \(\textbf{C}\textbf{D}^{1/2}\) è di ordine \(p \times p\) e non otteniamo quindi una riduzione di dimensioni. Quello che cerchiamo è una matrice \(\hat{\boldsymbol{\Lambda}}\) di ordine \(p \times m\) con \(m < p\). Dunque, definiamo la matrice \(\textbf{D}_1= \text{diag}(\theta_1, \theta_2, \dots, \theta_m)\) come la la matrice contenente gli \(m\) autovalori più grandi di \textbf{R} e \(\textbf{C}_1=( \textbf{c}_1, \textbf{c}_2, \dots, \textbf{c}_m)\) come la matrice contenente i rispettivi autovettori. Mediante il metodo delle componenti principali, le saturazioni fattoriali \(\hat{\boldsymbol{\Lambda}}\) vengono quindi stimate nel modo seguente:

\begin{equation}
\begin{aligned}
\hat{\boldsymbol{\Lambda}} &= \textbf{C}_1 \textbf{D}_1^{1/2}\notag\\
&= (\sqrt{\theta_1} \textbf{c}_1, \sqrt{\theta_2} \textbf{c}_2, 
\dots, \sqrt{\theta_m} \textbf{c}_m) 
\end{aligned}
\end{equation}

Per l'esempio presente, con \(m=2\) e \(p=5\), avremo

\[
\left[
  \begin{array}{ c c }
 \hat{\lambda}_{11} & \hat{\lambda}_{12} \\
 \hat{\lambda}_{21} & \hat{\lambda}_{22} \\
 \hat{\lambda}_{31} & \hat{\lambda}_{32} \\
 \hat{\lambda}_{41} & \hat{\lambda}_{42} \\
 \hat{\lambda}_{51} & \hat{\lambda}_{52} 
  \end{array} 
\right] =
\left[
  \begin{array}{ c c }
 c_{11} & c_{12} \\
 c_{21} & c_{22} \\
 c_{31} & c_{32} \\
 c_{41} & c_{42} \\
 c_{51} & c_{52} 
  \end{array} 
\right]
\left[
  \begin{array}{ c c }
 \sqrt{\theta_1} & 0\\
 0 &\sqrt{\theta_2} 
  \end{array} 
\right]
\]

Le saturazioni fattoriali stimate sono dunque uguali a

\[
\left[
  \begin{array}{ c c }
 \sqrt{\theta_1}c_{11} & \sqrt{\theta_2}c_{12} \\
 \sqrt{\theta_1}c_{21} & \sqrt{\theta_2}c_{22} \\
 \sqrt{\theta_1}c_{31} & \sqrt{\theta_2}c_{32} \\
 \sqrt{\theta_1}c_{41} & \sqrt{\theta_2}c_{42} \\
 \sqrt{\theta_1}c_{51} & \sqrt{\theta_2}c_{52} 
  \end{array} 
\right]
\]

Svolgendo i calcoli con \(\textsf{R}\) otteniamo:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{L }\OtherTok{\textless{}{-}} \FunctionTok{cbind}\NormalTok{(}
\NormalTok{  e}\SpecialCharTok{$}\NormalTok{vectors[, }\DecValTok{1}\NormalTok{] }\SpecialCharTok{*} \FunctionTok{sqrt}\NormalTok{(e}\SpecialCharTok{$}\NormalTok{values[}\DecValTok{1}\NormalTok{]),}
\NormalTok{  e}\SpecialCharTok{$}\NormalTok{vectors[, }\DecValTok{2}\NormalTok{] }\SpecialCharTok{*} \FunctionTok{sqrt}\NormalTok{(e}\SpecialCharTok{$}\NormalTok{values[}\DecValTok{2}\NormalTok{])}
\NormalTok{)}

\FunctionTok{round}\NormalTok{(L, }\DecValTok{3}\NormalTok{)}
\CommentTok{\#\textgreater{}        [,1]   [,2]}
\CommentTok{\#\textgreater{} [1,] {-}0.970 {-}0.231}
\CommentTok{\#\textgreater{} [2,] {-}0.519  0.807}
\CommentTok{\#\textgreater{} [3,] {-}0.785 {-}0.588}
\CommentTok{\#\textgreater{} [4,] {-}0.971 {-}0.210}
\CommentTok{\#\textgreater{} [5,] {-}0.704  0.667}
\end{Highlighting}
\end{Shaded}

La matrice di correlazione riprodotta (con le comunalità sulla diagonale principale) diventa

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{round}\NormalTok{(L }\SpecialCharTok{\%*\%} \FunctionTok{t}\NormalTok{(L), }\DecValTok{3}\NormalTok{)}
\CommentTok{\#\textgreater{}       [,1]   [,2]   [,3]  [,4]  [,5]}
\CommentTok{\#\textgreater{} [1,] 0.993  0.317  0.896 0.990 0.529}
\CommentTok{\#\textgreater{} [2,] 0.317  0.921 {-}0.067 0.335 0.904}
\CommentTok{\#\textgreater{} [3,] 0.896 {-}0.067  0.961 0.885 0.160}
\CommentTok{\#\textgreater{} [4,] 0.990  0.335  0.885 0.987 0.543}
\CommentTok{\#\textgreater{} [5,] 0.529  0.904  0.160 0.543 0.940}
\end{Highlighting}
\end{Shaded}

Possiamo ora capire il motivo del nome ``metodo delle componenti principali.'' Le saturazioni fattoriali sono proporzionali agli autovettori di \(\textbf{R}\). Tuttavia, dopo la rotazione delle saturazioni fattoriali, l'interpretazione dei fattori è diversa da quella che viene assegnata ai risultai dell'analisi delle componenti principali.

È possibile condurre l'analisi fattoriale con il metodo delle componenti principali sia utilizzando la matrice \(\textbf{S}\) di varianze-covarianze sia la matrice \(\textbf{R}\) delle correlazioni. Tuttavia, le soluzioni ottenute usando \(\textbf{S}\) o \(\textbf{R}\) non sono legate da una relazione algebrica: il metodo delle componenti principali non è invariante rispetto ai cambiamenti di scala delle osservazioni. Un altro svantaggio del metodo delle componenti principali è che non fornisce un test di bontà di adattamento. Tale test può essere invece svolto quando la soluzione viene trovata con il metodo della massima verosimiglianza.

\hypertarget{metodo-dei-fattori-principali}{%
\section{Metodo dei fattori principali}\label{metodo-dei-fattori-principali}}

Il \emph{metodo dei fattori principali} (\emph{principal factor method}, anche detto \emph{principal axis method}) è uno dei metodi maggiormente usati per la stima delle saturazioni fattoriali e delle comunalità. Il metodo delle componenti principali trascura la specificità \(\boldsymbol{\Psi}\) e si limita a fattorializzare le covarianze di \textbf{S} o le correlazioni di \textbf{R}. Il metodo dei fattori principali utilizza una procedura simile al metodo delle componenti principali, utilizzando però una matrice ridotta di varianze-covarianze \(\textbf{S} -  \hat{\boldsymbol{\Psi}}\) in cui una stima delle comunalità viene sostituita alle varianze presenti sulla diagonale principale. Nel caso della matrice ridotta di correlazioni \(\textbf{R} - \hat{\boldsymbol{\Psi}}\), per la comunalità \(i\)-esima \(\sum_{j}\lambda_{ij}^2\) si sceglie il quadrato del coefficiente di correlazione multipla tra \(Y_i\) e tutte le altre \(p-1\) variabili. Tale valore si può trovare nel modo seguente:

\[\hat{h}^2_i=R^2_i=1-\frac{1}{r^{ii}}\]

dove \(r^{ii}\) è l'elemento diagonale \(i\)-esimo di \(\textbf{R}^{-1}\). Nel caso di una matrice ridotta di varianze-covarianze \(\textbf{S} - \hat{\boldsymbol{\Psi}}\), le comunalità possono essere stimate calcolando

\[\hat{h}_i^2=s_{ii}-\frac{1}{r^{ii}}\]

dove \(s_{ii}\) è l'elemento diagonale \(i\)-esimo di \(\textbf{S}\).

Affinché le stime comunalità possano essere calcolate come descritto sopra, la matrice \(\textbf{R}\) deve essere non singolare. Nel caso in cui \(\textbf{R}\) sia singolare, per la stima della comunalità \(i\)-esima, \(\hat{h}^2_i\), si utilizza il valore assoluto del più elevato coefficiente di correlazione lineare tra \(Y_i\) e le altre variabili.

Scelta la stima della comunalità, la matrice ridotta di varianze-covarianze si ottiene sostituendo alle varianze sulla diagonale principale le stime delle comunalità:

\[
\textbf{S} - \hat{\boldsymbol{\Psi}} = 
\left[
  \begin{array}{ c c c c }
    \hat{h}^2_1 & s_{12} & \dots & s_{1p} \\
    s_{21} & \hat{h}^2_2 & \dots & s_{2p} \\
    \dots & \dots &           & \dots\\
    s_{p1} &  s_{p2} & \dots & \hat{h}^2_p
  \end{array} 
\right]
\]

In maniera equivalente, la matrice ridotta di correlazioni si ottiene nel modo seguente:

\[
\textbf{R} - \hat{\boldsymbol{\Psi}} = 
\left[
  \begin{array}{ c c c c }
    \hat{h}^2_1 & r_{12} & \dots & r_{1p} \\
    r_{21} & \hat{h}^2_2 & \dots & r_{2p} \\
    \dots & \dots &           & \dots\\
    r_{p1} &  r_{p2} & \dots & \hat{h}^2_p
  \end{array} 
\right]
\]

Verranno ora svolti i calcoli necessari per la stima dei coefficienti di saturazione con il metodo dei fattori principali utilizzando la matrice di correlazione dell'esempio precedente. Quale stima della comunalità \(i\)-esima, verrà utilizzato il valore assoluto più elevato nella riga \(i\)-esima della matrice \textbf{R}. Per i dati dell'esempio, le stime delle comunalità sono dunque pari a \(0.995\), \(0.837\), \(0.881\), \(0.995\) e \(0.837\).

Inserendo tali valori nella diagonale principale, otteniamo la matrice ridotta delle correlazioni \(\textbf{R} - \hat{\boldsymbol{\Psi}}\):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{R1 }\OtherTok{\textless{}{-}}\NormalTok{ R}
\NormalTok{h.hat }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(.}\DecValTok{995}\NormalTok{, .}\DecValTok{837}\NormalTok{, .}\DecValTok{881}\NormalTok{, .}\DecValTok{995}\NormalTok{, .}\DecValTok{837}\NormalTok{)}
\NormalTok{R1[}\FunctionTok{cbind}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{5}\NormalTok{, }\DecValTok{1}\SpecialCharTok{:}\DecValTok{5}\NormalTok{)] }\OtherTok{\textless{}{-}}\NormalTok{ h.hat}
\NormalTok{R1}
\CommentTok{\#\textgreater{}       K      I      H     L     J}
\CommentTok{\#\textgreater{} K 0.995  0.296  0.881 0.995 0.545}
\CommentTok{\#\textgreater{} I 0.296  0.837 {-}0.022 0.326 0.837}
\CommentTok{\#\textgreater{} H 0.881 {-}0.022  0.881 0.867 0.130}
\CommentTok{\#\textgreater{} L 0.995  0.326  0.867 0.995 0.544}
\CommentTok{\#\textgreater{} J 0.545  0.837  0.130 0.544 0.837}
\end{Highlighting}
\end{Shaded}

Gli autovalori della matrice ridotta di correlazioni \(\textbf{R} - \hat{\boldsymbol{\Psi}}\) sono:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ee }\OtherTok{\textless{}{-}} \FunctionTok{eigen}\NormalTok{(R1)}
\FunctionTok{round}\NormalTok{(ee}\SpecialCharTok{$}\NormalTok{values, }\DecValTok{3}\NormalTok{)}
\CommentTok{\#\textgreater{} [1]  3.202  1.394  0.029  0.000 {-}0.080}
\end{Highlighting}
\end{Shaded}

La somma degli autovalori è uguale a

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sum}\NormalTok{(ee}\SpecialCharTok{$}\NormalTok{values)}
\CommentTok{\#\textgreater{} [1] 4.545}
\end{Highlighting}
\end{Shaded}

I primi due autovalori di \(\textbf{R} - \hat{\boldsymbol{\Psi}}\) sono:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{round}\NormalTok{(ee}\SpecialCharTok{$}\NormalTok{vectors[, }\DecValTok{1}\SpecialCharTok{:}\DecValTok{2}\NormalTok{], }\DecValTok{3}\NormalTok{)}
\CommentTok{\#\textgreater{}        [,1]   [,2]}
\CommentTok{\#\textgreater{} [1,] {-}0.548 {-}0.177}
\CommentTok{\#\textgreater{} [2,] {-}0.272  0.656}
\CommentTok{\#\textgreater{} [3,] {-}0.431 {-}0.461}
\CommentTok{\#\textgreater{} [4,] {-}0.549 {-}0.159}
\CommentTok{\#\textgreater{} [5,] {-}0.373  0.549}
\end{Highlighting}
\end{Shaded}

Moltiplicando tali valori per la radice quadrata dei rispettivi autovalori si ottengono le stime delle saturazioni fattoriali:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{round}\NormalTok{(ee}\SpecialCharTok{$}\NormalTok{vectors[, }\DecValTok{1}\SpecialCharTok{:}\DecValTok{2}\NormalTok{] }\SpecialCharTok{\%*\%} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{diag}\NormalTok{(ee}\SpecialCharTok{$}\NormalTok{values[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{2}\NormalTok{])), }\DecValTok{3}\NormalTok{)}
\CommentTok{\#\textgreater{}        [,1]   [,2]}
\CommentTok{\#\textgreater{} [1,] {-}0.981 {-}0.209}
\CommentTok{\#\textgreater{} [2,] {-}0.487  0.774}
\CommentTok{\#\textgreater{} [3,] {-}0.772 {-}0.544}
\CommentTok{\#\textgreater{} [4,] {-}0.982 {-}0.187}
\CommentTok{\#\textgreater{} [5,] {-}0.667  0.648}
\end{Highlighting}
\end{Shaded}

Tale risultato replica quello riportato da Rencher (2002).

\hypertarget{metodo-dei-fattori-principali-iterato}{%
\section{Metodo dei fattori principali iterato}\label{metodo-dei-fattori-principali-iterato}}

Solitamente, per migliorare la stima della comunalità, la diagonale della matrice \(\textbf{S} - \hat{\boldsymbol{\Psi}}\) o \(\textbf{R} - \hat{\boldsymbol{\Psi}}\) viene ottenuta per iterazione. Dopo avere trovato \(\hat{\boldsymbol{\Lambda}}\) a partire da \(\textbf{S} - \hat{\boldsymbol{\Psi}}\) o \(\textbf{R} - \hat{\boldsymbol{\Psi}}\) come indicato in precedenza, utilizzando le stime delle saturazioni fattoriali così ottenute possiamo stimare le comunalità nel modo seguente:

\[\hat{h}^2_i = \sum_{i=1}^m \hat{\lambda}_{ij}^2.\]

I valori di \(\hat{h}^2_i\) vengono quindi sostituiti nella diagonale della matrice ridotta \(\textbf{S} - \hat{\boldsymbol{\Psi}}\) o \(\textbf{R} - \hat{\boldsymbol{\Psi}}\). A partire da questa nuova matrice, usando il metodo descritto in precedenza, possiamo così ottenere una nuova stima delle saturazioni fattoriali \(\hat{\boldsymbol{\Lambda}}\). Mediante questa nuova stima di \(\hat{\boldsymbol{\Lambda}}\), possiamo procedere ad una nuova stima delle comunalità. Tale processo continua iterativamente sino alla convergenza. Gli autovalori e gli autovettori della versione finale di \(\textbf{S} - \hat{\boldsymbol{\Psi}}\) o \(\textbf{R} - \hat{\boldsymbol{\Psi}}\) vengono infine usati per stimare i pesi fattoriali. Il metodo dei fattori principali iterato e il metodo delle componenti principali producono risultati molto simili quando \(m\) assume un piccolo valore (questo si verifica quando le correlazioni sono alte) e quando \(p\) (il numero delle variabili) è grande.

\hypertarget{casi-di-heywood}{%
\subsection{Casi di Heywood}\label{casi-di-heywood}}

Tra gli inconvenienti del metodo dei fattori principali iterato vi è il fatto che può talvolta portare a soluzioni inammissibili (quando viene fattorizzata la matrice \textbf{R}) caratterizzate da valori di comunalità maggiori di uno (\emph{caso di Heywood}). Se \(\hat{h}^2_i > 1\) allora \(\hat{\psi}_i < 0\) il che è chiaramente assurdo in quanto una varianza non può assumere un valore negativo. Solitamente, quando la stima di una comunalità è maggiore di uno, il processo iterativo viene interrotto e il programma riporta che non può essere trovata una soluzione.

Nell'esempio presente viene utilizzata la funzione \texttt{factor.pa()} contenuta nel pacchetto \texttt{psych} per trovare la soluzione dei fattori principali mediante il metodo iterativo:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pa }\OtherTok{\textless{}{-}} \FunctionTok{fa}\NormalTok{(R, }\AttributeTok{nfactors =} \DecValTok{2}\NormalTok{, }\AttributeTok{rotate =} \StringTok{"none"}\NormalTok{, }\AttributeTok{fm =} \StringTok{"pa"}\NormalTok{)}
\NormalTok{pa}
\CommentTok{\#\textgreater{} Factor Analysis using method =  pa}
\CommentTok{\#\textgreater{} Call: fa(r = R, nfactors = 2, rotate = "none", fm = "pa")}
\CommentTok{\#\textgreater{} Standardized loadings (pattern matrix) based upon correlation matrix}
\CommentTok{\#\textgreater{}    PA1   PA2   h2     u2 com}
\CommentTok{\#\textgreater{} K 0.98 {-}0.21 1.01 {-}0.008 1.1}
\CommentTok{\#\textgreater{} I 0.48  0.74 0.77  0.230 1.7}
\CommentTok{\#\textgreater{} H 0.78 {-}0.56 0.92  0.085 1.8}
\CommentTok{\#\textgreater{} L 0.98 {-}0.19 0.99  0.010 1.1}
\CommentTok{\#\textgreater{} J 0.69  0.69 0.95  0.049 2.0}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}                        PA1  PA2}
\CommentTok{\#\textgreater{} SS loadings           3.22 1.41}
\CommentTok{\#\textgreater{} Proportion Var        0.64 0.28}
\CommentTok{\#\textgreater{} Cumulative Var        0.64 0.93}
\CommentTok{\#\textgreater{} Proportion Explained  0.70 0.30}
\CommentTok{\#\textgreater{} Cumulative Proportion 0.70 1.00}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Mean item complexity =  1.5}
\CommentTok{\#\textgreater{} Test of the hypothesis that 2 factors are sufficient.}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} The degrees of freedom for the null model are  10  and the objective function was  12}
\CommentTok{\#\textgreater{} The degrees of freedom for the model are 1  and the objective function was  5.6 }
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} The root mean square of the residuals (RMSR) is  0.01 }
\CommentTok{\#\textgreater{} The df corrected root mean square of the residuals is  0.04 }
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Fit based upon off diagonal values = 1}
\end{Highlighting}
\end{Shaded}

Si noti che, in questo caso, le unicità assumono valori negativi, il che suggerisce che la soluzione è impropria.

\hypertarget{metodo-di-massima-verosimiglianza}{%
\section{Metodo di massima verosimiglianza}\label{metodo-di-massima-verosimiglianza}}

L'applicazione del metodo di massima verosimiglianza è indicata quando si può assumere che le variabili manifeste seguono una distribuzione normale multivariata. Sotto tali condizioni, tale metodo produce le stime dei pesi fattoriali che più verosimilmente hanno prodotto le correlazioni osservate. Gli stimatori di massima verosimiglianza sono preferibili a quelli ottenuti con altri metodi, sempre che siano pienamente realizzate le premesse. La funzione \(F\) da minimizzare rappresenta una misura di ``distanza'' tra la matrice di covarianza osservata e quella predetta dal modello. Uguagliando a zero le derivate di \(F\) rispetto a \(\boldsymbol{\Lambda}\) e \(\boldsymbol{\Psi}\) si ottengono le equazioni per le stime di massima verosimiglianza di \(\hat{\boldsymbol{\Lambda}}\) e \(\hat{\boldsymbol{\Psi}}\). Risolvendo tali equazioni rispetto alle incognite \(\hat{\boldsymbol{\Lambda}}\) e \(\hat{\boldsymbol{\Psi}}\) si ricavano le stime di massima verosimiglianza.

Non esistendo una soluzione analitica per queste equazioni, si ricorre a procedimenti numerici iterativi che talvolta presentano problemi di convergenza. La soluzione, pur presentando la possibilità di fornire delle stime di comunalità superiori a 1 (caso di Heywood), è equivariante rispetto a cambiamenti di scala: le stime di massima verosimiglianza sono indipendenti dall'unità di misura delle variabili manifeste. Pertanto, si ottiene la stessa soluzione sia che si analizzi la matrice delle varianze e covarianze, sia che si analizzi la matrice delle correlazioni.

Consideriamo nuovamente i dati dell'esempio precedente. Le istruzioni sono le seguenti:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{factanal}\NormalTok{(}\AttributeTok{covmat =}\NormalTok{ R, }\AttributeTok{factors =} \DecValTok{2}\NormalTok{, }\AttributeTok{rotation =} \StringTok{"none"}\NormalTok{, }\AttributeTok{n.obs =} \DecValTok{225}\NormalTok{)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Call:}
\CommentTok{\#\textgreater{} factanal(factors = 2, covmat = R, n.obs = 225, rotation = "none")}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Uniquenesses:}
\CommentTok{\#\textgreater{}     K     I     H     L     J }
\CommentTok{\#\textgreater{} 0.005 0.268 0.055 0.008 0.005 }
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Loadings:}
\CommentTok{\#\textgreater{}   Factor1 Factor2}
\CommentTok{\#\textgreater{} K  0.955  {-}0.289 }
\CommentTok{\#\textgreater{} I  0.528   0.673 }
\CommentTok{\#\textgreater{} H  0.720  {-}0.653 }
\CommentTok{\#\textgreater{} L  0.954  {-}0.287 }
\CommentTok{\#\textgreater{} J  0.764   0.642 }
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}                Factor1 Factor2}
\CommentTok{\#\textgreater{} SS loadings      3.203   1.457}
\CommentTok{\#\textgreater{} Proportion Var   0.641   0.291}
\CommentTok{\#\textgreater{} Cumulative Var   0.641   0.932}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Test of the hypothesis that 2 factors are sufficient.}
\CommentTok{\#\textgreater{} The chi square statistic is 648.1 on 1 degree of freedom.}
\CommentTok{\#\textgreater{} The p{-}value is 5.81e{-}143}
\end{Highlighting}
\end{Shaded}

\hypertarget{ch:numero_fattori}{%
\chapter{Il numero dei fattori}\label{ch:numero_fattori}}

Sono stati proposti quattro criteri per determinare il numero \(m\) di fattori da estrarre (Rencher, 2002). Tali criteri sono elencati di seguito.

\begin{itemize}
\tightlist
\item
  Scegliere \(m\) tale per cui la varianza spiegata dal modello fattoriale superi una soglia predeterminata, per esempio l'80\% della varianza totale, \(tr(\textbf{S})\) o \(tr(\textbf{R})\).
\item
  Scegliere \(m\) uguale al numero di autovalori aventi un valore maggiore del valore medio degli autovalori. Per \textbf{R} il valore medio degli autovalori è \(1\); per \textbf{S} è \(\sum_{j=1}^p \theta_j/p\).
\item
  Usare lo \emph{scree test}.
\item
  Valutare l'ipotesi che \(m\) sia il numero corretto di fattori, \(H_0: \boldsymbol{\Sigma} = \boldsymbol{\Lambda}  \boldsymbol{\Lambda}^{\ensuremath{\mathsf{T}}} + \boldsymbol{\Psi}\), dove \(\boldsymbol{\Lambda}\) è di ordine \(p \times m\).
\end{itemize}

\hypertarget{quota-di-varianza-spiegata}{%
\section{Quota di varianza spiegata}\label{quota-di-varianza-spiegata}}

Il primo criterio si applica soprattutto al metodo delle componenti principali. La proporzione della varianza capionaria spiegata dal fattore \(j\)-esimo estratto da \textbf{S} è uguale a

\[\sum_{i=i}^p \hat{\lambda}_{ij}^2 / tr(\textbf{S}).\]

Nel caso in cui i fattori vengano estratti da \textbf{R} avremo

\[\sum_{i=i}^p \hat{\lambda}_{ij}^2 / p.\]

Nel caso di fattori incorrelati, ciascun fattore contribuisce con una quota complessiva di varianza spiegata pari alla somma dei quadrati delle saturazioni fattoriali contenute nella matrice \(\hat{\boldsymbol{\Lambda}}\): \(\sum_{i=1}^p\sum_{j=1}^m\hat{\lambda}_{ij}^2\). Nel caso del metodo delle componenti principali, tale somma è anche uguale alla somma dei primi \(m\) autovalori, o alla somma di tutte le \(p\) comunalità:

\[\sum_{i=1}^p\sum_{j=1}^m\hat{\lambda}_{ij}^2= \sum_{i=1}^p \hat{h}_i^2
= \sum_{j=1}^m \theta_j\]

Sulla base di queste considerazioni, il numero \(m\) di fattori viene scelto in modo da spiegare una quota sufficientemente grande di \textbf{S} o \(p\).

Il numero dei fattori può essere determinato in questo modo anche nel caso in cui l'analisi fattoriale venga eseguita con il metodo dei fattori principali (ovvero, nel caso in cui vengano usate le stime delle comunalità per generare la matrice ridotta \(\textbf{S} - \hat{\boldsymbol{\Psi}}\) o \(\textbf{R} - \hat{\boldsymbol{\Psi}}\)). In questo caso, però, è possibile che alcuni autovalori della matrice \(\textbf{S} - \hat{\boldsymbol{\Psi}}\) o \(\textbf{R} - \hat{\boldsymbol{\Psi}}\) assumano valore negativo. In tali circostanze, è possibile che la proporzione cumulativa della varianza \(\sum_{j=1}^m \theta_j / \sum_{j=1}^p \theta_j\) assuma un valore maggiore di \(1.0\) per \(j < p\).

La proporzione cumulativa della varianza si riduce poi a \(1.0\) quando vengono considerati anche i successivi autovalori negativi. Di conseguenza, può succedere che, utilizzando la matrice \(\textbf{S} - \hat{\boldsymbol{\Psi}}\) o \(\textbf{R} - \hat{\boldsymbol{\Psi}}\), il criterio definito in base alla quota della varianza spiegata venga raggiunto per un valore \(m\) minore di quello che verrebbe trovato utilizzando la matrice \textbf{S} o \textbf{R}.

Nel caso del metodo dei fattori principali iterato, \(m\) viene specificato precedentemente a ciascuna iterazione e \(\sum_{i} \hat{h}^2_i\) viene ottenuto dopo ciascuna iterazione calcolando \(\text{tr}(\textbf{S} - \hat{\boldsymbol{\Psi}})\). Per scegliere \(m\), come per il metodo delle componenti principali, possono essere usati gli autovalori di \textbf{S} o \textbf{R}.

\hypertarget{valore-medio-degli-autovalori}{%
\section{Valore medio degli autovalori}\label{valore-medio-degli-autovalori}}

Il calcolo del valore medio degli autovalori è una procedura euristica implementata in molti software. In una variante di tale metodo, \(m\) viene scelto in modo tale da uguagliare il numero degli autovalori positivi della matrice ridotta \(\textbf{R} - \hat{\boldsymbol{\Psi}}\) (in tale matrice vi sono solitamente degli autovalori negativi). Tale variante ha però lo svantaggio di produrre solitamente un numero di fattori troppo grande.

\hypertarget{scree-test}{%
\section{Scree test}\label{scree-test}}

Lo scree test è basato su una rappresentazione grafica degli autovalori di \textbf{S} o \textbf{R}. Si costruisce un grafico che rappresenta gli autovalori ordinati in maniera decrescente in funzione del numero dei fattori. I punti che rappresentano gli autovalori vengono collegati con una spezzata. Il valore \(m\) viene determinato in corrispondenza di quel fattore oltre il quale il dislivello tra fattori successivi diventa esiguo e la spezzata tende a diventare orizzontale.

\hypertarget{parallel-analysis}{%
\section{Parallel analysis}\label{parallel-analysis}}

La Parallel Analysis è un metodo alternativo allo scree test{[}\^{}1{]}. Nella Parallel Analysis, il criterio usato per decidere il numero di fattori da estrarre viene determinato dal confronto con la media degli autovalori generati da un campione casuale di variabili standardizzate. Tale confronto ha lo scopo di controllare le variazioni dovute agli errori di campionamento. Anche se, nel caso di variabili incorrelate, tutti gli autovalori di una matrice di correlazione dovrebbero avere un valore pari a uno, come conseguenza della variabilità campionaria in qualunque campione finito vi sono comunque uno o più autovalori empirici maggiori di uno.

Tale fatto può essere illustrato mediante la seguente simulazione di Monte Carlo. Si consideri una matrice di correlazione calcolata su \(p=10\) variabili casuali mutuamente indipendenti, ciascuna costituita da \(n=20\) osservazioni.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{20}
\NormalTok{nsim }\OtherTok{\textless{}{-}} \DecValTok{1000}
\NormalTok{e1 }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{, nsim)}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{nsim) \{}
\NormalTok{  Y }\OtherTok{\textless{}{-}} \FunctionTok{cbind}\NormalTok{(}
    \FunctionTok{rnorm}\NormalTok{(n), }\FunctionTok{rnorm}\NormalTok{(n), }\FunctionTok{rnorm}\NormalTok{(n), }\FunctionTok{rnorm}\NormalTok{(n), }\FunctionTok{rnorm}\NormalTok{(n),}
    \FunctionTok{rnorm}\NormalTok{(n), }\FunctionTok{rnorm}\NormalTok{(n), }\FunctionTok{rnorm}\NormalTok{(n), }\FunctionTok{rnorm}\NormalTok{(n), }\FunctionTok{rnorm}\NormalTok{(n)}
\NormalTok{  )}
\NormalTok{  e }\OtherTok{\textless{}{-}} \FunctionTok{eigen}\NormalTok{(}\FunctionTok{cor}\NormalTok{(Y))}
\NormalTok{  e1[i] }\OtherTok{\textless{}{-}}\NormalTok{ e}\SpecialCharTok{$}\NormalTok{values[}\DecValTok{1}\NormalTok{]}
\NormalTok{\}}
\FunctionTok{max}\NormalTok{(e1)}
\CommentTok{\#\textgreater{} [1] 3.333}
\end{Highlighting}
\end{Shaded}

Per i dati di questa simulazione, l'autovalore maggiore ha un valore pari a \(3.53\), anche se i dati sono del tutto casuali. La Parallel Analysis tiene conto di questo fatto e determina \(m\) confrontando gli autovalori empirici con le loro ``controparti casuali.'' Vanno a determinare \(m\) solo gli autovalori empirici che hanno un valore superiore ai corrispondenti autovalori generati da una matrice di dati dello stesso ordine composta da colonne mutualmente incorrelate. Nel caso dell'esempio presente, per esempio, l'autovalore maggiore dovrà avere un valore maggiore di \(3.53\) (anziché di \(1.00\) o del punto di flesso della spezzata dello scree test).

\hypertarget{test-di-bontuxe0-di-adattamento}{%
\section{Test di bontà di adattamento}\label{test-di-bontuxe0-di-adattamento}}

Se si assume la normalità distributiva dei dati è possibile valutare la bontà di adattamento attraverso il test del rapporto di verosimiglianze. L'ipotesi nulla postula che la matrice di covarianza delle \(Y\) abbia la forma specificata dal modello fattoriale, ossia

\[H_0: \boldsymbol{\Sigma} =  \boldsymbol{\Lambda}
  \boldsymbol{\Lambda}^{\ensuremath{\mathsf{T}}} +  \boldsymbol{\Psi},\]

ovvero che \(m\) fattori comuni siano sufficienti per spiegare la struttura di interdipendenza della variabile casuale \(Y\) oggetto di osservazione campionaria. L'alternativa è che \(m\) fattori comuni non siano sufficienti a tale spiegazione

\[H_1: \boldsymbol{\Sigma} \neq  \boldsymbol{\Lambda}
  \boldsymbol{\Lambda}^{\ensuremath{\mathsf{T}}} +  \boldsymbol{\Psi},\]

dove \(\boldsymbol{\Lambda}\) è di ordine \(p \times m\). Se l'ipotesi nulla non viene rifiutata vuol dire che il modello fornisce un buon adattamento ai dati.

Sotto l'ipotesi nulla, il test ha una distribuzione asintotica, per \(n \rightarrow \infty\), di tipo chi quadrato con gradi di libertà pari a:

\[\nu=\frac{1}{2}\left[ (p-m)^2 - (p - m) \right].\]

Tale risultato di natura asintotica, valido per \(n\) grande, può essere migliorato, per ottenere una approssimazione migliore, sostituendo \(\nu\) con: \[\nu^* = n - 2 - \frac{2p-1}{6}-\frac{2}{3}m.\] Il rifiuto di \(H_0\) implica che \(m\) è troppo piccolo e un numero maggiore di fattori è necessario. Solitamente si inizia l'analisi considerando un numero di fattori molto piccolo: \(m^*=1\) e si prende come ipotesi per il test che il numero di fattori sia \(m^*\). Se l'ipotesi nulla è accettata il procedimento si arresta, altrimenti si passa a considerare \(m^* + 1\) fattori e si prosegue con lo stesso ragionamento. Il procedimento si arresta non appena si verifica una delle seguenti situazioni: è stata accettata l'ipotesi \(H_0\) per un certo valore di \(m\), oppure, \(\nu=\frac{1}{2}\left[ (p-m)^2 - (p - m) \right]=0\), ossia la variabile \(\chi^2\) dovrebbe avere zero gradi di libertà, che non è possibile.

Per poter applicare il test che determina il buon grado di adattamento del modello fattoriale occorre che i gradi di libertà della statistica del chi-quadrato siano positivi. Questo sta a significare che il numero di fattori comuni non può superare il più grande numero intero che soddisfa la seguente equazione:

\[m < \frac{1}{2} \left( 2p+1-\sqrt{8p+1} \right)\]

per un numero fissato \(p\) di variabili manifeste. In pratica, quando \(n\) è grande, il test basato sul rapporto di verosimiglianze rivela un numero di fattori maggiore degli altri metodi descritti in precedenza. Alcuni considerano dunque il valore \(m\) indicato dal test quale limite superiore del numero dei fattori che rivestono una qualche importanza pratica.

Per alcuni campioni di dati, la scelta di \(m\) non è ovvia. Questa indeterminazione costituisce un limite dell'analisi fattoriale. Solitamente, si procede con utilizzando un certo metodo per la scelta di \(m\) (diciamo lo scree test) e valuta la proporzione di varianza spiegata di ciascun item e, dopo un'appropriata rotazione, l'interpretabilità della soluzione ottenuta. Se le comunalità o l'interpretabilità dei fattori non sembrano adeguati, si procede con un numero maggiore di fattori. Tale procedura è certamente soggettiva e i limiti della soluzione che viene ottenuta sono evidenti.

Per altri campioni di dati, la scelta di \(m\) consente una maggiore certezza. Questo avviene quando tutti i metodi che abbiamo descritto prima forniscono la stessa risposta. In questi casi, possiamo essere più certi della soluzione dell'analisi fattoriale.

\begin{example}
Per confrontare i quattro metodi discussi per la scelta del numero \(m\) di fattori usiamo qui una matrice di correlazioni calcolata sulla WAIS. Le 11 sottoscale sono le seguenti:

\begin{itemize}
\tightlist
\item
  X1 = Information
\item
  X2 = Comprehension
\item
  X3 = Arithmetic
\item
  X4 = Similarities
\item
  X5 = Digit.span
\item
  X6 = Vocabulary
\item
  X7 = Digit.symbol
\item
  X8 = Picture.completion
\item
  X9 = Block.design
\item
  X10 = Picture.arrangement
\item
  X11 = Object.assembly
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{varnames }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}
  \StringTok{"IN"}\NormalTok{, }\StringTok{"CO"}\NormalTok{, }\StringTok{"AR"}\NormalTok{, }\StringTok{"SI"}\NormalTok{, }\StringTok{"DS"}\NormalTok{, }\StringTok{"VO"}\NormalTok{, }\StringTok{"SY"}\NormalTok{, }\StringTok{"PC"}\NormalTok{,}
  \StringTok{"BD"}\NormalTok{, }\StringTok{"PA"}\NormalTok{, }\StringTok{"OA"}\NormalTok{, }\StringTok{"AG"}\NormalTok{, }\StringTok{"ED"}
\NormalTok{)}
\NormalTok{temp }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{c}\NormalTok{(}
  \DecValTok{1}\NormalTok{, }\FloatTok{0.67}\NormalTok{, }\FloatTok{0.62}\NormalTok{, }\FloatTok{0.66}\NormalTok{, }\FloatTok{0.47}\NormalTok{, }\FloatTok{0.81}\NormalTok{, }\FloatTok{0.47}\NormalTok{, }\FloatTok{0.60}\NormalTok{, }\FloatTok{0.49}\NormalTok{, }\FloatTok{0.51}\NormalTok{, }\FloatTok{0.41}\NormalTok{,}
  \SpecialCharTok{{-}}\FloatTok{0.07}\NormalTok{, }\FloatTok{0.66}\NormalTok{, .}\DecValTok{67}\NormalTok{, }\DecValTok{1}\NormalTok{, }\FloatTok{0.54}\NormalTok{, }\FloatTok{0.60}\NormalTok{, }\FloatTok{0.39}\NormalTok{, }\FloatTok{0.72}\NormalTok{, }\FloatTok{0.40}\NormalTok{, }\FloatTok{0.54}\NormalTok{, }\FloatTok{0.45}\NormalTok{,}
  \FloatTok{0.49}\NormalTok{, }\FloatTok{0.38}\NormalTok{, }\SpecialCharTok{{-}}\FloatTok{0.08}\NormalTok{, }\FloatTok{0.52}\NormalTok{, .}\DecValTok{62}\NormalTok{, .}\DecValTok{54}\NormalTok{, }\DecValTok{1}\NormalTok{, }\FloatTok{0.51}\NormalTok{, }\FloatTok{0.51}\NormalTok{, }\FloatTok{0.58}\NormalTok{, }\FloatTok{0.41}\NormalTok{,}
  \FloatTok{0.46}\NormalTok{, }\FloatTok{0.48}\NormalTok{, }\FloatTok{0.43}\NormalTok{, }\FloatTok{0.37}\NormalTok{, }\SpecialCharTok{{-}}\FloatTok{0.08}\NormalTok{, }\FloatTok{0.49}\NormalTok{, .}\DecValTok{66}\NormalTok{, .}\DecValTok{60}\NormalTok{, .}\DecValTok{51}\NormalTok{, }\DecValTok{1}\NormalTok{, }\FloatTok{0.41}\NormalTok{,}
  \FloatTok{0.68}\NormalTok{, }\FloatTok{0.49}\NormalTok{, }\FloatTok{0.56}\NormalTok{, }\FloatTok{0.50}\NormalTok{, }\FloatTok{0.50}\NormalTok{, }\FloatTok{0.41}\NormalTok{, }\SpecialCharTok{{-}}\FloatTok{0.19}\NormalTok{, }\FloatTok{0.55}\NormalTok{, .}\DecValTok{47}\NormalTok{, .}\DecValTok{39}\NormalTok{, .}\DecValTok{51}\NormalTok{,}
\NormalTok{  .}\DecValTok{41}\NormalTok{, }\DecValTok{1}\NormalTok{, }\FloatTok{0.45}\NormalTok{, }\FloatTok{0.45}\NormalTok{, }\FloatTok{0.42}\NormalTok{, }\FloatTok{0.39}\NormalTok{, }\FloatTok{0.42}\NormalTok{, }\FloatTok{0.31}\NormalTok{, }\SpecialCharTok{{-}}\FloatTok{0.19}\NormalTok{, }\FloatTok{0.43}\NormalTok{,}
\NormalTok{  .}\DecValTok{81}\NormalTok{, .}\DecValTok{72}\NormalTok{, .}\DecValTok{58}\NormalTok{, .}\DecValTok{68}\NormalTok{, .}\DecValTok{45}\NormalTok{, }\DecValTok{1}\NormalTok{, }\FloatTok{0.49}\NormalTok{, }\FloatTok{0.57}\NormalTok{, }\FloatTok{0.46}\NormalTok{, }\FloatTok{0.52}\NormalTok{, }\FloatTok{0.40}\NormalTok{, }\SpecialCharTok{{-}}\FloatTok{0.02}\NormalTok{,}
  \FloatTok{0.62}\NormalTok{, .}\DecValTok{47}\NormalTok{, .}\DecValTok{40}\NormalTok{, .}\DecValTok{41}\NormalTok{, .}\DecValTok{49}\NormalTok{, .}\DecValTok{45}\NormalTok{, .}\DecValTok{49}\NormalTok{, }\DecValTok{1}\NormalTok{, }\FloatTok{0.50}\NormalTok{, }\FloatTok{0.50}\NormalTok{, }\FloatTok{0.52}\NormalTok{, }\FloatTok{0.46}\NormalTok{,}
  \SpecialCharTok{{-}}\FloatTok{0.46}\NormalTok{, }\FloatTok{0.57}\NormalTok{, .}\DecValTok{60}\NormalTok{, .}\DecValTok{54}\NormalTok{, .}\DecValTok{46}\NormalTok{, .}\DecValTok{56}\NormalTok{, .}\DecValTok{42}\NormalTok{, .}\DecValTok{57}\NormalTok{, .}\DecValTok{50}\NormalTok{, }\DecValTok{1}\NormalTok{, }\FloatTok{0.61}\NormalTok{, }\FloatTok{0.59}\NormalTok{,}
  \FloatTok{0.51}\NormalTok{, }\SpecialCharTok{{-}}\FloatTok{0.28}\NormalTok{, }\FloatTok{0.48}\NormalTok{, .}\DecValTok{49}\NormalTok{, .}\DecValTok{45}\NormalTok{, .}\DecValTok{48}\NormalTok{, .}\DecValTok{50}\NormalTok{, .}\DecValTok{39}\NormalTok{, .}\DecValTok{46}\NormalTok{, .}\DecValTok{50}\NormalTok{, .}\DecValTok{61}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \FloatTok{0.54}\NormalTok{, }\FloatTok{0.59}\NormalTok{, }\SpecialCharTok{{-}}\FloatTok{0.32}\NormalTok{, }\FloatTok{0.44}\NormalTok{, .}\DecValTok{51}\NormalTok{, .}\DecValTok{49}\NormalTok{, .}\DecValTok{43}\NormalTok{, .}\DecValTok{50}\NormalTok{, .}\DecValTok{42}\NormalTok{, .}\DecValTok{52}\NormalTok{, .}\DecValTok{52}\NormalTok{, .}\DecValTok{59}\NormalTok{,}
\NormalTok{  .}\DecValTok{54}\NormalTok{, }\DecValTok{1}\NormalTok{, }\FloatTok{0.46}\NormalTok{, }\SpecialCharTok{{-}}\FloatTok{0.37}\NormalTok{, }\FloatTok{0.49}\NormalTok{, .}\DecValTok{41}\NormalTok{, .}\DecValTok{38}\NormalTok{, .}\DecValTok{37}\NormalTok{, .}\DecValTok{41}\NormalTok{, .}\DecValTok{31}\NormalTok{, .}\DecValTok{40}\NormalTok{, .}\DecValTok{46}\NormalTok{, .}\DecValTok{51}\NormalTok{,}
\NormalTok{  .}\DecValTok{59}\NormalTok{, .}\DecValTok{46}\NormalTok{, }\DecValTok{1}\NormalTok{, }\SpecialCharTok{{-}}\FloatTok{0.28}\NormalTok{, }\FloatTok{0.40}\NormalTok{, }\SpecialCharTok{{-}}\NormalTok{.}\DecValTok{07}\NormalTok{, }\SpecialCharTok{{-}}\NormalTok{.}\DecValTok{08}\NormalTok{, }\SpecialCharTok{{-}}\NormalTok{.}\DecValTok{08}\NormalTok{, }\SpecialCharTok{{-}}\NormalTok{.}\DecValTok{19}\NormalTok{, }\SpecialCharTok{{-}}\NormalTok{.}\DecValTok{19}\NormalTok{, }\SpecialCharTok{{-}}\NormalTok{.}\DecValTok{02}\NormalTok{,}
  \SpecialCharTok{{-}}\NormalTok{.}\DecValTok{46}\NormalTok{, }\SpecialCharTok{{-}}\NormalTok{.}\DecValTok{28}\NormalTok{, }\SpecialCharTok{{-}}\NormalTok{.}\DecValTok{32}\NormalTok{, }\SpecialCharTok{{-}}\NormalTok{.}\DecValTok{37}\NormalTok{, }\SpecialCharTok{{-}}\NormalTok{.}\DecValTok{28}\NormalTok{, }\DecValTok{1}\NormalTok{, }\SpecialCharTok{{-}}\FloatTok{0.29}\NormalTok{, .}\DecValTok{66}\NormalTok{, .}\DecValTok{52}\NormalTok{, .}\DecValTok{49}\NormalTok{, .}\DecValTok{55}\NormalTok{, .}\DecValTok{43}\NormalTok{,}
\NormalTok{  .}\DecValTok{62}\NormalTok{, .}\DecValTok{57}\NormalTok{, .}\DecValTok{48}\NormalTok{, .}\DecValTok{44}\NormalTok{, .}\DecValTok{49}\NormalTok{, .}\DecValTok{40}\NormalTok{, }\SpecialCharTok{{-}}\NormalTok{.}\DecValTok{29}\NormalTok{, }\DecValTok{1}
\NormalTok{), }\AttributeTok{nrow =} \DecValTok{13}\NormalTok{, }\AttributeTok{ncol =} \DecValTok{13}\NormalTok{, }\AttributeTok{byrow =} \ConstantTok{TRUE}\NormalTok{)}

\FunctionTok{colnames}\NormalTok{(temp) }\OtherTok{\textless{}{-}}\NormalTok{ varnames}
\FunctionTok{rownames}\NormalTok{(temp) }\OtherTok{\textless{}{-}}\NormalTok{ varnames}

\NormalTok{wais\_cor }\OtherTok{\textless{}{-}}\NormalTok{ temp[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{11}\NormalTok{, }\DecValTok{1}\SpecialCharTok{:}\DecValTok{11}\NormalTok{]}
\NormalTok{wais\_cor}
\CommentTok{\#\textgreater{}      IN   CO   AR   SI   DS   VO   SY   PC   BD   PA}
\CommentTok{\#\textgreater{} IN 1.00 0.67 0.62 0.66 0.47 0.81 0.47 0.60 0.49 0.51}
\CommentTok{\#\textgreater{} CO 0.67 1.00 0.54 0.60 0.39 0.72 0.40 0.54 0.45 0.49}
\CommentTok{\#\textgreater{} AR 0.62 0.54 1.00 0.51 0.51 0.58 0.41 0.46 0.48 0.43}
\CommentTok{\#\textgreater{} SI 0.66 0.60 0.51 1.00 0.41 0.68 0.49 0.56 0.50 0.50}
\CommentTok{\#\textgreater{} DS 0.47 0.39 0.51 0.41 1.00 0.45 0.45 0.42 0.39 0.42}
\CommentTok{\#\textgreater{} VO 0.81 0.72 0.58 0.68 0.45 1.00 0.49 0.57 0.46 0.52}
\CommentTok{\#\textgreater{} SY 0.47 0.40 0.41 0.49 0.45 0.49 1.00 0.50 0.50 0.52}
\CommentTok{\#\textgreater{} PC 0.60 0.54 0.46 0.56 0.42 0.57 0.50 1.00 0.61 0.59}
\CommentTok{\#\textgreater{} BD 0.49 0.45 0.48 0.50 0.39 0.46 0.50 0.61 1.00 0.54}
\CommentTok{\#\textgreater{} PA 0.51 0.49 0.43 0.50 0.42 0.52 0.52 0.59 0.54 1.00}
\CommentTok{\#\textgreater{} OA 0.41 0.38 0.37 0.41 0.31 0.40 0.46 0.51 0.59 0.46}
\CommentTok{\#\textgreater{}      OA}
\CommentTok{\#\textgreater{} IN 0.41}
\CommentTok{\#\textgreater{} CO 0.38}
\CommentTok{\#\textgreater{} AR 0.37}
\CommentTok{\#\textgreater{} SI 0.41}
\CommentTok{\#\textgreater{} DS 0.31}
\CommentTok{\#\textgreater{} VO 0.40}
\CommentTok{\#\textgreater{} SY 0.46}
\CommentTok{\#\textgreater{} PC 0.51}
\CommentTok{\#\textgreater{} BD 0.59}
\CommentTok{\#\textgreater{} PA 0.46}
\CommentTok{\#\textgreater{} OA 1.00}
\end{Highlighting}
\end{Shaded}

Il primo metodo per la determinazione di \(m\) richiede di estrarre tanti fattori quanti sono necessari per spiegare una quota predeterminata della varianza totale. Supponiamo di porre il criterio pari all'80\% della varianza totale. La soluzione ottenuta in questo modo ci porterebbe a mantenere \(m=5\) fattori:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{out }\OtherTok{\textless{}{-}} \FunctionTok{eigen}\NormalTok{(wais\_cor)}
\FunctionTok{sum}\NormalTok{(out}\SpecialCharTok{$}\NormalTok{val[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{4}\NormalTok{]) }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(out}\SpecialCharTok{$}\NormalTok{val)}
\CommentTok{\#\textgreater{} [1] 0.7657}
\FunctionTok{sum}\NormalTok{(out}\SpecialCharTok{$}\NormalTok{val[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{5}\NormalTok{]) }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(out}\SpecialCharTok{$}\NormalTok{val)}
\CommentTok{\#\textgreater{} [1] 0.8119}
\end{Highlighting}
\end{Shaded}

Il secondo metodo suggerisce di mantenere tutti gli autovalori superiori al valore medio degli autovalori (che, nel caso di \textbf{R} è uguale a \(1\)). Nel caso presente, \(m=2\):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{round}\NormalTok{(out}\SpecialCharTok{$}\NormalTok{values, }\DecValTok{3}\NormalTok{)}
\CommentTok{\#\textgreater{}  [1] 6.074 1.015 0.746 0.587 0.508 0.431 0.423 0.377}
\CommentTok{\#\textgreater{}  [9] 0.351 0.310 0.177}
\end{Highlighting}
\end{Shaded}

Il terzo metodo, lo scree test, può essere eseguito usando la funzione \texttt{VSS.scree()} contenuta nel pacchetto \texttt{psych}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{VSS.scree}\NormalTok{(wais\_cor)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{cfa_book_files/figure-latex/unnamed-chunk-208-1} \end{center}

Lo scree test suggerisce una soluzione a \(m=1\) fattori, come indicato nella figura precedente. Il terzo metodo, nella versione della Parallel Analysis, può essere eseguito usando la funzione \texttt{paran()} contenuta nel pacchetto \texttt{paran}. La Parallel Analysis indica una soluzione a \(m=1\) fattore.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(}\StringTok{"paran"}\NormalTok{)}
\FunctionTok{paran}\NormalTok{(wais\_cor, }\AttributeTok{graph =} \ConstantTok{TRUE}\NormalTok{)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Using eigendecomposition of correlation matrix.}
\CommentTok{\#\textgreater{} Computing: 10\%  20\%  30\%  40\%  50\%  60\%  70\%  80\%  90\%  100\%}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Results of Horn\textquotesingle{}s Parallel Analysis for component retention}
\CommentTok{\#\textgreater{} 330 iterations, using the mean estimate}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-} }
\CommentTok{\#\textgreater{} Component   Adjusted    Unadjusted    Estimated }
\CommentTok{\#\textgreater{}             Eigenvalue  Eigenvalue    Bias }
\CommentTok{\#\textgreater{} {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-} }
\CommentTok{\#\textgreater{} 1           1.636878    3.765744      2.128865}
\CommentTok{\#\textgreater{} {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-} }
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Adjusted eigenvalues \textgreater{} 1 indicate dimensions to retain.}
\CommentTok{\#\textgreater{} (1 components retained)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{cfa_book_files/figure-latex/unnamed-chunk-209-1} \end{center}

Il quarto metodo consiste nell'applicazione di un test inferenziale relativo al numero di fattori. Anche questo metodo indica una soluzione a sei fattori:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{factanal}\NormalTok{(}\AttributeTok{covmat =}\NormalTok{ wais\_cor, }\AttributeTok{factors =} \DecValTok{5}\NormalTok{, }\AttributeTok{n.obs =} \DecValTok{933}\NormalTok{)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Call:}
\CommentTok{\#\textgreater{} factanal(factors = 5, covmat = wais\_cor, n.obs = 933)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Uniquenesses:}
\CommentTok{\#\textgreater{}    IN    CO    AR    SI    DS    VO    SY    PC    BD }
\CommentTok{\#\textgreater{} 0.235 0.389 0.117 0.419 0.600 0.109 0.277 0.308 0.334 }
\CommentTok{\#\textgreater{}    PA    OA }
\CommentTok{\#\textgreater{} 0.472 0.456 }
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Loadings:}
\CommentTok{\#\textgreater{}    Factor1 Factor2 Factor3 Factor4 Factor5}
\CommentTok{\#\textgreater{} IN  0.745   0.264   0.301   0.192   0.118 }
\CommentTok{\#\textgreater{} CO  0.667   0.278   0.244   0.129   0.111 }
\CommentTok{\#\textgreater{} AR  0.378   0.236   0.814   0.145         }
\CommentTok{\#\textgreater{} SI  0.591   0.332   0.207   0.252   0.121 }
\CommentTok{\#\textgreater{} DS  0.288   0.208   0.366   0.341   0.155 }
\CommentTok{\#\textgreater{} VO  0.865   0.216   0.207   0.229         }
\CommentTok{\#\textgreater{} SY  0.251   0.364   0.153   0.708         }
\CommentTok{\#\textgreater{} PC  0.425   0.548   0.156   0.216   0.375 }
\CommentTok{\#\textgreater{} BD  0.246   0.708   0.230   0.201   0.107 }
\CommentTok{\#\textgreater{} PA  0.355   0.457   0.163   0.325   0.245 }
\CommentTok{\#\textgreater{} OA  0.211   0.664   0.128   0.205         }
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}                Factor1 Factor2 Factor3 Factor4 Factor5}
\CommentTok{\#\textgreater{} SS loadings      2.799   1.986   1.176   1.043   0.280}
\CommentTok{\#\textgreater{} Proportion Var   0.254   0.181   0.107   0.095   0.025}
\CommentTok{\#\textgreater{} Cumulative Var   0.254   0.435   0.542   0.637   0.662}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Test of the hypothesis that 5 factors are sufficient.}
\CommentTok{\#\textgreater{} The chi square statistic is 12.46 on 10 degrees of freedom.}
\CommentTok{\#\textgreater{} The p{-}value is 0.256}
\end{Highlighting}
\end{Shaded}

Le differenze tra i risultati ottenuti con i quattro metodi descritti sopra suggeriscono la presenza di una componente di arbitrarietà nella scelta della soluzione da adottare.
\end{example}

\hypertarget{ch:rotazione}{%
\chapter{La rotazione fattoriale}\label{ch:rotazione}}

Nel capitolo \ref{ch:estrazione} abbiamo visto come sia possibile ottenere la soluzione fattoriale non ruotata per il numero di fattori comuni che meglio riassume l'informazione contenuta nella matrice di correlazioni (o covarianze). La soluzione non ruotata non garantisce l'identificazione di aggregati omogenei e interpretabili di variabili osservate. Si tende dunque a ricorrere alla rotazione degli assi fattoriali nella ricerca di una soluzione più facilmente interpretabile di quella ottenuta in prima istanza.

\hypertarget{indeterminatezza-della-soluzione-fattoriale}{%
\section{Indeterminatezza della soluzione fattoriale}\label{indeterminatezza-della-soluzione-fattoriale}}

Il problema della rotazione si pone perché la matrice delle saturazioni non presenta un'unica soluzione e, attraverso la sua trasformazione matematica, si possono ottenere infinite matrici dello stesso ordine. Tale fatto va sotto il nome di \emph{indeterminatezza della soluzione fattoriale}.

La matrice delle saturazioni fattoriali \(\boldsymbol{\Lambda}\) non risulta univocamente definita in quanto non esiste una soluzione unica alla determinazione delle saturazioni fattoriali. Una matrice di correlazioni \(\boldsymbol{R}\) consente di determinare soluzioni fattoriali diverse, ovvero matrici aventi lo stesso numero di fattori comuni ma una diversa configurazione di saturazioni fattoriali, oppure matrici di saturazioni fattoriali corrispondenti ad un diverso numero di fattori comuni.

Siano \(\boldsymbol{\Lambda}_1\) e \(\boldsymbol{\Lambda}_2\) due matrici aventi lo stesso numero di righe e colonne, ma contenenti saturazioni fattoriali diverse. \(\boldsymbol{\Lambda}_1\) è definita dai valori seguenti

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{l1 }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{c}\NormalTok{(}
  \FloatTok{0.766}\NormalTok{,  }\SpecialCharTok{{-}}\FloatTok{0.232}\NormalTok{,}
  \FloatTok{0.670}\NormalTok{,  }\SpecialCharTok{{-}}\FloatTok{0.203}\NormalTok{,}
  \FloatTok{0.574}\NormalTok{,  }\SpecialCharTok{{-}}\FloatTok{0.174}\NormalTok{,}
  \FloatTok{0.454}\NormalTok{,   }\FloatTok{0.533}\NormalTok{,}
  \FloatTok{0.389}\NormalTok{,   }\FloatTok{0.457}\NormalTok{,}
  \FloatTok{0.324}\NormalTok{,   }\FloatTok{0.381}
\NormalTok{),}
\AttributeTok{byrow =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{ncol =} \DecValTok{2}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

mentre per \(\boldsymbol{\Lambda}_2\) abbiamo

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{l2 }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{c}\NormalTok{(}
  \FloatTok{0.783}\NormalTok{,  }\FloatTok{0.163}\NormalTok{,}
  \FloatTok{0.685}\NormalTok{,  }\FloatTok{0.143}\NormalTok{,}
  \FloatTok{0.587}\NormalTok{,  }\FloatTok{0.123}\NormalTok{,}
  \FloatTok{0.143}\NormalTok{,  }\FloatTok{0.685}\NormalTok{,}
  \FloatTok{0.123}\NormalTok{,  }\FloatTok{0.587}\NormalTok{,}
  \FloatTok{0.102}\NormalTok{,  }\FloatTok{0.489}
\NormalTok{),}
\AttributeTok{byrow =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{ncol =} \DecValTok{2}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Esaminiamo la matrice delle correlazioni riprodotte dalle due matrici di pesi fattoriali (con le comunalità sulla diagonale di \(\boldsymbol{R}\)):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{l1 }\SpecialCharTok{\%*\%} \FunctionTok{t}\NormalTok{(l1)}
\CommentTok{\#\textgreater{}        [,1]   [,2]   [,3]   [,4]   [,5]   [,6]}
\CommentTok{\#\textgreater{} [1,] 0.6406 0.5603 0.4801 0.2241 0.1920 0.1598}
\CommentTok{\#\textgreater{} [2,] 0.5603 0.4901 0.4199 0.1960 0.1679 0.1397}
\CommentTok{\#\textgreater{} [3,] 0.4801 0.4199 0.3598 0.1679 0.1438 0.1197}
\CommentTok{\#\textgreater{} [4,] 0.2241 0.1960 0.1679 0.4902 0.4202 0.3502}
\CommentTok{\#\textgreater{} [5,] 0.1920 0.1679 0.1438 0.4202 0.3602 0.3002}
\CommentTok{\#\textgreater{} [6,] 0.1598 0.1397 0.1197 0.3502 0.3002 0.2501}
\NormalTok{l2 }\SpecialCharTok{\%*\%} \FunctionTok{t}\NormalTok{(l2)}
\CommentTok{\#\textgreater{}        [,1]   [,2]   [,3]   [,4]   [,5]   [,6]}
\CommentTok{\#\textgreater{} [1,] 0.6397 0.5597 0.4797 0.2236 0.1920 0.1596}
\CommentTok{\#\textgreater{} [2,] 0.5597 0.4897 0.4197 0.1959 0.1682 0.1398}
\CommentTok{\#\textgreater{} [3,] 0.4797 0.4197 0.3597 0.1682 0.1444 0.1200}
\CommentTok{\#\textgreater{} [4,] 0.2236 0.1959 0.1682 0.4897 0.4197 0.3496}
\CommentTok{\#\textgreater{} [5,] 0.1920 0.1682 0.1444 0.4197 0.3597 0.2996}
\CommentTok{\#\textgreater{} [6,] 0.1596 0.1398 0.1200 0.3496 0.2996 0.2495}
\end{Highlighting}
\end{Shaded}

Come si vede, viene ottenuto lo stesso risultato utilizzando matrici \(\boldsymbol{\Lambda}\) con lo stesso numero \(m\) di colonne ma saturazioni fattoriali diverse.

Si consideri ora il caso di matrici \(\boldsymbol{\Lambda}\) corrispondenti a soluzioni fattoriali con un diverso numero di fattori comuni. Siano \(\boldsymbol{\Lambda}_1\) e \(\boldsymbol{\Lambda}_2\) due matrici aventi lo stesso numero di righe ma un numero diverso di colonne:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{l1 }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{c}\NormalTok{(}
  \FloatTok{0.9}\NormalTok{,}
  \FloatTok{0.7}\NormalTok{,}
  \FloatTok{0.5}\NormalTok{,}
  \FloatTok{0.3}
\NormalTok{),}
\AttributeTok{byrow =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{ncol =} \DecValTok{1}
\NormalTok{)}

\NormalTok{l2 }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{c}\NormalTok{(}
  \FloatTok{0.78}\NormalTok{, }\FloatTok{0.45}\NormalTok{,}
  \FloatTok{0.61}\NormalTok{, }\FloatTok{0.35}\NormalTok{,}
  \FloatTok{0.43}\NormalTok{, }\FloatTok{0.25}\NormalTok{,}
  \FloatTok{0.25}\NormalTok{, }\FloatTok{0.15}
\NormalTok{),}
\AttributeTok{byrow =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{ncol =} \DecValTok{2}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Si noti che la stessa matrice di correlazioni riprodotte (con le comunalità sulla diagonale principale) viene generata dalle saturazioni fattoriali corrispondenti ad un numero diverso di fattori comuni:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{l1 }\SpecialCharTok{\%*\%} \FunctionTok{t}\NormalTok{(l1)}
\CommentTok{\#\textgreater{}      [,1] [,2] [,3] [,4]}
\CommentTok{\#\textgreater{} [1,] 0.81 0.63 0.45 0.27}
\CommentTok{\#\textgreater{} [2,] 0.63 0.49 0.35 0.21}
\CommentTok{\#\textgreater{} [3,] 0.45 0.35 0.25 0.15}
\CommentTok{\#\textgreater{} [4,] 0.27 0.21 0.15 0.09}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{l2 }\SpecialCharTok{\%*\%} \FunctionTok{t}\NormalTok{(l2)}
\CommentTok{\#\textgreater{}        [,1]   [,2]   [,3]   [,4]}
\CommentTok{\#\textgreater{} [1,] 0.8109 0.6333 0.4479 0.2625}
\CommentTok{\#\textgreater{} [2,] 0.6333 0.4946 0.3498 0.2050}
\CommentTok{\#\textgreater{} [3,] 0.4479 0.3498 0.2474 0.1450}
\CommentTok{\#\textgreater{} [4,] 0.2625 0.2050 0.1450 0.0850}
\end{Highlighting}
\end{Shaded}

\hypertarget{parsimonia-e-semplicituxe0}{%
\section{Parsimonia e semplicità}\label{parsimonia-e-semplicituxe0}}

Come si raggiunge allora una qualche certezza sui risultati dell'analisi fattoriale? Il problema dell'\emph{indeterminazione fattoriale} si affronta scegliendo la soluzione che soddisfa i seguenti due criteri: \emph{criterio della parsimonia}: se sia un modello ad un fattore comune sia un modello a due fattori comuni possono spiegare la covariazione tra le variabili si deve accettare quello ad un fattore; \emph{criterio della semplicità}: a parità di numero di fattori, sono da preferire le strutture più semplici della matrice \(\boldsymbol{\Lambda}\) (Thurstone, 1947).

Il criterio della parsimonia è facilmente applicabile: se due soluzioni fattoriali aventi un numero diverso di fattori riproducono allo stesso modo la matrice \textbf{S} o \textbf{R}, si sceglie la soluzione con il numero minore di fattori. D'altra parte, se vi sono diverse soluzioni fattoriali con lo stesso numero \(m\) di fattori, il criterio della semplicità ci guida nella scelta della trasformazione più appropriata della matrice \(\hat{\boldsymbol{\Lambda}}\). La trasformazione della matrice \(\hat{\boldsymbol{\Lambda}}\) va sotto il nome di \emph{rotazione}. A seconda che i fattori ruotati risultino o meno incorrelati, si distingue tra metodi di rotazione ortogonale o obliqua dei fattori.

\hypertarget{il-criterio-della-struttura-semplice}{%
\subsection{Il criterio della ``struttura semplice''}\label{il-criterio-della-struttura-semplice}}

Tramite la rotazione degli assi fattoriali miriamo alla ``struttura semplice'' della matrice delle saturazioni fattoriali: poche ma forti saturazioni diverse da zero e assenza di variabili saturate da più di un fattore. Il criterio della ``struttura semplice'' è stato originariamente proposto da Thurstone (1947) secondo il quale tale criterio viene raggiunto quando:

\begin{itemize}
\tightlist
\item
  nella matrice fattoriale ruotata, ogni variabile deve avere almeno un peso nullo;
\item
  ogni fattore deve avere almeno \(m\) saturazioni nulle (\(m\): numero dei fattori comuni);
\item
  per ciascuna coppia di fattori vi devono essere saturazioni basse su un fattore e saturazioni alte sull'altro;
\item
  nel caso di molti fattori, per ciascuna coppia di fattori una grande proporzione di saturazioni dovrebbe essere nulla;
\item
  per ciascuna coppia di fattori, vi dovrebbero essere solo poche saturazioni di entità non trascurabile su entrambi i fattori.
\end{itemize}

Nella pratica, il requisito della struttura semplice viene perseguito, non tanto seguendo le indicazioni di Thursone, quanto bensì cercando di massimizzare il numero di saturazioni nulle o quasi nulle nella matrice \(\hat{\boldsymbol{\Lambda}}\). Uno dei grandi vantaggi che derivano dall'ottenimento della struttura semplice è la facilitazione nell'interpretazione dei fattori (Cattell, 1978).

L'esame delle saturazioni fattoriali contenute nella matrice \(\hat{\boldsymbol{\Lambda}}^*\) ruotata consente infatti di fornire un'interpretazione ai fattori. Per poter interpretare un fattore, dobbiamo chiederci quali sono le variabili che risultano maggiormente associate con tale fattore e quanto forti siano tali legami. Se i coefficienti di impatto di un fattore sono positivi e piuttosto elevati su un sottoinsieme di variabili osservate, da ciò deduciamo che il fattore rappresenta ciò che hanno in comune le variabili che saturano sul fattore. Ovviamente, l'interpretazione si complica nel caso di variabili che saturano su più fattori.

\hypertarget{rotazione-nello-spazio-geometrico}{%
\section{Rotazione nello spazio geometrico}\label{rotazione-nello-spazio-geometrico}}

\hypertarget{rotazione-ortogonale}{%
\subsection{Rotazione ortogonale}\label{rotazione-ortogonale}}

Come è stato notato nella sezione precedente, la matrice \(\boldsymbol{\Lambda}\) non è \emph{identificabile} poiché non esiste una soluzione unica alla determinazione delle saturazioni fattoriali: qualunque matrice \(\hat{\boldsymbol{\Lambda}}^* = \hat{\boldsymbol{\Lambda}} \textbf{T}\), dove \textbf{T} è una matrice ortonormale di ordine \(m\), è in grado di riprodurre la matrice di varianze-covarianze allo stesso modo di \(\hat{\boldsymbol{\Lambda}}\). La matrice \(\hat{\boldsymbol{\Lambda}}\) è pertanto determinata a meno della moltiplicazione per una matrice ortonormale.

\begin{definition}
Geometricamente, i pesi fattoriali costituiscono le coordinate di un punto (ci sono tanti punti quante sono le \(p\) variabili manifeste) in uno spazio avente un numero di dimensioni pari al numero \(m\) dei fattori.
\end{definition}

Dal punto di vista geometrico, il problema dell'indeterminazione fattoriale si può descrivere facendo riferimento alla rotazione rigida dei punti che rappresentano le saturazioni fattoriali attorno l'origine del sistema di coordinate. Tale rotazione rigida lascia invariate le distanze tra i punti (ed è equivalente ad una rotazione (contraria) del sistema di assi cartesiani) e dà luogo ad un nuovo insieme di valori per i pesi fattoriali. Ciascuno di questi insiemi di pesi fattoriali così ottenuti produce la medesima matrice di correlazioni riprodotte dal modello fattoriale. L'indeterminazione fattoriale nasce dal fatto che sono possibili infinite rotazioni diverse degli assi.

\hypertarget{vincoli-alla-rotazione}{%
\subsection{Vincoli alla rotazione}\label{vincoli-alla-rotazione}}

Il problema della non identificabilità di \(\hat{\boldsymbol{\Lambda}}\) viene generalmente risolto imponendo dei vincoli alla rotazione. Il criterio che ci guida nella scelta di una delle possibili trasformazioni della matrice dei pesi fattoriali è quello della \emph{semplicità} della matrice \(\hat{\boldsymbol{\Lambda}}\) (Thurstone, 1947), ovvero la vicinanza dei suoi elementi ai valori 0 e 1. Quanto più ciò si verifica tanto più risulta semplice l'interpretazione dei fattori comuni nei termini delle variabili. L'identificazione dei fattori risulta infatti semplificata se ciascuno di essi è fortemente correlato con un numero limitato di variabili ed è poco correlato con le altre.

Le rotazioni ortogonali lasciano immutate le comunalità nel caso di fattori incorrelati. Questo accade perché qualunque rotazione rigida rispetto all'origine preserva le distanze tra i punti identificati dai pesi fattoriali e, nel caso di fattori incorrelati, la comunalità non è nient'altro che la distanza dall'origine (al quadrato):

\[\hat{h}^2_i = \sum_{i=1}^m \hat{\lambda}_{ij}^2\]

Rotazioni non ortogonali, però, mutano la quota di varianza spiegata da ciascun fattore, essendo questa data da

\[\frac{\sum_{i=1}^p \hat{\lambda}_{ij}^2}{\text{tr}(\textbf{S})}\] oppure da

\[\frac{\sum_{i=1}^p \hat{\lambda}_{ij}^2}{\text{tr}(\textbf{R})}\]

laddove \(\text{tr}(\textbf{R})=p\), con \(i=1, \dots, p\) (numero di item) e \(j=1, \dots, m\) (numero di fattori).

Diversi algoritmi sono stati proposti per la rotazione ortogonale dei fattori. Inizieremo ad esaminare una possibile soluzione al problema dell'indeterminazione fattoriale mediante il metodo grafico. Esamineremo poi i metodi Quartimax e Varimax.

\hypertarget{metodo-grafico}{%
\subsection{Metodo grafico}\label{metodo-grafico}}

Come si può ruotare il sitema degli assi? Se ci sono solo \(m=2\) fattori, per ottenere la loro rappresentazione geometrica utilizziamo un sistema di coordinate bidimensionale. L'ispezione visiva del diagramma delle saturazioni fattoriali ci può guidare alla scelta della rotazione più appropriata. Le righe di \(\hat{\boldsymbol{\Lambda}}\) corrispondono a coppie di pesi fattoriali (\(\hat{\lambda}_{i1}, \hat{\lambda}_{i2}\), con \(i=1, \dots, p\)) che possono essere interpretate come le coordinate di \(p\) punti (tanti quanti le variabili manifeste). Gli assi del diagramma vengono ruotati di un angolo \(\phi\) in modo tale da portarli il più vicino possibile ai punti presenti nel grafico. Le nuove coordinate (\(\hat{\lambda}_{i1}^*, \hat{\lambda}_{i2}^*\)) vengono calcolate come \(\hat{\boldsymbol{\Lambda}}^* = \hat{\boldsymbol{\Lambda}} \textbf{T}\), dove

\[
\textbf{T} = 
\left[
  \begin{array}{ c c }
  \cos{\phi} & - \sin{\phi}\\
  \sin{\phi} & \cos{\phi}
  \end{array} 
\right] 
\]

è una matrice ortogonale \(2 \times 2\).

Si considerino i dati di Brown, Williams e Barlow (1984) discussi da Rencher (2002). Ad una bambina di dodici anni è stato chiesto di valutare sette dei suoi conoscenti su cinque variabili: \emph{kind}, \emph{intelligent}, \emph{happy}, \emph{likeable} e \emph{just}. Per queste cinque variabili, la matrice di correlazioni è

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{R }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{c}\NormalTok{(}
  \FloatTok{1.00}\NormalTok{, .}\DecValTok{296}\NormalTok{, .}\DecValTok{881}\NormalTok{, .}\DecValTok{995}\NormalTok{, .}\DecValTok{545}\NormalTok{,}
\NormalTok{  .}\DecValTok{296}\NormalTok{, }\FloatTok{1.000}\NormalTok{, }\SpecialCharTok{{-}}\NormalTok{.}\DecValTok{022}\NormalTok{, .}\DecValTok{326}\NormalTok{, .}\DecValTok{837}\NormalTok{,}
\NormalTok{  .}\DecValTok{881}\NormalTok{, }\SpecialCharTok{{-}}\NormalTok{.}\DecValTok{022}\NormalTok{, }\FloatTok{1.000}\NormalTok{, .}\DecValTok{867}\NormalTok{, .}\DecValTok{130}\NormalTok{,}
\NormalTok{  .}\DecValTok{995}\NormalTok{, .}\DecValTok{326}\NormalTok{, .}\DecValTok{867}\NormalTok{, }\FloatTok{1.000}\NormalTok{, .}\DecValTok{544}\NormalTok{,}
\NormalTok{  .}\DecValTok{545}\NormalTok{, .}\DecValTok{837}\NormalTok{, .}\DecValTok{130}\NormalTok{, .}\DecValTok{544}\NormalTok{, }\FloatTok{1.00}
\NormalTok{),}
\AttributeTok{ncol =} \DecValTok{5}\NormalTok{, }\AttributeTok{byrow =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{dimnames =} \FunctionTok{list}\NormalTok{(}
  \FunctionTok{c}\NormalTok{(}\StringTok{"K"}\NormalTok{, }\StringTok{"I"}\NormalTok{, }\StringTok{"H"}\NormalTok{, }\StringTok{"L"}\NormalTok{, }\StringTok{"J"}\NormalTok{), }\FunctionTok{c}\NormalTok{(}\StringTok{"K"}\NormalTok{, }\StringTok{"I"}\NormalTok{, }\StringTok{"H"}\NormalTok{, }\StringTok{"L"}\NormalTok{, }\StringTok{"J"}\NormalTok{)}
\NormalTok{)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Dalla matrice \textbf{R} estraiamo due fattori con il metodo delle componenti principali:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(}\StringTok{"psych"}\NormalTok{)}
\NormalTok{f.pc }\OtherTok{\textless{}{-}} \FunctionTok{principal}\NormalTok{(R, }\DecValTok{2}\NormalTok{, }\AttributeTok{rotate =} \ConstantTok{FALSE}\NormalTok{)}
\NormalTok{f.pc}
\CommentTok{\#\textgreater{} Principal Components Analysis}
\CommentTok{\#\textgreater{} Call: principal(r = R, nfactors = 2, rotate = FALSE)}
\CommentTok{\#\textgreater{} Standardized loadings (pattern matrix) based upon correlation matrix}
\CommentTok{\#\textgreater{}    PC1   PC2   h2     u2 com}
\CommentTok{\#\textgreater{} K 0.97 {-}0.23 0.99 0.0067 1.1}
\CommentTok{\#\textgreater{} I 0.52  0.81 0.92 0.0792 1.7}
\CommentTok{\#\textgreater{} H 0.78 {-}0.59 0.96 0.0391 1.9}
\CommentTok{\#\textgreater{} L 0.97 {-}0.21 0.99 0.0135 1.1}
\CommentTok{\#\textgreater{} J 0.70  0.67 0.94 0.0597 2.0}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}                        PC1  PC2}
\CommentTok{\#\textgreater{} SS loadings           3.26 1.54}
\CommentTok{\#\textgreater{} Proportion Var        0.65 0.31}
\CommentTok{\#\textgreater{} Cumulative Var        0.65 0.96}
\CommentTok{\#\textgreater{} Proportion Explained  0.68 0.32}
\CommentTok{\#\textgreater{} Cumulative Proportion 0.68 1.00}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Mean item complexity =  1.6}
\CommentTok{\#\textgreater{} Test of the hypothesis that 2 components are sufficient.}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} The root mean square of the residuals (RMSR) is  0.03 }
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Fit based upon off diagonal values = 1}
\end{Highlighting}
\end{Shaded}

Nella seguente figura, i punti rappresentano le cinque coppie di pesi fattoriali non ruotati:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(}
\NormalTok{  f.pc}\SpecialCharTok{$}\NormalTok{load[, }\DecValTok{1}\NormalTok{], f.pc}\SpecialCharTok{$}\NormalTok{load[, }\DecValTok{2}\NormalTok{],}
  \AttributeTok{bty =} \StringTok{"n"}\NormalTok{, }\AttributeTok{xaxt =} \StringTok{"n"}\NormalTok{,}
  \AttributeTok{xlab =} \StringTok{"Primo Fattore"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"Secondo Fattore"}\NormalTok{,}
  \AttributeTok{ylim =} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{.}\DecValTok{6}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{xlim =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{pch =} \DecValTok{19}
\NormalTok{)}
\FunctionTok{axis}\NormalTok{(}\DecValTok{1}\NormalTok{, }\AttributeTok{pos =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{))}
\FunctionTok{abline}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{cfa_book_files/figure-latex/unnamed-chunk-220-1} \end{center}

Rencher (2002) nota che, per questi dati, una rotazione ortogonale di \(-35^{\circ}\) ci porterebbe ad avvicinare gli assi ai punti nel diagramma. Per verificare questo, disegnamo sul diagramma i nuovi assi dopo una rotazione di \(-35^{\circ}\). Le istruzioni \texttt{R} sono le seguenti:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(}
\NormalTok{  f.pc}\SpecialCharTok{$}\NormalTok{load[, }\DecValTok{1}\NormalTok{], f.pc}\SpecialCharTok{$}\NormalTok{load[, }\DecValTok{2}\NormalTok{],}
  \AttributeTok{bty =} \StringTok{"n"}\NormalTok{, }\AttributeTok{xaxt =} \StringTok{"n"}\NormalTok{,}
  \AttributeTok{xlab =} \StringTok{"Primo Fattore"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"Secondo Fattore"}\NormalTok{,}
  \AttributeTok{ylim =} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{.}\DecValTok{6}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{xlim =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{pch =} \DecValTok{19}
\NormalTok{)}
\FunctionTok{axis}\NormalTok{(}\DecValTok{1}\NormalTok{, }\AttributeTok{pos =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{))}
\FunctionTok{abline}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{)}

\NormalTok{ar }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{c}\NormalTok{(}
  \DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{,}
  \DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{,}
  \DecValTok{1}\NormalTok{, }\DecValTok{0}
\NormalTok{), }\AttributeTok{ncol =} \DecValTok{2}\NormalTok{, }\AttributeTok{byrow =} \ConstantTok{TRUE}\NormalTok{)}

\NormalTok{angle }\OtherTok{\textless{}{-}} \DecValTok{35}
\NormalTok{rad }\OtherTok{\textless{}{-}}\NormalTok{ angle }\SpecialCharTok{*}\NormalTok{ pi }\SpecialCharTok{/} \DecValTok{180}
\NormalTok{T }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{c}\NormalTok{(}
  \FunctionTok{cos}\NormalTok{(rad), }\SpecialCharTok{{-}}\FunctionTok{sin}\NormalTok{(rad),}
  \FunctionTok{sin}\NormalTok{(rad),  }\FunctionTok{cos}\NormalTok{(rad)}
\NormalTok{), }\AttributeTok{ncol =} \DecValTok{2}\NormalTok{, }\AttributeTok{byrow =} \ConstantTok{TRUE}\NormalTok{)}

\FunctionTok{round}\NormalTok{(ar }\SpecialCharTok{\%*\%}\NormalTok{ T, }\DecValTok{3}\NormalTok{)}
\CommentTok{\#\textgreater{}       [,1]   [,2]}
\CommentTok{\#\textgreater{} [1,] 0.000  0.000}
\CommentTok{\#\textgreater{} [2,] 0.574  0.819}
\CommentTok{\#\textgreater{} [3,] 0.000  0.000}
\CommentTok{\#\textgreater{} [4,] 0.819 {-}0.574}

\FunctionTok{arrows}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\FloatTok{0.574}\NormalTok{, }\FloatTok{0.819}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{2}\NormalTok{)}
\FunctionTok{arrows}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\FloatTok{0.819}\NormalTok{, }\SpecialCharTok{{-}}\FloatTok{0.574}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{cfa_book_files/figure-latex/unnamed-chunk-221-1} \end{center}

Nella figura precedente, le due frecce rappresentano gli assi ruotati. È chiaro come tale rotazione di \(-35^{\circ}\) ha effettivamente l'effetto di avvicinare gli assi ai punti del diagramma. Se usiamo dunque il valore \(\phi = -35^{\circ}\) nella matrice di rotazione, possiamo calcolare le saturazioni fattoriali della soluzione ruotata \(\hat{\boldsymbol{\Lambda}}^* = \hat{\boldsymbol{\Lambda}} \textbf{T}\). Le saturazioni fattoriali ruotate non sono altro che la proiezione ortogonale dei punti sugli assi ruotati:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{angle }\OtherTok{\textless{}{-}} \SpecialCharTok{{-}}\DecValTok{35}
\NormalTok{rad }\OtherTok{\textless{}{-}}\NormalTok{ angle }\SpecialCharTok{*}\NormalTok{ pi }\SpecialCharTok{/} \DecValTok{180}
\NormalTok{T }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{c}\NormalTok{(}
  \FunctionTok{cos}\NormalTok{(rad), }\SpecialCharTok{{-}}\FunctionTok{sin}\NormalTok{(rad),}
  \FunctionTok{sin}\NormalTok{(rad),  }\FunctionTok{cos}\NormalTok{(rad)}
\NormalTok{), }\AttributeTok{ncol =} \DecValTok{2}\NormalTok{, }\AttributeTok{byrow =} \ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{round}\NormalTok{(f.pc}\SpecialCharTok{$}\NormalTok{load }\SpecialCharTok{\%*\%}\NormalTok{ T, }\DecValTok{3}\NormalTok{)}
\CommentTok{\#\textgreater{}     [,1]   [,2]}
\CommentTok{\#\textgreater{} K  0.927  0.367}
\CommentTok{\#\textgreater{} I {-}0.037  0.959}
\CommentTok{\#\textgreater{} H  0.980 {-}0.031}
\CommentTok{\#\textgreater{} L  0.916  0.385}
\CommentTok{\#\textgreater{} J  0.194  0.950}
\end{Highlighting}
\end{Shaded}

La soluzione ottenuta in questo modo riproduce quella riportata da Rencher (2002).

\hypertarget{medodi-di-rotazione-ortogonale}{%
\subsection{Medodi di rotazione ortogonale}\label{medodi-di-rotazione-ortogonale}}

Un tipo di rotazione ortogonale molto utilizzato è la rotazione Varimax (Kaiser, 1958). La matrice \(\hat{\boldsymbol{\Lambda}}\) è semplificata in modo tale che le varianze dei quadrati degli elementi \(\lambda_{ij}\) appartenenti a colonne diverse di \(\hat{\boldsymbol{\Lambda}}\) siano massime. Se le saturazioni fattoriali in una colonna di \(\hat{\boldsymbol{\Lambda}}\) sono simili tra loro, la varianza sarà prossima a zero. Tale varianza è tanto più grande quanto più i quadrati degli elementi \(\lambda_{ij}\) assumono valori prossimi a \(0\) e \(1\). Amplificando le correlazioni più alte e riducendo quelle più basse, la rotazione Varimax agevola l'interpretazione di ciascun fattore.

Usando la funzione \texttt{factanal()} del modulo base, la rotazione Varimax può essere applicata alla soluzione ottenuta mediante il metodo di massima verosimiglianza. Usando le funzioni \texttt{principal()} e \texttt{factor.pa()} disponibili nel pacchetto \texttt{psych}, la rotazione Varimax può essere applicata alle soluzioni ottenute mediante il metodo delle componenti principali e il metodo del fattore principale. Ad esempio, otteniamo:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{f\_pc }\OtherTok{\textless{}{-}} \FunctionTok{principal}\NormalTok{(R, }\DecValTok{2}\NormalTok{, }\AttributeTok{n.obs =} \DecValTok{7}\NormalTok{, }\AttributeTok{rotate =} \StringTok{"varimax"}\NormalTok{)}
\NormalTok{f\_pc}
\CommentTok{\#\textgreater{} Principal Components Analysis}
\CommentTok{\#\textgreater{} Call: principal(r = R, nfactors = 2, rotate = "varimax", n.obs = 7)}
\CommentTok{\#\textgreater{} Standardized loadings (pattern matrix) based upon correlation matrix}
\CommentTok{\#\textgreater{}    RC1   RC2   h2     u2 com}
\CommentTok{\#\textgreater{} K 0.95  0.30 0.99 0.0067 1.2}
\CommentTok{\#\textgreater{} I 0.03  0.96 0.92 0.0792 1.0}
\CommentTok{\#\textgreater{} H 0.97 {-}0.10 0.96 0.0391 1.0}
\CommentTok{\#\textgreater{} L 0.94  0.32 0.99 0.0135 1.2}
\CommentTok{\#\textgreater{} J 0.26  0.93 0.94 0.0597 1.2}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}                        RC1  RC2}
\CommentTok{\#\textgreater{} SS loadings           2.81 1.99}
\CommentTok{\#\textgreater{} Proportion Var        0.56 0.40}
\CommentTok{\#\textgreater{} Cumulative Var        0.56 0.96}
\CommentTok{\#\textgreater{} Proportion Explained  0.58 0.42}
\CommentTok{\#\textgreater{} Cumulative Proportion 0.58 1.00}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Mean item complexity =  1.1}
\CommentTok{\#\textgreater{} Test of the hypothesis that 2 components are sufficient.}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} The root mean square of the residuals (RMSR) is  0.03 }
\CommentTok{\#\textgreater{}  with the empirical chi square  0.12  with prob \textless{}  0.73 }
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Fit based upon off diagonal values = 1}
\end{Highlighting}
\end{Shaded}

Il metodo Quartimax (Neuhaus e Wringley, 1954) opera una semplificazione della matrice \(\hat{\boldsymbol{\Lambda}}\) massimizzando le covarianze tra i quadrati degli elementi \(\lambda_{ij}\) appartenenti a righe diverse, subordinatamente alla condizione che la varianza delle righe rimanga inalterata.

\hypertarget{metodi-di-rotazione-obliqua}{%
\subsection{Metodi di rotazione obliqua}\label{metodi-di-rotazione-obliqua}}

Parlare di rotazione obliqua significa usare un termine improprio: per definizione, infatti, una rotazione implica una trasformazione ortogonale che preserva le distanze. Secondo Rencher (2002), un termine migliore sarebbe \emph{trasformazione} obliqua. Il termine rotazione obliqua, comunque, fa parte dell'uso corrente.

Nella rotazione obliqua, gli assi della soluzione ruotata non devono rimanere ortogonali e quindi possono più facilmente avvicinarsi ai raggruppamenti di punti nello spazio delle saturazioni fattoriali (assumendo che dei raggruppamenti esistano). Vari metodi analitici sono stati proposti per ottenere una rotazione obliqua. Qui esamineremo brevemente solo uno di essi, il metodo Direct Oblimin.

Il criterio usato nel metodo Direct Oblimin (Jennrich e Sampson, 1966) è il seguente:

\[
\sum_{ij} \left(\sum_v \lambda_i^2 \lambda_j^2 - w \frac{1}{p} \sum_v \lambda_i^2
\sum_v \lambda_j^2\right)
\]

dove \(\sum_{ij}\) si riferisce alla somma su tutte le coppie di fattori \(ij\). In questo caso si procede ad una minimizzazione piuttosto che a una masssimizzazione.

\hypertarget{matrice-dei-pesi-fattoriali-e-matrice-di-struttura}{%
\section{Matrice dei pesi fattoriali e matrice di struttura}\label{matrice-dei-pesi-fattoriali-e-matrice-di-struttura}}

Nella rotazione ortogonale i fattori sono incorrelati. In tali circostanze, le correlazioni tra le variabili e i fattori sono uguali alle saturazioni fattoriali. In un \emph{path diagram}, infatti, vi è un unico percorso legittimo (in base alle regole di Wright) che collega le variabili manifeste ai fattori.

Si consideri la situazione presentata nella figura \ref{fig:fact-rot4}, con due variabili latenti incorrelate (\(\xi_1\) e \(\xi_2\)) e quattro variabili manifeste (\(y_1\), \(y_2\), \(y_3\), \(y_4\)). Siano \(\lambda_{11}\), \(\lambda_{12}\), \(\lambda_{13}\) e \(\lambda_{14}\) le saturazioni fattoriali delle variabili nel primo fattore; siano \(\lambda_{21}\), \(\lambda_{22}\), \(\lambda_{23}\) e \(\lambda_{24}\) le saturazioni fattoriali delle variabili nel secondo fattore.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{images/rot_4} 

}

\caption{Modello fattoriale con due fattori comuni ortogonali.}\label{fig:fact-rot4}
\end{figure}

In un diagramma di percorso, la correlazione tra due variabili contenute è uguale alla somma dei valori numerici di tutti i percorsi legittimi che collegano le variabili. Se i fattori comuni sono incorrelati (come nella figura \ref{fig:fact-rot4}, allora c'è un unico percorso che collega ciascuna variabile manifesta a ciascun fattore comune. Le correlazioni tra variabili manifeste e fattori comuni sono dunque uguali ai pesi fattoriali.

In queste circostanze, la soluzione fattoriale contenuta nella matrice delle saturazioni fattoriali rappresenta le correlazioni fra variabili e fattori. Tale matrice viene detta matrice ``di struttura.'' Le saturazioni possono essere interpretate in maniera equivalente ai pesi beta del modello di regressione multipla, i quali stimano il contributo specifico di ciascun fattore comune nel determinare la varianza spiegata degli item (Tabachnick \& Fidell, 2001).

Invece, nel caso della rotazione obliqua, la soluzione fattoriale ruotata produce un insieme di fattori comuni fra loro correlati. Di conseguenza, i pesi contenuti nella matrice delle saturazioni fattoriali non rappresentano le correlazioni fra variabili e fattori. Nel caso di una rotazione obliqua è perciò necessario specificare tre matrici diverse:

\begin{itemize}
\tightlist
\item
  la matrice dei pesi fattoriali \(\hat{\boldsymbol{\Lambda}}\), detta \emph{matrice pattern} (\emph{factor pattern matrix}, o ``configurazione,'' o ``matrice dei modelli''),
\item
  la \emph{matrice di struttura} (\emph{factor structure matrix}), che è la matrice delle correlazioni tra variabili manifeste e fattori,
\item
  la \emph{matrice di intercorrelazione fattoriale} \(\hat{\boldsymbol{\Phi}}\) (\emph{factor intercorrelation matrix}), che è la matrice che esprime le correlazioni tra i fattori.
\end{itemize}

La matrice pattern rappresenta i coefficienti parziali di regressione della variabile sul fattore, al netto degli altri fattori. Nel caso della rotazione obliqua, è la matrice che viene usata per determinare in che grado viene raggiunta la ``struttura semplice''.

Esaminiamo ora più in dettaglio la soluzione fattoriale prodotta da una rotazione obliqua. Gli assi che rappresentano i fattori non sono ortogonali (ovvero, i fattori sono correlati) e, in un diagramma di percorso, le variabili manifeste sono collegate ai fattori attraverso due percorsi distinti. Tali percorsi rappresentano l'effetto ``diretto'' e ``indiretto'' dei fattori sulle variabili. Nel caso di una rotazione obliqua, come abbiamo detto sopra, le saturazioni fattoriali non coincidono con le correlazioni tra variabili e fattori.

Si consideri la figura \ref{fig:fact-rot5}. Nel caso di una rotazione obliqua, la correlazione tra i due fattori comuni viene rappresentata mediante la freccia non direzionata \(\phi_{12}\) che collega \(\xi_1\) e \(\xi_2\). In tali circostanze, ci sono due percorsi legittimi (in base alle regole di Wright) che consentono di collegare ciascuna variabile manifesta ad un fattore comune. Nel caso della variabile \(y_1\) e il fattore \(\xi_1\), ad esempio, i percorsi sono: la freccia causale \(\lambda_{11}\) che rappresenta l'effetto diretto di \(\xi_1\) su \(y_1\) e il percorso composto che rappresenta l'effetto indiretto di \(\xi_1\) su \(y_1\). Il valore numerico di tale percorso composto è uguale al prodotto \(\lambda_{21}\phi_{12}\). Nei termini dell'analisi dei percorsi, dunque, la correlazione tra \(\xi_1\) e \(y_1\) è uguale alla somma dei valori numerici dei percorsi legittimi che collegano \(y_1\) a \(\xi_1\), ovvero \(\lambda_{11} + \lambda_{21} \phi_{12}\).

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{images/rot_5} 

}

\caption{Modello fattoriale con due fattori comuni dopo una rotazione obliqua.}\label{fig:fact-rot5}
\end{figure}

Per illustrare la rotazione obliqua, utilizziamo i dati presentati da Rencher (2002). Si consideri la seguente matrice di correlazione:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{R }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}
  \FunctionTok{c}\NormalTok{(}
    \FloatTok{1.00}\NormalTok{, }\FloatTok{0.735}\NormalTok{, }\FloatTok{0.711}\NormalTok{, }\FloatTok{0.704}\NormalTok{,}
    \FloatTok{0.735}\NormalTok{, }\FloatTok{1.00}\NormalTok{, }\FloatTok{0.693}\NormalTok{, }\FloatTok{0.709}\NormalTok{,}
    \FloatTok{0.711}\NormalTok{, }\FloatTok{0.693}\NormalTok{, }\FloatTok{1.00}\NormalTok{, }\FloatTok{0.839}\NormalTok{,}
    \FloatTok{0.704}\NormalTok{, }\FloatTok{0.709}\NormalTok{, }\FloatTok{0.839}\NormalTok{, }\FloatTok{1.00}
\NormalTok{  ),}
  \AttributeTok{ncol =} \DecValTok{4}\NormalTok{,}
  \AttributeTok{byrow =} \ConstantTok{TRUE}
\NormalTok{)}
\NormalTok{R}
\CommentTok{\#\textgreater{}       [,1]  [,2]  [,3]  [,4]}
\CommentTok{\#\textgreater{} [1,] 1.000 0.735 0.711 0.704}
\CommentTok{\#\textgreater{} [2,] 0.735 1.000 0.693 0.709}
\CommentTok{\#\textgreater{} [3,] 0.711 0.693 1.000 0.839}
\CommentTok{\#\textgreater{} [4,] 0.704 0.709 0.839 1.000}
\end{Highlighting}
\end{Shaded}

Iniziamo a calcolare una soluzione a due fattori usando il metodo delle componenti principali e una rotazione Varimax. I pesi fattoriali sono:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{f1\_pc }\OtherTok{\textless{}{-}} \FunctionTok{principal}\NormalTok{(R, }\DecValTok{2}\NormalTok{, }\AttributeTok{rotate =} \StringTok{"varimax"}\NormalTok{)}
\NormalTok{f1\_pc}
\CommentTok{\#\textgreater{} Principal Components Analysis}
\CommentTok{\#\textgreater{} Call: principal(r = R, nfactors = 2, rotate = "varimax")}
\CommentTok{\#\textgreater{} Standardized loadings (pattern matrix) based upon correlation matrix}
\CommentTok{\#\textgreater{}    RC1  RC2   h2    u2 com}
\CommentTok{\#\textgreater{} 1 0.50 0.78 0.86 0.140 1.7}
\CommentTok{\#\textgreater{} 2 0.47 0.81 0.88 0.124 1.6}
\CommentTok{\#\textgreater{} 3 0.90 0.33 0.92 0.078 1.3}
\CommentTok{\#\textgreater{} 4 0.89 0.35 0.92 0.083 1.3}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}                        RC1  RC2}
\CommentTok{\#\textgreater{} SS loadings           2.08 1.50}
\CommentTok{\#\textgreater{} Proportion Var        0.52 0.37}
\CommentTok{\#\textgreater{} Cumulative Var        0.52 0.89}
\CommentTok{\#\textgreater{} Proportion Explained  0.58 0.42}
\CommentTok{\#\textgreater{} Cumulative Proportion 0.58 1.00}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Mean item complexity =  1.5}
\CommentTok{\#\textgreater{} Test of the hypothesis that 2 components are sufficient.}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} The root mean square of the residuals (RMSR) is  0.06 }
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Fit based upon off diagonal values = 0.99}
\end{Highlighting}
\end{Shaded}

Si noti che i due fattori non sono molto distinti. La soluzione prodotta da una rotazione obliqua si ottiene nel modo seguente:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pr\_oblimin }\OtherTok{\textless{}{-}} \FunctionTok{principal}\NormalTok{(R, }\DecValTok{2}\NormalTok{, }\AttributeTok{rotate =} \StringTok{"oblimin"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

La matrice \(\hat{\boldsymbol{\Lambda}}\) dei pesi fattoriali si ricava nel modo seguente:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cbind}\NormalTok{(pr\_oblimin}\SpecialCharTok{$}\NormalTok{load[, }\DecValTok{1}\NormalTok{], pr\_oblimin}\SpecialCharTok{$}\NormalTok{load[, }\DecValTok{2}\NormalTok{])}
\CommentTok{\#\textgreater{}          [,1]     [,2]}
\CommentTok{\#\textgreater{} [1,]  0.03207  0.90186}
\CommentTok{\#\textgreater{} [2,] {-}0.02543  0.95557}
\CommentTok{\#\textgreater{} [3,]  0.96859 {-}0.01097}
\CommentTok{\#\textgreater{} [4,]  0.94727  0.01328}
\end{Highlighting}
\end{Shaded}

La matrice \(\hat{\boldsymbol{\Phi}}\) di intercorrelazione fattoriale è

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pr\_oblimin}\SpecialCharTok{$}\NormalTok{Phi}
\CommentTok{\#\textgreater{}       TC1   TC2}
\CommentTok{\#\textgreater{} TC1 1.000 0.787}
\CommentTok{\#\textgreater{} TC2 0.787 1.000}
\end{Highlighting}
\end{Shaded}

La matrice di struttura si ottiene premoltiplicando la matrice \(\boldsymbol{\Lambda}\) dei pesi fattoriali alla matrice \(\boldsymbol{\Phi}\) di intercorrelazione fattoriale:

\[
\text{matrice di struttura} = \boldsymbol{\Lambda}\boldsymbol{\Phi}.
\]

Per esempio, la correlazione tra la prima variabile e il primo fattore è

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pr\_oblimin}\SpecialCharTok{$}\NormalTok{load[}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{] }\SpecialCharTok{+}\NormalTok{ pr\_oblimin}\SpecialCharTok{$}\NormalTok{load[}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{] }\SpecialCharTok{*}\NormalTok{ pr\_oblimin}\SpecialCharTok{$}\NormalTok{Phi[}\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{]}
\CommentTok{\#\textgreater{}    TC1 }
\CommentTok{\#\textgreater{} 0.7418}
\end{Highlighting}
\end{Shaded}

L'intera matrice di struttura si trova nel modo seguente:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{round}\NormalTok{(pr\_oblimin}\SpecialCharTok{$}\NormalTok{load }\SpecialCharTok{\%*\%}\NormalTok{ pr\_oblimin}\SpecialCharTok{$}\NormalTok{Phi, }\DecValTok{3}\NormalTok{)}
\CommentTok{\#\textgreater{}        TC1   TC2}
\CommentTok{\#\textgreater{} [1,] 0.742 0.927}
\CommentTok{\#\textgreater{} [2,] 0.727 0.936}
\CommentTok{\#\textgreater{} [3,] 0.960 0.751}
\CommentTok{\#\textgreater{} [4,] 0.958 0.759}
\end{Highlighting}
\end{Shaded}

\hypertarget{ch:val_sol_fattoriale}{%
\chapter{Come valutare e rifinire la soluzione fattoriale}\label{ch:val_sol_fattoriale}}

\hypertarget{valutazione-della-matrice-pattern}{%
\section{Valutazione della matrice pattern}\label{valutazione-della-matrice-pattern}}

La maggior parte di strumenti usati nell'assessment psicologico e neuropsicologico non valuta una singola dimensione psicologica, ma piuttosto misura molteplici aspetti di un costrutto. Di conseguenza, l'analisi fattoriale produce solitamente una soluzione con più di un fattore. Idealmente, dopo la rotazione, ciascun item saturerà fortemente in un singolo fattore e debolmente negli altri. In realtà, anche dopo la rotazione degli assi fattoriali, talvolta si presentano item che saturano debolmente in tutti i fattori, oppure item che saturano fortemente in più di un fattore.

Uno dei primi passi da compiere per valutare e rifinire la soluzione fattoriale è quello di valutare la matrice di struttura in base al criterio della ``struttura semplice'' e poi esaminare gli effetti delle azioni intraprese (es., eliminare alcuni item) nella matrice pattern. Ricordiamo che la matrice di struttura contiene le correlazioni tra item e fattori, mentre la matrice pattern contiene le saturazioni fattoriali.

\hypertarget{item-con-basse-saturazioni-su-tutti-i-fattori}{%
\subsection{Item con basse saturazioni su tutti i fattori}\label{item-con-basse-saturazioni-su-tutti-i-fattori}}

Prima di procedere all'analisi fattoriale è auspicabile esaminare la matrice di correlazioni tra gli item ed eliminare quegli item che sono insufficientemente correlati con tutti gli altri item nella matrice. Tuttavia, anche dopo questo screening iniziale, è possibile trovare item con basse saturazioni su tutti i fattori. Dal punto di vista pratico, per basse saturazioni si intendono quelle il cui valore assoluto è minore di 0.30 (Hair et al., 1995). Hair e collaboratori suggeriscono due soluzioni nel caso di item con basse saturazioni su tutti i fattori: (1) eliminare gli item con basse saturazioni, (2) valutare le comunalità degli item problematici e il contributo specifico che forniscono allo strumento. Se un item ha una bassa comunalità, o se il contributo di un item nei confronti del significato generale dello strumento è di poca importanza, allora l'item dovrebbe essere eliminato. Si procede dunque alla creazione di una nuova soluzione fattoriale e i risultati vengono riesaminati.

Se vi sono degli item con basse saturazioni su tutti i fattori che però contribuiscono in maniera importante a determinare il significato della scala nel suo complesso, allora questi item dovrebbero essere mantenuti. Alle volte, per tali item è possibile creare delle sottoscale separate dalle altre.

\hypertarget{item-con-saturazioni-evevate-su-piuxf9-di-un-fattore}{%
\subsection{Item con saturazioni evevate su più di un fattore}\label{item-con-saturazioni-evevate-su-piuxf9-di-un-fattore}}

È comune trovare item che saturano su fattori multipli (pesi fattoriali \(>\) .30), specialmente nel caso di soluzioni fattoriali ottenuti dopo una rotazione obliqua. Kline (2000) suggerisce di eliminare tali item in quanto rendono difficile da interpretare il significato della scala che così si ottiene. Hair e collaboratori (1995) ritengono invece che tali item debbano essere mantenuti dato possono chiarire il significato dei fattori che la scala identifica.

\hypertarget{valutazione-dellattendibilituxe0}{%
\section{Valutazione dell'attendibilità}\label{valutazione-dellattendibilituxe0}}

All'interno del problema della costruzione di uno strumento vengono esaminati tre aspetti dell'attendibilità: la consistenza interna, la stabilità e l'equivalenza.

\hypertarget{la-procedura-split-half}{%
\subsection{La procedura split-half}\label{la-procedura-split-half}}

La consistenza interna misura il grado di coerenza tra gli item che costituiscono lo strumento o le sottoscale dello strumento. Se tutti gli item che costituiscono uno strumento o una sua sottoscala misurano la stessa cosa, allora saranno fortemente associati tra loro. La consistenza interna misurata con il metodo dello split-half si determina calcolando la correlazione di Pearson tra i punteggi ottenuti utilizzando ciascuna delle due metà degli item dello strumento. Usando un software, è meglio trovare la media delle correlazioni inter-item ricavabili a partire da tutte le possibili divisioni a metà dell'insieme di item che costituiscono lo strumento. La correlazione trovata in questo modo viene poi corretta utilizzando la formula ``profetica'' di Spearman-Brown per tenere in considerazione il fatto che l'attendibilità è stata calcolata utilizzando soltanto metà degli item dello strumento.

Si noti che la formula di Spearman-Brown è basata sull'assunzione che le due metà dello strumento siano parallele, ovvero che abbiano identici punteggi veri e uguali varianze d'errore (questa assunzione comporta la conseguenza che le due metà degli item producono punteggi aventi uguali medie e varianze). Se queste assunzioni molto stringenti non vengono soddisfatte, allora ciò conduce ad una sovrastima dell'attendibilità della scala.

\hypertarget{lanalisi-della-varianza}{%
\paragraph{L'analisi della varianza}\label{lanalisi-della-varianza}}

Se tutti gli item di uno strumento o di una sottoscala sono espressione dello stesso costrutto, allora ci dobbiamo aspettare che anche le medie dei punteggi sugli item siano uguali. Come è stato detto sopra, questa è infatti una delle assunzioni delle forme strettamente parallele di un test. È dunque possibile verificare questa assunzione mediante un'ANOVA che, appunto, sottopone a test l'ipotesi nulla dell'uguaglianza delle medie. Nel caso degli item di un test, dato che ciascun soggetto completa tutti gli item che costituiscono lo strumento, è appropriato usare un'ANOVA per misure ripetute che, nella sua declinazione più moderna, corrisponde ad un modello multilivello (\emph{mixed-effect model}).

\hypertarget{lindice-alpha-di-cronbach}{%
\subsection{\texorpdfstring{L'indice \(\alpha\) di Cronbach}{L'indice \textbackslash alpha di Cronbach}}\label{lindice-alpha-di-cronbach}}

L'indice \(\alpha\) di Cronbach è la misura più utilizzata per valutare l'attendibilità quale consistenza interna di uno strumento. L'\(\alpha\) di Cronbach è stato interpretato come la proporzione di varianza della scala che può essere attribuita al fattore comune (DeVellis, 1991). Può anche essere interpretato come la correlazione stimata tra i punteggi della scala e un'altro strumento della stessa lunghezza tratto dall'universo degli item possibili che costituiscono il dominio del costrutto (Kline, 1986). La radice quadrata del coefficiente \(\alpha\) di Cronbach rappresenta la correlazione stimata tra i punteggi ottenuti tramite lo strumento e i punteggi veri (Nunnally \& Bernstein, 1994).

In precedenza abbiamo descritto una serie di limiti del coefficiente \(\alpha\) di Cronbach. In generale, molti ricercatori suggeriscono di usare al suo posto l'indice \(\omega\) di McDonald.

\hypertarget{lattendibilituxe0-quale-stabilituxe0-temporale}{%
\subsection{L'attendibilità quale stabilità temporale}\label{lattendibilituxe0-quale-stabilituxe0-temporale}}

La stabilità temporale viene valutata attraverso la procedura di test-retest. La correlazione tra le misure ottenute in due momenti negli stessi rispondenti ci fornisce l'attendibilità di test-retest.

Kline (2000) ha messo in evidenza come l'attendibilità di test-retest sia influenzata da molteplici fattori, tra cui le caratteristiche del campione, la maturità dei rispondenti, i cambiamenti nello stato emozionale, le differenze nelle condizioni di somministrazione del test, la possibilità di ricordare le risposte date in precedenza, la difficoltà degli item, la grandezza del campione e le caratteristiche del costrutto (ad esempio, stato vs.~tratto).

Particolare attenzione deve essere rivolta all'intervallo temporale usato nella procedura di test-retest. Se il periodo di tempo che intercorre tra le due somministrazioni è troppo corto, i risultati possono risultare distorti a causa del fatto che i soggetti si ricordano le risposte date in precedenza. Questo può condurre ad una sovrastima dell'attendibilità test-retest (Pedhazur \& Schmelkin, 1991). Un intervallo temporale troppo lungo tra le due somministrazioni ha invece come limite il fatto che, in questo caso, vi è un'alta possibilità che intervengano dei cambiamenti nei rispondenti rispetto al costrutto in esame. Alla luce di queste considerazioni è stato suggerito di utilizzare un intervallo temporale abbastanza breve, ovvero di una o due settimane (Nunnally \& Bernstein, 1994; Pedhazur \& Schmelkin, 1991). Se è necessario valutare la stabilità temporale nel corso di un lungo arco temporale, Nunnally e Bernstein (1994) suggeriscono di utilizzare un intervallo di sei mesi o maggiore.

\hypertarget{forme-parallele}{%
\subsection{Forme parallele}\label{forme-parallele}}

Per cercare di evitare i problemi associati all'attendibilità quale stabilità temporale, alcuni autori si sono posti il problema di esaminare la correlazione tra forme parallele (o equivalenti) dello strumento. La correlazione tra forme parallele di uno strumento va sotto il nome di coefficiente di equivalenza e fornisce una misura alternativa dell'attendibilità dello strumento (Burns \& Grove, 2001; Pedhazur \& Schmelkin, 1991; Polit \& Hungler, 1999).

Nunnally e Bernstein (1994) suggeriscono di confrontare i risultati ottenuti con la somministrazione delle forme parallele lo stesso giorno con quelli ottenuti nel caso di un intervallo temporale di due settimane. Kline (2000) ritiene che l'attendibilità tra due forme parallele debba essere di almeno 0.9 perché, per valori inferiori, sarebbe difficile sostenere che le forme sono veramente parallele.

È tuttavia molto oneroso predisporre due forme parallele di uno strumento. Per questa ragione, il coefficiente di equivalenza viene raramente usato.

\hypertarget{selezione-di-un-sottoinsieme-di-item}{%
\section{Selezione di un sottoinsieme di item}\label{selezione-di-un-sottoinsieme-di-item}}

Tipicamente, la costruzione di un test viene realizzata somministrando un grande numero di item per poi selezionare gli item ``migliori'' che andranno a fare parte del test vero e proprio. Si supponga di somministrare inizialmente \(m\) item, quando si desidera che il test finale sia costituito da \(p < m\) item. Un modo di affrontare questo problema potrebbe essere quello di calcolare l'attendibilità del test (coefficiente \(\omega\)) per tutti i possibili sottoinsiemi di \(p\) item, così da individuare il sottoinsieme migliore. Questo modo di procedere, però, è problematico perché richiede la valutazione di un elevatissimo numero di possibilità. Per esempio, da un insieme iniziale neanche troppo numeroso di 100 item, il numero di sottoinsiemi di 20 item è uguale a

\[\binom{100}{20} = 5.36 \times 10^{20}\]

È dunque necessario trovare metodi alternativi che evitino una tale esplosione combinatoria.

A questo fine è utile calcolare la \emph{quantità di informazione} di ciascun item:

\[
\frac{\lambda_i^2}{\psi_{ii}}.
\]

McDonald (2013) mostra che l'omissione di uno o più item produce sempre una riduzione dell'attendibilità del test (ovvero, una riduzione nel valore di \(\omega\)). Tuttavia, tale riduzione è tanto più piccola quanto più piccola è la quantità di informazione degli item omessi. Il processo di selezione degli item può dunque essere guidato da un semplice principio: si selezionano gli item aventi la quantità di informazione maggiore.

\begin{example}
Si consideri nuovamente la matrice di varianze e di covarianze SWLS:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{varnames }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"Y1"}\NormalTok{, }\StringTok{"Y2"}\NormalTok{, }\StringTok{"Y3"}\NormalTok{, }\StringTok{"Y4"}\NormalTok{, }\StringTok{"Y5"}\NormalTok{)}
\NormalTok{SWLS }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{c}\NormalTok{(}
  \FloatTok{2.565}\NormalTok{, }\FloatTok{1.424}\NormalTok{, }\FloatTok{1.481}\NormalTok{, }\FloatTok{1.328}\NormalTok{, }\FloatTok{1.529}\NormalTok{,}
  \FloatTok{1.424}\NormalTok{, }\FloatTok{2.493}\NormalTok{, }\FloatTok{1.267}\NormalTok{, }\FloatTok{1.051}\NormalTok{, }\FloatTok{1.308}\NormalTok{,}
  \FloatTok{1.481}\NormalTok{, }\FloatTok{1.267}\NormalTok{, }\FloatTok{2.462}\NormalTok{, }\FloatTok{1.093}\NormalTok{, }\FloatTok{1.360}\NormalTok{,}
  \FloatTok{1.328}\NormalTok{, }\FloatTok{1.051}\NormalTok{, }\FloatTok{1.093}\NormalTok{, }\FloatTok{2.769}\NormalTok{, }\FloatTok{1.128}\NormalTok{,}
  \FloatTok{1.529}\NormalTok{, }\FloatTok{1.308}\NormalTok{, }\FloatTok{1.360}\NormalTok{, }\FloatTok{1.128}\NormalTok{, }\FloatTok{3.355}
\NormalTok{),}
\AttributeTok{ncol =} \DecValTok{5}\NormalTok{, }\AttributeTok{byrow =} \ConstantTok{TRUE}\NormalTok{,}
\AttributeTok{dimnames =} \FunctionTok{list}\NormalTok{(varnames, varnames)}
\NormalTok{)}
\NormalTok{SWLS}
\CommentTok{\#\textgreater{}       Y1    Y2    Y3    Y4    Y5}
\CommentTok{\#\textgreater{} Y1 2.565 1.424 1.481 1.328 1.529}
\CommentTok{\#\textgreater{} Y2 1.424 2.493 1.267 1.051 1.308}
\CommentTok{\#\textgreater{} Y3 1.481 1.267 2.462 1.093 1.360}
\CommentTok{\#\textgreater{} Y4 1.328 1.051 1.093 2.769 1.128}
\CommentTok{\#\textgreater{} Y5 1.529 1.308 1.360 1.128 3.355}
\end{Highlighting}
\end{Shaded}

Utilizzando la funzione \texttt{sem()} contenuta nel pacchetto \texttt{sem} il modello ad un fattore viene definito nel modo seguente:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mod\_1 }\OtherTok{\textless{}{-}} \StringTok{"}
\StringTok{  F =\textasciitilde{} Y1 + Y2 + Y3 + Y4 + Y5}
\StringTok{"}
\end{Highlighting}
\end{Shaded}

Otteniamo così una stima dei pesi fattoriali e delle varianze specifiche:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit }\OtherTok{\textless{}{-}}\NormalTok{ lavaan}\SpecialCharTok{::}\FunctionTok{cfa}\NormalTok{(}
\NormalTok{  mod\_1,}
  \AttributeTok{sample.cov =}\NormalTok{ SWLS,}
  \AttributeTok{sample.nobs =} \DecValTok{215}\NormalTok{,}
  \AttributeTok{std.lv =} \ConstantTok{TRUE}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Esaminiamo la \emph{quantità di informazione} fornita da ciascun item.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lambda }\OtherTok{\textless{}{-}} \FunctionTok{inspect}\NormalTok{(fit, }\AttributeTok{what =} \StringTok{"std"}\NormalTok{)}\SpecialCharTok{$}\NormalTok{lambda}
\NormalTok{lambda}
\CommentTok{\#\textgreater{}        F}
\CommentTok{\#\textgreater{} Y1 0.817}
\CommentTok{\#\textgreater{} Y2 0.694}
\CommentTok{\#\textgreater{} Y3 0.726}
\CommentTok{\#\textgreater{} Y4 0.591}
\CommentTok{\#\textgreater{} Y5 0.643}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{theta }\OtherTok{\textless{}{-}} \FunctionTok{diag}\NormalTok{(}\FunctionTok{inspect}\NormalTok{(fit, }\AttributeTok{what =} \StringTok{"std"}\NormalTok{)}\SpecialCharTok{$}\NormalTok{theta)}
\NormalTok{theta}
\CommentTok{\#\textgreater{}     Y1     Y2     Y3     Y4     Y5 }
\CommentTok{\#\textgreater{} 0.3330 0.5182 0.4732 0.6512 0.5867}
\end{Highlighting}
\end{Shaded}

Possiamo calcolare tale quantità facendo il rapporto tra ciascun peso fattoriale innalzato al quadrato e la sua varianza specifica:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\DecValTok{5}\NormalTok{) \{}
  \FunctionTok{print}\NormalTok{(lambda[i]}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{/}\NormalTok{ theta[i])}
\NormalTok{\}}
\CommentTok{\#\textgreater{}    Y1 }
\CommentTok{\#\textgreater{} 2.003 }
\CommentTok{\#\textgreater{}     Y2 }
\CommentTok{\#\textgreater{} 0.9299 }
\CommentTok{\#\textgreater{}    Y3 }
\CommentTok{\#\textgreater{} 1.113 }
\CommentTok{\#\textgreater{}     Y4 }
\CommentTok{\#\textgreater{} 0.5356 }
\CommentTok{\#\textgreater{}     Y5 }
\CommentTok{\#\textgreater{} 0.7046}
\end{Highlighting}
\end{Shaded}

Tale risultato indica che il quarto item è il meno informativo e che il quinto item è il secondo meno informativo. Se un solo item deve essere eliminato, dunque, questo sarà il quarto item. Se devono essere eliminati due item, dunque, andranno eliminati il quarto e il quinto item.
\end{example}

In conclusione, possiamo dire che l'omissione di un item provoca sempre una riduzione del valore di \(\omega\) del test. Tale riduzione è però tanto minore quanto più piccola è la quantità di informazione dell'item omesso. Questo principio può essere usato per selezionare gli item del test.

\hypertarget{sec:reliability_number_item}{%
\section{Attendibilità e numero di item}\label{sec:reliability_number_item}}

Di quanto cambia l'attendibilità di uno strumento se viene variato il numero di item? Una risposta a questa domanda può essere fornita dalla formula profetica di Spearman-Brown. Supponiamo che nella formula di Spearman-Brown,

\begin{equation}
  \rho_p = \frac{p \rho_1}{(p-1)\rho_1 + 1},
  \label{eq:spearman-brown}
\end{equation}

\(\rho_1\) rappresenti l'attendibilità di un test costituito da un certo numero di item. Ponendo \(p=2\), la \eqref{eq:spearman-brown} ci fornisce una stima dell'attendibilità di un test costituito da un numero doppio di item rispetto al test originario. Valori di \(p\) minori di \(1\), invece, vengono usati per predire le variazioni dell'attendibilità conseguenti ad una diminuzione nel numero degli item del test.

Ricordiamo che le predizioni della formula di Spearman-Brown sono accurate solo se la forma allungata o accorciata del test è parallela al test considerato. Per esempio, se ad un test con un coefficiente di attendibilità molto alto vengono aggiunti item aventi una bassa attendibilità, allora l'attendibilità del test allungato sarà minore di quella predetta dalla formula di Spearman-Brown.

Si consideri la scala SWLS. Chiediamoci come varia l'attendibilità della scala se il numero di item aumenta da 5 a 20. L'attendibilità della scala SWLS costituita da 5 item è 0.824. Applicando la formula di Spearman-Brown otteniamo:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\DecValTok{4} \SpecialCharTok{*} \FloatTok{0.824}\NormalTok{) }\SpecialCharTok{/}\NormalTok{ ((}\DecValTok{4} \SpecialCharTok{{-}} \DecValTok{1}\NormalTok{) }\SpecialCharTok{*} \FloatTok{0.824} \SpecialCharTok{+} \DecValTok{1}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 0.9493}
\end{Highlighting}
\end{Shaded}

In maniera alternativa, supponiamo che i 15 item aggiuntivi abbiano le stesse saturazioni fattoriali medie (\(\bar{\lambda}\)) e le stesse varianze specifiche medie (\(\bar{\psi}\)) rispetto agli item originali. Mediante gli item di cui disponiamo, definiamo l'attendibilità di un ``item medio'' come

\[\rho_1 = \frac{\bar{\lambda}^2}{\bar{\lambda}^2 + \bar{\psi}}.\]

Ovvero

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rho\_1 }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(lambda)}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{/}\NormalTok{ (}\FunctionTok{mean}\NormalTok{(lambda)}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{+} \FunctionTok{mean}\NormalTok{(theta))}
\NormalTok{rho\_1}
\CommentTok{\#\textgreater{} [1] 0.4845}
\end{Highlighting}
\end{Shaded}

L'attendibilità predetta di un test costituito da 20 item sarà dunque uguale a

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\DecValTok{20} \SpecialCharTok{*}\NormalTok{ rho\_1) }\SpecialCharTok{/}\NormalTok{ ((}\DecValTok{20} \SpecialCharTok{{-}} \DecValTok{1}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ rho\_1 }\SpecialCharTok{+} \DecValTok{1}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 0.9495}
\end{Highlighting}
\end{Shaded}

il che replica il risultato ottenuto precedentemente.

Un altro modo ancora per ottenere lo stesso risultato è quello di adattare ai dati il modello monofattoriale con item paralleli:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mod\_2 }\OtherTok{\textless{}{-}} \StringTok{"}
\StringTok{  F =\textasciitilde{} a*Y1 + a*Y2 + a*Y3 + a*Y4 + a*Y5}
\StringTok{  Y1 \textasciitilde{}\textasciitilde{} b*Y1}
\StringTok{  Y2 \textasciitilde{}\textasciitilde{} b*Y2}
\StringTok{  Y3 \textasciitilde{}\textasciitilde{} b*Y3}
\StringTok{  Y4 \textasciitilde{}\textasciitilde{} b*Y4}
\StringTok{  Y5 \textasciitilde{}\textasciitilde{} b*Y5}
\StringTok{"}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit2 }\OtherTok{\textless{}{-}}\NormalTok{ lavaan}\SpecialCharTok{::}\FunctionTok{cfa}\NormalTok{(}
\NormalTok{  mod\_2,}
  \AttributeTok{sample.cov =}\NormalTok{ SWLS,}
  \AttributeTok{sample.nobs =} \DecValTok{215}\NormalTok{,}
  \AttributeTok{std.lv =} \ConstantTok{TRUE}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

da cui

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lambda }\OtherTok{\textless{}{-}} \FunctionTok{inspect}\NormalTok{(fit2, }\AttributeTok{what =} \StringTok{"std"}\NormalTok{)}\SpecialCharTok{$}\NormalTok{lambda}
\NormalTok{lambda}
\CommentTok{\#\textgreater{}        F}
\CommentTok{\#\textgreater{} Y1 0.689}
\CommentTok{\#\textgreater{} Y2 0.689}
\CommentTok{\#\textgreater{} Y3 0.689}
\CommentTok{\#\textgreater{} Y4 0.689}
\CommentTok{\#\textgreater{} Y5 0.689}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{theta }\OtherTok{\textless{}{-}} \FunctionTok{diag}\NormalTok{(}\FunctionTok{inspect}\NormalTok{(fit2, }\AttributeTok{what =} \StringTok{"std"}\NormalTok{)}\SpecialCharTok{$}\NormalTok{theta)}
\NormalTok{theta}
\CommentTok{\#\textgreater{}     Y1     Y2     Y3     Y4     Y5 }
\CommentTok{\#\textgreater{} 0.5247 0.5247 0.5247 0.5247 0.5247}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rho\_1 }\OtherTok{\textless{}{-}}\NormalTok{ lambda[}\DecValTok{1}\NormalTok{]}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{/}\NormalTok{ (lambda[}\DecValTok{1}\NormalTok{]}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{+}\NormalTok{ theta[}\DecValTok{2}\NormalTok{])}
\NormalTok{rho\_1}
\CommentTok{\#\textgreater{}     Y2 }
\CommentTok{\#\textgreater{} 0.4753}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\DecValTok{20} \SpecialCharTok{*}\NormalTok{ rho\_1) }\SpecialCharTok{/}\NormalTok{ ((}\DecValTok{20} \SpecialCharTok{{-}} \DecValTok{1}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ rho\_1 }\SpecialCharTok{+} \DecValTok{1}\NormalTok{)}
\CommentTok{\#\textgreater{}     Y2 }
\CommentTok{\#\textgreater{} 0.9477}
\end{Highlighting}
\end{Shaded}

Anche se la formula di Spearman-Brown ha un ruolo centrale nella teoria classica dei test, si tenga conto che non rappresenta l'unico strumento che può essere utilizzato a questo proposito. La quantità detta \emph{informazione dell'item} (\emph{item information}), formulata dai modelli IRT, consente di predire con maggiore precisione i cambiamenti nella qualità della misura a seguito dell'aggiunta o della cancellazione di un sottoinsieme di item.

\hypertarget{numero-di-item-e-affidabilituxe0}{%
\subsection{Numero di item e affidabilità}\label{numero-di-item-e-affidabilituxe0}}

La formula di Spearman-Brown può anche essere riarrangiata in maniera tale da consentirci di predire il numero degli item necessari per raggiungere un determinato livello di affidabilità:

\begin{equation}
p = \frac{\rho_p (1-\rho_1)}{\rho_1(1-\rho_p)}, 
\label{eq:s-b-inv}
\end{equation}

dove \(\rho_1\) è l'attendibilità stimata di un ``item medio,'' \(\rho_p\) è il livello desiderato di attendibilità del test totale e \(p\) è il numero di item del test allungato.

L'attendibilità della scala SWLS costituita da 5 item è \(\omega = 0.824\). Quanti item devono essere aggiunti se si vuole raggiungere un livello di attendibilità pari a \(0.95\)?

Ponendo \(\rho_p = 0.95\) e \(\rho_1= 0.479\), in base alla \eqref{eq:s-b-inv} si ottiene che

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(.}\DecValTok{95} \SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ rho\_1)) }\SpecialCharTok{/}\NormalTok{ (rho\_1 }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ .}\DecValTok{95}\NormalTok{))}
\CommentTok{\#\textgreater{}    Y2 }
\CommentTok{\#\textgreater{} 20.98}
\end{Highlighting}
\end{Shaded}

il test dovrà essere costituito da 21 item.

\hypertarget{analisi-degli-item}{%
\section{Analisi degli item}\label{analisi-degli-item}}

L'analisi degli item esamina le risposte fornite ai singoli item del questionario allo scopo di valutare la qualità degli item e del questionario nel suo complesso. Sotto al rubrica di analisi degli item possiamo raggruppare le procedure che possono essere utilizzate per descrivere la difficoltà degli item, le relazioni tra coppie di item, il punteggio totale del test, le relazioni tra gli item e il punteggio totale del test. Tali procedure vengono utilizzate per la selezione degli item al fine di costruire un questionario omogeneo, attendibile e dotato di validità predittiva.

L'esame delle caratteristiche psicometriche degli item che compongono il test non può però essere automatizzata ed eseguita solo sulla base dei risultati delle analisi statiche. L'analisi degli item, invece, va integrata con considerazioni di ordine teorico basate sulla centralità dell'item rispetto alla definizione del costrutto, agli scopi della misurazione e al modo in cui l'item è stato formulato e costruito. Se alcuni aspetti di un costrutto non vengono rappresentanti da item che soddisfano i criteri descritti sopra, o se c'è un numero insufficiente di item per produrre uno strumento attendibile, allora alcuni item devono essere riscritti. Nello scrivere gli item, risultano utili le intuizioni che si sono guadagnate nello scrivere gli item che non hanno funzionato.

\hypertarget{difficoltuxe0-degli-item}{%
\subsection{Difficoltà degli item}\label{difficoltuxe0-degli-item}}

La più ovvia caratteristica psicometrica di un item in un test di prestazione massima è la proporzione di soggetti che risponde correttamente all'item.La proporzione \(p_j\) di soggetti che rispondono correttamente all'item \(j\)-esimo, o si dichiarano in accordo con l'affermazione espressa dall'item, fornisce una stima di \(\pi_j\), ovvero il \emph{livello di difficoltà} dell'item. In realtà, \(p_j\) dovrebbe essere chiamato ``facilità dell'item'' in quanto assume il suo valore maggiore (ovvero \(1\)) quando tutti i rispondenti rispondono correttamente all'item considerato e il suo valore minimo (ovvero \(0\)) quando le risposte sono tutte sbagliate. I valori \(p_j\) giocano un ruolo importante nelle procedure di selezione degli item.

La difficoltà degli item deve essere interpretata in riferimento alla probabilità di indovinare la risposta corretta. Si suppone, infatti, che i rispondenti tirino ad indovinare quando non conoscono la risposta alla domanda di un questionario. Nel caso di item dicotomici, per esempio, ci possiamo aspettare un valore \(p_j\) pari a \(0.50\) sulla base del caso soltanto; nel caso di item a risposta multipla con quattro opzioni di scelta, invece, \(p_j\) assume un valore pari a \(0.25\) quando i rispondenti tirano ad indovinare.

Se il test è composto, per la maggior parte, da item ``facili,'' allora il test non sarà in grado di discriminare tra rispondenti con livelli di abilità diversi, in quanto quasi tutti i rispondenti saranno in grado di fornire una risposta corretta alla maggioranza degli item. Lo stesso si può dire per un test composto da item ``difficili.'' Se consideriamo un test composto unicamente da item di difficoltà media, è facile rendersi conto che non potrà differenziare i rispondenti di abilità media da quelli con abilità superiori alla media (dato che non ci sono item ``difficili''), e neppure da quelli con abilità inferiori alla media (dato che non ci sono item ``facili'').

In generale è buona pratica costruire test composti da item che coprano tutti i livelli di difficoltà. La scelta che viene usualmente fatta è quella di una dispersione moderata e simmetrica del livello di difficoltà attorno ad un valore leggermente superiore al valore che sta a metà tra il livello del caso (\(1.0\) diviso per il numero di alternative) e il punteggio pieno (\(1.0\)). Per item che presentano quattro alternative di risposta, ad esempio, il livello del caso è pari a \(1.00/4 = 0.25\). Il livello ottimale di difficoltà media è dunque uguale a

\[0.25 + (1.00 - 0.25) / 2 = 0.62.\]

Per item dicotomici, il livello del caso è \(1.00/2 = 0.50\) e il livello ottimale di difficoltà media è

\[0.50+(1.00-.50)/2 = 0.75.\]

In generale, item con livelli di difficoltà superiore a \(0.90\) o inferiore a \(0.20\) dovrebbero essere utilizzati con cautela.

\hypertarget{correzione-per-guessing}{%
\subsection{Correzione per guessing}\label{correzione-per-guessing}}

Alle volte i valori \(p_j\) sono calcolati introducendo una correzione per le risposte fornite casualmente dai soggetti (\emph{guessing}). Si consideri un test a scelta multipla composto da item aventi ciascuno \(C\) alternative di risposta ed una sola risposta corretta. Si supponga che un rispondente risponda correttamente a \(R\) item e risponda in maniera sbagliata a \(W\) item.

La correzione per guessing si ottiene applicando una formula basata sul seguente ragionamento. Se assumiamo che un rispondente si limita a tirare ad indovinare allora, ogni \(C\) risposte, ci aspettiamo 1 risposta giusta e \(C-1\) risposte sbagliate. Per calcolare il punteggio totale del test in modo da eliminare il numero di risposte corrette ottenute tirando ad indovinare è necessario sottrarre 1 punto per ogni \(C-1\) item a cui è stata fornita una risposta corretta. Questo ragionamento conduce alla seguente formula:

\begin{equation}
FS = R - \frac{W}{C - 1},
\label{eq:guessing}
\end{equation}

con \(R\) = \# risposte corrette, \(W\) = \# risposte sbagliate, \(C\) = \# alternative di risposta. Per esempio, se \(C=5\), allora è necessario sottrarre un punto ogni 4, il che è proprio quello che fa la \eqref{eq:guessing}. La \eqref{eq:guessing} per la correzione per guessing produce un punteggio totale corretto per il guessing identico a quello che si otterrebbe pesando ciascuna risposta con 1 punto per le risposte corrette e \(- \frac{1}{C-1}\) punti per le risposte sbagliate -- senza considerare le risposte non date.

La correzione per guessing rappresenta il tentativo di scomporre il numero totale di risposte corrette in due componenti: le risposte corrette dovute alle conoscenze del soggetto, le risposte che risultano corrette come effetto del caso. La stessa formula può anche essere utilizzata per calcolare la difficoltà degli item corretta per guessing.

\hypertarget{discriminativituxe0}{%
\subsection{Discriminatività}\label{discriminativituxe0}}

La discriminatività è una misura di quanto ogni item è in grado di distinguere i soggetti con elevati livelli nel costrutto da quelli con un livello basso. L'indice di discriminatività \(D\) per i test di prestazione massima si trova nel modo seguente. Dopo avere calcolato il punteggio totale al test, si dividono i soggetti in due gruppi: soggetti con basso punteggio e soggetti con alto punteggio. Una volta definiti i due gruppi, l'indice di discriminatività \(D\) sarà dato da:

\[D = P(\text{alto}) - P(\text{basso}),\]

dove \(P(\text{alto}\) è la proporzione di soggetti che ha risposto correttamente all'item nel gruppo con punteggi alti e \(P(\text{basso}\) è la proporzione di soggetti che ha risposto correttamente all'item nel gruppo con punteggi bassi. Il valore di \(D\) può variare da -1 a +1. Nella tabella seguente sono fornite le linee guida per l'interpretazione di questo indice (Ebel, 1965).

\hypertarget{tab:ebel_1965}{}
\begin{longtable}[]{@{}ll@{}}
\caption{Linee guida per l'interpretazione dell'indice di discriminatività \(D\).}\tabularnewline
\toprule
Valore di \(D\) & Commento \\
\midrule
\endfirsthead
\toprule
Valore di \(D\) & Commento \\
\midrule
\endhead
\(D \geq 0.40\) & Ottima, nessuna revision \\
\(0.30 \leq D < 0.40\) & Buona, revisioni minime \\
\(0.20 \leq D < 0.30\) & Sufficiente, revisioni parziali \\
\(D < 0.20\) & Insufficiente, riformulazione o eliminazione \\
\bottomrule
\end{longtable}

\protect\hypertarget{tab:ebel_1965}{}{}

La discriminatività degli item di tipo Likert viene valutata con la medesima procedura degli item dei testi di prestazione massima, anche se cambiano le procedure statistiche da utilizzare. Si può dividere la distribuzione dei punteggi totali (o punteggi medi) in quartili e confrontare il punteggio medio o mediano del quartile superiore con quello del quartile inferiore, oppure, se il test è orientato al criterio e lo scopo è selezionare gli item che discriminano meglio due gruppi precostituiti di soggetto, eseguire i medesimi confronti tra il gruppo target (ad esempio, pazienti) e quello ``di controllo'' (per esempio, popolazione generale). È consigliabile valutare la dimensione dell'effetto, ad esempio attraverso l'indice \(d\) di Cohen. La dimensione dell'effetto dovrebbe essere almeno moderata (\(d > |0.50|\)).

\hypertarget{potere-discriminante-dellitem-e-analisi-fattoriale}{%
\subsection{Potere discriminante dell'item e analisi fattoriale}\label{potere-discriminante-dellitem-e-analisi-fattoriale}}

Secondo McDondald (1999), la nozione di potere discriminante dell'item può essere trattata in maniera più precisa nell'ambito del modello monofattoriale. Se l'insieme di item a disposizione non è eccessivamente grande (200 o meno), infatti, è possibile procedere alla selezione degli item migliori tramite l'analisi fattoriale -- ovvero, scegliendo gli item con le saturazioni maggiori.

\hypertarget{punteggio-sullitem-e-punteggio-totale}{%
\subsection{Punteggio sull'item e punteggio totale}\label{punteggio-sullitem-e-punteggio-totale}}

Il grado di associazione tra il punteggio sull'item e il punteggio totale viene considerato dalla teoria classica dei test quale indice del potere discriminante dell'item. Se il test fornisce una misura attendibile di un unico attributo, e se un item è fortemente associato al punteggio del test, allora l'item medesimo sarà in grado di distinguere tra rispondenti che ottengono un punteggio basso nel test e rispondenti che ottengono un punteggio alto nel test.

Nel caso di una forte associazione positiva tra il punteggio sull'item e il punteggio totale, la probabilità di risposta corretta sull'item è alta per rispondenti che ottengono un punteggio totale alto, e bassa per i rispondenti che ottengono un punteggio totale basso. Nel caso di una debole associazione tra il punteggio sull'item e il punteggio totale, invece, la probabilità di risposta corretta all'item non è predittiva del punteggio totale. Gli item con un basso potere discriminante dovrebbero dunque essere rimossi dal reattivo.

È necessario distinguere i casi in cui gli item sono dicotomici dal caso di item continui. Nel caso di item dicotomici e di un test unidimensionale, il potere discriminante viene calcolato mediante la correlazione biseriale o punto-biseriale.

\hypertarget{relazioni-tra-coppie-di-item}{%
\subsection{Relazioni tra coppie di item}\label{relazioni-tra-coppie-di-item}}

Le relazioni tra coppie di item sono importanti sia per la costruzione sia per l'analisi dei test. La teoria classica dei test definisce l'attendibilità di un test (o di un item) come il rapporto tra la varianza del punteggio vero e la varianza del punteggio osservato. Il coefficiente di attendibilità può però essere calcolato anche trovando la correlazione tra due forme parallele di un test (o tra due item). Inoltre, è possibile interpretare la correlazione tra due forme parallele di un test (o tra due item) come il quadrato del coefficiente di correlazione tra i punteggi osservati e i punteggi veri di un test (o di un item).

Molti indici sono disponibili per misurare il grado di associazione tra gli item. Per item quantitativi, possiamo usare la correlazione di Pearson o la covarianza. Per item qualitativi politomici ordinali, usiamo la correlazione policorica. Per item ordinali dicotomici, usiamo la correlazione tetracorica. Per item dicotomici usiamo, ad esempio, l'indice \(\phi\).

\hypertarget{ridondanza}{%
\subsection{Ridondanza}\label{ridondanza}}

Nel processo di raffinamento del test occorre tenere conto degli item ridondanti, ossia di quelli che sono troppo associati tra loro. La ridondanza può essere valutata con indici statistici quali la correlazione: se due o più item hanno tra loro una correlazione maggiore di \(|0.70|\) viene mantenuto nell'item pool solo un item, dato che gli altri apportano la stessa informazione.

\hypertarget{massimizzazione-della-varianza-del-punteggio-totale}{%
\subsection{Massimizzazione della varianza del punteggio totale}\label{massimizzazione-della-varianza-del-punteggio-totale}}

Uno dei criteri che possono essere utilizzati per selezionare gli item che andranno a costituire la versione finale di un test è quello di massimizzare la varianza del punteggio totale. Più in particolare, si vuole massimizzare il rapporto tra la varianza del punteggio totale e la somma delle varianze dei punteggi dei \(p\) item. Dato che il coefficiente \(\alpha\) di Cronbach ha la seguente forma:

\[\alpha = \frac{p}{p-1}\left[1- \frac{\sum \sigma^2_{X_i}}{\sigma^2_T} \right],\]

la scelta di massimizzare il rapporto definito in precedenza avrà anche la conseguenza di massimizzare \(\alpha\).

McDondald (1999) fa notare che una procedura di selezione degli item basata sul principio della massimizzazione di \(\alpha\) ha però dei limiti. In primo luogo, tale procedura è appropriata solo quando l'insieme di item è troppo grande per selezionare gli item in base all'esame dell saturazioni fattoriali ottenute applicando il modello monofattoriale. Inoltre, anche se il modello monofattoriale non può essere applicato per problemi pratici, a causa del numero di item troppo grande, tale modello deve essere comunque adeguato anche se si procede selezionando gli item sulla base di \(\alpha\). Ovviamente, però, tale assunzione non può essere verificata. In secondo luogo, McDondald (1999) nota che la procedura di selezione basata sulla massimizzazione di \(\alpha\) non è adeguata neanche nel caso in cui il costrutto latente abbia una struttura gerarchica, con un fattore generale ed una serie di fattori subordinati. In quel caso, infatti, la selezione degli item basata sulla massimizzazione di \(\alpha\) può portare all'eliminazione degli item che definiscono tutti i fattori subordinati tranne uno. Nel caso in cui il costrutto abbia una struttura gerarchica, dunque, la selezione degli item basata sulla massimizzazione di \(\alpha\) deve essere accompagnata da considerazione relative al contenuto del costrutto.

\hypertarget{ch:factorial-invariance}{%
\chapter{Invarianza di misura}\label{ch:factorial-invariance}}

I precedenti esempi di CFA presentati in questa dispensa sono stati stimati all'interno di un singolo gruppo, hanno utilizzato come input un'unica matrice covarianza e hanno portato alla stima dei parametri del modello sui quali non è stata imposta alcuna restrizione. In questo capitolo, le analisi precedenti verranno estese considerano il problema dell'invarianza di misura. Quello che ci chiediamo è se sia sensato considerare la medesima struttura fattoriale in gruppi diversi. In altre parole, ci chiediamo se viene misurata la stessa variabile latente tra gruppi diversi. Questa proprietà è chiamata \emph{invarianza di misura} \citep{meredith1993measurement}. L'approccio che viene utilizzato per stabilire l'evidenze dell'invarianza di misura è attraverso l'analisi fattoriale confermativa a gruppi multipli (\emph{multiple-group confirmatory factor analysis}, MG-CFA). È solo nella misura in cui viene dimostrata l'equivalenza di misura che sono possibili i confronti tra gruppi. Nel presente capitolo, verrà affrontato il invarianza di misura considerando prima il caso di indicatori continui e poi il caso di indicatori categoriali.

\hypertarget{indicatori-continui}{%
\section{Indicatori continui}\label{indicatori-continui}}

\hypertarget{intercette-degli-item}{%
\subsection{Intercette degli item}\label{intercette-degli-item}}

In generale, i modelli di equazioni strutturali vengono utilizzati per modellare unicamente la matrice di covarianza delle variabili osservate in un set di dati. Ricordiamo che, quando abbiamo introdotto il modello dell'analisi fattoriale,

\[
y_i = \mu + \lambda_j \xi_k + \delta_i,
\]

per semplicità abbiamo ignorato la media \(\mu\) degli indicatori esprimendo i dati osservati nei termini degli scarti dalla media, \(y_i -\mu\), in quanto ciò lascia immutate le covarianze. Tuttavia, in alcune applicazioni (quali l'invarianza di misura, ad esempio), è utile considerare anche le medie delle variabili osservate. Per ottenere ciò è possibile fare esplicito riferimento alle intercette delle equazioni precedenti nella sintassi \texttt{lavaan} del modello. È possibile fare riferimento all'intercetta di una variabile manifesta nel modo seguente:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{variable }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}
\end{Highlighting}
\end{Shaded}

laddove la parte sinistra dell'espressione precedente contiene il nome della variabile osservata a cui si fa riferimento. Per esempio, nel caso di un modello a due fattori comuni, è possibile aggiungere le intercette delle variabili manifeste nel modo seguente:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mod }\OtherTok{\textless{}{-}} \StringTok{"}
\StringTok{  \# two{-}factor model}
\StringTok{  f1 =\textasciitilde{} x1 + x2 + x3}
\StringTok{  f2 =\textasciitilde{} x4 + x5 + x6}
\StringTok{  \# intercepts}
\StringTok{  x1 \textasciitilde{} 1}
\StringTok{  x2 \textasciitilde{} 1}
\StringTok{  x3 \textasciitilde{} 1}
\StringTok{  x4 \textasciitilde{} 1}
\StringTok{  x5 \textasciitilde{} 1}
\StringTok{  x6 \textasciitilde{} 1}
\StringTok{"}
\end{Highlighting}
\end{Shaded}

Tuttavia, è più conveniente omettere le intercette nella specificazione del modello e aggiungere l'argomento \texttt{meanstructure\ =\ TRUE} nella funzione \texttt{cfa()}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{cfa}\NormalTok{(}
\NormalTok{  mod,}
  \AttributeTok{data =}\NormalTok{ d,}
  \AttributeTok{meanstructure =} \ConstantTok{TRUE}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Si noti che la statistica chi-quadrato e il numero di gradi di libertà sono gli stessi in un modello con o senza \texttt{meanstructure}. Il motivo è che, nel caso di un modello con \texttt{meanstructure}, vengono introdotti nuovi dati (il valore della media per ciascuna delle \(p\) variabili osservate) ma vengono anche aggiunti \(p\) parametri da stimare (un'intercetta per ciascuna delle \(p\) variabili osservate). Il risultato finale è che la bontà dell'adattamento resta immutata. In pratica, l'unico motivo per aggiungere le interecette nella sintassi del modello è quello di stabilire dei vincoli nella stima di tali parametri.

\hypertarget{terminologia}{%
\subsection{Terminologia}\label{terminologia}}

La discussione dell'invarianza di misura nel contesto della CFA fa uso della seguente terminologia.

\begin{itemize}
\tightlist
\item
  L'invarianza configurale (\emph{configural invariance}) verifica se la struttura dei fattori è la stessa tra i gruppi, ovvero verifica la presenza dello stesso numero di fattori e di pattern di saturazioni fattoriali simili tra gruppi.
\item
  L'invarianza metrica (\emph{metric invariance}) o ``invarianza fattoriale debole'' (\emph{weak factorial invariance}) verifica se i carichi fattoriali degli elementi sono gli stessi tra i gruppi. Invarianza scalare (\emph{scalar invariance}) o ``invarianza fattoriale forte'' verifica se le intercette sono le stesse tra i gruppi.
\item
  L'invarianza fattoriale rigorosa (\emph{strict factorial invariance}), infine, verifica se i residui degli indicatori sono gli stessi tra i gruppi.
\end{itemize}

\hypertarget{un-esempio-concreto-3}{%
\subsection{Un esempio concreto}\label{un-esempio-concreto-3}}

Consideriamo qui un esempio discusso da \citet{brown2015confirmatory}. Il modello CFA riguarda un modello di misurazione per la depressione maggiore così come definita nel DSM-IV. Ci sono 9 indicatori:

\begin{itemize}
\tightlist
\item
  MDD1, depressed mood;
\item
  MDD2, loss of interest in usual activities;
\item
  MDD3, weight/appetite change;
\item
  MDD4, sleep disturbance;
\item
  MDD5, psychomotor agitation/retardation;
\item
  MDD6, fatigue/loss of energy;
\item
  MDD7, feelings of worthlessness/guilt;
\item
  MDD8, concentration difficulties;
\item
  MDD9, thoughts of death/suicidality.
\end{itemize}

Leggiamo i dati:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d }\OtherTok{\textless{}{-}} \FunctionTok{readRDS}\NormalTok{(}
\NormalTok{  here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{(}\StringTok{"data"}\NormalTok{, }\StringTok{"mdd\_sex.RDS"}\NormalTok{)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Il problema riguarda l'invarianza fattoriale in funzione del genere. Consideriamo il seguente modello:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model\_mdd }\OtherTok{\textless{}{-}} \StringTok{"}
\StringTok{  MDD =\textasciitilde{} mdd1 + mdd2 + mdd3 + mdd4 + mdd5 + mdd6 + mdd7 + mdd8 +}
\StringTok{         mdd9}
\StringTok{  mdd1 \textasciitilde{}\textasciitilde{} mdd2}
\StringTok{"}
\end{Highlighting}
\end{Shaded}

Si noti la presenza di una correlazione residua tra gli indicatori \texttt{mdd1} e \texttt{mdd2}.

Esaminiamo dunque le varie forme di invarianza fattoriale:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# configural invariance}
\NormalTok{fit\_ef }\OtherTok{\textless{}{-}} \FunctionTok{cfa}\NormalTok{(}
\NormalTok{  model\_mdd,}
  \AttributeTok{data =}\NormalTok{ d,}
  \AttributeTok{group =} \StringTok{"sex"}\NormalTok{,}
  \AttributeTok{meanstructure =} \ConstantTok{TRUE}
\NormalTok{)}
\CommentTok{\# equal factor laodings}
\NormalTok{fit\_efl }\OtherTok{\textless{}{-}} \FunctionTok{update}\NormalTok{(}
\NormalTok{  fit\_ef,}
  \AttributeTok{group.equal =} \FunctionTok{c}\NormalTok{(}\StringTok{"loadings"}\NormalTok{)}
\NormalTok{)}
\CommentTok{\# equal indicator intercepts}
\NormalTok{fit\_eii }\OtherTok{\textless{}{-}} \FunctionTok{update}\NormalTok{(}
\NormalTok{  fit\_efl,}
  \AttributeTok{group.equal =} \FunctionTok{c}\NormalTok{(}\StringTok{"loadings"}\NormalTok{, }\StringTok{"intercepts"}\NormalTok{)}
\NormalTok{)}
\CommentTok{\# equal indicator error variances}
\NormalTok{fit\_eir }\OtherTok{\textless{}{-}} \FunctionTok{update}\NormalTok{(}
\NormalTok{  fit\_eii,}
  \AttributeTok{group.equal =} \FunctionTok{c}\NormalTok{(}\StringTok{"loadings"}\NormalTok{, }\StringTok{"intercepts"}\NormalTok{, }\StringTok{"residuals"}\NormalTok{)}
\NormalTok{)}
\CommentTok{\# equal factor variances}
\NormalTok{fit\_fv }\OtherTok{\textless{}{-}} \FunctionTok{update}\NormalTok{(}
\NormalTok{  fit\_eir,}
  \AttributeTok{group.equal =} \FunctionTok{c}\NormalTok{(}
    \StringTok{"loadings"}\NormalTok{, }\StringTok{"intercepts"}\NormalTok{, }\StringTok{"residuals"}\NormalTok{,}
    \StringTok{"lv.variances"}
\NormalTok{  )}
\NormalTok{)}
\CommentTok{\# equal latent means}
\NormalTok{fit\_fm }\OtherTok{\textless{}{-}} \FunctionTok{update}\NormalTok{(}
\NormalTok{  fit\_fv,}
  \AttributeTok{group.equal =} \FunctionTok{c}\NormalTok{(}
    \StringTok{"loadings"}\NormalTok{, }\StringTok{"intercepts"}\NormalTok{, }\StringTok{"residuals"}\NormalTok{,}
    \StringTok{"lv.variances"}\NormalTok{, }\StringTok{"means"}
\NormalTok{  )}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Confrontiamo i modelli:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{lavTestLRT}\NormalTok{(fit\_ef, fit\_efl, fit\_eii, fit\_eir, fit\_fv, fit\_fm)}
\CommentTok{\#\textgreater{} Chi{-}Squared Difference Test}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}         Df   AIC   BIC Chisq Chisq diff Df diff}
\CommentTok{\#\textgreater{} fit\_ef  52 27526 27785  98.9                   }
\CommentTok{\#\textgreater{} fit\_efl 60 27514 27735 102.8       3.93       8}
\CommentTok{\#\textgreater{} fit\_eii 68 27510 27695 115.3      12.47       8}
\CommentTok{\#\textgreater{} fit\_eir 77 27502 27645 125.0       9.71       9}
\CommentTok{\#\textgreater{} fit\_fv  78 27501 27639 125.8       0.79       1}
\CommentTok{\#\textgreater{} fit\_fm  79 27501 27635 127.7       1.92       1}
\CommentTok{\#\textgreater{}         Pr(\textgreater{}Chisq)}
\CommentTok{\#\textgreater{} fit\_ef            }
\CommentTok{\#\textgreater{} fit\_efl       0.86}
\CommentTok{\#\textgreater{} fit\_eii       0.13}
\CommentTok{\#\textgreater{} fit\_eir       0.37}
\CommentTok{\#\textgreater{} fit\_fv        0.37}
\CommentTok{\#\textgreater{} fit\_fm        0.17}
\end{Highlighting}
\end{Shaded}

Il confronto tra i precedenti modelli nidificati che introducono vincoli sempre più tringenti sui parametri indica che non vi è una ``significativa'' perdita di bontà dell'adattamento passando dal modello congenerico al modello che assume l'uguaglianza delle saturazioni fattoriali, delle intercette, delle varianze residue, delle varianze delle variabili latenti e delle medie nei due gruppi. Questi dati, dunque, forniscono forti evidenze di invarianza fattoriale tra maschi e femmine in relazione al costrutto di depressione maggiore.

\hypertarget{variabili-a-livello-ordinale}{%
\section{Variabili a livello ordinale}\label{variabili-a-livello-ordinale}}

I test di invarianza per i dati ordinali sono diversi da quelli utilizzati con continuo variabili in termini dello stimatore che viene utilizzato e del tipo di analisi statistica che viene svolta. Le variabili ordinali hanno opzioni di risposta che hanno un ordine logico, come come la gamma da fortemente in disaccordo a fortemente d'accordo; o da mai, a volte, spesso, a sempre. Queste opzioni possono essere ordinate logicamente e per convenzione ad esse venono assegnati valori numerici interi. Tuttavia, poiché le risposte ordinali non corrispondono a veri valori quantitativi (come 0 volte a settimana, 5 volte a settimana e 10 volte a settimana), l'assegnazione di numeri alle risposte ordinali da utilizzare nelle analisi è arbitraria. Ad esempio, le stesse cinque opzioni di risposta ordinate potrebbero essere assegnati valori da 0 a 4, da 1 a 5 o da 5 a 1. Pertanto, i dati ordinali non possono essere analizzati come se fossero continui. ``Le medie, le varianze e le covarianze delle variabili ordinali non hanno significato'' ( Jöreskog, p.~1). Tuttavia, l'ordinamento delle risposte può essere analizzato tramite apposite procedure speficiche ai dati ordinali. Abbiamo visto in precedenza come lo stimatore attualmente consigliato per i dati ordinali è quello dei minimi quadrati ponderati. Consideriamo qui il problema dell'invarianza di misura.

Oltre alla stima WLS, nell'analisi di dati ordinali viene utilizzata una matrice di correlazione policorica invece della solita matrice di covarianza. Per ciascuna coppia di variabili ordinali viene calcolata una correlazione policorica sulla base dell'ipotesi che una variabile continua latente normalmente distribuita sia responsabile delle frequenze osservate delle risposte ordinali in ciascuna variabile. Secondo questa ipotesi, ogni valore di risposta ordinale osservato corrisponde a un intervallo di valori normalizzati tra soglie, o cutoff, sulla variabile continua latente sottostante. Tali soglie (\(\tau_1, \tau_2, \dots, \tau_k\)) sono dei margini verticali che suddividono l'area sottesa alla funzione di densità della distribuzione normale sottostante in \(k\) sezioni, ciascuna delle quali corrisponde alla frequenza del punteggio ordinale che è stato osservato in quella categoria di risposta. L'invarianza delle soglie (\emph{treshold invariance}) assume che tali soglie necessarie per definire le correlazioni policoriche siano invarianti tra gruppi.

\citet{wu2016identification} mostrano come la procedura per la valutazione dell'invarianza di misura che è stata descritta in precedenza debba essere modificata nel caso di indicatori categoriali. La procedura usuale consiste nel definire prima un modello di riferimento e successivamente di imporre restrizioni crescenti ai parametri. Secondo \citet{wu2016identification}, tale approccio non è ottimale nel caso di dati categoriali perché dipende fortemente dal modo in cui vengono definite le soglie rispetto alle scale delle risposte continue latenti nel modello di base. Dunque, secondo \citet{wu2016identification}, è prima necessario valutare l'equivalenza delle soglie tra gruppi (\emph{threshold model}) e poi valutare il modello che ipotizza l'equivalenza tra i gruppi delle saturazioni fattoriali.

Per illutrare tale procedura, replichiamo qui il tutorial messo a punto da \citet{svetina2020multiple}. Questi autori utilizzano quattro item dei una scala del bullismo per tre paesi (31 = Azerbaigian; 40 = Austria; 246 = Finlandia). Tutti gli item sono misurati su una scala di tipo Likert a 4 punti, che va da 0 (mai) a 3 (almeno una volta alla settimana). Gli item di questa scala chiedono agli studenti quante volte durante l'anno è successo loro a scuola uno degli episodi in questione; per esempio: ``mi prendevano in giro o mi insultavano''. Le dimensioni del campione per l'Azerbaigian, l'Austria e la Finlandia sono rispettivamente 3808, 4457 e 4520. Leggiamo in dati in \(\textsf{R}\):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dat }\OtherTok{\textless{}{-}} \FunctionTok{read.table}\NormalTok{(}\StringTok{"data/BULLY.dat"}\NormalTok{, }\AttributeTok{header =} \ConstantTok{FALSE}\NormalTok{)}
\FunctionTok{names}\NormalTok{(dat) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"IDCNTRY"}\NormalTok{, }\StringTok{"R09A"}\NormalTok{, }\StringTok{"R09B"}\NormalTok{, }\StringTok{"R09C"}\NormalTok{, }\StringTok{"R09D"}\NormalTok{)}
\FunctionTok{head}\NormalTok{(dat)}
\CommentTok{\#\textgreater{}   IDCNTRY R09A R09B R09C R09D}
\CommentTok{\#\textgreater{} 1      31    3    3    0    0}
\CommentTok{\#\textgreater{} 2      31    0    0    0    0}
\CommentTok{\#\textgreater{} 3      31    3    2    1    3}
\CommentTok{\#\textgreater{} 4      31    0    0    3    0}
\CommentTok{\#\textgreater{} 5      31    0    0    0    0}
\CommentTok{\#\textgreater{} 6      31    0    0    0    0}
\end{Highlighting}
\end{Shaded}

Viene creata la matrice \texttt{all.results} per immagazzinare i risultati dei diversi modelli che verranno confrontati, chiamati \emph{baseline} (nessun vincolo tra gruppi), \emph{proposition 4} (equivalenza delle soglie tra gruppi), e \emph{proposition 7} (equivalenza delle soglie e delle saturazioni fattoriali tra gruppi). Gli indici di bontà dell'adattamento che verranno considerati sono: chi-square, df, p, RMSEA, CFI, e TLI.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{all.results }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\ConstantTok{NA}\NormalTok{, }\AttributeTok{ncol =} \DecValTok{6}\NormalTok{, }\AttributeTok{nrow =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{baseline-model}{%
\subsection{Baseline model}\label{baseline-model}}

Nel \emph{baseline model} non viene posto alcun vincolo tra i gruppi o le misure ripetute:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mod.cat }\OtherTok{\textless{}{-}} \StringTok{"F1 =\textasciitilde{} R09A + R09B + R09C + R09D"}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{baseline }\OtherTok{\textless{}{-}} \FunctionTok{measEq.syntax}\NormalTok{(}
  \AttributeTok{configural.model =}\NormalTok{ mod.cat,}
  \AttributeTok{data =}\NormalTok{ dat,}
  \AttributeTok{ordered =} \FunctionTok{c}\NormalTok{(}\StringTok{"R09A"}\NormalTok{, }\StringTok{"R09B"}\NormalTok{, }\StringTok{"R09C"}\NormalTok{, }\StringTok{"R09D"}\NormalTok{),}
  \AttributeTok{parameterization =} \StringTok{"delta"}\NormalTok{,}
  \AttributeTok{ID.fac =} \StringTok{"std.lv"}\NormalTok{,}
  \AttributeTok{ID.cat =} \StringTok{"Wu.Estabrook.2016"}\NormalTok{,}
  \AttributeTok{group =} \StringTok{"IDCNTRY"}\NormalTok{,}
  \AttributeTok{group.equal =} \StringTok{"configural"}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Informazioni sul modello baseline si ottengono nel modo seguente:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(baseline)}
\end{Highlighting}
\end{Shaded}

Le proprietà del modello possono essere esplicitate con la seguente istruzione:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cat}\NormalTok{(}\FunctionTok{as.character}\NormalTok{(baseline))}
\end{Highlighting}
\end{Shaded}

Per potere essere passato a \texttt{lavaan}, l'oggetto \texttt{baseline} deve essere in formato \texttt{char}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model.baseline }\OtherTok{\textless{}{-}} \FunctionTok{as.character}\NormalTok{(baseline)}
\end{Highlighting}
\end{Shaded}

Adattiamo il modello ai dati:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit.baseline }\OtherTok{\textless{}{-}} \FunctionTok{cfa}\NormalTok{(}
\NormalTok{  model.baseline,}
  \AttributeTok{data =}\NormalTok{ dat,}
  \AttributeTok{group =} \StringTok{"IDCNTRY"}\NormalTok{,}
  \AttributeTok{ordered =} \FunctionTok{c}\NormalTok{(}\StringTok{"R09A"}\NormalTok{, }\StringTok{"R09B"}\NormalTok{, }\StringTok{"R09C"}\NormalTok{, }\StringTok{"R09D"}\NormalTok{)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Salviamo i risultati:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{all.results[}\DecValTok{1}\NormalTok{, ] }\OtherTok{\textless{}{-}}
  \FunctionTok{round}\NormalTok{(}\FunctionTok{data.matrix}\NormalTok{(}
    \FunctionTok{fitmeasures}\NormalTok{(fit.baseline, }\AttributeTok{fit.measures =} \FunctionTok{c}\NormalTok{(}
      \StringTok{"chisq.scaled"}\NormalTok{, }\StringTok{"df.scaled"}\NormalTok{, }\StringTok{"pvalue.scaled"}\NormalTok{,}
      \StringTok{"rmsea.scaled"}\NormalTok{, }\StringTok{"cfi.scaled"}\NormalTok{, }\StringTok{"tli.scaled"}
\NormalTok{    ))}
\NormalTok{  ),}
  \AttributeTok{digits =} \DecValTok{3}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\hypertarget{invarianza-delle-soglie}{%
\subsection{Invarianza delle soglie}\label{invarianza-delle-soglie}}

Consideriamo ora il modello \emph{threshold invariance} \citep[chiamata \emph{Proposition 4} da][]{wu2016identification}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{prop4 }\OtherTok{\textless{}{-}} \FunctionTok{measEq.syntax}\NormalTok{(}
  \AttributeTok{configural.model =}\NormalTok{ mod.cat,}
  \AttributeTok{data =}\NormalTok{ dat,}
  \AttributeTok{ordered =} \FunctionTok{c}\NormalTok{(}\StringTok{"R09A"}\NormalTok{, }\StringTok{"R09B"}\NormalTok{, }\StringTok{"R09C"}\NormalTok{, }\StringTok{"R09D"}\NormalTok{),}
  \AttributeTok{parameterization =} \StringTok{"delta"}\NormalTok{,}
  \AttributeTok{ID.fac =} \StringTok{"std.lv"}\NormalTok{,}
  \AttributeTok{ID.cat =} \StringTok{"Wu.Estabrook.2016"}\NormalTok{,}
  \AttributeTok{group =} \StringTok{"IDCNTRY"}\NormalTok{,}
  \AttributeTok{group.equal =} \FunctionTok{c}\NormalTok{(}\StringTok{"thresholds"}\NormalTok{)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Adattiamo il modello ai dati:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model.prop4 }\OtherTok{\textless{}{-}} \FunctionTok{as.character}\NormalTok{(prop4)}
\NormalTok{fit.prop4 }\OtherTok{\textless{}{-}} \FunctionTok{cfa}\NormalTok{(}
\NormalTok{  model.prop4,}
  \AttributeTok{data =}\NormalTok{ dat,}
  \AttributeTok{group =} \StringTok{"IDCNTRY"}\NormalTok{,}
  \AttributeTok{ordered =} \FunctionTok{c}\NormalTok{(}\StringTok{"R09A"}\NormalTok{, }\StringTok{"R09B"}\NormalTok{, }\StringTok{"R09C"}\NormalTok{, }\StringTok{"R09D"}\NormalTok{)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Salviamo i risulati

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# store model fit information for proposition 4}
\NormalTok{all.results[}\DecValTok{2}\NormalTok{, ] }\OtherTok{\textless{}{-}}
  \FunctionTok{round}\NormalTok{(}\FunctionTok{data.matrix}\NormalTok{(}
    \FunctionTok{fitmeasures}\NormalTok{(fit.prop4, }\AttributeTok{fit.measures =} \FunctionTok{c}\NormalTok{(}
      \StringTok{"chisq.scaled"}\NormalTok{, }\StringTok{"df.scaled"}\NormalTok{, }\StringTok{"pvalue.scaled"}\NormalTok{,}
      \StringTok{"rmsea.scaled"}\NormalTok{, }\StringTok{"cfi.scaled"}\NormalTok{, }\StringTok{"tli.scaled"}
\NormalTok{    ))}
\NormalTok{  ),}
  \AttributeTok{digits =} \DecValTok{3}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

Eseguiamo il confronto tra il modello di \emph{threshold invariance} e il modello di \emph{baseline}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{lavTestLRT}\NormalTok{(fit.baseline, fit.prop4)}
\CommentTok{\#\textgreater{} Scaled Chi{-}Squared Difference Test (method = "satorra.2000")}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} lavaan }\AlertTok{NOTE}\CommentTok{:}
\CommentTok{\#\textgreater{}     The "Chisq" column contains standard test statistics, not the}
\CommentTok{\#\textgreater{}     robust test that should be reported per model. A robust difference}
\CommentTok{\#\textgreater{}     test is a function of two standard (not robust) statistics.}
\CommentTok{\#\textgreater{}  }
\CommentTok{\#\textgreater{}              Df AIC BIC Chisq Chisq diff Df diff}
\CommentTok{\#\textgreater{} fit.baseline  6          26.9                   }
\CommentTok{\#\textgreater{} fit.prop4    14          42.2       46.1       8}
\CommentTok{\#\textgreater{}              Pr(\textgreater{}Chisq)    }
\CommentTok{\#\textgreater{} fit.baseline               }
\CommentTok{\#\textgreater{} fit.prop4       2.2e{-}07 ***}
\CommentTok{\#\textgreater{} {-}{-}{-}}
\CommentTok{\#\textgreater{} Signif. codes:  }
\CommentTok{\#\textgreater{} 0 \textquotesingle{}***\textquotesingle{} 0.001 \textquotesingle{}**\textquotesingle{} 0.01 \textquotesingle{}*\textquotesingle{} 0.05 \textquotesingle{}.\textquotesingle{} 0.1 \textquotesingle{} \textquotesingle{} 1}
\end{Highlighting}
\end{Shaded}

\hypertarget{threshold-and-loading-invariance}{%
\subsection{Threshold and loading invariance}\label{threshold-and-loading-invariance}}

Consideriamo ora il modello \emph{threshold and loading invariance} \citep[chiamato \emph{Proposition 7} da][]{wu2016identification}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{prop7 }\OtherTok{\textless{}{-}} \FunctionTok{measEq.syntax}\NormalTok{(}
  \AttributeTok{configural.model =}\NormalTok{ mod.cat,}
  \AttributeTok{data =}\NormalTok{ dat,}
  \AttributeTok{ordered =} \FunctionTok{c}\NormalTok{(}\StringTok{"R09A"}\NormalTok{, }\StringTok{"R09B"}\NormalTok{, }\StringTok{"R09C"}\NormalTok{, }\StringTok{"R09D"}\NormalTok{),}
  \AttributeTok{parameterization =} \StringTok{"delta"}\NormalTok{,}
  \AttributeTok{ID.fac =} \StringTok{"std.lv"}\NormalTok{,}
  \AttributeTok{ID.cat =} \StringTok{"Wu.Estabrook.2016"}\NormalTok{,}
  \AttributeTok{group =} \StringTok{"IDCNTRY"}\NormalTok{,}
  \AttributeTok{group.equal =} \FunctionTok{c}\NormalTok{(}\StringTok{"thresholds"}\NormalTok{, }\StringTok{"loadings"}\NormalTok{)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Adattiamo il modello ai dati:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model.prop7 }\OtherTok{\textless{}{-}} \FunctionTok{as.character}\NormalTok{(prop7)}
\NormalTok{fit.prop7 }\OtherTok{\textless{}{-}} \FunctionTok{cfa}\NormalTok{(}
\NormalTok{  model.prop7,}
  \AttributeTok{data =}\NormalTok{ dat, }\AttributeTok{group =} \StringTok{"IDCNTRY"}\NormalTok{,}
  \AttributeTok{ordered =} \FunctionTok{c}\NormalTok{(}\StringTok{"R09A"}\NormalTok{, }\StringTok{"R09B"}\NormalTok{, }\StringTok{"R09C"}\NormalTok{, }\StringTok{"R09D"}\NormalTok{)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Salviamo i risultati:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{all.results[}\DecValTok{3}\NormalTok{, ] }\OtherTok{\textless{}{-}}
  \FunctionTok{round}\NormalTok{(}\FunctionTok{data.matrix}\NormalTok{(}
    \FunctionTok{fitmeasures}\NormalTok{(fit.prop7, }\AttributeTok{fit.measures =} \FunctionTok{c}\NormalTok{(}
      \StringTok{"chisq.scaled"}\NormalTok{, }\StringTok{"df.scaled"}\NormalTok{, }\StringTok{"pvalue.scaled"}\NormalTok{,}
      \StringTok{"rmsea.scaled"}\NormalTok{, }\StringTok{"cfi.scaled"}\NormalTok{, }\StringTok{"tli.scaled"}
\NormalTok{    ))}
\NormalTok{  ), }\AttributeTok{digits =} \DecValTok{3}\NormalTok{)}

\NormalTok{column.names }\OtherTok{\textless{}{-}}
  \FunctionTok{c}\NormalTok{(}
    \StringTok{"chisq.scaled"}\NormalTok{, }\StringTok{"df.scaled"}\NormalTok{, }\StringTok{"pvalue.scaled"}\NormalTok{, }\StringTok{"rmsea.scaled"}\NormalTok{,}
    \StringTok{"cfi.scaled"}\NormalTok{, }\StringTok{"tli.scaled"}
\NormalTok{  )}

\NormalTok{row.names }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"baseline"}\NormalTok{, }\StringTok{"prop4"}\NormalTok{, }\StringTok{"prop7"}\NormalTok{)}

\FunctionTok{colnames}\NormalTok{(all.results) }\OtherTok{\textless{}{-}}\NormalTok{ column.names}
\FunctionTok{rownames}\NormalTok{(all.results) }\OtherTok{\textless{}{-}}\NormalTok{ row.names}
\end{Highlighting}
\end{Shaded}

Eseguiamo i confronti tra modelli:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{lavTestLRT}\NormalTok{(fit.prop4, fit.prop7)}
\CommentTok{\#\textgreater{} Scaled Chi{-}Squared Difference Test (method = "satorra.2000")}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} lavaan }\AlertTok{NOTE}\CommentTok{:}
\CommentTok{\#\textgreater{}     The "Chisq" column contains standard test statistics, not the}
\CommentTok{\#\textgreater{}     robust test that should be reported per model. A robust difference}
\CommentTok{\#\textgreater{}     test is a function of two standard (not robust) statistics.}
\CommentTok{\#\textgreater{}  }
\CommentTok{\#\textgreater{}           Df AIC BIC Chisq Chisq diff Df diff}
\CommentTok{\#\textgreater{} fit.prop4 14          42.2                   }
\CommentTok{\#\textgreater{} fit.prop7 20          93.1       54.7       6}
\CommentTok{\#\textgreater{}           Pr(\textgreater{}Chisq)    }
\CommentTok{\#\textgreater{} fit.prop4               }
\CommentTok{\#\textgreater{} fit.prop7    5.4e{-}10 ***}
\CommentTok{\#\textgreater{} {-}{-}{-}}
\CommentTok{\#\textgreater{} Signif. codes:  }
\CommentTok{\#\textgreater{} 0 \textquotesingle{}***\textquotesingle{} 0.001 \textquotesingle{}**\textquotesingle{} 0.01 \textquotesingle{}*\textquotesingle{} 0.05 \textquotesingle{}.\textquotesingle{} 0.1 \textquotesingle{} \textquotesingle{} 1}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{lavTestLRT}\NormalTok{(fit.prop7, fit.baseline)}
\CommentTok{\#\textgreater{} Scaled Chi{-}Squared Difference Test (method = "satorra.2000")}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} lavaan }\AlertTok{NOTE}\CommentTok{:}
\CommentTok{\#\textgreater{}     The "Chisq" column contains standard test statistics, not the}
\CommentTok{\#\textgreater{}     robust test that should be reported per model. A robust difference}
\CommentTok{\#\textgreater{}     test is a function of two standard (not robust) statistics.}
\CommentTok{\#\textgreater{}  }
\CommentTok{\#\textgreater{}              Df AIC BIC Chisq Chisq diff Df diff}
\CommentTok{\#\textgreater{} fit.baseline  6          26.9                   }
\CommentTok{\#\textgreater{} fit.prop7    20          93.1        102      14}
\CommentTok{\#\textgreater{}              Pr(\textgreater{}Chisq)    }
\CommentTok{\#\textgreater{} fit.baseline               }
\CommentTok{\#\textgreater{} fit.prop7       2.3e{-}15 ***}
\CommentTok{\#\textgreater{} {-}{-}{-}}
\CommentTok{\#\textgreater{} Signif. codes:  }
\CommentTok{\#\textgreater{} 0 \textquotesingle{}***\textquotesingle{} 0.001 \textquotesingle{}**\textquotesingle{} 0.01 \textquotesingle{}*\textquotesingle{} 0.05 \textquotesingle{}.\textquotesingle{} 0.1 \textquotesingle{} \textquotesingle{} 1}
\end{Highlighting}
\end{Shaded}

Un confronto tra gli indici di bontà di adattamento dei tre modelli è fornito di seguito:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{all.results}
\CommentTok{\#\textgreater{}          chisq.scaled df.scaled pvalue.scaled}
\CommentTok{\#\textgreater{} baseline        50.94         6             0}
\CommentTok{\#\textgreater{} prop4          111.98        14             0}
\CommentTok{\#\textgreater{} prop7          210.64        20             0}
\CommentTok{\#\textgreater{}          rmsea.scaled cfi.scaled tli.scaled}
\CommentTok{\#\textgreater{} baseline        0.042      0.997      0.991}
\CommentTok{\#\textgreater{} prop4           0.041      0.993      0.992}
\CommentTok{\#\textgreater{} prop7           0.047      0.987      0.989}
\end{Highlighting}
\end{Shaded}

In conclusione, nel caso presente, il test del rapporto di verosimiglianza indica che non viene rispettata neppure l'invarianza delle soglie tra gruppi. Gli altri confronti, dunque, al di là dei presenti scopi didattici, sono superflui.

\hypertarget{ch:gof}{%
\chapter{Indici di bontà dell'adattamento}\label{ch:gof}}

I passi principali nella CFA e nei modelli SEM comprendono la specificazione del modello, la stima dei parametri, la valutazione del modello e dei parametri e la modificazione del modello. Questa sequenza può essere ripetuta molte volte fino a quando non si trovi un modello considerato accettabile. La valutazione del modello viene eseguita calcolando gli indici di bontà dell'adattamento. In questo capitolo considereremo i principali indici di bontà dell'adattamento utilizzati nella letteratura.

\hypertarget{stima-del-modello}{%
\section{Stima del modello}\label{stima-del-modello}}

L'obiettivo della CFA è ottenere stime per ogni parametro del modello di misura (vale a dire, saturazioni fattoriali, varianze e covarianze fattoriali, varianze residue ed eventualmente covarianze degli errori) che producano una matrice di covarianza prevista (denotata da \(\boldsymbol{\Sigma}\)) che assomiglia il più possibile alla matrice di covarianza delle variabili campionarie (denotata da \(\boldsymbol{S}\)). Questo processo fa riferimento ad una funzione di adattamento che consente di ridurre al minimo la differenza tra \(\boldsymbol{\Sigma}\) e \(\boldsymbol{S}\). Il metodo di stima più utilizzato nella CFA (e, in generale, nei modelli SEM) è la massima verosimiglianza (ML).

\hypertarget{massima-verosimiglianza}{%
\section{Massima verosimiglianza}\label{massima-verosimiglianza}}

L'equazione fondamentale dell'analisi fattoriale è

\[
\boldsymbol y = \boldsymbol \Lambda  \boldsymbol x  + \boldsymbol z, 
\]

dove \(\boldsymbol{y}\) è un vettore di \(p\) componenti (i punteggi del test), \(\boldsymbol{x}\) è un vettore di \(k < p\) componenti (i punteggi dei fattori comuni), \(\boldsymbol{z}\) è un vettore di \(p\) componenti (la componente unica dei punteggi del test) e \(\boldsymbol{\Lambda}\) è una \(p \cdot k\) matrice (di saturazioni fattoriali).

Dalle assunzioni del modello fattoriale deriva che

\[
\boldsymbol{\Sigma} = \boldsymbol{\Lambda}\boldsymbol{\Lambda}^\prime + \Psi.
\]

Si assume che il vettore casuale \(\boldsymbol{y}\) abbia una distribuzione normale multivariata con matrice di covarianza \(\boldsymbol{\Sigma}\) e che da tale distribuzione sia stato estratto un campione casuale di \(n\) osservazioni \(y_l, y_2, \dots, y_n\). Il logaritmo della funzione di verosimiglianza per il campione è dato da

\[
\log L = \frac{1}{2}n [\log | \boldsymbol{\Sigma}| + \mbox{tr}(\boldsymbol{\boldsymbol{S} \Sigma}^{-1})].
\]

L'equazione precedente viene vista come funzione di \(\Lambda\) e \(\Psi\). Anziché massimizzare \(\log L\), è equivalente e più conveniente minimizzare

\[
F_{k}(\Lambda, \Psi) = \log |\boldsymbol{\Sigma}| + \mbox{tr}[\boldsymbol{S}\boldsymbol{\Sigma}^{-1}]  - \log|\boldsymbol{S}| – p,
\]

dove \(|\boldsymbol{S}|\) è il determinante della matrice di covarianza tra le variabili osservate, \(|\boldsymbol{\Sigma}|\) è il determinante della matrice di covarianza prevista e \(p\) è il numero di indicatori.

L'obiettivo della stima di massima verosimiglianza della CFA è trovare le stime dei parametri che rendono più probabili i dati osservati (o, al contrario, massimizzano la probabilità dei parametri dati i dati). Le stime dei parametri in un modello CFA si ottengono con una procedura iterativa. Cioè, l'algoritmo inizia con una serie iniziale di stime dei parametri (denominate valori iniziali o stime iniziali, che possono essere generate automaticamente dal software o specificate dall'utente) e raffina ripetutamente queste stime nel tentativo di minimizzare la differenza tra \(\boldsymbol{\Sigma}\) e \(\boldsymbol{S}\). Il programma effettua controlli interni per valutare i suoi progressi nell'ottenere stime dei parametri che al meglio riproducono \(\boldsymbol{S}\). Si raggiunge la convergenza quando l'algoritmo produce una serie di stime dei parametri che non possono essere ulteriormente migliorate per ridurre la differenza tra \(\boldsymbol{\Sigma}\) e \(\boldsymbol{S}\).

\hypertarget{identificabilituxe0-del-modello}{%
\section{Identificabilità del modello}\label{identificabilituxe0-del-modello}}

Un modello CFA deve essere formulato in modo tale da garantire la risolvibilità matematica dello stesso, ovvero deve essere tale da consentire una stima univoca dei parametri del modello. Detto in altre parole, la specificazione del modello ne deve garantire l'dentificabilità.

Il problema dell'identificazione richiede, innanzitutto, di chiarire il concetto di gradi di libertà (\emph{degrees of freedom}). Nel presente contesto, per gradi di libertà (\(\mbox{df}\)) intendiamo

\[
\mbox{df} = \# (\text{unità di informazione}) - \# (\text{parametri da stimare}).
\]

I dati che vengono analizzati da un modello CFA sono contenuti in una matrice di covarianza. Per una matrice di covarianza di ordine \(p\), il numero di unità di informazione è

\[
\frac{p (p+1)}{2}.
\]

Affinché il modello sia identificabile, devono essere soddisfatte le seguenti condizioni.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Indipendentemente dalla complessità del modello (ad es. modelli ad un fattore rispetto a più fattori), l'unità di misura delle variabili latenti deve essere specificata (di solito fissandola a un valore di 1);
\item
  Indipendentemente dalla complessità del modello, il numero di unità di informazione (es. la matrice di covarianza degli indicatori) deve essere uguale o superiore al numero di parametri da stimare (es. saturazioni fattoriali, specificità, covarianze degli errori dell'indicatore, covarianze tra i fattori);
\item
  Nel caso di modelli ad un fattore è richiesto un minimo di tre indicatori. Quando vengono utilizzati tre indicatori, la soluzione a un fattore si dice ``appena identificata'' (\emph{just-identified}); in tali condizioni non è possibile valutare la bontà dell'adattamento.
\item
  Nel caso di modelli a due o più fattori e due indicatori per costrutto latente, la soluzione è sovraidentificata, a condizione che ogni variabile latente sia correlata con almeno un'altra variabile latente e gli errori tra gli indicatori siano tra loro incorrelati. Tuttavia, poiché tali soluzioni sono suscettibili di scarsa identificazione empirica, viene raccomandato un minimo di tre indicatori per variabile latente.
\end{enumerate}

In conclusione, una semplice e necessaria condizione per l'identificazione di un modello CFA è che vi siano più unità di informazione che parametri da stimare. Dunque, abbiamo che:

\begin{itemize}
\tightlist
\item
  se \(\mbox{df} < 0\), il modello \emph{non è identificato} e, in questo caso, non è possibile stimare i parametri;
\item
  se \(\mbox{df} = 0\), il modello è \emph{appena identificato} o ``saturo''; in questo caso, la matrice di covarianza riprodotta coincide con la matrice di covarianza delle variabili osservate e, di conseguenza, non esiste un residuo attraverso cui valutare la bontà dell'adattamento del modello;
\item
  se \(\mbox{df} > 0\), il modello è \emph{sovra-identificato} ed esistono le condizioni per valutare la bontà dell'adattamento.
\end{itemize}

Le considerazioni precedenti ci fanno capire perché non si può fare un'analisi fattoriale con solo due indicatori e un fattore; in tali circostanze, infatti, ci sono \((2 \cdot 3)/2 = 3\) gradi di libertà, ma 4 parametri da stimare (due saturazioni fattoriali e due specificità). Il caso di tre item e un fattore definisce un modello ``appena identificato'', ovvero, il caso in cui ci sono zero gradi di libertà. In tali circostanze è possibile stimare i parametri (ricordiamo il metodo dell'annullamento della tetrade), ma non è possibile un test di bonta dell'adattamento. Questo vuol dire che, in pratica, è necessario un numero minimo di quattro indicatori per ciascun fattore.

\hypertarget{bontuxe0-delladattamento}{%
\section{Bontà dell'adattamento}\label{bontuxe0-delladattamento}}

\hypertarget{chi-quadrato}{%
\subsection{Chi quadrato}\label{chi-quadrato}}

L'indice classico di bontà dell'adattamento dei modelli CFA è il \(\chi^2\). Sotto determinate condizioni, la funzione di discrepanza \(F_{k}(\boldsymbol{\Sigma}, \boldsymbol{S})\) moltiplicata per \(n\) o \(n-1\) (a seconda dei software)

\[
n F_{k}(\Lambda, \Psi) \quad \text{oppure}\quad (n-1) F_{k}(\Lambda, \Psi)
\]

con \(n\) uguale alla numerosità campionaria, si distribuisce come una \(\chi^2\) con gradi di libertà (\emph{degrees of freedom})

\begin{equation}
\mbox{df} = \frac{p (p+1)}{2}-t,
\end{equation}

dove \(p\) è il numero di item (variabili osservate) e \(t\) è il numero di parametri da stimare.

Sebbene l'indice \(\chi^2\) sia stato il primo indice di adattamento ad essere sviluppato, esso è raramente usato nella ricerca applicata quale unico indice di adattamento del modello. Infatti,

\begin{itemize}
\tightlist
\item
  in molti casi (es. piccolo N, dati non normali) la distribuzione sottostante non è \(\chi^2\) (il che compromette i test di significatività statistica del modello basati su \(\chi^2\));
\item
  \(\chi^2\) dipende fortemente dalla dimensione del campione; soluzioni fattoriali in corrispondenza di valori N grandi vengono regolarmente rifiutate sulla base di \(\chi^2\) anche quando differenze tra \(\boldsymbol{\Sigma}\) e \(\boldsymbol{S}\) sono trascurabili;
\item
  \(\chi^2\) si basa sull'ipotesi molto stringente \(\boldsymbol{\Sigma} = \boldsymbol{S}\). Come discusso di seguito, molti indici di adattamento alternativi si basano su standard meno stringenti come l'adattamento ``ragionevole'' e l'adattamento relativo a un modello di indipendenza.
\end{itemize}

Nonostante questi limiti, la statistica \(\chi^2\) viene comunque utilizzata per altri scopi, come il confronto di modelli nidificati, il calcolo di altri indici di adattamento (ad es. l'indice di Tucker--Lewis) e il calcolo del rapporto tra \(\chi^2\) e gradi di libertà.

Sebbene la statistica \(\chi^2\) sia riportata di routine nell'output dei software che svolgono la CFA, nella valutazione dell'adattamento del modello si fa solitamente affidamento su altri indici di adattamento. Tali indici possono essere suddivisi in tre categorie:

\begin{itemize}
\tightlist
\item
  \emph{misure di adeguamento assoluto} -- indicano l'abilità del modello di riprodurre i dati osservati;
\item
  \emph{misure di adeguamento per il confronto o comparative} -- permettono di confrontare fra loro 2 o più modelli e di scegliere il migliore (statisticamente);
\item
  \emph{misure di adeguamento parsimonioso} -- indici ``aggiustati'' in base ai gradi di libertà.
\end{itemize}

\hypertarget{misure-di-adeguamento-per-il-confronto}{%
\section{Misure di adeguamento per il confronto}\label{misure-di-adeguamento-per-il-confronto}}

\hypertarget{cfi}{%
\subsection{CFI}\label{cfi}}

Gli indici di adattamento comparativo {[}indicati anche come indici di adattamento incrementale; ad es. \citet{hu1998fit}{]} valutano l'adattamento di una soluzione specificata dall'utente in relazione a un modello di base nidificato più ristretto. Tipicamente, questo modello di base è un modello ``nullo'' o ``di indipendenza'' in cui le covarianze tra tutti gli indicatori di input sono fissate a zero, ma nessun vincolo viene posto sulle varianze degli indicatori. Uno di questi indici, l'\emph{indice di adattamento comparativo} (\emph{comparative fit index}, CFI; Bentler, 1990), è calcolato come segue.

Sia \(\delta = \chi^2 - \mbox{df}\), dove \(\mbox{df}\) sono i gradi di libertà di un particolare modello. Tanto più \(\delta\) è prossimo allo zero tanto maggiore è la bontà dell'adattamento. La formula di CFI è

\begin{equation}
\mbox{CFI} = \frac{\delta_B - \delta_T}{\delta_B},
\end{equation}

dove il pedice \(T\) denota il modello target (cioè il modello in valutazione) e il pedice \(B\) denota il modello baseline (cioè il modello ``nullo'').

\hypertarget{misure-di-adeguamento-parsimonioso}{%
\section{Misure di adeguamento parsimonioso}\label{misure-di-adeguamento-parsimonioso}}

\hypertarget{tli}{%
\subsection{TLI}\label{tli}}

Un indice che rientra in questa categoria è l'\emph{indice Tucker-Lewis} (\emph{Tucker--Lewis index}, TLI, anche chiamato indice di adattamento non normato). Il TLI si pone il problema di compensare per l'effetto della complessità del modello, ovvero include una funzione di penalizzazione per l'addizione di parametri che non migliorano notevolmente l'adattamento del modello. Il TLI è calcolato con la seguente formula:

\begin{equation}
\mbox{TLI} = \frac{(\chi^2_B / \mbox{df}_B)–(\chi^2_T / \mbox{df}_T)}{(\chi^2_B / \mbox{df}_B) – 1},
\end{equation}

dove \(\chi^2_T\) è il valore \(\chi^2\) del modello target, \(\mbox{df}_T\) sono i gradi di libertà del modello target, \(\chi^2_B\) è il valore \(\chi^2\) del modello baseline e \(\mbox{df}_B\) sono i gradi di libertà del modello base.

\hypertarget{misure-di-adeguamento-assoluto}{%
\section{Misure di adeguamento assoluto}\label{misure-di-adeguamento-assoluto}}

\hypertarget{rmsea}{%
\subsection{RMSEA}\label{rmsea}}

L'errore quadratico medio di approssimazione è una misura assoluta dell'adattamento perché non confronta la discrepanza del modello target rispetto a un modello di base, come CFI o TLI. Invece, RMSEA definisce \(\delta\) come parametro di non centralità che misura il grado di errata specificazione. Ricordiamo dal CFI che \(\delta = \chi^2 - df\), dove \(df\) sono i gradi di libertà del modello; tanto maggiore è \(\delta\) tanto più grande è la mancanza di adattamento del modello ai dati. L'indice RMSEA si ottiene nel modo seguente:

\begin{equation}
\mbox{RMSEA} = \sqrt{\frac{\delta}{\mbox{df}(n-1)}},
\end{equation}

dove \(n\) corrisponde alla numerosità campionaria.

L'indice RMSEA fornisce una stima dell'errore di approssimazione che si commette quando la matrice delle correlazioni (o covarianze) osservate viene riprodotta tramite la matrice ricavata dalle saturazioni fattoriali. Questo indice rappresenta una stima della bontà di adattamento del modello nella popolazione, ponderata per i gradi di liberà e quindi è una misura che tiene in considerazione la parsimonia del modello.

\hypertarget{rmrs}{%
\subsection{RMRS}\label{rmrs}}

L'indice RMRS viene definito come la radice quadrata della media dei residui al quadrato. L'indice RMRS rappresenta la media della correlazione residua, cioé non spiegata dal modello, ed è ricavabile con la seguente formula:

\begin{equation}
\mbox{RMRS} = \sqrt{ \frac{2 \sum_i\sum_j(r_{ij} - \hat{r}_{ij})^2}{q(q+1)}},
\end{equation}

dove \(q\) è il numero di variabili manifeste, e \(r_{ij}\) e \(\hat{r}_{ij}\) sono rispettivamente la correlazione osservata e la correlazione riprodotta tra le variabili \(i\) e \(j\).

\hypertarget{interpretazione-1}{%
\section{Interpretazione}\label{interpretazione-1}}

Un valore RMSEA \textless{} .05 indica un ``close fit'' e quello \textless{} .08 suggerisce un ragionevole adattamento modello-dati. Bentler e Bonett (1980) raccomandano TLI \textgreater{} .90 per un adattamento accettabile.

L'interpretazione degli indici di bontà di adattamento trovati nella CFA o nella modellazione di equazioni strutturali può essere ottenuta usando le funzioni del pacchetto \texttt{effectsize}. Ad esempio (dal manuale):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{structure }\OtherTok{\textless{}{-}} \StringTok{" ind60 =\textasciitilde{} x1 + x2 + x3}
\StringTok{               dem60 =\textasciitilde{} y1 + y2 + y3}
\StringTok{               dem60 \textasciitilde{}\textasciitilde{} ind60 "}
\NormalTok{fit }\OtherTok{\textless{}{-}}\NormalTok{ lavaan}\SpecialCharTok{::}\FunctionTok{sem}\NormalTok{(structure, }\AttributeTok{data =}\NormalTok{ lavaan}\SpecialCharTok{::}\NormalTok{PoliticalDemocracy)}
\NormalTok{effectsize}\SpecialCharTok{::}\FunctionTok{interpret}\NormalTok{(fit)}
\CommentTok{\#\textgreater{}     Name   Value Interpretation}
\CommentTok{\#\textgreater{} 1    GFI 0.96664   satisfactory}
\CommentTok{\#\textgreater{} 2   AGFI 0.91243   satisfactory}
\CommentTok{\#\textgreater{} 3    NFI 0.97486   satisfactory}
\CommentTok{\#\textgreater{} 4   NNFI 1.00010   satisfactory}
\CommentTok{\#\textgreater{} 5    CFI 1.00000   satisfactory}
\CommentTok{\#\textgreater{} 6  RMSEA 0.00000   satisfactory}
\CommentTok{\#\textgreater{} 7   SRMR 0.02726   satisfactory}
\CommentTok{\#\textgreater{} 8    RFI 0.95287   satisfactory}
\CommentTok{\#\textgreater{} 9   PNFI 0.51993   satisfactory}
\CommentTok{\#\textgreater{} 10   IFI 1.00005   satisfactory}
\end{Highlighting}
\end{Shaded}

\hypertarget{una-nota-di-cautela}{%
\section{Una nota di cautela}\label{una-nota-di-cautela}}

Nella letteratura SEM sono state sollevate forti argomentazioni contro l'applicazione di RMSEA, CFI e TLI e i loro valori di cutoff convenzionali \citep[ad esempio,][]{barrett2007structural}. Tuttavia, prima che i ricercatori propongano e accettino alternative migliori, l'applicazione di questi indici di bontà dell'adattamento continuerà nella maggior parte degli studi SEM. \citet{xia2019rmsea} fanno notare come, in base alla consuetudine corrente, valori RMSEA più grandi e valori CFI e TLI più piccoli indicano un adattamento peggiore. Ciò spinge i ricercatori a modificare i loro modelli per cercare di ottenere indici migliori. Tuttavia, la pratica attuale si è evoluta in una fase in cui gli indici di adattamento servono come criteri (e gli unici criteri, in molte situazioni) per determinare se accettare o rifiutare un modello ipotizzato: se i valori degli indici di adattamento raggiungono la soglia ``di pubblicabilità'' (ad es. RMSEA \textless{} .06), allora non si ritiene più necessario migliorare il modello. In realtà, un'affermazione come ``poiché i valori RMSEA, CFI e TLI suggeriscono un buon adattamento, questo modello è stato scelto come modello finale'' non è sufficiente. Il raggiungimento di una serie di soglie desiderate di RMSEA, CFI e TLI è solo uno dei possibili indicatori che devono essere considerati nel processo di selezione di modelli. I ricercatori dovrebbero anche spiegare se esistono altre opzioni per migliorare il modello, perché tali opzioni sono o non sono adottate e quali sono le conseguenze scientifiche della scelta del modello in questione come quello finale.

\hypertarget{ch:growth_models}{%
\chapter{Curve di crescita latente}\label{ch:growth_models}}

\hypertarget{dati-longitudinali}{%
\section{Dati longitudinali}\label{dati-longitudinali}}

Un importante classe di modelli a variabili latenti è quella dei modelli delle curve di crescita latente (\emph{latent growth models}, LGM). I modelli delle curve di crescita latente vengono spesso utilizzati per analizzare dati longitudinali. In questo tipo di dati, una misura di esito viene ottenuta in diversi momenti del tempo e si vuole studiare il cambiamento nel tempo. In molti casi, la traiettoria nel tempo può essere modellata come una semplice funzione lineare o quadratica. Le differenze individuali vengono catturate dagli \emph{effetti random} che sono convenientemente rappresentati da variabili latenti (continue), spesso chiamate \emph{fattori di crescita} (\emph{growth factors}).

Possiamo pensare ai modelli LGM come ad un'estensione del modello CFA dotato di \texttt{meanstructure}. L'inclusione della \texttt{meanstructure} significa che non possiamo usare in input la matrice di covarianza campionaria, ma dobbiamo invece utilizzare i dati grezzi (ovvero, le singole osservazioni per ciascun parecipante). Un'altro requisito degli LGM è che i dati devono essere forniti del formato \texttt{wide}, il che significa che ogni colonna rappresenta la variabile di esito in un diverso momento nel tempo. Si presume che ogni osservazione o riga sia indipendente dalle altre; le colonne motrano invece una dipendenza temporale tra loro.

I modelli LGM sono un caso speciale di CFA e corrispondono un modello CFA a due fattori in cui le saturazioni fattoriali sono fissate a valori predefiniti. Nello specifico, le saturazioni sul fattore che specifica le intercette delle funzioni individuali di crescita sono tutte fissate a 1; le saturazioni sul fattore che specifica le pendenze delle funzioni individuali di crescita sono fissate in modo tale da corrispondere ai diversi momenti del tempo, laddove la saturazione in corrispondenza del momento \(t_0\) è uguale a 0 e la progressione procede con incrementi di 1 (ovvvero, \(0, 1, \dots, t-1\)).

Si giunge così alla seguente specifiazione del modello fattoriale:

\begin{equation}
y_{it} = \tau_i + (1) \xi_1 + (t) \xi_2 + \delta_t,
\end{equation}

con \(t = 0, 1, 2, 3\) nel caso di quattro misurazioni temporali. Si noti che, per disegno, \(\tau_i = 0\).

\hypertarget{un-esempio-concreto-4}{%
\subsection{Un esempio concreto}\label{un-esempio-concreto-4}}

L'esempio che discuteremo utilizza i dati di un tutorial \texttt{lavaan}, ovvero un campione di dati artificiali chiamato \texttt{Demo.growth} in cui un punteggio viene misurato su quattro punti temporali. I dati sono i seguenti:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data}\NormalTok{(Demo.growth)}
\FunctionTok{glimpse}\NormalTok{(Demo.growth)}
\CommentTok{\#\textgreater{} Rows: 400}
\CommentTok{\#\textgreater{} Columns: 10}
\CommentTok{\#\textgreater{} $ t1 \textless{}dbl\textgreater{} 1.7256, {-}1.9842, 0.3195, 0.7769, 0.4489, {-}\textasciitilde{}}
\CommentTok{\#\textgreater{} $ t2 \textless{}dbl\textgreater{} 2.1424, {-}4.4006, {-}1.2691, 3.5314, {-}0.7728,\textasciitilde{}}
\CommentTok{\#\textgreater{} $ t3 \textless{}dbl\textgreater{} 2.7732, {-}6.0166, 1.5600, 3.1382, {-}1.5035, \textasciitilde{}}
\CommentTok{\#\textgreater{} $ t4 \textless{}dbl\textgreater{} 2.51596, {-}7.02962, 2.86853, 5.36374, 0.078\textasciitilde{}}
\CommentTok{\#\textgreater{} $ x1 \textless{}dbl\textgreater{} {-}1.1641, {-}1.7454, 0.9202, 2.3595, {-}1.0887,\textasciitilde{}}
\CommentTok{\#\textgreater{} $ x2 \textless{}dbl\textgreater{} 0.1742, {-}1.5769, {-}0.1418, 0.7080, {-}1.0100,\textasciitilde{}}
\CommentTok{\#\textgreater{} $ c1 \textless{}dbl\textgreater{} {-}0.02768, {-}2.03197, 0.05237, 0.01911, 0.65\textasciitilde{}}
\CommentTok{\#\textgreater{} $ c2 \textless{}dbl\textgreater{} 0.55492, 0.12533, {-}1.25774, 0.64738, 0.730\textasciitilde{}}
\CommentTok{\#\textgreater{} $ c3 \textless{}dbl\textgreater{} 0.25448, {-}1.56423, {-}1.80339, {-}0.43238, {-}0.\textasciitilde{}}
\CommentTok{\#\textgreater{} $ c4 \textless{}dbl\textgreater{} {-}1.00640, 1.22927, {-}0.32726, {-}1.03240, {-}0.\textasciitilde{}}
\end{Highlighting}
\end{Shaded}

La variabile dipendente è rappresentata dalle quattro colonne chiamate \texttt{t1}, \texttt{t2}, \texttt{t3} e \texttt{t4} che corrispondono alla serie temporale con quattro misurazioni per ciascun soggetto.

Trasformiamo i dati in formato \texttt{long}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{demo\_growth\_long }\OtherTok{\textless{}{-}}\NormalTok{ Demo.growth }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{select}\NormalTok{(t1, t2, t3, t4) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{pivot\_longer}\NormalTok{(}
    \AttributeTok{cols =} \FunctionTok{starts\_with}\NormalTok{(}\StringTok{"t"}\NormalTok{),}
    \AttributeTok{names\_to =} \StringTok{"t"}\NormalTok{,}
    \AttributeTok{values\_to =} \StringTok{"y"}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{as.data.frame}\NormalTok{()}
\NormalTok{demo\_growth\_long}\SpecialCharTok{$}\NormalTok{time }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\DecValTok{0}\SpecialCharTok{:}\DecValTok{3}\NormalTok{, }\DecValTok{400}\NormalTok{)}
\NormalTok{demo\_growth\_long}\SpecialCharTok{$}\NormalTok{id }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{400}\NormalTok{, }\AttributeTok{each =} \DecValTok{4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Esaminiamo un campione casuale di 9 soggetti. È presente una notevole variazione da soggetto a soggetto:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{id\_sel }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{400}\NormalTok{, }\DecValTok{9}\NormalTok{)}
\NormalTok{d }\OtherTok{\textless{}{-}}\NormalTok{ demo\_growth\_long[demo\_growth\_long}\SpecialCharTok{$}\NormalTok{id }\SpecialCharTok{\%in\%}\NormalTok{ id\_sel, ]}
\NormalTok{d }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ time, }\AttributeTok{y =}\NormalTok{ y)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{id)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{cfa_book_files/figure-latex/unnamed-chunk-280-1} \end{center}

Notiamo che un semplce modello lineare è appropriato per rendere conto della variazione temporale della variabile risposta:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ time, }\AttributeTok{y =}\NormalTok{ y)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{stat\_smooth}\NormalTok{(}\AttributeTok{method =} \StringTok{"lm"}\NormalTok{, }\AttributeTok{se =} \ConstantTok{FALSE}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{id)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{cfa_book_files/figure-latex/unnamed-chunk-281-1} \end{center}

Complessivamente, i dati suggeriscono un andamento crescente della variabile risposta in funzione del tempo:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{demo\_growth\_long }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(time, y, }\AttributeTok{group =}\NormalTok{ id)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{alpha =} \FloatTok{0.1}\NormalTok{) }\SpecialCharTok{+} \CommentTok{\# add individual line with transparency}
  \FunctionTok{stat\_summary}\NormalTok{( }\CommentTok{\# add average line}
    \FunctionTok{aes}\NormalTok{(}\AttributeTok{group =} \DecValTok{1}\NormalTok{),}
    \AttributeTok{fun =}\NormalTok{ mean,}
    \AttributeTok{geom =} \StringTok{"line"}\NormalTok{,}
    \AttributeTok{size =} \FloatTok{1.5}\NormalTok{,}
    \AttributeTok{color =} \StringTok{"black"}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Time"}\NormalTok{, }\AttributeTok{y =} \StringTok{"y"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{cfa_book_files/figure-latex/unnamed-chunk-282-1} \end{center}

Per adattare un modello lineare di crescita a questi dati, specifichiamo il seguente modello a variabili latenti

\[
y_j = \alpha_0 + \alpha_1 \lambda_j + \zeta_{00} + \zeta_{11} \lambda_j + \epsilon_j,
\] dove

\begin{itemize}
\tightlist
\item
  \(y_j\) è la variabile di interesse che cambia nel tempo, \(j\).
\item
  \(\alpha_0\) rappresenta l'intercetta della retta di regressione al tempo \(t = 0\) (il punto di partenza della linea nera sopra).
\item
  \(\alpha_1 \lambda_j\) è il tasso medio di variazione nel tempo (la pendenza della linea nera nel grafico sopra). Qui \(\lambda_j\) è solo l'indice dei punti temporali considerati (0, 1, 2, 3).
\item
  \(\zeta_{00}\) è la varianza tra i soggetti nel punto \(t = 0\).
\item
  \(\zeta_{11} \lambda_j\) è la varianza del tasso di variazione tra i soggetti.
\item
  \(\epsilon_j\) è la varianza di ciascun soggetto attorno alla sua retta di regressione.
\end{itemize}

Tali relazioni statistiche vengono rappresentate dal modello di equazioni strutturali della figura \ref{fig:growth01}.

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{images/lgm} 

}

\caption{Modello di crescita latente.}\label{fig:growth01}
\end{figure}

In altre parole, un lineare di crescita latente corrisponde ad un modello fattoriale con due variabili latenti: un fattore che corrisponde al ``punteggio vero'' delle intercette individuali e un fattore che corrisponde al ``punteggio vero'' delle pendenze individuali. Nella sitassi \texttt{lavaan} questo diventa:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model }\OtherTok{\textless{}{-}} \StringTok{"}
\StringTok{ i =\textasciitilde{} 1*t1 + 1*t2 + 1*t3 + 1*t4}
\StringTok{ s =\textasciitilde{} 0*t1 + 1*t2 + 2*t3 + 3*t4}
\StringTok{"}
\end{Highlighting}
\end{Shaded}

Si noti che, per il fattore \(\eta_0\) (che rappresenta le intercette), i valori delle saturazioni fattoriali sono fissate a 1 -- questo è il motivo per cui \(\alpha_0\) e \(\zeta_{00}\) compaiono da soli nell'equazione precedente: in maniera esplicita sono \(1 \cdot \alpha_0\) e \(1 \cdot \zeta_{00}\). Le saturazioni per il fattore \(\eta_1\) (che specifica le pendenze delle funzioni lineari) sono fissate ai valori dei diversi momenti nel tempo: qui i valori \(\lambda_j\) da 0 a 3. Abbiamo anche la correlazione tra \(\eta_0\) e \(\eta_1\), rappresentata dalla doppia freccia \(\zeta_{01}\). Se questo parametro è positivo, questo significa che i partecipanti tendono a diventare sempre più diversi tra loro, al passare del tempo; un'interpretazione opposta si ha se il valore del parametro è negativo.

Adattiamo il modello ai dati:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{growth}\NormalTok{(model, }\AttributeTok{data =}\NormalTok{ Demo.growth)}
\end{Highlighting}
\end{Shaded}

Esaminiamo il path diagram:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{semPaths}\NormalTok{(}
\NormalTok{  fit, }\StringTok{"std"}\NormalTok{,}
  \AttributeTok{posCol =} \FunctionTok{c}\NormalTok{(}\StringTok{"black"}\NormalTok{),}
  \AttributeTok{edge.label.cex =} \FloatTok{0.9}\NormalTok{,}
  \AttributeTok{sizeMan =} \DecValTok{7}\NormalTok{,}
  \AttributeTok{what =} \StringTok{"path"}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{cfa_book_files/figure-latex/unnamed-chunk-285-1} \end{center}

Ci sono 6 tipi di parametri di interesse:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{kable}\NormalTok{(}\FunctionTok{coef}\NormalTok{(fit), }\AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{format =} \StringTok{"markdown"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}lr@{}}
\toprule
& x \\
\midrule
\endhead
t1\textasciitilde\textasciitilde t1 & 0.5953 \\
t2\textasciitilde\textasciitilde t2 & 0.6760 \\
t3\textasciitilde\textasciitilde t3 & 0.6349 \\
t4\textasciitilde\textasciitilde t4 & 0.5076 \\
i\textasciitilde\textasciitilde i & 1.9320 \\
s\textasciitilde\textasciitilde s & 0.5869 \\
i\textasciitilde\textasciitilde s & 0.6179 \\
i\textasciitilde1 & 0.6147 \\
s\textasciitilde1 & 1.0063 \\
\bottomrule
\end{longtable}

\begin{itemize}
\tightlist
\item
  l'intercetta \(i\) = 0.615 è il valore atteso della variabile risposta al momento \(t_0\);
\item
  la pendenza \(s\) = 1.006 è il tasso di cambiamento medio della variabile risposta nel tempo. Ad ogni successivo momento temporale, il valore medio della variabile risposta aumenta in media di 1.006 punti;
\item
  varianza \(i\) = 1.932 misura la variazione tra i soggetti al momento \(t_0\) (ci dice quanto sono diverse le intercette delle rette di regressione tra i soggetti);
\item
  varianza \(s\) = 0.587 misura la variazione del tasso di crescita tra i soggetti (ci dice quanto sono diverse le pendenze delle rette di regressione tra i soggetti);
\item
  varianze \texttt{t1}, \ldots, \texttt{t4}: i valori da 0.595 a 0.508 ci dicono la variazione tra i soggetti all'interno di ciascun momento del tempo;
\item
  la covarianza tra \texttt{i} e \texttt{s} = 0.618 ci dice che i valori della variabile risposta diventano via via più diversi nel tempo tra i rispondenti (un valore negativo avrebbe l'interpretazione opposta).
\end{itemize}

Le stime dell'intercetta e della pendenza della funzione di crescita per ciascun partecipante si ottengono nel modo seguente:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rand\_eff }\OtherTok{\textless{}{-}} \FunctionTok{as.data.frame}\NormalTok{(}\FunctionTok{lavPredict}\NormalTok{(fit))}
\FunctionTok{head}\NormalTok{(rand\_eff)}
\CommentTok{\#\textgreater{}         i        s}
\CommentTok{\#\textgreater{} 1  1.2276  0.60278}
\CommentTok{\#\textgreater{} 2 {-}2.6796 {-}1.38498}
\CommentTok{\#\textgreater{} 3 {-}0.2955  0.88828}
\CommentTok{\#\textgreater{} 4  1.1576  1.34051}
\CommentTok{\#\textgreater{} 5 {-}0.4356  0.03193}
\CommentTok{\#\textgreater{} 6 {-}1.3122  0.50259}
\end{Highlighting}
\end{Shaded}

Le distribuzione delle stime individuali dell'intercetta e della pendenza della curva di crescita si ottengono nel modo seguente:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gi }\OtherTok{\textless{}{-}}\NormalTok{ rand\_eff }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ i)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{()}
\NormalTok{gh }\OtherTok{\textless{}{-}}\NormalTok{ rand\_eff }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ s)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{()}
\NormalTok{gi }\SpecialCharTok{+}\NormalTok{ gh}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{cfa_book_files/figure-latex/unnamed-chunk-288-1} \end{center}

Un buon modo per capire cosa fa il modello è quello di visualizzare i punteggi previsti. Useremo qui la funzione \texttt{predict()} per salvare un nuovo oggetto con i punteggi previsti a livello individuale per l'intercetta e la pendenza;

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pred\_lgm }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(fit)}
\FunctionTok{head}\NormalTok{(pred\_lgm)}
\CommentTok{\#\textgreater{}            i        s}
\CommentTok{\#\textgreater{} [1,]  1.2276  0.60278}
\CommentTok{\#\textgreater{} [2,] {-}2.6796 {-}1.38498}
\CommentTok{\#\textgreater{} [3,] {-}0.2955  0.88828}
\CommentTok{\#\textgreater{} [4,]  1.1576  1.34051}
\CommentTok{\#\textgreater{} [5,] {-}0.4356  0.03193}
\CommentTok{\#\textgreater{} [6,] {-}1.3122  0.50259}
\end{Highlighting}
\end{Shaded}

Questi sono i valori previsti dal modello per ciascun partecipante. Se calcoliamo la media di queste variabili otteniamo gli stessi risultati che sono stati riportati sopra:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# average of the intercepts (first column)}
\FunctionTok{mean}\NormalTok{(pred\_lgm[, }\DecValTok{1}\NormalTok{])}
\CommentTok{\#\textgreater{} [1] 0.6147}
\CommentTok{\# average of the slope (second column)}
\FunctionTok{mean}\NormalTok{(pred\_lgm[, }\DecValTok{2}\NormalTok{])}
\CommentTok{\#\textgreater{} [1] 1.006}
\end{Highlighting}
\end{Shaded}

Il cambiamento nel tempo previsto dal modello per il soggetto \(j\)-esimo è

\[
y_j = \eta_0 + \lambda_j \eta_1.
\]

Il cambiamento previsto per tutti i soggetti può essere visualizzato nel modo seguente:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# create long data for each individual}
\NormalTok{pred\_lgm\_long }\OtherTok{\textless{}{-}} \FunctionTok{map}\NormalTok{(}
  \DecValTok{0}\SpecialCharTok{:}\DecValTok{3}\NormalTok{, }\CommentTok{\# loop over time}
  \ControlFlowTok{function}\NormalTok{(x) pred\_lgm[, }\DecValTok{1}\NormalTok{] }\SpecialCharTok{+}\NormalTok{ x }\SpecialCharTok{*}\NormalTok{ pred\_lgm[, }\DecValTok{2}\NormalTok{]}
\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{reduce}\NormalTok{(cbind) }\SpecialCharTok{\%\textgreater{}\%} \CommentTok{\# bring together the wave predictions}
  \FunctionTok{as.data.frame}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} \CommentTok{\# make data frame}
  \FunctionTok{setNames}\NormalTok{(}\FunctionTok{str\_c}\NormalTok{(}\StringTok{"time"}\NormalTok{, }\DecValTok{0}\SpecialCharTok{:}\DecValTok{3}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%} \CommentTok{\# give names to variables}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{id =} \FunctionTok{row\_number}\NormalTok{()) }\SpecialCharTok{\%\textgreater{}\%} \CommentTok{\# make unique id}
  \FunctionTok{gather}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{id, }\AttributeTok{key =}\NormalTok{ time, }\AttributeTok{value =}\NormalTok{ pred) }\CommentTok{\# make long format}
\CommentTok{\# make graph}
\NormalTok{pred\_lgm\_long }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(time, pred, }\AttributeTok{group =}\NormalTok{ id)) }\SpecialCharTok{+} \CommentTok{\# what variables to plot?}
  \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{alpha =} \FloatTok{0.1}\NormalTok{) }\SpecialCharTok{+} \CommentTok{\# add a transparent line for each person}
  \FunctionTok{stat\_summary}\NormalTok{( }\CommentTok{\# add average line}
    \FunctionTok{aes}\NormalTok{(}\AttributeTok{group =} \DecValTok{1}\NormalTok{),}
    \AttributeTok{fun =}\NormalTok{ mean,}
    \AttributeTok{geom =} \StringTok{"line"}\NormalTok{,}
    \AttributeTok{size =} \FloatTok{1.5}\NormalTok{,}
    \AttributeTok{color =} \StringTok{"black"}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{y =} \StringTok{"y"}\NormalTok{, }\AttributeTok{x =} \StringTok{"time"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{cfa_book_files/figure-latex/unnamed-chunk-291-1} \end{center}

La linea nera più spessa rappresenta l'intercetta media e la pendenza media della curva di crescita del modello LGM. Ogni individuo ha una sua specifica intercetta e uno specifico tasso di cambiamento e questa diversità è catturata nelle componenti di varianza del modello

È anche possibile utilizzare le funzionalità di \texttt{lavaan} per verificare specifiche ipotesi di interesse relative ai dati longitudinali. Ad esempio, una possibile domanda riguarda l'ugualianza degli errori nel tempo. Tale domanda può essere affrontata introducendo dei vincoli nella specificazione del modello LGM e, successivamente, confrontanto la bontà dell'adattamento del modello vincolato e del modello generale.

Il modello vincolato è

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model\_eqerr }\OtherTok{\textless{}{-}} \StringTok{"}
\StringTok{ i =\textasciitilde{} 1*t1 + 1*t2 + 1*t3 + 1*t4}
\StringTok{ s =\textasciitilde{} 0*t1 + 1*t2 + 2*t3 + 3*t4}
\StringTok{ t1 \textasciitilde{}\textasciitilde{} a*t1}
\StringTok{ t2 \textasciitilde{}\textasciitilde{} a*t2}
\StringTok{ t3 \textasciitilde{}\textasciitilde{} a*t3}
\StringTok{ t4 \textasciitilde{}\textasciitilde{} a*t4}
\StringTok{"}
\end{Highlighting}
\end{Shaded}

Adattiamo il modello vincolato:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_eqerr }\OtherTok{\textless{}{-}} \FunctionTok{growth}\NormalTok{(model\_eqerr, }\AttributeTok{data =}\NormalTok{ Demo.growth)}
\end{Highlighting}
\end{Shaded}

Confrontiamo il modello vincolato con il modello libero:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{anova}\NormalTok{(fit, fit\_eqerr)}
\CommentTok{\#\textgreater{} Chi{-}Squared Difference Test}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}           Df  AIC  BIC Chisq Chisq diff Df diff}
\CommentTok{\#\textgreater{} fit        5 5528 5564  8.07                   }
\CommentTok{\#\textgreater{} fit\_eqerr  8 5524 5548  9.68       1.61       3}
\CommentTok{\#\textgreater{}           Pr(\textgreater{}Chisq)}
\CommentTok{\#\textgreater{} fit                 }
\CommentTok{\#\textgreater{} fit\_eqerr       0.66}
\end{Highlighting}
\end{Shaded}

Il test del rapporto di verosimiglianza (\emph{likelihood ratio}) eseguito dalla funzione \texttt{anova()} produce un \(p\)-valore di 0.6573. Ciò significa che, nei dati esaminati, non si rileva una decremento della bontà dell'adattamento degna di nota nel passare dal modello libero al modello vincolato. Dunque, l'ipotesi dell'equaglianza della varianza degli errori nel tempo sembra ragionevole.

\hypertarget{un-secondo-esempio}{%
\subsection{Un secondo esempio}\label{un-secondo-esempio}}

Un modello leggermente più complesso aggiunge due regressori (\texttt{x1} e \texttt{x2}) che influenzano i fattori di crescita latenti. Inoltre, è stata aggiunta al modello una covariata \texttt{c} variabile nel tempo che influenza la misura del risultato nei quattro punti temporali.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model2 }\OtherTok{\textless{}{-}} \StringTok{"}
\StringTok{  \# intercept and slope with fixed coefficients}
\StringTok{    i =\textasciitilde{} 1*t1 + 1*t2 + 1*t3 + 1*t4}
\StringTok{    s =\textasciitilde{} 0*t1 + 1*t2 + 2*t3 + 3*t4}
\StringTok{  \# regressions}
\StringTok{    i \textasciitilde{} x1 + x2}
\StringTok{    s \textasciitilde{} x1 + x2}
\StringTok{  \# time{-}varying covariates}
\StringTok{    t1 \textasciitilde{} c1}
\StringTok{    t2 \textasciitilde{} c2}
\StringTok{    t3 \textasciitilde{} c3}
\StringTok{    t4 \textasciitilde{} c4}
\StringTok{"}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit2 }\OtherTok{\textless{}{-}} \FunctionTok{growth}\NormalTok{(model2, }\AttributeTok{data =}\NormalTok{ Demo.growth)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{kable}\NormalTok{(}\FunctionTok{coef}\NormalTok{(fit2), }\AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{format =} \StringTok{"markdown"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}lr@{}}
\toprule
& x \\
\midrule
\endhead
i\textasciitilde x1 & 0.60839 \\
i\textasciitilde x2 & 0.60411 \\
s\textasciitilde x1 & 0.26224 \\
s\textasciitilde x2 & 0.52173 \\
t1\textasciitilde c1 & 0.14336 \\
t2\textasciitilde c2 & 0.28900 \\
t3\textasciitilde c3 & 0.32754 \\
t4\textasciitilde c4 & 0.33049 \\
t1\textasciitilde\textasciitilde t1 & 0.57982 \\
t2\textasciitilde\textasciitilde t2 & 0.59559 \\
t3\textasciitilde\textasciitilde t3 & 0.48141 \\
t4\textasciitilde\textasciitilde t4 & 0.53521 \\
i\textasciitilde\textasciitilde i & 1.07946 \\
s\textasciitilde\textasciitilde s & 0.22376 \\
i\textasciitilde\textasciitilde s & 0.07475 \\
i\textasciitilde1 & 0.58024 \\
s\textasciitilde1 & 0.95758 \\
\bottomrule
\end{longtable}

I risultati mostrano che le due covariate \(x\) influenzano sia l'intercetta sia la pendenza della curva di crescita. Inoltre, vi sono evidenze di un effetto della covariata \texttt{c}.

\hypertarget{ch:missing_data}{%
\chapter{Dati mancanti}\label{ch:missing_data}}

Raramente un ricercatore si trova nella situazione fortunata nella quale un'analisi statistica (CFA o altro) può essere condotta utilizzando un set di dati in cui tutte le variabili sono presenti per tutte le osservazioni: i dati mancanti sono la norma piuttosto che l'eccezione nella pratica della ricerca.

\hypertarget{tipologie-di-dati-mancanti}{%
\section{Tipologie di dati mancanti}\label{tipologie-di-dati-mancanti}}

I dati mancanti possono verificarsi per una serie di motivi. Ad esempio, i dati possono mancare per disegno dello studio (``mancanza pianificata''), come ad esempio nei progetti di ricerca in cui i partecipanti al campione vengono selezionati casualmente per completare vari sottoinsiemi della batteria di valutazione completa (a causa di considerazioni pratiche come vincoli di tempo). In tali condizioni, si presume che i dati mancanti si distribuiscano in un modo completamente casuale rispetto a tutte le altre variabili nello studio. In generale, i meccanismi che determinano la presenza di dati mancanti possono essere classificati in tre categorie:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \emph{valori mancanti completamente casuali} (\emph{Missing Completely At Random}, MCAR). La probabilità di dati mancanti su una variabile non è collegata né al valore mancante sulla variabile, né al valore di ogni altra variabile presente nella matrice dati che si sta analizzando;
\item
  \emph{valori mancanti casuali} (\emph{Missing At Random}, MAR). I valori mancanti sono indipendenti dal valore che viene a mancare, ma dipendono da altre variabili, cioè i dati sulla variabile sono mancanti per categorie di partecipanti che potrebbero essere identificati da valori su altre variabili;
\item
  \emph{valori mancanti non ignorabili} (\emph{Missing Not At Random}, MNAR). La mancanza di un dato può dipendere sia dal valore del dato stesso che dalle altre variabili. Per esempio, se si studia la salute mentale e le persone depresse riferiscono meno volentieri informazioni riguardanti il loro stato di salute, allora i dati non sono mancanti per caso.
\end{enumerate}

\hypertarget{la-gestione-dei-dati-mancanti}{%
\section{La gestione dei dati mancanti}\label{la-gestione-dei-dati-mancanti}}

Il passo successivo dopo la definizione dei meccanismi è quello della gestione dei dati mancanti. Sostanzialmente le scelte possibili sono due: l'eliminazione dei casi o la sostituzione dei dati mancanti. Un metodo semplice, indicato solo nel caso in cui l'ammontare dei dati mancanti è limitato e questi sono mancanti completamente a caso (MCAR), è quello di cancellare i casi (\emph{case deletion}).

I modi per eliminare i casi sono due: \emph{listwise deletion} e \emph{pairwise deletion}. Nel primo caso si elimina dal campione ogni caso che ha dati mancanti. Le analisi avverranno quindi solo sui casi che hanno valori validi per tutte le variabili in esame. Si ha una maggiore semplicità di trattazione, tuttavia non si utilizza tutta l'informazione osservata (si riduce la numerosità campionaria e, quindi, l'informazione). Il secondo metodo è la pairwise deletion, che utilizza tutti i casi che hanno i dati validi su due variabili volta per volta. In questo modo si riesce a massimizzare la numerosità del campione da utilizzare, ma si tratta comunque di un metodo che presenta dei problemi, per esempio il fatto che con questo approccio i parametri del modello saranno basati su differenti insiemi di dati, con differenti numerosità campionarie e differenti errori standard.

Quando i dati non sono MCAR è opportuno sostituirli con appropriate funzioni dei dati effettivamente osservati (\emph{imputation}). Di seguito sono indicati alcuni metodi.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \emph{Mean Imputation}. Il dato mancante viene sostituito con la media della variabile. Questo metodo, utilizzato troppo spesso per la sua semplicità, riducendo la variabilità dei dati, ha invece effetti importanti su molte analisi dei dati e generalmente dovrebbe essere evitato.
\item
  \emph{Regression Imputation}. Si tratta di un approccio basato sulle informazioni disponibili per le altre variabili. Si stima una equazione di regressione lineare per ogni variabile utilizzando le altre come predittori. Questo metodo offre il vantaggio di poter utilizzare dei rapporti esistenti tra le variabili per effettuare le valutazioni dei dati mancanti; tuttavia esso è usato raramente, in quanto amplifica i rapporti di correllazione tra le variabili; quindi se le analisi si baseranno su regressioni, questo metodo è sconsigliato.
\item
  \emph{Multiple Imputation}. La tecnica multiple imputation, applicabile in caso di MAR, prevede che un dato mancante su una variabile sia sostituito, sulla base dei dati esistenti anche sulle altre variabili, con un valore che però comprende anche una componente di errore ricavata dalla distribuzione dei residui della variabile.
\item
  \emph{Expectation-Maximization}. Un altro approccio moderno del trattamento dei dati mancanti è l'applicazione dell'algoritmo Expectation Maximization (EM). La tecnica è quella di stimare i parametri sulla base dei dati osservati, e di stimare poi i dati mancanti sulla base di questi parametri (fase E). Poi i parametri vengono nuovamente stimati sulla base della nuova matrice di dati (fase M), e così via. Questo processo viene iterato fino a quando i valori stimati convergono. Tuttavia, una limitazione fondamentale dell'utilizzo dell'algoritmo EM per calcolare le matrici di input per le analisi CFA/SEM è che gli errori standard risultanti delle stime dei parametri non sono consistenti. Pertanto, gli intervalli di confidenza e i test di significatività possono essere compromessi.
\end{enumerate}

\hypertarget{metodo-direct-ml}{%
\subsection{Metodo Direct ML}\label{metodo-direct-ml}}

Benché vengano talvolta usati, i metodi precedenti sono stati presentati solo per ragioni storiche. Nella pratica concreta è meglio usare il metodo \emph{Direct ML}, conosciuto anche come ``raw ML'' o ``full information ML'' (FIML), in quanto è generalmente considerano come il metodo migliore per gestire i dati mancanti nella maggior parte delle applicazioni CFA e SEM. Direct ML è esente dai problemi associati all'utilizzo dell'algoritmo EM e produce stime consistenti sotto l'ipotesi di normalità multivariata per dati mancanti MAR.

Intuitivamente, l'approccio utilizza la relazione tra le variabili per dedurre quali siano i valori mancanti con maggiore probabilità. Ad esempio, se due variabili, \(X\) e \(Y\), sono correlate positivamente, allora se, per alcuni \(i\), \(X_i\) è il valore più alto nella variabile, è probabile che anche il valore mancante \(Y_i\) sia un valore alto. FIML utilizza queste informazioni senza procedere all'imputazione dei valori mancanti, ma invece basandosi sulle stime più verosimili dei parametri della popolazione, ovvero massimizzando direttamente la verosimiglianza del modello specificato. Sotto l'assunzione di normalità multivariata, la funzione di verosimiglianza diventa

\[
L(\mu, \Sigma) = \prod_i f(y_i \mid \mu_i, \Sigma_i),
\] laddove \(y_i\) sono i dati, \(\mu_i\) e \(\Sigma_i\) sono i parametri della popolazione se gli elementi mancanti in \(y_i\) vengono rimossi. Si cercano i valori \(\mu\) e \(\Sigma\) che massimizzano la verosimiglianza.

In \texttt{lavaan} l'applicazione di tale metodo si ottiene specificando l'argomento \texttt{missing\ =\ "ml"}.

\hypertarget{un-esempio-concreto-5}{%
\subsection{Un esempio concreto}\label{un-esempio-concreto-5}}

Per applicare il metodo \emph{direct ML}, \citet{brown2015confirmatory} prende in esame i dati reali di un questionario (un singolo fattore, quattro item, una covarianza di errore) con dati mancanti (N = 650). Leggiamo i dati dell'esempio:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d }\OtherTok{\textless{}{-}} \FunctionTok{readRDS}\NormalTok{(here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{(}\StringTok{"data"}\NormalTok{, }\StringTok{"brown\_table\_9\_1.RDS"}\NormalTok{))}
\FunctionTok{head}\NormalTok{(d)}
\CommentTok{\#\textgreater{}   subject s1 s2 s3 s4}
\CommentTok{\#\textgreater{} 1    5760  2  0  1 NA}
\CommentTok{\#\textgreater{} 2    5761  3  3  3 NA}
\CommentTok{\#\textgreater{} 3    5763  2  4  4 NA}
\CommentTok{\#\textgreater{} 4    5761  2  0  0 NA}
\CommentTok{\#\textgreater{} 5    5769  2  1  1 NA}
\CommentTok{\#\textgreater{} 6    5771  4  3  3 NA}
\end{Highlighting}
\end{Shaded}

Il modello viene specificato come segue \citep[seguiamo][]{brown2015confirmatory}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model }\OtherTok{\textless{}{-}} \StringTok{"}
\StringTok{  esteem =\textasciitilde{} s1 + s2 + s3 + s4}
\StringTok{  s2 \textasciitilde{}\textasciitilde{} s4}
\StringTok{"}
\end{Highlighting}
\end{Shaded}

Adattiamo il modello ai dati:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{cfa}\NormalTok{(model, }\AttributeTok{data =}\NormalTok{ d, }\AttributeTok{missing =} \StringTok{"ml"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

È possibile identificare le configurazioni di risposte agli item che contengono dati mancanti:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit}\SpecialCharTok{@}\NormalTok{Data}\SpecialCharTok{@}\NormalTok{Mp[[}\DecValTok{1}\NormalTok{]]}\SpecialCharTok{$}\NormalTok{npatterns}
\CommentTok{\#\textgreater{} [1] 5}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pats }\OtherTok{\textless{}{-}}\NormalTok{ fit}\SpecialCharTok{@}\NormalTok{Data}\SpecialCharTok{@}\NormalTok{Mp[[}\DecValTok{1}\NormalTok{]]}\SpecialCharTok{$}\NormalTok{pat }\SpecialCharTok{*}\NormalTok{ 1L}
\FunctionTok{colnames}\NormalTok{(pats) }\OtherTok{\textless{}{-}}\NormalTok{ fit}\SpecialCharTok{@}\NormalTok{Data}\SpecialCharTok{@}\NormalTok{ov.names[[}\DecValTok{1}\NormalTok{]]}
\FunctionTok{print}\NormalTok{(pats)}
\CommentTok{\#\textgreater{}      s1 s2 s3 s4}
\CommentTok{\#\textgreater{} [1,]  1  1  1  1}
\CommentTok{\#\textgreater{} [2,]  1  1  1  0}
\CommentTok{\#\textgreater{} [3,]  0  1  1  1}
\CommentTok{\#\textgreater{} [4,]  1  0  1  1}
\CommentTok{\#\textgreater{} [5,]  1  1  0  1}
\end{Highlighting}
\end{Shaded}

Possiamo ora esaminare la copertura della covarianza nei dati, ovvero la proporzione di dati disponibili per ciascun indicatore e per ciascuna coppia di indicatori:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{coverage }\OtherTok{\textless{}{-}}\NormalTok{ fit}\SpecialCharTok{@}\NormalTok{Data}\SpecialCharTok{@}\NormalTok{Mp[[}\DecValTok{1}\NormalTok{]]}\SpecialCharTok{$}\NormalTok{coverage}
\FunctionTok{colnames}\NormalTok{(coverage) }\OtherTok{\textless{}{-}} \FunctionTok{rownames}\NormalTok{(coverage) }\OtherTok{\textless{}{-}}\NormalTok{ fit}\SpecialCharTok{@}\NormalTok{Data}\SpecialCharTok{@}\NormalTok{ov.names[[}\DecValTok{1}\NormalTok{]]}
\FunctionTok{print}\NormalTok{(coverage)}
\CommentTok{\#\textgreater{}        s1     s2     s3     s4}
\CommentTok{\#\textgreater{} s1 0.9615 0.9231 0.9231 0.6692}
\CommentTok{\#\textgreater{} s2 0.9231 0.9615 0.9231 0.6692}
\CommentTok{\#\textgreater{} s3 0.9231 0.9231 0.9615 0.6692}
\CommentTok{\#\textgreater{} s4 0.6692 0.6692 0.6692 0.7077}
\end{Highlighting}
\end{Shaded}

Ad esempio, consideriamo l'item \texttt{s1}; se moltiplichiamo la copertura di questo elemento per la numerosità campionaria

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{650} \SpecialCharTok{*} \FloatTok{0.9615385}
\CommentTok{\#\textgreater{} [1] 625}
\end{Highlighting}
\end{Shaded}

possiamo concludere che questa variabile contiene 25 osservazioni mancanti; e così via.

Procediamo poi come sempre per esaminare la soluzione ottentua.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{effectsize}\SpecialCharTok{::}\FunctionTok{interpret}\NormalTok{(fit)}
\CommentTok{\#\textgreater{}     Name    Value Interpretation}
\CommentTok{\#\textgreater{} 1    GFI 0.999449   satisfactory}
\CommentTok{\#\textgreater{} 2   AGFI 0.992292   satisfactory}
\CommentTok{\#\textgreater{} 3    NFI 0.999193   satisfactory}
\CommentTok{\#\textgreater{} 4   NNFI 0.998978   satisfactory}
\CommentTok{\#\textgreater{} 5    CFI 0.999830   satisfactory}
\CommentTok{\#\textgreater{} 6  RMSEA 0.020238   satisfactory}
\CommentTok{\#\textgreater{} 7   SRMR 0.004853   satisfactory}
\CommentTok{\#\textgreater{} 8    RFI 0.995155   satisfactory}
\CommentTok{\#\textgreater{} 9   PNFI 0.166532           poor}
\CommentTok{\#\textgreater{} 10   IFI 0.999830   satisfactory}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{standardizedSolution}\NormalTok{(fit)}
\CommentTok{\#\textgreater{}       lhs op    rhs est.std    se      z pvalue}
\CommentTok{\#\textgreater{} 1  esteem =\textasciitilde{}     s1   0.737 0.020 37.086      0}
\CommentTok{\#\textgreater{} 2  esteem =\textasciitilde{}     s2   0.920 0.013 68.651      0}
\CommentTok{\#\textgreater{} 3  esteem =\textasciitilde{}     s3   0.880 0.013 66.432      0}
\CommentTok{\#\textgreater{} 4  esteem =\textasciitilde{}     s4   0.905 0.016 55.400      0}
\CommentTok{\#\textgreater{} 5      s2 \textasciitilde{}\textasciitilde{}     s4  {-}0.886 0.216 {-}4.109      0}
\CommentTok{\#\textgreater{} 6      s1 \textasciitilde{}\textasciitilde{}     s1   0.456 0.029 15.554      0}
\CommentTok{\#\textgreater{} 7      s2 \textasciitilde{}\textasciitilde{}     s2   0.153 0.025  6.190      0}
\CommentTok{\#\textgreater{} 8      s3 \textasciitilde{}\textasciitilde{}     s3   0.225 0.023  9.636      0}
\CommentTok{\#\textgreater{} 9      s4 \textasciitilde{}\textasciitilde{}     s4   0.182 0.030  6.151      0}
\CommentTok{\#\textgreater{} 10 esteem \textasciitilde{}\textasciitilde{} esteem   1.000 0.000     NA     NA}
\CommentTok{\#\textgreater{} 11     s1 \textasciitilde{}1          2.375 0.078 30.610      0}
\CommentTok{\#\textgreater{} 12     s2 \textasciitilde{}1          1.881 0.066 28.592      0}
\CommentTok{\#\textgreater{} 13     s3 \textasciitilde{}1          1.584 0.059 26.781      0}
\CommentTok{\#\textgreater{} 14     s4 \textasciitilde{}1          1.850 0.071 26.048      0}
\CommentTok{\#\textgreater{} 15 esteem \textasciitilde{}1          0.000 0.000     NA     NA}
\CommentTok{\#\textgreater{}    ci.lower ci.upper}
\CommentTok{\#\textgreater{} 1     0.698    0.776}
\CommentTok{\#\textgreater{} 2     0.894    0.947}
\CommentTok{\#\textgreater{} 3     0.854    0.906}
\CommentTok{\#\textgreater{} 4     0.873    0.937}
\CommentTok{\#\textgreater{} 5    {-}1.309   {-}0.463}
\CommentTok{\#\textgreater{} 6     0.399    0.514}
\CommentTok{\#\textgreater{} 7     0.104    0.201}
\CommentTok{\#\textgreater{} 8     0.179    0.271}
\CommentTok{\#\textgreater{} 9     0.124    0.240}
\CommentTok{\#\textgreater{} 10    1.000    1.000}
\CommentTok{\#\textgreater{} 11    2.223    2.527}
\CommentTok{\#\textgreater{} 12    1.752    2.010}
\CommentTok{\#\textgreater{} 13    1.468    1.700}
\CommentTok{\#\textgreater{} 14    1.710    1.989}
\CommentTok{\#\textgreater{} 15    0.000    0.000}
\end{Highlighting}
\end{Shaded}

\hypertarget{ch:cat_data}{%
\chapter{Dati non gaussiani e categoriali}\label{ch:cat_data}}

\hypertarget{dati-non-gaussiani}{%
\section{Dati non gaussiani}\label{dati-non-gaussiani}}

Negli esempi precedenti di questa dispensa è stato utilizzato lo stimatore di massima verosimiglianza (ML). Molti dei modelli CFA e SEM riportati nella letteratura di ricerca applicata utilizzano stime di ML. Tuttavia, ML è appropriata solo per dati multivariati normali, a livello di scala a intervalli (cioè, quando la distribuzione congiunta delle variabili continue è distribuita normalmente). Quando i dati continui si discostano marcatamente dalla normalità (cioè, forti asimmetria o curtosi), o quando alcuni degli indicatori non sono a livello di cala a intervalli (cioè, dati binari, politomici o ordinali), allora dovrebbe essere utilizzato uno stimatore diverso dalla ML.

La ricerca ha dimostrato che ML è robusta nel caso di lievi deviazioni nella normalità. Tuttavia, quando la non normalità è più pronunciata, è necessario utilizzare uno stimatore diverso da ML per ottenere risultati statistici affidabili (vale a dire, statistiche accurate sulla bontà dell'adattamento ed errori standard delle stime dei parametri). ML è particolarmente sensibile ad una eccessiva curtosi.

Le conseguenze dell'uso del ML in condizioni di grave non normalità includono

\begin{itemize}
\tightlist
\item
  valori eccessivi della statistica \(\chi^2\) del modello;
\item
  sottostima degli indici di bontà dell'adattamento come TLI e CFI;
\item
  sottostima degli errori standard delle stime dei parametri.
\end{itemize}

Questi effetti deleteri sono esacerbati con la diminuzione della dimensione del campione.

I due stimatori più comunemente usati per dati continui non normali sono

\begin{itemize}
\tightlist
\item
  ML robusto,
\item
  minimi quadrati ponderati.
\end{itemize}

L'uso di WLS non è, in generale, raccomandato, a meno che le dimensioni del campione non siano molto grandi. Al contrario, la ricerca ha dimostrato che il metodo ML robusto fornisce uno stimatore adeguato rispetto a diversi livelli di non normalità.

Esaminiamo qui un esempio che usa gli stessi dati utilizzati da \citet{brown2015confirmatory} nelle tabelle 9.5 -- 9.7.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d }\OtherTok{\textless{}{-}} \FunctionTok{readRDS}\NormalTok{(here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{(}\StringTok{"data"}\NormalTok{, }\StringTok{"brown\_table\_9\_5\_data.RDS"}\NormalTok{))}
\FunctionTok{head}\NormalTok{(d)}
\CommentTok{\#\textgreater{}   x1 x2 x3 x4 x5}
\CommentTok{\#\textgreater{} 1  0  0  0  0  0}
\CommentTok{\#\textgreater{} 2  0  0  0  0  0}
\CommentTok{\#\textgreater{} 3  0  0  0  0  0}
\CommentTok{\#\textgreater{} 4  4  2  2  1  1}
\CommentTok{\#\textgreater{} 5  1  0  1  6  0}
\CommentTok{\#\textgreater{} 6  0  0  0  0  0}
\end{Highlighting}
\end{Shaded}

Le statistiche descrittive dei dati dell'esempio mostrano valori eccessivi di asimmetria e di curtosi.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{psych}\SpecialCharTok{::}\FunctionTok{describe}\NormalTok{(d)}
\CommentTok{\#\textgreater{}    vars   n mean   sd median trimmed mad min max range}
\CommentTok{\#\textgreater{} x1    1 870 1.47 2.17      0    1.01   0   0   8     8}
\CommentTok{\#\textgreater{} x2    2 870 0.82 1.60      0    0.42   0   0   8     8}
\CommentTok{\#\textgreater{} x3    3 870 1.27 2.07      0    0.78   0   0   8     8}
\CommentTok{\#\textgreater{} x4    4 870 1.03 1.93      0    0.54   0   0   8     8}
\CommentTok{\#\textgreater{} x5    5 870 0.61 1.52      0    0.18   0   0   8     8}
\CommentTok{\#\textgreater{}    skew kurtosis   se}
\CommentTok{\#\textgreater{} x1 1.51     1.25 0.07}
\CommentTok{\#\textgreater{} x2 2.40     5.67 0.05}
\CommentTok{\#\textgreater{} x3 1.80     2.34 0.07}
\CommentTok{\#\textgreater{} x4 2.16     3.98 0.07}
\CommentTok{\#\textgreater{} x5 3.10     9.37 0.05}
\end{Highlighting}
\end{Shaded}

Definiamo un modello ad un fattore e, seguendo \citet{brown2015confirmatory}, aggiungiamo una correlazione residua tra gli indicatori \texttt{X1} e \texttt{X3}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model }\OtherTok{\textless{}{-}} \StringTok{"}
\StringTok{  f1 =\textasciitilde{} x1 + x2 + x3 + x4 + x5}
\StringTok{  x1 \textasciitilde{}\textasciitilde{} x3}
\StringTok{"}
\end{Highlighting}
\end{Shaded}

Procediamo alla stima dei parametri utilizzando uno stimatore di ML robusto. La sintassi \texttt{lavaan} è la seguente:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{cfa}\NormalTok{(model, }\AttributeTok{data =}\NormalTok{ d, }\AttributeTok{mimic =} \StringTok{"MPLUS"}\NormalTok{, }\AttributeTok{estimator =} \StringTok{"MLM"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Possiamo esaminare la soluzione ottenuta con i soliti metodi:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{standardizedSolution}\NormalTok{(fit)}
\CommentTok{\#\textgreater{}    lhs op rhs est.std    se      z pvalue ci.lower}
\CommentTok{\#\textgreater{} 1   f1 =\textasciitilde{}  x1   0.753 0.030 25.226      0    0.695}
\CommentTok{\#\textgreater{} 2   f1 =\textasciitilde{}  x2   0.718 0.035 20.495      0    0.649}
\CommentTok{\#\textgreater{} 3   f1 =\textasciitilde{}  x3   0.845 0.022 38.183      0    0.801}
\CommentTok{\#\textgreater{} 4   f1 =\textasciitilde{}  x4   0.779 0.031 25.377      0    0.719}
\CommentTok{\#\textgreater{} 5   f1 =\textasciitilde{}  x5   0.806 0.027 29.651      0    0.753}
\CommentTok{\#\textgreater{} 6   x1 \textasciitilde{}\textasciitilde{}  x3   0.414 0.061  6.777      0    0.294}
\CommentTok{\#\textgreater{} 7   x1 \textasciitilde{}\textasciitilde{}  x1   0.433 0.045  9.619      0    0.344}
\CommentTok{\#\textgreater{} 8   x2 \textasciitilde{}\textasciitilde{}  x2   0.484 0.050  9.623      0    0.386}
\CommentTok{\#\textgreater{} 9   x3 \textasciitilde{}\textasciitilde{}  x3   0.287 0.037  7.674      0    0.213}
\CommentTok{\#\textgreater{} 10  x4 \textasciitilde{}\textasciitilde{}  x4   0.393 0.048  8.202      0    0.299}
\CommentTok{\#\textgreater{} 11  x5 \textasciitilde{}\textasciitilde{}  x5   0.350 0.044  7.987      0    0.264}
\CommentTok{\#\textgreater{} 12  f1 \textasciitilde{}\textasciitilde{}  f1   1.000 0.000     NA     NA    1.000}
\CommentTok{\#\textgreater{} 13  x1 \textasciitilde{}1       0.677 0.020 33.542      0    0.637}
\CommentTok{\#\textgreater{} 14  x2 \textasciitilde{}1       0.514 0.018 28.848      0    0.479}
\CommentTok{\#\textgreater{} 15  x3 \textasciitilde{}1       0.612 0.019 32.539      0    0.575}
\CommentTok{\#\textgreater{} 16  x4 \textasciitilde{}1       0.533 0.018 29.758      0    0.498}
\CommentTok{\#\textgreater{} 17  x5 \textasciitilde{}1       0.400 0.016 25.596      0    0.369}
\CommentTok{\#\textgreater{} 18  f1 \textasciitilde{}1       0.000 0.000     NA     NA    0.000}
\CommentTok{\#\textgreater{}    ci.upper}
\CommentTok{\#\textgreater{} 1     0.812}
\CommentTok{\#\textgreater{} 2     0.787}
\CommentTok{\#\textgreater{} 3     0.888}
\CommentTok{\#\textgreater{} 4     0.840}
\CommentTok{\#\textgreater{} 5     0.859}
\CommentTok{\#\textgreater{} 6     0.534}
\CommentTok{\#\textgreater{} 7     0.521}
\CommentTok{\#\textgreater{} 8     0.583}
\CommentTok{\#\textgreater{} 9     0.360}
\CommentTok{\#\textgreater{} 10    0.486}
\CommentTok{\#\textgreater{} 11    0.436}
\CommentTok{\#\textgreater{} 12    1.000}
\CommentTok{\#\textgreater{} 13    0.717}
\CommentTok{\#\textgreater{} 14    0.549}
\CommentTok{\#\textgreater{} 15    0.649}
\CommentTok{\#\textgreater{} 16    0.568}
\CommentTok{\#\textgreater{} 17    0.430}
\CommentTok{\#\textgreater{} 18    0.000}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{effectsize}\SpecialCharTok{::}\FunctionTok{interpret}\NormalTok{(fit)}
\CommentTok{\#\textgreater{}     Name   Value Interpretation}
\CommentTok{\#\textgreater{} 1    GFI 0.99084   satisfactory}
\CommentTok{\#\textgreater{} 2   AGFI 0.95420   satisfactory}
\CommentTok{\#\textgreater{} 3    NFI 0.98975   satisfactory}
\CommentTok{\#\textgreater{} 4   NNFI 0.97823   satisfactory}
\CommentTok{\#\textgreater{} 5    CFI 0.99129   satisfactory}
\CommentTok{\#\textgreater{} 6  RMSEA 0.07935           poor}
\CommentTok{\#\textgreater{} 7   SRMR 0.01595   satisfactory}
\CommentTok{\#\textgreater{} 8    RFI 0.97436   satisfactory}
\CommentTok{\#\textgreater{} 9   PNFI 0.39590           poor}
\CommentTok{\#\textgreater{} 10   IFI 0.99131   satisfactory}
\end{Highlighting}
\end{Shaded}

\hypertarget{dati-categoriali}{%
\section{Dati categoriali}\label{dati-categoriali}}

Quando almeno un indicatore è categoriale (cioè binario, politomico o ordinale), il metodo ML ordinario non dovrebbe essere utilizzato per stimare i modelli CFA. Le potenziali conseguenze del trattamento delle variabili categoriali come variabili continue in un'analisi CFA sono molteplici, incluso il fatto che può tale scelta può

\begin{itemize}
\tightlist
\item
  produrre stime attenuate delle relazioni tra indicatori, specialmente quando ci sono effetti pavimento o soffitto;
\item
  portare ad individuare ``pseudofattori'' che sono solo artefatti del metodo statistico;\\
\item
  produrre distorsioni negli indici di bontà dell'adattamento e nella stima degli errori standard;
\item
  produrre stime errate dei parametri.
\end{itemize}

Esistono vari stimatori che possono essere utilizzati con indicatori categoriali; ad esempio, minimi quadrati ponderati (WLS), minimi quadrati ponderati robusti (WLSMV) e minimi quadrati non ponderati (ULS).

\hypertarget{un-esempio-concreto-6}{%
\subsection{Un esempio concreto}\label{un-esempio-concreto-6}}

Nell'esempio discusso da \citet{brown2015confirmatory}, i ricercatori desiderano verificare un modello unifattoriale di dipendenza da alcol in un campione di 750 pazienti ambulatoriali. Gli indicatori di alcolismo sono item binari che riflettono la presenza/assenza di sei criteri diagnostici per l'alcolismo (0 = criterio non soddisfatto, 1 = criterio soddisfatto). I dati sono i seguenti:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d1 }\OtherTok{\textless{}{-}} \FunctionTok{readRDS}\NormalTok{(here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{(}\StringTok{"data"}\NormalTok{, }\StringTok{"brown\_table\_9\_9\_data.RDS"}\NormalTok{))}
\FunctionTok{head}\NormalTok{(d1)}
\CommentTok{\#\textgreater{}   y1 y2 y3 y4 y5 y6}
\CommentTok{\#\textgreater{} 1  1  1  1  1  1  1}
\CommentTok{\#\textgreater{} 2  1  1  1  1  1  1}
\CommentTok{\#\textgreater{} 3  1  1  1  1  1  0}
\CommentTok{\#\textgreater{} 4  1  1  1  1  1  1}
\CommentTok{\#\textgreater{} 5  0  0  0  0  0  0}
\CommentTok{\#\textgreater{} 6  1  1  0  1  1  1}
\end{Highlighting}
\end{Shaded}

Il modello viene specificato nel modo seguente:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model1 }\OtherTok{\textless{}{-}} \StringTok{"}
\StringTok{  etoh =\textasciitilde{} y1 + y2 + y3 + y4 + y5 + y6}
\StringTok{"}
\end{Highlighting}
\end{Shaded}

Adattiamo il modello specificando che i dati sono a livello di scala ordinale:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit1 }\OtherTok{\textless{}{-}} \FunctionTok{cfa}\NormalTok{(}
\NormalTok{  model1,}
  \AttributeTok{data =}\NormalTok{ d1,}
  \AttributeTok{ordered =} \FunctionTok{names}\NormalTok{(d1),}
  \AttributeTok{estimator =} \StringTok{"WLSMVS"}\NormalTok{,}
  \AttributeTok{mimic =} \StringTok{"mplus"}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Esaminiamo la soluzione ottenuta:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(fit1, }\AttributeTok{fit.measures =} \ConstantTok{TRUE}\NormalTok{)}
\CommentTok{\#\textgreater{} lavaan 0.6{-}10 ended normally after 16 iterations}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}   Estimator                                       DWLS}
\CommentTok{\#\textgreater{}   Optimization method                           NLMINB}
\CommentTok{\#\textgreater{}   Number of model parameters                        12}
\CommentTok{\#\textgreater{}                                                       }
\CommentTok{\#\textgreater{}   Number of observations                           750}
\CommentTok{\#\textgreater{}                                                       }
\CommentTok{\#\textgreater{} Model Test User Model:}
\CommentTok{\#\textgreater{}                                                      Standard      Robust}
\CommentTok{\#\textgreater{}   Test Statistic                                        5.651       9.540}
\CommentTok{\#\textgreater{}   Degrees of freedom                                        9           9}
\CommentTok{\#\textgreater{}   P{-}value (Chi{-}square)                                  0.774       0.389}
\CommentTok{\#\textgreater{}   Scaling correction factor                                         0.592}
\CommentTok{\#\textgreater{}        mean and variance adjusted correction (WLSMV)                     }
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Model Test Baseline Model:}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}   Test statistic                              1155.845     694.433}
\CommentTok{\#\textgreater{}   Degrees of freedom                                15           9}
\CommentTok{\#\textgreater{}   P{-}value                                        0.000       0.000}
\CommentTok{\#\textgreater{}   Scaling correction factor                                  1.664}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} User Model versus Baseline Model:}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}   Comparative Fit Index (CFI)                    1.000       0.999}
\CommentTok{\#\textgreater{}   Tucker{-}Lewis Index (TLI)                       1.005       0.999}
\CommentTok{\#\textgreater{}                                                                   }
\CommentTok{\#\textgreater{}   Robust Comparative Fit Index (CFI)                            NA}
\CommentTok{\#\textgreater{}   Robust Tucker{-}Lewis Index (TLI)                               NA}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Root Mean Square Error of Approximation:}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}   RMSEA                                          0.000       0.009}
\CommentTok{\#\textgreater{}   90 Percent confidence interval {-} lower         0.000       0.000}
\CommentTok{\#\textgreater{}   90 Percent confidence interval {-} upper         0.028       0.051}
\CommentTok{\#\textgreater{}   P{-}value RMSEA \textless{}= 0.05                          0.999       0.944}
\CommentTok{\#\textgreater{}                                                                   }
\CommentTok{\#\textgreater{}   Robust RMSEA                                                  NA}
\CommentTok{\#\textgreater{}   90 Percent confidence interval {-} lower                     0.000}
\CommentTok{\#\textgreater{}   90 Percent confidence interval {-} upper                        NA}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Standardized Root Mean Square Residual:}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}   SRMR                                           0.031       0.031}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Weighted Root Mean Square Residual:}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}   WRMR                                           0.519       0.519}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Parameter Estimates:}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}   Standard errors                           Robust.sem}
\CommentTok{\#\textgreater{}   Information                                 Expected}
\CommentTok{\#\textgreater{}   Information saturated (h1) model        Unstructured}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Latent Variables:}
\CommentTok{\#\textgreater{}                    Estimate  Std.Err  z{-}value  P(\textgreater{}|z|)}
\CommentTok{\#\textgreater{}   etoh =\textasciitilde{}                                             }
\CommentTok{\#\textgreater{}     y1                1.000                           }
\CommentTok{\#\textgreater{}     y2                0.822    0.072   11.392    0.000}
\CommentTok{\#\textgreater{}     y3                0.653    0.092    7.097    0.000}
\CommentTok{\#\textgreater{}     y4                1.031    0.075   13.703    0.000}
\CommentTok{\#\textgreater{}     y5                1.002    0.072   13.861    0.000}
\CommentTok{\#\textgreater{}     y6                0.759    0.076   10.011    0.000}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Intercepts:}
\CommentTok{\#\textgreater{}                    Estimate  Std.Err  z{-}value  P(\textgreater{}|z|)}
\CommentTok{\#\textgreater{}    .y1                0.000                           }
\CommentTok{\#\textgreater{}    .y2                0.000                           }
\CommentTok{\#\textgreater{}    .y3                0.000                           }
\CommentTok{\#\textgreater{}    .y4                0.000                           }
\CommentTok{\#\textgreater{}    .y5                0.000                           }
\CommentTok{\#\textgreater{}    .y6                0.000                           }
\CommentTok{\#\textgreater{}     etoh              0.000                           }
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Thresholds:}
\CommentTok{\#\textgreater{}                    Estimate  Std.Err  z{-}value  P(\textgreater{}|z|)}
\CommentTok{\#\textgreater{}     y1|t1            {-}0.759    0.051  {-}14.890    0.000}
\CommentTok{\#\textgreater{}     y2|t1            {-}0.398    0.047   {-}8.437    0.000}
\CommentTok{\#\textgreater{}     y3|t1            {-}1.244    0.061  {-}20.278    0.000}
\CommentTok{\#\textgreater{}     y4|t1            {-}0.795    0.051  {-}15.436    0.000}
\CommentTok{\#\textgreater{}     y5|t1            {-}0.384    0.047   {-}8.148    0.000}
\CommentTok{\#\textgreater{}     y6|t1            {-}0.818    0.052  {-}15.775    0.000}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Variances:}
\CommentTok{\#\textgreater{}                    Estimate  Std.Err  z{-}value  P(\textgreater{}|z|)}
\CommentTok{\#\textgreater{}    .y1                0.399                           }
\CommentTok{\#\textgreater{}    .y2                0.594                           }
\CommentTok{\#\textgreater{}    .y3                0.744                           }
\CommentTok{\#\textgreater{}    .y4                0.361                           }
\CommentTok{\#\textgreater{}    .y5                0.397                           }
\CommentTok{\#\textgreater{}    .y6                0.653                           }
\CommentTok{\#\textgreater{}     etoh              0.601    0.063    9.596    0.000}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Scales y*:}
\CommentTok{\#\textgreater{}                    Estimate  Std.Err  z{-}value  P(\textgreater{}|z|)}
\CommentTok{\#\textgreater{}     y1                1.000                           }
\CommentTok{\#\textgreater{}     y2                1.000                           }
\CommentTok{\#\textgreater{}     y3                1.000                           }
\CommentTok{\#\textgreater{}     y4                1.000                           }
\CommentTok{\#\textgreater{}     y5                1.000                           }
\CommentTok{\#\textgreater{}     y6                1.000}
\end{Highlighting}
\end{Shaded}

\mainmatter

\hypertarget{part-appendici}{%
\part{Appendici}\label{part-appendici}}

\hypertarget{appendix-appendici}{%
\appendix \addcontentsline{toc}{chapter}{\appendixname}}


\hypertarget{simbologia-di-base}{%
\chapter{Simbologia di base}\label{simbologia-di-base}}

Per una scrittura più sintetica possono essere utilizzati alcuni simboli matematici.

\begin{itemize}
\tightlist
\item
  \(\log(x)\): il logaritmo naturale di \(x\).
\item
  L'operatore logico booleano \(\land\) significa ``e'' (congiunzione forte) mentre il connettivo di disgiunzione \(\lor\) significa ``o'' (oppure) (congiunzione debole).
\item
  Il quantificatore esistenziale \(\exists\) vuol dire ``esiste almeno un'' e indica l'esistenza di almeno una istanza del concetto/oggetto indicato. Il quantificatore esistenziale di unicità \(\exists!\) (``esiste soltanto un'') indica l'esistenza di esattamente una istanza del concetto/oggetto indicato. Il quantificatore esistenziale \(\nexists\) nega l'esistenza del concetto/oggetto indicato.
\item
  Il quantificatore universale \(\forall\) vuol dire ``per ogni.''
\item
  \(\mathcal{A, S}\): insiemi.
\item
  \(x \in A\): \(x\) è un elemento dell'insieme \(A\).
\item
  L'implicazione logica ``\(\Rightarrow\)'' significa ``implica'' (se \ldots allora). \(P \Rightarrow Q\) vuol dire che \(P\) è condizione sufficiente per la verità di \(Q\) e che \(Q\) è condizione necessaria per la verità di \(P\).
\item
  L'equivalenza matematica ``\(\iff\)'' significa ``se e solo se'' e indica una condizione necessaria e sufficiente, o corrispondenza biunivoca.
\item
  Il simbolo \(\vert\) si legge ``tale che.''
\item
  Il simbolo \(\triangleq\) (o \(:=\)) si legge ``uguale per definizione.''
\item
  Il simbolo \(\Delta\) indica la differenza fra due valori della variabile scritta a destra del simbolo.
\item
  Il simbolo \(\propto\) si legge ``proporzionale a.''
\item
  Il simbolo \(\approx\) si legge ``circa.''
\item
  Il simbolo \(\in\) della teoria degli insiemi vuol dire ``appartiene'' e indica l'appartenenza di un elemento ad un insieme. Il simbolo \(\notin\) vuol dire ``non appartiene.''
\item
  Il simbolo \(\subseteq\) si legge ``è un sottoinsieme di'' (può coincidere con l'insieme stesso). Il simbolo \(\subset\) si legge ``è un sottoinsieme proprio di.''
\item
  Il simbolo \(\#\) indica la cardinalità di un insieme.
\item
  Il simbolo \(\cap\) indica l'intersezione di due insiemi. Il simbolo \(\cup\) indica l'unione di due insiemi.
\item
  Il simbolo \(\emptyset\) indica l'insieme vuoto o evento impossibile.
\item
  In matematica, \(\mbox{argmax}\) identifica l'insieme dei punti per i quali una data funzione raggiunge il suo massimo. In altre parole, \(\mbox{argmax}_x f(x)\) è l'insieme dei valori di \(x\) per i quali \(f(x)\) raggiunge il valore più alto.
\item
  \(a, c, \alpha, \gamma\): scalari.
\item
  \(\boldsymbol{x}, \boldsymbol{y}\): vettori.
\item
  \(\boldsymbol{X}, \boldsymbol{Y}\): matrici.
\item
  \(X \sim p\): la variabile casuale \(X\) si distribuisce come \(p\).
\item
  \(p(\cdot)\): distribuzione di massa o di densità di probabilità.
\item
  \(p(y \mid \boldsymbol{x})\): la probabilità o densità di \(y\) dato \(\boldsymbol{x}\), ovvero \(p(y = \boldsymbol{Y} \mid x = \boldsymbol{X})\).
\item
  \(f(x)\): una funzione arbitraria di \(x\).
\item
  \(f(\boldsymbol{X}; \theta, \gamma)\): \(f\) è una funzione di \(\boldsymbol{X}\) con parametri \(\theta, \gamma\). Questa notazione indica che \(\boldsymbol{X}\) sono i dati che vengono passati ad un modello di parametri \(\theta, \gamma\).
\item
  \(\mathcal{N}(\mu, \sigma^2)\): distribuzione gaussiana di media \(\mu\) e varianza \(sigma^2\).
\item
  \(\mbox{Beta}(\alpha, \beta)\): distribuzione Beta di parametri \(\alpha\) e \(\beta\).
\item
  \(\mathcal{U}(a, b)\): distribuzione uniforme con limite inferiore \(a\) e limite superiore \(b\).
\item
  \(\mbox{Cauchy}(\alpha, \beta)\): distribuzione di Cauchy di parametri \(\alpha\) (posizione: media) e \(\beta\) (scala: radice quadrata della varianza).
\item
  \(\mathcal{B}(p)\): distribuzione di Bernoulli di parametro \(p\) (probabilità di successo).
\item
  \(\mbox{Bin}(n, p)\): distribuzione binomiale di parametri \(n\) (numero di prove) e \(p\) (probabilità di successo).
\item
  \(\mathbb{KL} (p \mid\mid q)\): la divergenza di Kullback-Leibler da \(p\) a \(q\).
\end{itemize}

\hypertarget{ch:single_case}{%
\chapter{Lo studio del caso singolo}\label{ch:single_case}}

\hypertarget{sec:motivazione}{%
\section{Motivazione}\label{sec:motivazione}}

In anni recenti c'è stata una sostanziale ripresa di interesse nei confronti degli studi sul caso singolo in neuropsicologia. Tra le ragioni di ciò vi è la convinzione che la prestazione media di un gruppo di pazienti possa essere considerata come un artefatto statistico privo di significato il quale oscura differenze teoricamente importanti tra i pazienti. La versione più estrema di questo argomento è stata fatta da Caramazza e colleghi (ad esempio, Caramazza, 1986; Caramazza e McCloskey, 1988), i quali hanno sostenuto che i neuropsicologi dovrebbero studiare solo casi singoli. Vallar (2000) ha fornito un riassunto conciso di questa posizione: ``{[}Hence{]} studies in groups of patients which aim at elucidating the neurological and functional architecture of mental processes are useless and harmful, since they provide misleading results. The only appropriate method is to study individual patients. (p.~334)

Questa è una visione minoritaria (anche se influente). Tuttavia, molti altri neuropsicologi hanno sottolineato l'importanza dello studio dei casi singoli (Capitani e Laiacona, 2000; Coltheart, 2001; Ellis \& Young, 1996; Shallice, 1988). Ad esempio, la posizione di Vallar (2000) è meno estrema: ``Single-case studies have a number of advantages, in comparison with group studies. The probability to produce significant theoretical advances is perhaps higher'' (p.~332).

Gli studi sul caso singolo pongono però al neuropsicologo difficili problemi dal punto di vista statistico. Esaminiamo qui alcuni temi di tale discussione: il confronto tra caso singolo e un gruppo di controllo e lo studio delle dissociazioni.

\hypertarget{sec:comparison-single-case-controls}{%
\section{Il confronto tra caso singolo e un gruppo di controllo}\label{sec:comparison-single-case-controls}}

I neuropsicologi hanno spesso bisogno di confrontare un singolo caso con un piccolo gruppo di controllo. Tuttavia, il test \(t\) di Student per due campioni indipendenti non può essere applicato perché un gruppo è costituito da un'unica osservazione. Crawford e Garthwaite (2012) dimostrano che il test \(t\) di Student messo a punto da Crawford e Garthwaite (2007) fornisce un approccio migliore (in termini del controllo del tasso di errore di Tipo I) rispetto ad altre alternative comunemente usate.

Crawford e Garthwaite (2012) hanno esaminato il problema dello studio del caso singolo in neuropsicologia nel quale le inferenze riguardanti le prestazioni cognitive di un singolo caso vengono confrontate con un campione di controlli sani appaiati. Fino a poco tempo fa il metodo standard per l'inferenza sulla differenza tra un caso e un gruppo di controlli era quello di convertire il punteggio del caso in un punteggio \(z\) utilizzando la media campionaria e la deviazione standard del controllo, per poi valutare tale punteggio \(z\) con riferimento alla distribuzione normale.

Il problema di questo approccio è che non tiene in considerazione l'incertezza relativa alla media e alla deviazione standard del gruppo di controllo, trattando la media e la deviazione standard del gruppo di controllo come se fossero la media e la deviazione standard della popolazione del gruppo di controllo. Come conseguenza di ciò, l'errore di I tipo viene inflazionato (in questo contesto si verifica un errore di tipo I quando si conclude che il punteggio del caso non è un'osservazione che appartiene alla popolazione del punteggi dei controlli) e viene sovrastimata l'anormalità del punteggio del caso singolo. A tale problema sono state proposte diverse soluzioni.

\hypertarget{sec:Crawford-Howell-1998}{%
\subsection{Il metodo di Crawford e Howell (1998)}\label{sec:Crawford-Howell-1998}}

Questo metodo differisce dall'uso del punteggio \(z\) descritto sopra perché tratta la media e la deviazione standard del gruppo di controllo per quello che sono, ovvero statistiche campionarie, e poi utilizza il test \(t\) di Student per esaminare la differenza tra caso e controlli. La formula per il test \(t\) di Student da applicare nel caso presente è

\[
t_{n-1} = \frac{x^* - \bar{x}}{s \sqrt{\frac{n+1}{n}}},
\label{eq:Crawford-Howell-1998}
\]

dove \(x^*\) è il punteggio del paziente, \(\bar{x}\) e \(s\) sono la media e la deviazione standard del gruppo di controllo, e \(n\) è l'ampiezza campionaria del gruppo di controllo.

Se il valore \(t\) ottenuto da questo test è minore del quantile \(t_{n-1}\) di ordine 0.05, allora si può concludere che il punteggio del caso è sufficientemente basso da consentirci di rifiutare ipotesi nulla che il punteggio del caso singolo appartiene alla popolazione di punteggi dei controlli. Se rifiutiamo l'ipotesi nulla possiamo così concludere che il caso esibisce un deficit relativo all'abilità in questione.

Il valore-\(p\) del test unidirezionale prodotto dalla \eqref{eq:Crawford-Howell-1998} (a differenza del valore-\(p\) del test \(z\) discusso sopra) fornisce anche una stima puntuale statisticamente corretta dell'anormalità del punteggio del caso. Quindi se il valore-\(p\) è 0.023, allora possiamo affermare che solo il 2.3\% della popolazione di controllo otterrà punteggi più bassi (il che significa che, in questo esempio, il punteggio del caso è anormalmente basso).

\begin{exercise}
Una versione bayesiana di questo test è implementata nella funzione \texttt{crawford.test()} del pacchetto \texttt{psycho}. Supponiamo che il caso mostri un QI pari a 61 mentre il QI dei controlli è \(\{86, 100, 112, 95, 121, 102\}\). Ci chiediamo se il QI del caso sia anormalmente basso.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(}\StringTok{"psycho"}\NormalTok{)}
\NormalTok{patient }\OtherTok{\textless{}{-}} \DecValTok{61} \CommentTok{\# The IQ of a patient}
\NormalTok{controls }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{86}\NormalTok{, }\DecValTok{100}\NormalTok{, }\DecValTok{112}\NormalTok{, }\DecValTok{95}\NormalTok{, }\DecValTok{121}\NormalTok{, }\DecValTok{102}\NormalTok{) }\CommentTok{\# The IQs of a control group}
\FunctionTok{crawford.test}\NormalTok{(patient, controls)}
\CommentTok{\#\textgreater{} The Bayesian test for single case assessment (Crawford, Garthwaite, 2007) suggests that the patient\textquotesingle{}s score (Raw = 61.00, Z = {-}3.36, percentile = 0.04) is significantly different from the controls (M = 102.67, SD = 12.39, p p = 0.013). The patient\textquotesingle{}s score is lower than 98.69\% (95\% CI [1.33e{-}15, 0.07]) of the control population.}
\end{Highlighting}
\end{Shaded}

Utilizzando la \eqref{eq:Crawford-Howell-1998} otteniamo un risultato quasi identico:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{crawford\_howell\_test }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(patient, controls) \{}
\NormalTok{  n }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(controls)}
\NormalTok{  s }\OtherTok{\textless{}{-}} \FunctionTok{sd}\NormalTok{(controls)}
\NormalTok{  t }\OtherTok{\textless{}{-}}\NormalTok{ (patient }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(controls)) }\SpecialCharTok{/}\NormalTok{ (s }\SpecialCharTok{*} \FunctionTok{sqrt}\NormalTok{((n }\SpecialCharTok{+} \DecValTok{1}\NormalTok{) }\SpecialCharTok{/}\NormalTok{ n))}
  \FunctionTok{list}\NormalTok{(t, }\DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{pt}\NormalTok{(t, n }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{))}
\NormalTok{\}}
\FunctionTok{crawford\_howell\_test}\NormalTok{(patient, controls)}
\CommentTok{\#\textgreater{} [[1]]}
\CommentTok{\#\textgreater{} [1] {-}3.114}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} [[2]]}
\CommentTok{\#\textgreater{} [1] 0.9868}
\end{Highlighting}
\end{Shaded}

In entrambi i casi la risposta è che il 98.7\% dei controlli ha un QI superiore a quello del caso. In tali circostanze possiamo dunque concludere che siamo in presenza di un deficit.
\end{exercise}

\hypertarget{sec:barton-2002}{%
\subsection{Il metodo di Barton et al.~(2002)}\label{sec:barton-2002}}

Un metodo equivalente alla \eqref{eq:Crawford-Howell-1998} è stato proposto da Barton et al.~(2002). Questi autori confrontano il valore del caso con l'intervallo di confidenza costruito utilizzando i valori dei controlli:

\[
\bar{x} \pm t_{n-1; 0.975} \left(s \sqrt{\frac{n+1}{n}} \right),
\label{eq:Barton-2002}
\]

laddove le quantità nella \eqref{eq:Barton-2002} hanno lo stesso significato che in precedenza. Se il valore del caso singolo cade al di fuori dell'intervallo definito dalla \eqref{eq:Barton-2002} , allora possiamo concludere che il caso manifesta un deficit.

\hypertarget{lintervallo-di-confidenza-tradizionale}{%
\subsubsection{L'intervallo di confidenza ``tradizionale''}\label{lintervallo-di-confidenza-tradizionale}}

Alcuni autori utilizzano una procedura simile a quella descritta nella \eqref{eq:Barton-2002}, ma utilizzando la formula

\[
\bar{x} \pm t_{n-1; 0.975} \left(\sqrt{\frac{s^2}{n}} \right),
\label{eq:Barton-2002-b}
\]

Secondo Crawford e Garthwaite (2012), questo approccio è sbagliato perché, all'aumentare di \(n\), si finirebbe per decidere che il caso manifesta un deficit anche quando ci sono piccolissime differenze rispetto alla media dei controlli. Questo approccio, dunque, è da rifiutare.

\hypertarget{il-test-t-di-student-versione-1}{%
\subsubsection{\texorpdfstring{Il test \(t\) di Student -- versione 1}{Il test t di Student -- versione 1}}\label{il-test-t-di-student-versione-1}}

Alcuni autori utilizzano la formula del test \(t\) di Student nel modo seguente:

\[
t_{n-1} = \frac{\bar{x} - x^*}{\frac{s}{\sqrt{n}}}.
\label{eq:ttest-mean-case}
\]

Per esempio, Reinhold and Markowitsch (2007) descrivono tale procedura nel modo seguente: ``Separately for each patient, all comparisons were computed by t-tests for one group with the score of each patient as the tested value (p.~\textgreater{} 60)''.

Questo è un uso del tutto bizzarro del test \(t\) di Student e non trova giustificazione alcuna.

\hypertarget{il-test-t-di-student-versione-2}{%
\subsubsection{\texorpdfstring{Il test \(t\) di Student -- versione 2}{Il test t di Student -- versione 2}}\label{il-test-t-di-student-versione-2}}

Altri autori hanno usato la formula del test \(t\) di Student scritta nel modo seguente:

\[
t_{n-1} = \frac{x^* - \bar{x}}{\frac{s}{\sqrt{n}}},
\label{eq:ttest-v2}
\]

laddove, nuovamente, utilizziamo la media del campione dei controlli come se fosse la media della popolazione. Questo metodo è stato usato in molti studi sul caso singolo, ma conduce ad una grande inflazione dell'errore di I tipo e ad un'esagerazione dell'anormalità del valore del caso singolo.

\hypertarget{lo-studio-delle-dissociazioni}{%
\section{Lo studio delle dissociazioni}\label{lo-studio-delle-dissociazioni}}

Parallelamente all'aumento di interesse nei confronti dello studio del caso singolo, le dissociazioni hanno assunto un'importanza sempre maggiore nello sviluppo teorico in neuropsicologia. Ad esempio, Dunn e Kirsner (2003) hanno notato che ``dissociations play an increasingly crucial role in the methodology of cognitive neuropsychology \ldots they have provided critical support for several influential, almost paradigmatic, models in the field'' (p.~2).

Ciò è in parte dovuto ai limiti delle strategie alternative. Ad esempio, Vallar (2000) ha notato che le dissociazioni costituiscono ``the most effective paradigm for investigating the modularity of the mental processes and their neural correlates''. Lo studio delle dissociazioni in rapporto al caso singolo pone però difficili problemi. Come notato da Vallar (2000), un ricercatore che studia un caso singolo può ritenere che ``given the complex architecture of the cognitive system and the variability of the site and extent of naturally occurring lesions, it is very unlikely that two patients have similar functional deficits'' (p.~334).

Di conseguenza, Coltheart (2001) ha posto la domanda retorica: ``If every patient is unique, how can you replicate your results?'' e ha concluso che in alcuni casi potrebbe essere che ``the result is literally unreplicable, no matter how genuine''.

Storicamente, gran parte degli studi in neuropsicologia si sono posti il problema di dimostrare l'esistenza di associazioni tra diversi compiti cognitivi. Cioè, è stata posta enfasi sulla rilevazione di gruppi di sintomi cognitivi che si verificano insieme in modo affidabile al fine di identificare sindromi neurologiche o neuropsicologiche. L'insoddisfazione per la scarsa robustezza di tali evidenze è servita quale uno dei fattori trainanti per l'aumento di interesse nei confronti degli studi sul caso singolo. Infatti, indipendentemente dal numero di pazienti che dimostrano la co-occorrenza di deficit in due compiti, l'ipotesi che vi possa essere un processo cognitivo soggiacente comune viene facilmente falsificata dall'osservazione di un singolo paziente che presenta una dissociazione tra i due compiti. Per ritornare al famoso esempio di Karl Popper, l'affermazione ``Tutti i cigni sono bianchi'' può essere falsificata dalla scoperta di un solo cigno nero.

Tuttavia, sebbene i limiti delle prove associative siano ampiamente riconosciuti, è anche chiaro che ci sono difficoltà pratiche nella valutazione delle prove basate sull'osservazione delle dissociazioni. Ad esempio, supponiamo che ci siano evidenze a sostegno del fatto che un insieme di compiti cognitivi risulta associato con una funzione unitaria sottostante. Se tali evidenze devono essere falsificate da un'unica prova di segno contrario, allora dobbiamo essere sicuri della forza dell'evidenza del contro-esempio. Per continuare con l'esempio precedente, dobbiamo essere sicuri che il cigno sia effettivamente nero e non piuttosto un cigno bianco che, per qualche ragione, si è sporcato di nero. I criteri che ci portano a concludere che vi è una dissociazione nel caso singolo, dunque, devono essere più stringenti di quelli che si usano nello studio di gruppi di pazienti. Ma quali devono essere tali criteri? Secondo Shallice (1988) evidenze di una `forte' dissociazione sono fornite quando ``neither task is performed at normal level, but Task I is performed very much better than Task II''.

Coltheart (2001) fornisce una definizione simile: ``One can still speak of dissociations between two tasks even if performance is impaired on both tasks. If a patient is impaired at both Task A and Task B, but is significantly more impaired on the second task than on the first, that can be treated as a dissociation'' (p.~12).

Nello studio dell'architettura funzionale alla base della cognizione umana, viene dato grande peso alla doppia dissociazione. Per stabilire l'esistenza di una doppia dissociazione occorrono due pazienti che mostrano pattern opposti di funzioni cognitive preservate e compromesse. Come afferma Coltheart (2001) ``With double dissociations we need two patients: patient A who is impaired on Task X but normal on Task Y, and patient B who is normal on Task X but is impaired on Task Y'' (p.~12).

Una singola dissociazione non viene considerata come una prova definitiva della divisione funzionale del sistema cognitivo perché i due compiti coinvolti possono attingere a un singolo processo sottostante ma semplicemente differire nella misura in cui vengono determinati da tale processo; cioè, le singole dissociazioni sono soggette agli artefatti derivanti dalla difficoltà del compito. L'esistenza di una doppia dissociazione, invece, è considerata dalla maggior parte dei ricercatori (ma non da tutti) come prova che esclude la difficoltà del compito come spiegazione alternativa dei risultati.

Molti studi su singoli casi usano più misure dei costrutti in esame (cioè usano misure di prestazione in compiti diversi ma correlati per esaminare i costrutti X e Y). In altre parole, il paziente viene confrontato con i controlli su una serie di compiti. Ciò è in linea con il fatto che i ricercatori sono interessati all'esistenza di una dissociazione tra funzioni, non nella dissociazione tra specifiche coppie di misure indirette e imperfette di queste funzioni. Quindi, i ricercatori cercano prove convergenti del deficit o della dissociazione. Tuttavia, l'integrazione di queste molteplici fonti di informazione è un compito estemamente complesso. Su tale aspetto vi è attualmente poca coerenza tra gli studi e i tentativi esistenti tendono ad essere qualitativi piuttosto che quantitativi. Lo sviluppo e la valutazione di un sistema quantitativo, in base al quale le probabilità di una dissociazione potrebbero essere combinate o aggiornate a seconda delle diverse fasi di uno studio, darebbero un contributo significativo alla disciplina. Per la natura di questo problema, l'approccio basato su metodi statistici bayesiani piuttosto che frequentisti sembra essere la scelta più ovvia.

\begin{exercise}

Concludiamo questa discussione esaminando un caso concreto nel quale è necessario valutare se vi è una dissociazione tra due compiti, nel confronto tra un caso singolo e un piccolo gruppo di confronto. Anche in questo caso viene utilizzato il test \(t\) di Student nella versione di Crawford e Howell (1998). Tale test è implementato nella funzione \texttt{crawford\_dissociation.test()} del pacchetto \texttt{psycho}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{case\_X }\OtherTok{\textless{}{-}} \DecValTok{132}
\NormalTok{case\_Y }\OtherTok{\textless{}{-}} \DecValTok{7}
\NormalTok{controls\_X }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{100}\NormalTok{, }\DecValTok{125}\NormalTok{, }\DecValTok{89}\NormalTok{, }\DecValTok{105}\NormalTok{, }\DecValTok{109}\NormalTok{, }\DecValTok{99}\NormalTok{)}
\NormalTok{controls\_Y }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{7}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{10}\NormalTok{)}

\NormalTok{result }\OtherTok{\textless{}{-}} \FunctionTok{crawford\_dissociation.test}\NormalTok{(}
\NormalTok{  case\_X, case\_Y, controls\_X, controls\_Y}
\NormalTok{)}
\CommentTok{\#\textgreater{} The Crawford{-}Howell (1998) t{-}test suggests no dissociation between test X and test Y (t(5) = 1.62, p p = 0.165). The patient\textquotesingle{}s score on test X is not significantly altered compared to its score on test Y.}
\NormalTok{result}
\CommentTok{\#\textgreater{}       t df      p}
\CommentTok{\#\textgreater{} 1 1.625  5 0.1651}
\end{Highlighting}
\end{Shaded}

\end{exercise}

\hypertarget{la-misura-del-cambiamento}{%
\section{La misura del cambiamento}\label{la-misura-del-cambiamento}}

Un argomento ricorrente nella storia della psicometria è la misurazione del cambiamento. Ad esempio, ci si pone il problema dell'attendibilità della differenza tra due punteggi dei test, ovvero dell'attendibilità della differenza pre-test / post-test. Anche i metodi per studiare il cambiamento di un singolo partecipante sono stati molto discussi. Si possono distinguere studi che valutano le prestazioni di un singolo partecipante in due diversi momenti, oppure studi che esaminano una serie storica con più di due misurazioni.

È importante distinguere tra cambiamenti in un singolo soggetto e cambiamenti nella popolazione. In uno studio sul caso singolo, il neuropsicologo si concentra sul cambiamento di un singolo partecipante, mentre quando si esamina una popolazione di partecipanti il focus è su caratteristiche quali la media e la varianza di una popolazione. Ciò ci conduce ad una distinzione tra diverse interpretazioni che possono essere assegnate al concetto di precisione della misurazione. La teoria classica dei test si basa sul concetto di attendibilità, mentre nei modelli IRT viene usato il concetto di informazione. L'attendibilità è un concetto di precisione della misurazione che dipende dalle proprietà della popolazione. È infatti definita come la correlazione al quadrato dei punteggi osservati nel test e dei punteggi veri in una popolazione di partecipanti (Lord \& Novick, 1968). L'informazione, d'altra parte, è un concetto di precisione indipendente dalla popolazione. In concetto di informazione si applica allo stimatore di massima verosimiglianza del valore del tratto latente in un singolo partecipante. La quantità di informazione sul valore del tratto latente di un singolo partecipante è alta se la varianza del valore del tratto latente stimato nel partecipante è piccola, mentre quantità di informazione è bassa se la varianza del valore del tratto latente è grande. Tale concetti si applica anche alle misure di cambiamento.

Quello che è importante notare è che una bassa attendibilità nel test non implica necessariamente una bassa precisione a livello di misurazione del caso singolo. Questa affermazione è valida nel senso che una bassa attendibilità dipendente dalla popolazione non implica necessariamente una bassa quantità di informazione a livello del singolo partecipante. Se l'attendibilità del test è bassa ma la quantità di informazione a livello del singolo partecipante è alta, allora le affermazioni sul cambiamento a livello della popolazione sono imprecise ma le affermazioni sul cambiamento a livello del partecipante possono essere precise. Questa distinzione tra attendibilità e informazione è importante per la misurazione del cambiamento. Per fare affermazioni sul cambiamento al livello del caso singolo, l'aspetto importante della precisione della misurazione è quello che riguarda la quantità di informazione, non l'attendibilità del test.

Un aspetto finale riguarda i cambiamenti a livello del punteggio totale o a livello dei singoli item. Il punteggio totale del test è uguale alla somma ponderata dei punteggi ai singoli item. La teoria classica dei test considera il punteggio totale osservato del test come una variabile continua, mentre il modello IRT considera il punteggio totale del test come una variabile discreta. Il modello IRT si applica agli item con punteggio dicotomico (0 o 1), in cui il punteggio totale del test è dato dalla somma non ponderata dei punteggi dei singoli item.

Consideriamo ora il caso nel quale lo stesso test viene somministrato ad un singolo partecipante in molteplici occasioni. Poniamoci il problema di misurare il cambiamento dal punto di vista della teoria classica dei test. La teoria classica dei test considera il caso di un punteggio continuo e trae origine da un \emph{Gedankenexperiment} (Lord \& Novick, 1968, sezione 2.2) nel quale si suppone che il test venga somministrato ripetutamente allo stesso rispondente e che i punteggi così osservati siano tra loro indipendenti. Il punteggio vero del rispondente è definito come il valore atteso di questa \emph{propensity distribution} (Lord \& Novick, 1968, sezione 2.3). La varianza di tale \emph{propensity distribution} è specifica per il singolo rispondente e indica la precisione della misurazione per l'individuo considerato; l'inverso di questa varianza è la quantità di informazione (Mellenbergh, 1996). Il modello classico si può estendere al caso di un cambiamento nella risposta del singolo soggetto.

Il test viene somministrato ad un rispondente in diverse occasioni e il punteggio vero del rispondente nella \(i\)-esima occasione è uguale al valore atteso dei punteggi nella \(i\)-esima \emph{propensity distribution}. Si assume che le varianze delle \emph{propensity distribution} del rispondente siano omogenee (vale a dire, si assume una eguale varianza in ciascuna delle occasioni). Inoltre, si assume che i punteggi dei test del rispondente in occasioni consecutive siano distribuiti in modo indipendente le une dalle altre. Si pone dunque il problema di come misurare la varianza dei punteggi in somministrazioni ripetute del test.

Sappiamo che la teoria classica dei test fornisce una risposta a questa domanda nei termini della formula seguente, \[\sigma^2_E = \sigma^2_X (1 - \rho_{XX'}), \notag\] dove \(\sigma^2_X\) e \(\rho_{XX'}\) sono, rispettivamente, la deviazione standard dei punteggi del test nella popolazione e l'attendibilità del test. Una stima dell'errore standard della misurazione \(\sigma^2_E\) si ottiene utilizzando i valori campionari anziché quelli della popolazione riportanti nell'equazione precedente. Uno svantaggio di tale approssimazione è che la stima di \(\sigma^2_E\) risulta essere uguale per ciascun partecipante, mentre quello che in realtà vorremmo conoscere è una stima della variabilità delle misure di uno specifico soggetto.

La teoria classica dei test procede poi valutando il cambiamento (per esempio, post/pre-test) del \(k\)-esimo partecipante nella \(t\)-esima occasione nei termini della seguente equazione:

\[
z_{kt} = \frac{\hat{\gamma}_{kt}}{\hat{\sigma}_E} \sqrt{2}, 
\label{eq:Lord-Novick-1968-7-4}
\]

laddove

\[
\hat{\gamma}_{kt} = x_{kt} - x_{k, t-1}, 
\]

è la differenza dei punteggi osservati per il partecipante \(k\)-esimo in due diverse occasioni.

\begin{exercise}
Consideriamo un esempio basato sui dati di Meyers (1978). Meyers selezionò, da un campione più grande di 500 bambine di 13 anni d'età, un campione di 33 bambine che mostravano segni di ansia sociale. Le bambine selezionate furono assegnate in modo casuale a tre diverse condizioni (lista di attesa e due trattamenti diversi). Al pretest e circa 2 mesi dopo, al post-test, fu somministrato alle bambine un test di ansia sociale. Esaminiamo qui un test statistico relativo al cambiamento dei punteggi di una singola bambina. Per la bambina considerata, il punteggio al pre-test era pari a 8 e il punteggio post-test era uguale a 2, laddove un punteggio più basso indica un livello di ansia sociale minore. Il manuale del test riporta una stima dell'errore standard di misurazione pari a 2.6, nel caso di un campione casuale di 1.039 ragazze. Una stima del cambiamento dal pretest al post test è \(\hat{\gamma}_{kt} = 2 - 8 = -6\). Usando la \eqref{eq:Lord-Novick-1968-7-4} otteniamo così un punteggio pari a

\[
z_{k2} = -6 / 2.6 \sqrt{2} = -1.63,
\]

il quale non ci consente di rigettare l'ipotesi nulla di assenza di cambiamento al livello \(\alpha = 0.05\) con un test monodirezionale.
\end{exercise}

\hypertarget{cambiamento-nel-caso-singolo-e-confronto-con-un-campione-di-controllo}{%
\subsection{Cambiamento nel caso singolo e confronto con un campione di controllo}\label{cambiamento-nel-caso-singolo-e-confronto-con-un-campione-di-controllo}}

Mellenbergh e van den Brink (1998) hanno sviluppato le considerazioni precedenti allo scopo di mettere a punto un test che consenta di valutare il cambiamento nel caso singolo mediante un confronto con un campione di controllo. Tale test è implementato nella funzione \texttt{mellenbergh.test()} contenuto nel pacchetto \texttt{psycho}. Vediamo qui sotto un esempio di applicazione di tale test.

\begin{exercise}

Si consideriano i seguenti dati

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{12345}\NormalTok{)}
\NormalTok{t0 }\OtherTok{\textless{}{-}} \DecValTok{80} \CommentTok{\# The IQ of a patient at baseline}
\NormalTok{t1 }\OtherTok{\textless{}{-}} \DecValTok{100} \CommentTok{\# The IQ of a patient after the therapy}
\NormalTok{controls }\OtherTok{\textless{}{-}} \FunctionTok{round}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(}\DecValTok{20}\NormalTok{, }\DecValTok{100}\NormalTok{, }\DecValTok{15}\NormalTok{))}
\NormalTok{controls}
\CommentTok{\#\textgreater{}  [1] 109 111  98  93 109  73 109  96  96  86  98 127}
\CommentTok{\#\textgreater{} [13] 106 108  89 112  87  95 117 104}
\end{Highlighting}
\end{Shaded}

Il test si svolge come indicato di seguito:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mellenbergh.test}\NormalTok{(t0, t1, }\AttributeTok{controls =}\NormalTok{ controls)}
\CommentTok{\#\textgreater{} The Mellenbergh \& van den Brink (1998) test suggests that the change is not significant (d = 20.00, 90\% CI [{-}9.05, 49.05], z = 1.14, p p = 0.256).}
\end{Highlighting}
\end{Shaded}

\end{exercise}

\hypertarget{considerazioni-conclusive}{%
\section*{Considerazioni conclusive}\label{considerazioni-conclusive}}


Crawford e Garthwaite (2012) esaminano il problema del confronto tra caso singolo e un gruppo di controllo e concludono che solo la soluzione discussa nel \S \ref{sec:Crawford-Howell-1998} e quella equivalente discussa nel \S\ref{sec:barton-2002} sono appropriate per effettuare il confronto. Le altre soluzioni presentate nel \S \ref{sec:comparison-single-case-controls} e molto utilizzate in letteratura, sono inappropriate. Crawford e Garthwaite (2012) concludono che la maggior parte degli studi a caso singolo in neuro-psicologia rivelano una conoscenza sofisticata della teoria cognitiva da parte dei ricercatori. Inoltre, il disegno della ricerca è spesso basato su un'attenta analisi logica delle domande da affrontare e grande attenzione viene prestata allo sviluppo dei compiti sperimentali e dei materiali stimolo. Tuttavia, un'attenzione molto minore viene dedicata ai metodi statistici che vengono impiegati per rispondere alla domanda della ricerca. Secondo Crawford e Garthwaite (2012), è chiaro invece, anche sulla base di una serie di simulazioni Monte Carlo, che i metodi diversi da quello discusso nel \S\ref{sec:Crawford-Howell-1998}, la versione bayesiana equivalente presentata da Crawford e Garthwaite (2007), dovrebbero essere abbandonati perché portano ad un'esagerazione del disturbo. La discussione precedente è stata poi estesa all'analisi statistica dei dati raccolti mediante l'uso di compiti diversi per studiare multicomponenzialità dei processi cognitivi nel caso singolo e lo studio del cambiamento pre-test / post-test nel caso singolo.

\hypertarget{ch:effectiveness}{%
\chapter{La valutazione dell'intervento psicologico}\label{ch:effectiveness}}

La valutazione neuropsicologica dei pazienti che presentano disturbi cognitivi fornisce informazioni cruciali su cui basare la diagnosi e valutare se ci sono stati cambiamenti nelle condizioni di un individuo. Essa costituisce uno degli strumenti che possono essere usati per la valutazione gli effetti di un trattamento.

Ma come si misurano gli effetti di un trattamento psicologico, in generale, o neuropsicologico, in particolare? Consideriamo il caso di un intervento psicologico. La valutazione di un intervento psicologico è molto diversa rispetto alla valutazione sull'effetto dei farmaci, ad esempio, perché c'è un numero quasi infinito di fattori che possono essere esaminati per decidere se un determinato tipo di intervento psicologico ha portato ad un esito positivo, e semplicemente non c'è modo di controllarli tutti. I ricercatori non concordano neppure su cosa debba essere valutato quando si valutano gli effetti di un trattamento. Miglioramento nel benessere soggettivo? Diminuzione dei sintomi? Cambiamento di personalità? Miglioramento nei rapporti interpersonali? Miglioramento nelle capacità lavorative? Crescita personale, realizzazione e miglioramento della persona? Tutti i precedenti?

Molto spesso gli studi sugli effetti del trattamento considerano punteggi medi di misure di esito basate sui sintomi. Questo modo di quantificare l'esito del trattamento non tiene in considerazione il fatto che, in qualunque trattamento, si osserva un cambiamento in alcuni pazienti ma non in altri. Ciò è ulteriormente complicato dai problemi della comorbidità. È possibile infatti che un trattamento possa produrre un esito favorevole rispetto ad alcune dimensioni di un deficit ma, nel contempo, un esito negativo per altre. Anche se la maggior parte degli studi sugli effetti di un trattamento psicologico esamina la riduzione dei sintomi, il fine ultimo del trattamento dovrebbe essere quello di un miglioramento del funzionamento dell'individuo in contesti sociali e del livello di benessere percepito. Ma non è chiaro come ciò possa essere misurato.

\hypertarget{efficacia-dellintervento-ed-efficienza-clinica}{%
\section{Efficacia dell'intervento ed efficienza clinica}\label{efficacia-dellintervento-ed-efficienza-clinica}}

Indipendentemente dal problema di cosa deve essere misurato, è anche necessario chiedersi quali siano le finalità della valutazione. La letteratura psicologica distingue tra efficacia ed efficienza clinica del trattamento, laddove per efficacia (\emph{efficacy}) si intende la capacità del trattamento di produrre un cambiamento, mentre l'efficienza clinica (\emph{effectiveness}) può essere definita ``la capacità di un intervento di produrre gli effetti benefici desiderati nella pratica clinica corrente'' e fa anche riferimento al rapporto costi/benefici dell'intervento. Come descritto da Hunsley (2007), ``Treatment efficacy studies involve methodological efforts to maximize the internal validity of a study. This commonly includes the use of design features, such as random assignment to treatment and control conditions, training of therapists to a specified level of competence in providing the treatment, and ensuring that all participants have the condition that the treatment was designed to address. Treatment effectiveness studies, on the other hand, strive to maximize external validity while maintaining an adequate level of internal validity (without which, of course, no viable conclusions could be drawn about the impact of the treatment). Most commonly, efforts to enhance external validity involve locating the treatment study within clinical service sites that provide ongoing health services, thus using clinicians who are routinely providing psychological services and patients who have been referred to the clinical settings'' (p.~117).

I dati degli studi sull'\emph{efficacy} e sull'\emph{effectiveness} sono fondamentali per una piena comprensione dell'impatto potenziale di un trattamento. Una volta che un trattamento abbia dimostrato la sua \emph{efficacy} attraverso la riproducibilità dei dati di un esperimento, il passo successivo è determinare l'impatto effettivo del trattamento nella pratica clinica. Deve essere infatti dimostrato che i trattamenti esaminati nelle condizioni controllate degli studi di ricerca (studi sull'\emph{efficacy}) possano anche avere un adeguato impatto clinico quando vengono utilizzati nell'effettiva pratica clinica (studi sull'\emph{effectiveness}).

Nel concetto di \emph{effectiveness} si possono individuare quattro componenti: efficacia del trattamento, tollerabilità e sicurezza del trattamento, funzionamento del paziente, accettabilità dell'intervento da parte del paziente. Tutte le componenti interagiscono tra di loro e forniscono informazioni sull'esito di un determinato intervento. Per quanto riguarda l'efficacia del trattamento, le variabili più importanti sono la scomparsa dei sintomi, il tasso di ricadute, la comorbidità. Gli elementi più importanti che incidono sulla tollerabilità e sicurezza del trattamento sono gli effetti collaterali, la sicurezza e la facilità di assunzione della terapia. Il funzionamento del paziente, il terzo dominio, include le normali attività quotidiane e la qualità della vita, elementi che possono essere quantificati e valutati in studi clinici randomizzati o in studi osservazionali. L'accettabilità di un intervento da parte del paziente infine, è il dominio della compliance, ed è strettamente legato alle altre tre componenti.

Sebbene ciascun dominio possa essere quantificabile singolarmente, è anche possibile misurare l'\emph{effectiveness} in maniera globale. Uno strumento che può essere usato a tale scopo è la scala \emph{Clinical Global Impression} (CGI), che rappresenta il modo più semplice per valutare e quantificare, in generale, l'\emph{effectiveness} di un intervento. Inoltre, la scala della \emph{Valutazione Globale del Funzionamento} (GAF) fornisce un punteggio singolo, composito della funzione psicologica, sociale ed occupazionale su un ipotetico continuum che va dal benessere mentale al funzionamento più deficitario causato dalla malattia.

\hypertarget{ch:effect_size}{%
\chapter{La dimensione dell'effetto del trattamento}\label{ch:effect_size}}

I risultati degli studi di ricerca sull'\emph{efficacy} e sull'\emph{effectiveness} degli interventi psicologici usano una metrica comune chiamata \emph{dimensione dell'effetto}. La dimensione dell'effetto può essere calcolata per quasi tutti i tipi di disegni della ricerca e nel caso di quasi tutte le analisi statistiche. Le analisi statistiche basate sui confronti tra gruppi danno luogo a due tipi di indici che misurano la dimensione dell'effetto. Il primo tipo di dimensione dell'effetto riguarda le differenze tra le medie dei gruppi e si calcola nei termini della differenza tra le medie dei gruppi (per esempio gruppi con il trattamento e senza trattamento) divisa per la stima della deviazione standard raggruppata. Tali indici vanno sotto il nome di \(d\), \(g\) o \(\eta^2\).

Il secondo tipo di dimensione dell'effetto comporta un confronto di gruppi in termini degli odds o della probabilità di un risultato. Un \emph{odds ratio} (OR) viene calcolato per determinare l'associazione tra la condizione di gruppo (ad es., trattamento e non trattamento) e una variabile ad esito binario (ad esempio, la presenza o la non insorgenza di un evento, come la ricaduta). Un \emph{rischio relativo} (RR) viene calcolato per confrontare la probabilità che un evento si verifichi in base ai due livelli del fattore di rischio considerato (ad es., trattamento/non trattamento, esposizione/non esposizione ad un fattore di rischio).

Si noti inoltre un punto importante: non è possibile confrontare direttamente la dimensione dell'effetto ottenuta in studi sull'\emph{efficacy} e sull'\emph{effectiveness} del trattamento perché, quasi sempre, tali studi vengono svolti mediante disegni sperimentali molto diversi. Gli studi sull'\emph{efficacy} sono generalmente studi randomizzati controllati nei quali i risultati del trattamento vengono confrontati con i risultati di una condizione di controllo (ad esempio, nessun trattamento o una forma alternativa di trattamento). In questo caso, la dimensione dell'effetto si basa sul cambiamento che può essere attribuito all'effetto causale del trattamento. Pochi studi sull'\emph{effectiveness} del trattamento sono invece studi randomizzati controllati: tali studi consistono tipicamente in un'indagine entro i gruppi -- cioè, in un confronto tra la condizione pre-trattamento e la condizione post-trattamento, senza alcuna condizione di controllo. Di conseguenza, la dimensione dell'effetto ottenuta in questo tipo di indagini è basata su un cambiamento dovuto a cause molteplici: oltre agli effetti del trattamento, ci sono agli effetti dovuti alla maturazione, alla regressione verso la media, alla remissione spontanea dei sintomi dovuta al passaggio di tempo e la reattività delle misure. Pertanto, è probabile che gli studi sull'\emph{efficacy} portino ad una stima della dimensione dell'effetto maggiore rispetto ai valori che tipicamente vengono ottenuti negli studi sull'\emph{effectiveness} del trattamento.

\hypertarget{sec:cont_reponse_eff_size}{%
\section{Risposta continua}\label{sec:cont_reponse_eff_size}}

\hypertarget{indici-d-di-cohen-e-g-di-hedges}{%
\subsection{\texorpdfstring{Indici \(d\) di Cohen e \(g\) di Hedges}{Indici d di Cohen e g di Hedges}}\label{indici-d-di-cohen-e-g-di-hedges}}

Per valutare la dimensione dell'effetto, Cohen (1962, 1988) ha introdotto una misura simile a un punteggio \(z\) in cui una di due medie campionarie viene sottratta dall'altra e il risultato è diviso per la deviazione standard della popolazione:

\begin{equation}
d = \frac{M_A - M_B}{\sigma},
\label{eq:d-cohen}
\end{equation}

laddove \(M_A\) e \(M_B\) sono le due medie campionarie e \(\sigma\) è la media della popolazione.

Hedges (1982) ha proposto una piccola modifica alla @ref(eq:d\_cohen) nella quale la deviazione standard raggruppata sostituisce il parametro ignoto \(\sigma\), ottenendo in questo modo la statistica \(g\):

\begin{equation}
g = \frac{M_A - M_B}{s}.
\label{eq:g-eff-size}
\end{equation}

Al fine di evitare una sistematica sovrastima della dimensione dell'effetto in piccoli campioni, Borenstein, Hedges, Higgins e Rothstein (2009) hanno proposto la seguente correzione:

\begin{equation}
d_{unb} = d \left(1 - \frac{3}{4 \cdot \text{df} - 1} \right).
\label{eq:d-unbiased}
\end{equation}

La correzione è molto piccola quando l'ampiezza campionaria è grande (solo il 3\% per 25 gradi di libertà) ma è sostanziale per piccoli campioni.

\hypertarget{sec:binary_reponse_eff_size}{%
\section{Risposta binaria}\label{sec:binary_reponse_eff_size}}

Supponiamo che la variabile risposta \(Y\) abbia due modalità, convenzionalmente chiamate successo (\(1\)) e insuccesso (\(0\)). Per esempio, un individuo con certi fattori di rischio può ammalarsi oppure no. Supponiamo che le osservazioni siano indipendenti e che \(P(Y=1) = \pi\) e \(P(Y=0) = 1-\pi\). Spesso, ogni unità di osservazione è associata a un vettore (\(X_1, \dots, X_p\)) di variabili esplicative. L'obbiettivo è studiare la relazione tra la probabilità \(P(Y=1)\) e le variabili esplicative. Il caso più semplice si ha quando esiste un solo carattere esplicativo \(X\), con \(I\) modalità sconnesse (un fattore). In tal caso i dati binari sono raggruppati per modalità della variabile esplicativa e le risposte \(Y_1, \dots, Y_I\) sono il \emph{numero di successi} nelle \(n_i\) prove indipendenti dell'\(i\)-esimo gruppo (\(i = 1, \dots, I\)). Se i dati sono raggruppati si possono presentare come una tavola di contingenza \(I \times 2\):

\begin{longtable}[]{@{}lccc@{}}
\toprule
& Successo & Insuccesso & Totale \\
\midrule
\endhead
1 & \(Y_{11}\) & \(Y_{12}\) & \(Y_{1+}\) \\
2 & \(Y_{21}\) & \(Y_{22}\) & \(Y_{2+}\) \\
\(\vdots\) & \(\vdots\) & \(\vdots\) & \(\vdots\) \\
I & \(Y_{I1}\) & \(Y_{I2}\) & \(Y_{I+}\) \\
\bottomrule
\end{longtable}

Nelle applicazioni che considereremo i totali di riga non sono variabili aleatorie, ma costanti fisse per disegno. Pertanto

\begin{longtable}[]{@{}cccc@{}}
\toprule
X & Successo & Insuccesso & Totale \\
\midrule
\endhead
\(x_1\) & \(Y_{1}\) & \(n_1-Y_1\) & \(n_1\) \\
\(x_2\) & \(Y_{2}\) & \(n_2-Y_2\) & \(n_2\) \\
\(\vdots\) & \(\vdots\) & \(\vdots\) & \(\vdots\) \\
\(x_I\) & \(Y_{I}\) & \(n_I-Y_{I}\) & \(n_I\) \\
\bottomrule
\end{longtable}

Le situazioni in cui i totali di riga sono v.a. non saranno qui considerate.

Il caso fondamentale è quello della tavola \(2 \times 2\) in cui vi è una sola variabile esplicativa binaria. Supponiamo che \(X\) sia il trattamento (1: presente; 0: controllo) e \(Y\) sia la risposta (1: successo; 0: insuccesso). La situazione è riassunta nella tavola seguente:

\begin{longtable}[]{@{}lcl@{}}
\toprule
& Risposta & \\
\midrule
\endhead
Trattamento & Successo & Insuccesso \\
Presente & \(\pi_1\) & \(1-\pi_1\) \\
Controllo & \(\pi_2\) & \(1-\pi_2\) \\
\bottomrule
\end{longtable}

dove \(\pi_1\) e \(\pi_2\) sono le probabilità condizionate \(P(Y = \text{successo} \mid X=\text{trattamento presente})\) e \(P(Y = \text{successo} \mid X=\text{controllo})\). Le proporzioni di successi nel campione forniscono delle stime di \(\pi_1\) e \(\pi_2\):

\begin{equation}
\begin{aligned}
\hat{\pi}_1 &= Y_1/n_1,\notag\\
\hat{\pi}_2 & = Y_2/n_2,\notag\end{aligned}
\end{equation}

dove \(Y_i\) è il numero ottenuto di successi ed \(n_i\) è la numerosità delle prove per \(X = x_i\). Per studiare l'\emph{efficacy} del trattamento si calcolano i seguenti indici:

\begin{itemize}
\tightlist
\item
  la \emph{differenza delle probabilità} \(D=\pi_{1} -  \pi_{2}\);
\item
  il \emph{rapporto delle probabilità} \(RR=\pi_{1} / \pi_{2}\), il cosiddetto \emph{rischio relativo};
\item
  il \emph{rapporto delle quote} (odds-ratio) detto anche \emph{rapporto crociato} \(\theta = \frac{\pi_1/(1-\pi_1)}{\pi_2/ (1-\pi_2)}\);
\item
  il \emph{logaritmo del rapporto delle quote} \(\log_e \theta\).
\end{itemize}

\begin{exercise}
Il Physicians' Health Study è stata un'indagine prospettiva svolta per verificare se l'uso regolare di Aspirina riduce la mortalità per malattie cardiovascolari. I partecipanti allo studio (dei medici volontari) venivano assegnati in modo casuale al trattamento (uso regolare di Aspirina, \(n_1=11037\)) o al placebo (\(n_2=11034\)). I soggetti non erano a conoscenza del tipo di trattamento cui erano stati assegnati.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{aspirina }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}
  \FunctionTok{c}\NormalTok{(}\DecValTok{104}\NormalTok{, }\DecValTok{10933}\NormalTok{, }\DecValTok{189}\NormalTok{, }\DecValTok{10845}\NormalTok{),}
  \AttributeTok{nrow =} \DecValTok{2}\NormalTok{,}
  \AttributeTok{byrow =} \ConstantTok{TRUE}
\NormalTok{)}
\FunctionTok{dimnames}\NormalTok{(aspirina) }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}
  \FunctionTok{c}\NormalTok{(}\StringTok{"Aspirina"}\NormalTok{, }\StringTok{"Placebo"}\NormalTok{),}
  \FunctionTok{c}\NormalTok{(}\StringTok{"Si"}\NormalTok{, }\StringTok{"No"}\NormalTok{)}
\NormalTok{)}
\FunctionTok{names}\NormalTok{(}\FunctionTok{dimnames}\NormalTok{(aspirina)) }\OtherTok{\textless{}{-}}
  \FunctionTok{c}\NormalTok{(}\StringTok{"Gruppo"}\NormalTok{, }\StringTok{"Infarto miocardico"}\NormalTok{)}

\NormalTok{aspirina}
\CommentTok{\#\textgreater{}           Infarto miocardico}
\CommentTok{\#\textgreater{} Gruppo      Si    No}
\CommentTok{\#\textgreater{}   Aspirina 104 10933}
\CommentTok{\#\textgreater{}   Placebo  189 10845}
\end{Highlighting}
\end{Shaded}

L'evento chiamato convenzionalmente successo è la presenza di un infarto.

Calcolare la grandezza totale del campione e le proporzioni \(\hat{\pi}_{ij}\) è facile:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tot }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(aspirina)}
\NormalTok{tot}
\CommentTok{\#\textgreater{} [1] 22071}
\NormalTok{aspirina }\SpecialCharTok{/}\NormalTok{ tot}
\CommentTok{\#\textgreater{}           Infarto miocardico}
\CommentTok{\#\textgreater{} Gruppo           Si     No}
\CommentTok{\#\textgreater{}   Aspirina 0.004712 0.4954}
\CommentTok{\#\textgreater{}   Placebo  0.008563 0.4914}
\end{Highlighting}
\end{Shaded}

Le stime delle probabilità condizionate di successo dato \(X\) (proporzioni di riga) si ottengono nel modo seguente:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rowtot }\OtherTok{\textless{}{-}} \FunctionTok{apply}\NormalTok{(aspirina, }\DecValTok{1}\NormalTok{, sum)}
\NormalTok{rowtot}
\CommentTok{\#\textgreater{} Aspirina  Placebo }
\CommentTok{\#\textgreater{}    11037    11034}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rowprop }\OtherTok{\textless{}{-}} \FunctionTok{sweep}\NormalTok{(aspirina, }\DecValTok{1}\NormalTok{, rowtot, }\StringTok{"/"}\NormalTok{)}
\NormalTok{rowprop}
\CommentTok{\#\textgreater{}           Infarto miocardico}
\CommentTok{\#\textgreater{} Gruppo           Si     No}
\CommentTok{\#\textgreater{}   Aspirina 0.009423 0.9906}
\CommentTok{\#\textgreater{}   Placebo  0.017129 0.9829}
\end{Highlighting}
\end{Shaded}

quindi \(\hat{\pi}_1=0.0094\) e \(\hat{\pi}_2=0.0171\).
\end{exercise}

\hypertarget{differenza-tra-due-proporzioni}{%
\subsection{Differenza tra due proporzioni}\label{differenza-tra-due-proporzioni}}

Il modo più semplice per misurare l'effetto del trattamento sulla variabile risposta è la differenza delle probabilità

\[
D =\pi_1 - \pi_2.
\]

La differenza di probabilità assume valori compresi tra \(-1\) e \(1\) ed è nulla se la risposta non dipende da \(X\), cioè se il trattamento non ha effetto.

\begin{exercise}

Per l'esempio dell'aspirina, \(\hat{\pi}_1=104/11037 = 0.0094\) è la proporzione di attacchi di cuore (successi) tra gli individui trattati con aspirina e \(\hat{\pi}_2=189/11034 = 0.0171\) è la proporzione di attacchi di cuore tra gli individui trattati con il placebo. La differenza tra le proporzioni è \(\hat{\pi}_1 - \hat{\pi}_2 = 0.0094 - 0.0171 = -0.0077\). L'errore standard stimato della differenza tra le proporzioni è

\[
\sqrt{\frac{\hat{\pi}_1(1-\hat{\pi}_1)}{n_1} +
\frac{\hat{\pi}_2(1-\hat{\pi}_2)}{n_2}} = 0.0015.
\]

Un intervallo di confidenza al 95\% per la differenza tra le proporzioni è \(-0.0077 \pm 1.96(0.0015)\) cioè (\(-0.011, -0.005\)). Poiché l'intervallo contiene solo valori negativi si conclude che \(\pi_1 < \pi_2\), per cui il trattamento con aspirina appare ridurre la probabilità di infarto.

Il risultato precedente si ottiene con nel modo seguente:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p1 }\OtherTok{\textless{}{-}} \DecValTok{104} \SpecialCharTok{/} \DecValTok{11037}
\NormalTok{p2 }\OtherTok{\textless{}{-}} \DecValTok{189} \SpecialCharTok{/} \DecValTok{11034}
\NormalTok{n1 }\OtherTok{\textless{}{-}} \DecValTok{11037}
\NormalTok{n2 }\OtherTok{\textless{}{-}} \DecValTok{11034}
\NormalTok{se }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{((p1 }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ p1) }\SpecialCharTok{/}\NormalTok{ n1) }\SpecialCharTok{+}\NormalTok{ (p2 }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ p2) }\SpecialCharTok{/}\NormalTok{ n2))}
\NormalTok{se}
\CommentTok{\#\textgreater{} [1] 0.00154}
\NormalTok{p1 }\SpecialCharTok{{-}}\NormalTok{ p2 }\SpecialCharTok{+} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{) }\SpecialCharTok{*} \FunctionTok{qnorm}\NormalTok{(}\FloatTok{0.975}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ se}
\CommentTok{\#\textgreater{} [1] {-}0.010724 {-}0.004688}
\end{Highlighting}
\end{Shaded}

\end{exercise}

\hypertarget{rischio-relativo}{%
\subsection{Rischio relativo}\label{rischio-relativo}}

La differenza tra due proporzioni può rivestire un'importanza maggiore quando entrambe le proporzioni sono vicine a 0 o a 1 che quando esse sono vicine a 0.5. Per esempio, in uno studio che confronta la mortalità associata a due trattamenti, la differenza \(0.010 - 0.001 = 0.009\) può essere più importante della differenza tra \(0.410 - 0.401 = 0.009\). Infatti, la prima differenza coinvolge due proporzioni che stanno in rapporto di 10 a 1, mentre la seconda riguarda due proporzioni quasi uguali. Quindi la prima differenza appare di maggiore rilevanza. Nelle situazioni precedenti è utile calcolare il rischio relativo, cioè il rapporto \[RR = \frac{\pi_1}{\pi_2}.\] Il \(RR\) è sempre un numero non negativo. Se è uguale a 1 la risposta non dipende da \(X\).

\begin{exercise}
Per le proporzioni precedenti, il rischio relativo è \(0.010/0.001=10.0\) e \(0.410/0.401=1.02\). Nell'esempio dell'aspirina il \(RR\) campionario è

\[
0.0171/0.0094 = 1.82.
\]

Quindi la proporzione campionaria di casi di infarto è più grande dell'82\% per il gruppo dei trattati col placebo.
\end{exercise}

\hypertarget{odds-ratio}{%
\subsection{Odds ratio}\label{odds-ratio}}

Invece del \(RR\) si può misurare la dipendenza delle probabilità dal trattamento con il rapporto tra le \emph{quote di scommessa} (gli odds). Gli odds di successo \(\omega\) sono per definizione il rapporto tra la probabilità di successo (\(\pi\)) e la probabilità di insuccesso (\(1 - \pi\)):

\[
\omega = \frac{\pi}{1 - \pi}.
\]

La quota di scommessa \(\omega\) è un indice non negativo che misura quanti successi ci si attendono per ogni insuccesso. Nel campo delle scommesse quando la quota dell'evento \(Y = 1\) contro \(Y = 0\) è \(\omega\), scomettendo su \(Y = 0\) si vince \(\omega\) volte la posta. Per esempio, se \(\pi = 0.75\) la quota è \(\omega = 0.75/0.25 = 3\); scommettendo su \(Y = 0\) si riceve, in caso di vincita, 3 volte la posta. Se la quota è minore di \(1\), si può calcolare il reciproco (\(1/\omega\)) e interpretare il risultato come riferito all'evento complementare. Per esempio, se \(\omega\) è \(0.3333\), uno si aspetta \(0.3333\) successi per ogni insuccesso ossia \(1/0.3333=3\) insuccessi per ogni successo. La relazione inversa tra probabilità di successo e odds è \(\pi =\frac{\omega}{1 + \omega}.\) Per esempio, se \(\omega =3\), la probabilità di successo sarà \(\pi = \frac{3}{1 + 3}\) uguale a 0.75.

\begin{exercise}
Nell'esempio dell'aspirina l'odds di infarto per il gruppo aspirina è

\[
\omega_1 = 104/10933 = 0.0095
\]

e per il gruppo placebo è

\[
\omega_2 = 189/10845 = 0.0174.
\]

Dato l'odds \(\omega_1 = 0.0095\), la probabilità di infarto per il gruppo aspirina è

\[
\pi_1 =\frac{\omega_1}{1 + \omega_1} = \frac{0.0095}{1 + 0.0095}= 0.0094
\]

ovvero \[\pi_1 = \frac{104}{104+10933}= 0.0094.\]
\end{exercise}

\hypertarget{logit}{%
\subsection{Logit}\label{logit}}

Il logaritmo della quota (\(\phi\)) o \emph{logit} definito da

\[
\phi = \log_e \omega = \log_e \frac{\pi}{1 - \pi} = \ln (\pi) - \ln (1-\pi)
\]

trasforma la probabilità \(\pi \in (0, 1)\) in un numero \(\phi \in \Re\). Il logit è simmetrico attorno allo 0 ed è privo di limite superiore e inferiore.

Per esempio, se \(\pi = 0.75\) la quota è \(\omega = 0.75/0.25 = 3\). Il logaritmo della quota (logit) è \(\log_e 3 = 1.0986.\) Vediamo di seguito alcuni valori rappresentativi che illustrano la realzione tra \(\pi\) e \(\phi\):

\begin{longtable}[]{@{}clc@{}}
\toprule
\endhead
Probabilità & Odds & logit \\
\(\pi\) & \(\omega= \frac{\pi}{1-\pi}\) & \(\phi = \ln \frac{\pi}{1-\pi}\) \\
0.01 & 1/99=0.0101 & -4.60 \\
0.05 & 5/95=0.0526 & -2.94 \\
0.10 & 1/9=0.1111 & -2.20 \\
0.30 & 3/7=0.4286 & -0.85 \\
0.50 & 5/5=1 & 0.00 \\
0.70 & 7/3 = 2.333 & 0.85 \\
0.90 & 9/1 = 9 & 2.20 \\
0.95 & 95/5 = 19 & 2.94 \\
0.99 & 99/1 = 99 & 4.60 \\
\bottomrule
\end{longtable}

La trasformazione inversa del logit è

\[
\pi = \frac{e^{\phi}}{1+e^{\phi}},
\]

dove \(e \simeq 2.718\).

A un logit \(\phi = 1.0986\), per esempio, corrisponde una probabilità

\[\
pi = \frac{e^{\phi}}{1+e^{\phi}}=\frac{e^{1.0986}}{1+e^{1.0986}}=0.75
\]

uguale a 0.75.

Si noti che il logit della probabilità complementare \(1 -\pi = 0.25\) è -1.0986, cioè l'opposto. Se \(\pi = 0.25\) la quota è \(\omega = 0.25/0.75 = 0.3333\). Il logit di \(\pi = 0.25\) è

\[
\log_e (0.25/0.75) = \log_e 0.3333 = -1.0986.
\]

La distribuzione campionaria della proporzione \(\hat{\pi}\) è esattamente una Binomiale. Asintoticamente, è normale con media \(\pi\) e varianza asintotica stimata \(\hat{\pi}(1 - \hat{\pi})/n\). Lo stimatore del logit ha una distribuzione asintotica normale con media \(\pi/(1 -\pi)\) e varianza asintotica stimata \(1/(n \hat{\pi}(1 - \hat{\pi}))\).

\begin{exercise}
Per il campione di 11037 volontari sottoposti al trattamento aspirina la probabilità stimata di infarto miocardico è

\[
\hat{\pi} = 104/11037 = 0.0094
\]

Il logit empirico è

\[
ln \left( \frac{0.0094}{1- 0.0094} \right) =-4.655
\]

con errore standard asintotico

\[
\sqrt{\frac{1}{11037 \times 0.0094 \times (1-0.0094)}}= 0.0985.
\]
\end{exercise}

\hypertarget{rapporto-delle-quote}{%
\subsection{Rapporto delle quote}\label{rapporto-delle-quote}}

Una volta chiarito il concetto di odds, consideriamo ora il \emph{rapporto delle quote} (\emph{odds-ratio}) detto anche \emph{rapporto crociato} (\emph{cross-product ratio}). In una tabella \(2 \times 2\) gli odds di successo nella riga \(i\)-esima sono \(\omega_i = \pi_i / (1-\pi_i)\). Il rapporto degli odds \(\omega_1\) e \(\omega_2\) nelle due righe

\[
\theta = \frac{\omega_1}{\omega_2}=\frac{\pi_1 / (1-\pi_1)}{\pi_2 / (1-\pi_2)}
\]

è chiamato rapporto delle quote.

Un rapporto delle quote può assumere solo valori non negativi. Se è uguale a 1 gli odds sono uguali e quindi sono uguali anche le probabilità, cioè la risposta è indipendente dal trattamento. I rapporti degli odds si valutano in rapporto a 1:

\begin{itemize}
\tightlist
\item
  se \(1 < \theta < \infty\) gli odds sono più grandi nel gruppo 1 che nel gruppo 2, e quindi anche \(\pi_1 > \pi_2\);
\item
  se \(0 < \theta < 1\) gli odds sono più piccoli nel gruppo 1 che nel gruppo 2 e \(\pi_1 < \pi_2\).
\end{itemize}

Il rapporto degli odds non cambia se si permutano la variabile risposta e la variabile esplicativa; quindi \(\theta\) tratta le variabili in modo simmetrico.

\begin{exercise}
Nell'esempio dell'aspirina il rapporto degli odds stimato è

\[
\hat{\theta} = \frac{189/10845}{104/10933}= 1.832,
\]

cioè gli odds a favore dell'infarto sono più grandi dell'83\% per il gruppo placebo. Un rapporto degli odds di \(1.832\) non significa che \(\pi_2\) è 1.832 volte \(\pi_1\), ma che gli odds \(\pi_2/(1 - \pi_2)\) sono 1.832 volte gli odds \(\pi_1/(1 - \pi_1)\). Tuttavia,

\[
\theta = RR \frac{1-\pi_1}{1-\pi_2}.
\] Perciò quando la proporzione di successi è prossima a zero in entrambi i gruppi \(\theta\) e il RR hanno valori simili. Si osservi infatti che il RR nell'esempio dell'aspirina è 1.83.
\end{exercise}

\hypertarget{logaritmo-del-rapporto-delle-quote}{%
\subsection{Logaritmo del rapporto delle quote}\label{logaritmo-del-rapporto-delle-quote}}

La distribuzione del rapporto degli odds è molto asimmetrica ed è conveniente usare la distribuzione del suo logaritmo \(\log_e \theta\). Tale distribuzione è meno asimmetrica e più vicina alla normalità. Il logaritmo di \(\theta\) è 0 in caso di indipendenza e l'interpretazione è simmetrica rispetto allo zero. Cioè se si invertono le righe o le colonne della tavola \(\log_e \theta\) cambia il segno. Due valori di \(\log_e \theta\) diversi solo per il segno rappresentano due livelli di associazione uguali. Raddoppiando \(\log_e \theta\) corrisponde ad elevare al quadrato il rapporto delle quote.

L'errore standard asintotico del logaritmo del rapporto degli odds ha una formula semplice

\[
\sqrt{\frac{1}{Y_{11}} + \frac{1}{Y_{12}} + \frac{1}{Y_{21}} +
\frac{1}{Y_{22}}},
\]

dove \(Y_{ij}\) sono le frequenze nelle celle della tavola di contingenza.

Un intervallo di confidenza al 95\% per \(\ln \theta\) è dato dalla stima \(\ln \hat{\theta} \pm 1.96\) l'errore standard stimato. Per ottenere l'intervallo di confidenza al 95\% per l'odds ratio esponenziamo i limiti \(L\) dell'intervallo di confidenza: \(e^L\).

\begin{exercise}
Nell'esempio dell'aspirina il rapporto degli odds è

\[
\hat{\theta} = \frac{189/10845}{104/10933}= 1.832
\]

e il logaritmo del rapporto degli odds è

\[
\log_e 1.832 = 0.605.
\]

Il logaritmo del rapporto delle quote ha la seguente proprietà: se invertiamo l'ordine delle categorie di una delle variabili, il logaritmo del rapporto delle quote cambia semplicemente di segno:

\[
\hat{\theta} = \frac{104/10933}{189/10845}= 0.5458
\]

e quindi

\[
\log_e 0.5458 = -0.605.
\]

L'errore standard stimato del logaritmo dell'odds ratio è

\[
\sqrt{\frac{1}{189} + \frac{1}{10845} + \frac{1}{104} + \frac{1}{10933}} = 0.1228.
\]

Un intervallo di confidenza al 95\% per \(\log_e \theta\) è

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{se }\OtherTok{\textless{}{-}} \FloatTok{0.1228}
\FloatTok{0.6054377} \SpecialCharTok{+} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{) }\SpecialCharTok{*} \FloatTok{1.96} \SpecialCharTok{*}\NormalTok{ se}
\CommentTok{\#\textgreater{} [1] 0.3647 0.8461}
\end{Highlighting}
\end{Shaded}

e il corrispondente intervallo di confidenza per \(\theta\) è

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{exp}\NormalTok{(}\FloatTok{0.8462073}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 2.331}
\FunctionTok{exp}\NormalTok{(}\FloatTok{0.3646681}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 1.44}
\end{Highlighting}
\end{Shaded}

Poiché non contiene il valore 1, i veri valori degli odds per il gruppo placebo e per il gruppo aspirina sono significativamente diversi: gli odds per l'infarto sono almeno il 44\% in più rispetto al gruppo aspirina.
\end{exercise}

\hypertarget{tipi-fondamentali-di-indagine}{%
\section{Tipi fondamentali di indagine}\label{tipi-fondamentali-di-indagine}}

Si distinguono due tipi fondamentali di indagine: gli esperimenti e gli studi osservazionali. Negli esperimenti si studia l'effetto di uno o più trattamenti sulle risposte delle unità sperimentali. Negli esperimenti randomizzati ogni unità sperimentale viene assegnata casualmente dal ricercatore a una delle possibili modalità di trattamento. L'iportanza della randomizzazione consiste nel produrre dei sottogruppi a seconda dei livelli del trattamento, in cui tutte le altre variabili, anche quelle non misurate, hanno approssimativamente la stessa distribuzione e quindi sono comparabili.

Negli studi osservazionali invece il ricercatore non può assegnare le unità ai trattamenti. Le indagini osservazionali si possono distinguere in studi longitudinali prospettici, trasversali (cross-sectional) e caso-controllo.

\hypertarget{studi-prospettici}{%
\subsection{Studi prospettici}\label{studi-prospettici}}

In un studio prospettico viene seguito un numero fisso di unità per ciascuna modalità della variabile esplicativa (\(X = x_1, \dots, X = x_I\)) e dopo un periodo prefissato si rilevano le proporzioni di successi negli \(I\) gruppi.

\begin{exercise}
Il Physicians' Health Study è stata un'indagine prospettica svolta per verificare se l'uso regolare di Aspirina riduce la mortalità per malattie cardiovascolari. I partecipanti allo studio (dei medici volontari) venivano assegnati in modo casuale al trattamento (uso regolare di Aspirina, \(n_1=11037\)) o al placebo (\(n_2=11034\)). Per cinque anni, i medici che parteciparono allo studio assunsero giornalmente una pastiglia di aspirina o un placebo. Alla fine dello studio l'incidenza di infarti miocardici venne misurata nei due gruppi.
\end{exercise}

\hypertarget{studi-trasversali}{%
\subsection{Studi trasversali}\label{studi-trasversali}}

Se si estrae un campione ad un tempo prefissato e si classificano le unità nella tabella \(I \times 2\) a seconda delle modalità dei due caratteri si ha uno studio trasversale.

\begin{exercise}
Sulla base del General Social Survey (1984), 901 individui sono stati classificati in base alla soddisfazione lavorativa (soddisfatto verso insoddisfatto) e a due categorie di reddito (\(< \$ 15.000, \geq \$ 15.000\)).

\begin{longtable}[]{@{}lcc@{}}
\toprule
& Soddisfatto & Insoddisfatto \\
\midrule
\endhead
\(< \$ 15.000\) & 391 & 104 \\
\(\geq \$ 15.000\) & 340 & 66 \\
\bottomrule
\end{longtable}

Ci si chiede: la soddisfazione lavorativa dipende dal reddito?
\end{exercise}

\hypertarget{studi-longitudinali-retrospettivi}{%
\subsection{Studi longitudinali retrospettivi}\label{studi-longitudinali-retrospettivi}}

Se si estraggono due campioni per \(Y = 0\) e \(Y = 1\) e si controlla nel passato se i soggetti appartengono al gruppo \(x_1, x_2, \dots, x_I\) allora si ha un studio retrospettivo. Un esempio tipico di indagine basata su un disegno retrospettivo è lo studio caso-controllo. Si considerino i dati seguenti:

\begin{longtable}[]{@{}lcl@{}}
\toprule
& Cancro ai polmoni & \\
\midrule
\endhead
Mai fumato? & Casi & Controlli \\
Sı̀ & 688 & 650 \\
No & 21 & 59 \\
Totale & 709 & 709 \\
\bottomrule
\end{longtable}

La prima colonna si riferisce a \(709\) pazienti ricoverati in 20 ospedali londinesi per cancro polmonare. Ogni caso è stato appaiato a un controllo, cioè a un paziente ricoverato nello stesso ospedale per disturbi diversi dal cancro polomonare. Casi e controlli sono stati classificati poi a seconda che siano o siano stati fumatori oppure no.

Sarebbe naturale considerare il cancro polmonare come variabile risposta e il comportamento relativo al fumo quale variabile esplicativa, e confrontare le proporzioni di cancro polmonare tra fumatori e non fumatori, \(P(cancro \mid fumo)\). In questo studio, tuttavia, questo non ha senso dato che la distribuzione marginale della variabile risposta è fissa per disegno.

\begin{itemize}
\tightlist
\item
  Nello studio Aspirina erano i totali di riga a essere fissi -- avevamo cioè un campione indipendente per ciascuna modalità della variabile esplicativa.
\item
  Nel caso presente, invece, sono i totali di colonna ad essere fissi -- ovvero, abbiamo un campione indipendente per ciascuna modalità della variabile risposta.
\end{itemize}

Invece è sensato usare le proporzioni nell'altro verso, cioè \(688/709 = 0.970\) e \(650/709=0.917\) come stime delle probabilità \(P(X = fumatore \mid Y = caso)\) e \(P(X = fumatore \mid Y = controllo)\). Se conoscessimo la proporzione di individui nella popolazione con cancro polmonare, potremmo stimare \(P(Y = \text{cancro polmonare} \mid X = \text{fumatore})\) e \(P(Y = \text{non cancro polmonare} \mid X = \text{fumatore})\). Ponendo \(C\) = cancro e \(F\) = fumatore, con Bayes avremo

\[
P(C \mid F)=\frac{P(C)P(F \mid C)}{P(C)P(F \mid C) + P(C^c)P(F \mid C^c)}.
\] Non possiamo però procedere in questo modo, dato che la probabilità \(P(C)\) è ignota. Con questo disegno, inoltre, dalle probabilità \(P( X = \text{fumatore} \mid Y = \text{cancro polmonare})\) e \(P(X = \text{fumatore} \mid Y = \text{non cancro polmonare})\) non è neppure possibile calcolare il rischio relativo per la risposta \(Y\).

Possiamo però stimare il rapporto degli odds

\[
\frac{(688/709)/(21/709)}{(650/709)/(59/709)}=\frac{688 \times
59}{650 \times 21}=  2.97
\] e utilizzarlo per l'interpretazione di interesse (anche se lo studio è retrospettivo): gli odds per il cancro polmonare sono circa 3 volte più grandi tra i fumatori.

Se le probabilità condizionate di \(Y = \text{cancro polmonare}\) dato \(X = \text{fumatore}\) e \(X = \text{non fumatore}\) sono vicine a zero, il \(RR\) ha un valore simile a quello di \(\theta\). Nell'esempio possiamo attenderci che tali probabilità siano piccole e quindi possiamo considerare il rapporto degli odds come un indicatore grezzo del \(RR\). Possiamo perciò concludere dicendo che la frequenza relativa del cancro polmonare è circa 3 volte più grande per gli individui che hanno fumato rispetto a quelli che non hanno mai fumato.

Un intervallo di confidenza si calcola come indicato in precedenza.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{se }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(}\DecValTok{1} \SpecialCharTok{/} \DecValTok{688} \SpecialCharTok{+} \DecValTok{1} \SpecialCharTok{/} \DecValTok{650} \SpecialCharTok{+} \DecValTok{1} \SpecialCharTok{/} \DecValTok{21} \SpecialCharTok{+} \DecValTok{1} \SpecialCharTok{/} \DecValTok{59}\NormalTok{)}
\NormalTok{se}
\CommentTok{\#\textgreater{} [1] 0.2599}
\NormalTok{theta }\OtherTok{\textless{}{-}}\NormalTok{ (}\DecValTok{688} \SpecialCharTok{*} \DecValTok{59}\NormalTok{) }\SpecialCharTok{/}\NormalTok{ (}\DecValTok{650} \SpecialCharTok{*} \DecValTok{21}\NormalTok{)}
\NormalTok{theta}
\CommentTok{\#\textgreater{} [1] 2.974}
\FunctionTok{log}\NormalTok{(theta)}
\CommentTok{\#\textgreater{} [1] 1.09}
\FunctionTok{log}\NormalTok{(theta) }\SpecialCharTok{+} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{) }\SpecialCharTok{*} \FloatTok{1.96} \SpecialCharTok{*}\NormalTok{ se}
\CommentTok{\#\textgreater{} [1] 0.5804 1.5993}
\FunctionTok{exp}\NormalTok{(}\FloatTok{0.5803817}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 1.787}
\FunctionTok{exp}\NormalTok{(}\FloatTok{1.5992813}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 4.949}
\end{Highlighting}
\end{Shaded}

Poiché non contiene il valore 1, i veri valori degli odds per il gruppo fumatori e per il gruppo non fumatori sono significativamente diversi: gli odds per il cancro ai polmoni sono almeno il 78\% in più rispetto al gruppo non fumatori.

\hypertarget{considerazioni-conclusive-1}{%
\section*{Considerazioni conclusive}\label{considerazioni-conclusive-1}}


Nel caso di una variabile risposta binaria e una variabile esplicativa con due sole modalità i dati si possono rappresentare in una tavola di contingenza \(2 \times 2\). Negli studi sperimentali l'efficacia del trattamento si può stabilire calcolando la differenza tra le proporzioni, il rapporto tra le proporzioni, il rapporto tra le quote e il logaritmo del rapporto tra le quote. I dati raccolti mediante un esperimento e mediante un'indagine osservazionale prospettico o trasversale hanno la stessa struttura. Le differenze nella risposta possono dunque essere analizzate mediante gli stessi indici descritti in precedenza. Negli studi osservazionali, però, le conclusioni sono molto meno stringenti. Nell'esperimento i gruppi sono in tutto confrontabili tranne per la modalità del trattamento e quindi eventuali differenze nella risposta non possono essere dovute ad altro che al trattamento. Negli studi osservazionali, invece, la mancanza di controllo sull'assegnazione dei trattamenti fa sì che i gruppi di unità non siano mai totalmente comparabili. Negli studi retrospettivi, come ad esempio i disegni caso-controllo, non ha senso calcolare la differenza tra le proporzioni condizionate alla variabile esplicativa e il rischio relativo. Possiamo però calcolare il rapporto tra le quote e, per la proprietà simmetrica di questo indice (\(\theta\) non cambia se vengono invertite la variabile sulle righe e quella sulle colonne), procedere poi all'interpretazione nella direzione di interesse. Dato che il logaritmo dell'odds ratio ha una distribuzione asintotica normale, un intervallo di confidenza per \(\ln \theta\) può essere facilmente calcolato. Esponenziando i limiti dell'intervallo di confidenza per \(\ln \theta\) si trovano i limiti dell'intervallo di confidenza per \(\theta\).

\hypertarget{ch:lin-alg}{%
\chapter{Elementi di algebra lineare}\label{ch:lin-alg}}

Un aspetto che rende difficile la comprensione dell'analisi fattoriale è il fatto che l'analisi fattoriale sia una tecnica di analisi multivariata e, come tutte le tecniche di analisi multivariata, richiede la comprensione di almeno alcuni concetti di base dell'algebra lineare. A livello minimale è necessario capire che cosa sono i vettori e le matrici, che cosa è il determinante di una matrice, e in che modo possano essere eseguite le operazioni algebriche su vettori e matrici. Questo capitolo si pone l'obiettivo di chiarire le nozioni elencate sopra.

\hypertarget{vettori}{%
\section{Vettori}\label{vettori}}

\hypertarget{vettori-nello-spazio-euclideo}{%
\subsection{Vettori nello spazio euclideo}\label{vettori-nello-spazio-euclideo}}

Un vettore geometrico è un segmento orientato dotato di una lunghezza, una direzione e un verso. Spesso viene rappresentato con una freccia. Dato che i vettori non hanno posizione (ma solo direzione, verso e intensità), sono possibili rappresentazioni multiple dello stesso vettore. Nella discussione seguente, considereremo soltanto vettori che hanno origine nel punto (0, 0). Questo verr\{`a\} chiarito dall'esempio seguente. La posizione di un punto nel piano pu\{`o\} essere espressa nei termini di una coppia ordinata di numeri (\(x, y\)), le coordinate di quel punto. Tale coppia di valori rappresenta la distanza verticale dal punto a ciascuno degli assi coordinati.

Possiamo anche definire il punto \(P\) specificando la distanza e la direzione di \(P\) dall'origine, ovvero nei termini del vettore \(\overrightarrow{OP}\). A sua volta, questo vettore può essere espresso nei termini delle sue componenti nelle direzioni orizzontali e verticali:

\[
\overrightarrow{OP} = \left[ \begin{array}{c}
2\\
3
\end{array}
 \right]
\]

Se volessimo specificare un punto in uno spazio a 3 dimensioni, avremmo:

\[
\overrightarrow{OP} = \left[ \begin{array}{c}
x\\
y\\
z
\end{array}
\right]
\]

In generale, un punto \(P\) in uno spazio a \(n\)-dimensioni sarà specificato da:

\[\overrightarrow{OP} = \left[ \begin{array}{c}
v_1\\
v_2\\
\dots\\
v_n
\end{array}
 \right]\]

Dal punto di vista geometrico, dunque, un vettore rappresenta un punto in uno spazio \(n\)-dimensionale.

\hypertarget{somma-e-differenza-di-vettori}{%
\subsection{Somma e differenza di vettori}\label{somma-e-differenza-di-vettori}}

La somma di due vettori è definita come

\[(a_1, a_2) + (b_1, b_2) = (a_1 + b_1, a_2 + b_2).\]

La differenza di due vettori è

\[(a_1, a_2) - (b_1, b_2) = (a_1 - b_1, b_2 - b_2).\]

\hypertarget{moltiplicazione-scalare}{%
\subsection{Moltiplicazione scalare}\label{moltiplicazione-scalare}}

La moltiplicazione scalare di un vettore per un numero reale (o scalare) è data da

\[
\rho (a_1, a_2) = (\rho a_1, \rho a_2)
\]

Dal punto di vista geometrico, la moltiplicazione scalare effettua una estensione o contrazione del vettore \(\boldsymbol{a}\), preservandone la direzione.

\hypertarget{combinazione-lineare}{%
\subsection{Combinazione lineare}\label{combinazione-lineare}}

Dati due scalari \(\rho_1\) e \(\rho_2\) e due vettori \(\boldsymbol{a}\), \(\boldsymbol{b}\),

\[
\rho_1 \boldsymbol{a}_1 + \rho_2 \boldsymbol{a}_2
\]

rappresenta la combinazione lineare dei vettori \(\boldsymbol{a}\) e \(\boldsymbol{b}\) con coefficienti \(\rho_1\) e \(\rho_2\). Dati due vettori \(\boldsymbol{a}\) e \(\boldsymbol{b}\) di dimensione \(n\) definiamo il loro prodotto scalare come la somma dei prodotti degli elementi che occupano la stessa posizione:

\[(a_1, a_2) \cdot (b_1, b_2) = a_1 b_1 + a_2 b_2,\]

\[\boldsymbol{a}'\boldsymbol{b} = \sum_{i=1}^{n}a_i b_i.\]

\hypertarget{ortogonalituxe0-tra-vettori}{%
\subsection{Ortogonalità tra vettori}\label{ortogonalituxe0-tra-vettori}}

Due vettori si dicono ortogonali, e si scrive \(\boldsymbol{a} \bot \boldsymbol{b}\), se e solo se il loro prodotto scalare è nullo:

\[\boldsymbol{a}'\boldsymbol{b} = 0.\]

\hypertarget{norma-o-lunghezza-di-un-vettore}{%
\subsection{Norma o lunghezza di un vettore}\label{norma-o-lunghezza-di-un-vettore}}

Per il teorema di Pitagora, la norma di un vettore \((a_1, a_2)\) è \(\sqrt{a_1^2 + a_2^2}\) ed è denotata da \(\| (a_1, a_2) \|\). Infatti, se un vettore \(\boldsymbol{a}\) (l'ipotenusa) è la somma di due vettori ortogonali \(\boldsymbol{a}_1\) e \(\boldsymbol{a}_2\) (i cateti), allora la lunghezza al quadrato di \(\boldsymbol{a}\) è uguale alla somma dei quadrati delle lunghezze di \(\boldsymbol{a}_1\) e \(\boldsymbol{a}_2\).

Viene detta norma di \(\boldsymbol{a}\) la radice del prodotto scalare di un vettore per se stesso:

\[\| \boldsymbol{a} \| = \sqrt{\boldsymbol{a}'\boldsymbol{a}}.\]

\hypertarget{matrici}{%
\section{Matrici}\label{matrici}}

Una matrice costituisce un insieme rettangolare di scalari ordinati per riga e colonna. Può anche essere vista come la raccolta di \(m\) vettori colonna di dimensione \(n\) o come la raccolta di \(n\) vettori riga di dimensione \(m\). Per esempio:

\[\boldsymbol{A} =  \left[ \begin{array}{c c c}
a_{11} & a_{12} & a_{13}\\
a_{21} & a_{22} & a_{23} \end{array} \right]\]

\hypertarget{dimensioni-della-matrice}{%
\subsection{Dimensioni della matrice}\label{dimensioni-della-matrice}}

I numeri interi \(m\) ed \(n\) si dicono dimensioni della matrice, ovvero \(\boldsymbol{A}\) si dice matrice di dimensioni \(m \times n\) o di ordine \(m \times n\). Nel caso presente, la matrice \(\boldsymbol{A}\) ha dimensioni \(2 \times 3\).

\hypertarget{matrice-quadrata-o-rettangolare}{%
\subsection{Matrice quadrata o rettangolare}\label{matrice-quadrata-o-rettangolare}}

Se \(m = n\) allora la matrice \(\boldsymbol{A}\) si dice quadrata di dimensione \(n\) o di ordine \(n\) altrimenti si dice rettangolare. Le righe di \(\boldsymbol{A}\) sono \([a_{11}\
a_{12}\ a_{13}]\) e \([a_{21}\ a_{22}\ a_{23}]\). Le colonne di \(\boldsymbol{A}\) sono \(\left[ \begin{array}{c} a_{11} \\ a_{21} \end{array} \right]\), \(\left[ \begin{array}{c} a_{12} \\ a_{22} \end{array} \right]\) e \(\left[ \begin{array}{c} a_{13} \\ a_{23} \end{array} \right]\).

\hypertarget{diagonale-principale}{%
\subsection{Diagonale principale}\label{diagonale-principale}}

Se \(i\) e \(j\) sono numeri interi con \(1 \leq i \leq m\) e \(1 \leq j \leq n\) allora l'elemento della matrice \(\boldsymbol{A}\) di dimensione \(m \times n\) che si trova in posizione (\(i, j\)) viene indicato con \(a_{ij}\). Gli elementi \(a_{ij}\) di una matrice quadrata \(\boldsymbol{A}\) di ordine \(n\) tali che \(i = j\) sono detti elementi principali o diagonali e formano la cosiddetta \emph{diagonale principale} di \(\boldsymbol{A}\).

\[\boldsymbol{A} =  \left[ \begin{array}{c c c}
a_{11} & a_{12} & a_{13}\\
a_{21} &  a_{22} & a_{23}\\
a_{31} & a_{32} & a_{33} \end{array} \right]\]

\hypertarget{matrice-diagonale}{%
\subsection{Matrice diagonale}\label{matrice-diagonale}}

Se gli elementi \(a_{ij}\) di una matrice quadrata \(\boldsymbol{A}\) sono tali che \(a_{ij} =0\) e \(a_{ii} \neq 0\), allora la matrice \(\boldsymbol{A}\) viene detta \emph{matrice diagonale}.

\[\boldsymbol{A} =  \left[ \begin{array}{c c c}
a_{11} & 0 & 0\\
0 & a_{22} & 0\\
0 & 0 & a_{33} \end{array} \right]\]

\hypertarget{matrice-identituxe0}{%
\subsection{Matrice identità}\label{matrice-identituxe0}}

Si definisce \emph{matrice identità} di ordine \(n\) la matrice quadrata diagonale \(\boldsymbol{I}_n\) avente tutti gli elementi principali uguali a \(1\):

\[\boldsymbol{I}_3 =  \left[ \begin{array}{c c c}
1 & 0 & 0\\
0 & 1 & 0\\
0 & 0 & 1 \end{array} \right]\]

La matrice identità ha la stessa funzione del numero ``1'' nel sistema dei numeri reali.

\hypertarget{matrici-diagonali-e-triangolari}{%
\subsection{Matrici diagonali e triangolari}\label{matrici-diagonali-e-triangolari}}

Gli elementi di una matrice che si trovano al di sopra della diagonale principale sono detti \emph{sopradiagonali}, mentre quelli che si trovano al di sotto della stessa diagonale principale sono detti \emph{sottodiagonali}. Se una matrice ha tutti gli elementi sopradiagonali e sottodiagonali uguali a zero viene detta \emph{matrice diagonale}. Se invece ha solo gli elementi sopradiagonali nulli allora viene detta \emph{triangolare inferiore}. Se ha gli elementi sottodiagonali nulli allora è detta \emph{triangolare superiore}.

\hypertarget{somma-e-sottrazione}{%
\subsection{Somma e sottrazione}\label{somma-e-sottrazione}}

La somma e la sottrazione di due matrici sono operazioni definite \emph{elemento per elemento}. Per sommare due matrici sommiamo gli elementi corrispondenti. Per sottrarre due matrici sottraiamo gli elementi corrispondenti. Si noti che queste operazioni hanno senso solo se le due matrici hanno \emph{le stesse dimensioni} (altrimenti queste operazioni non sono definite). Per esempio,

\[\left[ \begin{array}{c c}
-2 & 5\\
3 & 1\\
7 & -6
\end{array}
 \right]+
\left[ \begin{array}{c c}
3 & -2\\
4 & 5\\
10 & -3
\end{array}
 \right]=
 \left[ \begin{array}{c c}
1 & 3\\
7 & 6\\
17 & -9
\end{array}
 \right]\]

\[\left[ \begin{array}{c c}
-2 & 5\\
3 & 1\\
7 & -6
\end{array}
 \right]-
\left[ \begin{array}{c c}
3 & -2\\
4 & 5\\
10 & -3
\end{array}
 \right]=
 \left[ \begin{array}{c c}
-5 & 7\\
-1 & -4\\
-3 & -3
\end{array}
 \right]\]

\hypertarget{moltiplicazione-di-scalari-e-matrici}{%
\subsection{Moltiplicazione di scalari e matrici}\label{moltiplicazione-di-scalari-e-matrici}}

L'effetto della moltiplicazione di una matrice \(\boldsymbol{A}\) di qualsiasi dimensione per un numero reale \emph{b} (scalare) è quello di moltiplicare ciascun elemento in \(\boldsymbol{A}\) per \emph{b}. Questo è equivalente a sommare \(\boldsymbol{A}\) a se stessa \emph{b} volte. Per esempio,

\[3 \left[ \begin{array}{c c}
-2 & 5\\
3 & 1\\
7 & -6
\end{array}
 \right]=
\left[ \begin{array}{c c}
-6 & 15\\
9 & 3\\
21 & -18
\end{array}
 \right]\]

\hypertarget{proprietuxe0-della-somma-e-differenza}{%
\subsection{Proprietà della somma e differenza}\label{proprietuxe0-della-somma-e-differenza}}

È facile verificare che la somma e la differenza cosı̀ definite godono delle proprietà commutativa e associativa. Siano \(k\) uno scalare e \(A\) e \(B\) due matrici aventi le stesse dimensioni. Allora

\begin{itemize}
\item
  \(\boldsymbol{A}+ \boldsymbol{B} = \boldsymbol{B} + \boldsymbol{A}\)(Proprietà commutativa)
\item
  \(\boldsymbol{A} + (\boldsymbol{B} + \boldsymbol{C}) = (\boldsymbol{A} + \boldsymbol{B}) + \boldsymbol{C}\) (Proprietà associativa)
\item
  \(k(l\boldsymbol{A}) = (kl)\boldsymbol{A}\)
\item
  \(k(\boldsymbol{A} + \boldsymbol{B}) = k\boldsymbol{A} + k\boldsymbol{B}\)(Proprietà distributiva)
\item
  \((k+l)\boldsymbol{A} = k\boldsymbol{A} + l\boldsymbol{A}\)
\item
  \(1\boldsymbol{A} = \boldsymbol{A}\)
\end{itemize}

\hypertarget{matrice-trasposta}{%
\subsection{Matrice trasposta}\label{matrice-trasposta}}

Si definisce \emph{matrice trasposta} di \(\boldsymbol{A}\), e si denota con \(\boldsymbol{A}'\) oppure \(\boldsymbol{A}'\), la matrice \(\boldsymbol{B} = \boldsymbol{A}'\) di ordine \(n \times m\) cui elementi sono: \[b_{ij} = a_{ji},  \quad        i = 1 \dots m, j = 1 \dots n\] Per esempio,

\[\left[ \begin{array}{c c}
-2 & 5\\
3 & 1\\
7 & -6
\end{array}
 \right]'=
\left[ \begin{array}{c c c}
-2 & 3 & 7\\
5 & 1 & -6
\end{array}
 \right]\]

\hypertarget{matrice-simmetrica}{%
\subsection{Matrice simmetrica}\label{matrice-simmetrica}}

Se accade che \(\boldsymbol{A} = \boldsymbol{A}'\) allora la matrice è detta \emph{simmetrica}.

\[\boldsymbol{A} =  \left[ \begin{array}{c c c}
7 & 1 & 2\\
1 & 8 & 3\\
2 & 3 & 9 \end{array} \right]\]

\begin{itemize}
\item
  \((\boldsymbol{A} + \boldsymbol{B})' = (\boldsymbol{A})' + (\boldsymbol{B})'\)
\item
  \((\boldsymbol{A} - \boldsymbol{B})' = (\boldsymbol{A})' - (\boldsymbol{B})'\)
\item
  \((\boldsymbol{a} + \boldsymbol{b})' = (\boldsymbol{a})' + (\boldsymbol{b})'\)
\item
  \((\boldsymbol{a} - \boldsymbol{b})' = (\boldsymbol{a})' - (\boldsymbol{b})'\)
\end{itemize}

\hypertarget{prodotto-di-matrici}{%
\subsection{Prodotto di matrici}\label{prodotto-di-matrici}}

La moltiplicazione di matrici non è un'operazione intuitiva come la somma e la differenza, ma fornisce uno strumento potente per eseguire una lunga serie di calcoli in un modo molto semplice. L'ordine è importante: il numero delle colonne della prima matrice deve essere uguale al numero di righe della seconda matrice. Quando ciò accade le matrici si dicono \emph{conformabili}, altrimenti si dicono \emph{non conformabili}.

Sia \(\boldsymbol{A}\) una matrice \(m \times p\) e \(\boldsymbol{B}\) una matrice \(p \times n\). Il prodotto tra le due matrici \(\boldsymbol{C} = \boldsymbol{AB}\) è la matrice di ordine \(m \times n\) il cui elemento generico è

\[c_{ij} = \sum_{k=1}^{p} a_{ik}a_{kj},  \quad        i = 1 \dots m,
j = 1 \dots n\]

Pertanto, il prodotto si effettua riga per colonna. È facile verificare che il prodotto tra matrici gode della proprietà associativa ma in generale non di quella commutativa. Vale invece la seguente proprietà:

\[(\boldsymbol{AB})' = \boldsymbol{B}'\boldsymbol{A}'\]

Ad esempio, siano \(\boldsymbol{A}\) e \(\boldsymbol{B}\) le seguenti matrici

\[\left[ \begin{array}{c c c}
-2 & 1 & 1\\
1 & 1 & 4\\
2 & -3 & 2
\end{array}
 \right] \quad \text{e} \quad
\left[ \begin{array}{c c c}
3 & -2 &1\\
4 & 5 & 0\\
1 & -3 & 1
\end{array}
 \right]\]

Calcoliamo la matrice \(\boldsymbol{C} = \boldsymbol{AB}\). L'elemento \(c_{ij}\) è uguale alla somma dei prodotti degli elementi della \emph{i}-esima riga di \(\boldsymbol{A}\) per la \emph{j}-esima colonna di \(\boldsymbol{B}\).

\(c_{11} = (-2) \cdot 3 + 1 \cdot 4 + 1 \cdot 1 = -1\)

\(c_{12} = (-2) \cdot (-2) + 1 \cdot 5 + 1 \cdot (-3) = 6\)

\(c_{13} = (-2) \cdot 3 + 1 \cdot 0 + 1 \cdot 1 = -1\)

\(c_{21} = 1 \cdot 3 + 1 \cdot 4 + 4 \cdot 1 = 11\)

\(c_{22} = 1 \cdot (-2) + 1 \cdot 5 + 4 \cdot (-3) = -9\)

\(c_{23} = 1 \cdot 3 + 1 \cdot 0 + 4 \cdot 1 = 5\)

\(c_{31} = 2 \cdot 3 +(-3) \cdot 4 + 2 \cdot 1 = -4\)

\(c_{32} = 2 \cdot (-2) +(-3) \cdot 5 + 2 \cdot (-3) = -25\)

\(c_{33} = 2 \cdot 1 + (-3) \cdot 0 + 2 \cdot 1 = 4\)

In definitiva

\[\boldsymbol{C} =  \left[ \begin{array}{c c c}
-1 & 6 & -1\\
11 & -9 & 5\\
-4 & -25 & 4
\end{array}
 \right]\]

Calcolando il prodotto \(\boldsymbol{D} = \boldsymbol{BA}\) si trova invece:

\[\boldsymbol{D} =  \left[ \begin{array}{c c c}
-6 & -2 & -3\\
-3 & 9 & 24\\
-3 & -5 & -9
\end{array}
 \right]\]

da cui risulta evidente che \(\boldsymbol{AB} \neq \boldsymbol{BA}\).

\hypertarget{proprietuxe0-del-prodotto-di-matrici}{%
\subsection{Proprietà del prodotto di matrici}\label{proprietuxe0-del-prodotto-di-matrici}}

\begin{itemize}
\item
  \(\boldsymbol{A}(\boldsymbol{B} + \boldsymbol{C}) = \boldsymbol{AB} +  \boldsymbol{AC}\)
\item
  \((\boldsymbol{A} + \boldsymbol{B})\boldsymbol{C} = \boldsymbol{AC} +  \boldsymbol{BC}\)
\item
  Per qualunque matrice \(\boldsymbol{A}\), \(\boldsymbol{A}'\boldsymbol{A}\) sarà una matrice quadrata.
\item
  \((\boldsymbol{AB})' = \boldsymbol{B}'\boldsymbol{A}'\)
\end{itemize}

\hypertarget{casi-particolari}{%
\subsection{Casi particolari}\label{casi-particolari}}

La matrice identità è l'elemento neutro per il prodotto, cioè se \(\boldsymbol{I}\) è una matrice \(n \times n\) si ha

\[\boldsymbol{A} \boldsymbol{I}_n = \boldsymbol{I}_n \boldsymbol{A}
= \boldsymbol{A}.\]

Per esempio,

\[\boldsymbol{IA} = \left(%
\begin{array}{cc}
  1 & 0 \\
  0 & 1 \\
\end{array}%
\right)
\left(%
\begin{array}{ccc}
  2 & 3 & -1 \\
  1 & 4 & 7 \\
\end{array}%
\right)=
\left(%
\begin{array}{ccc}
  2 & 3 & -1 \\
  1 & 4 & 7 \\
\end{array}%
\right)\]

Un secondo caso particolare si verifica quando una matrice è costituita da un'unica colonna o un'unica riga. Se la matrice \(\boldsymbol{A}\) si riduce ad una sola colonna (o una sola riga) e viene detta vettore colonna (o riga) ad \(m\) elementi o componenti. Un vettore colonna è una matrice \(n \times 1\); un vettore riga è una matrice \(1 \times m\). Se \(\boldsymbol{a}\) è un vettore colonna di \(m\) elementi allora \(\boldsymbol{a}'\) è un vettore riga sempre di \(m\) elementi.

Per le operazioni tra vettori valgono le stesse regole viste per le matrici, cioè la somma e la differenza sono possibili tra vettori dello stesso tipo e con lo stesso numero di componenti. La moltiplicazione è possibile tra una matrice e un vettore di dimensioni appropriate, e tra due vettori di dimensioni appropriate. In questo secondo caso, distinguiamo tra \emph{prodotto interno} e \emph{prodotto esterno}.

\hypertarget{operazioni-tra-vettori}{%
\subsection{Operazioni tra vettori}\label{operazioni-tra-vettori}}

Il \emph{prodotto interno} (o scalare) di un vettore \(\boldsymbol{a}'\) \(1 \times n\) che premoltiplica un vettore \(\boldsymbol{b}\) \(n \times 1\) produce uno scalare:

\[\boldsymbol{a}'\boldsymbol{b} = \sum_{i=1}^{n}a_i b_i\]

Dati due vettori \(\boldsymbol{a}\), \(\boldsymbol{b}\) di ordini \(n \times 1\) e \(m \times 1\), il \emph{prodotto esterno} \(\boldsymbol{C} = \boldsymbol{ab}'\) è una matrice \(n \times m\) di elementi \(c_{ij} = a_i b_j\).

\hypertarget{prodotto-interno}{%
\subsection{Prodotto interno}\label{prodotto-interno}}

Siano \(\boldsymbol{a}\) e \(\boldsymbol{b}\) i seguenti vettori:

\[\left[ \begin{array}{c}
1 \\
2 \\
3
\end{array}
 \right] \quad e \quad
\left[ \begin{array}{c}
-1 \\
-2 \\
4
\end{array}
 \right]\]

Il prodotto interno è:

\[\boldsymbol{a}'\boldsymbol{b}= 1 \cdot (-1) + 2 \cdot (-2) + 3
\cdot 4 = 7\] Osserviamo che tale operazione gode della proprietà commutativa, poichè \(\boldsymbol{b}'\boldsymbol{a}=7\).

\hypertarget{prodotto-esterno}{%
\subsection{Prodotto esterno}\label{prodotto-esterno}}

Il prodotto esterno è la matrice

\[\boldsymbol{C} = \boldsymbol{a}\boldsymbol{b}'= \left[
\begin{array}{c c c}
-1 & -2 & 4\\
-2 & -4 & 8\\
-3 & -6 & 12
\end{array}
 \right]\]

Tale prodotto non gode della proprietà commutativa, infatti:

\[\boldsymbol{D} = \boldsymbol{b}\boldsymbol{a}'= \left[
\begin{array}{c c c}
-1 & -2 & -3\\
-2 & -4 & -6\\
4 & 8 & 12
\end{array}
 \right]\]

\hypertarget{traccia-di-una-matrice}{%
\subsection{Traccia di una matrice}\label{traccia-di-una-matrice}}

Si definisce \emph{traccia} di una matrice quadrata \(\boldsymbol{A}\) \(n \times n\), e si denota con \(tr(\boldsymbol{A})\) la somma degli elementi sulla diagonale principale di \(\boldsymbol{A}\):

\[tr(\boldsymbol{A}) = \sum_{i=1}^{n} a_{ii}\]

La traccia gode delle seguenti proprietà:

\[\begin{aligned}
&tr(\rho \boldsymbol{A}) = \rho tr( \boldsymbol{A}) \notag \\
&tr(\boldsymbol{A} + \boldsymbol{B}) =  tr( \boldsymbol{A})+tr( \boldsymbol{B}) \notag \\
&tr(\boldsymbol{A}') =  tr( \boldsymbol{A}) \notag \\
&tr(\boldsymbol{AB}) =  tr( \boldsymbol{BA}) \notag\end{aligned}\]

Per esempio, sia

\[\boldsymbol{A} =  \left[ \begin{array}{c c c}
7 & 1 & 2\\
1 & 8 & 3\\
2 & 3 & 9 \end{array} \right]\]

allora

\[tr(\boldsymbol{A}) = 7 + 8 + 9 = 24.\]

\hypertarget{dipendenza-lineare}{%
\paragraph{Dipendenza lineare}\label{dipendenza-lineare}}

Si consideri la matrice

\[\boldsymbol{A}=
\left(%
\begin{array}{ccc}
  1 & 1 & 1 \\
  3 & 1 & 5 \\
  2 & 3 & 1 \\
\end{array}%
\right)\]

Siano \(\boldsymbol{c}_1\), \(\boldsymbol{c}_2\), \(\boldsymbol{c}_3\) le colonne di \(\boldsymbol{A}\). Si noti che

\[2\boldsymbol{c}_1 + -\boldsymbol{c}_2 + - \boldsymbol{c}_3 =
\boldsymbol{0}\]

dove \(\boldsymbol{0}\) è un vettore (\(3 \times 1\)) di zeri.

Dato che le 3 colonne di \(\boldsymbol{A}\) possono essere combinate linearmente in modo da produrre un vettore \(\boldsymbol{0}\) vi è chiaramente una qualche forma di relazione, o dipendenza, tra le informazioni nelle colonne. Detto in un altro modo, sembra esserci una qualche duplicazione delle informazione nelle colonne. In generale, si dice che \(k\) colonne \(\boldsymbol{c}_1, \boldsymbol{c}_2, \dots \boldsymbol{c}_k\) di una matrice sono \emph{linearmente dipendenti} se esiste un insieme di valori scalari \(\lambda_1, \dots, \lambda_k\) tale per cui

\[\lambda_1 \boldsymbol{c}_1 + \dots + \lambda_k \boldsymbol{c}_k=\boldsymbol{0}\]

e almeno uno dei valori \(\lambda_i\) non è uguale a 0.

La dipendenza lineare implica che ciascun vettore colonna è una combinazione degli altri. Per esempio

\[\boldsymbol{c}_k= -(\lambda_1 \boldsymbol{c}_1 + \dots + \lambda_{k-1}
   \boldsymbol{c}_{k-1})/\lambda_k\]

Questo implica che tutta ``l'informazione'' della matrice è contenuta in un sottoinsieme delle colonne -- se \(k-1\) colonne sono conosciute, l'ultima resta determinata. È in questo senso che abbiamo detto che l'informazione della matrice veniva ``duplicata''.

Se l'unico insieme di valori scalari \(\lambda_i\) che soddisfa l'equazione

\[\lambda_1 \boldsymbol{c}_1 + \dots + \lambda_k \boldsymbol{c}_k=\boldsymbol{0}\]

è un vettore di zeri, allora questo significa che non vi è alcuna relazione tra le colonne della matrice. Le colonne si dicono \emph{linearmente indipendenti}, nel senso che non contengono alcuna ``duplicazione'' di informazione.

\hypertarget{rango-di-una-matrice}{%
\subsection{Rango di una matrice}\label{rango-di-una-matrice}}

Il \emph{rango della matrice} è il massimo numero di vettori colonna linearmente indipendenti che possono essere selezionati dalla matrice. In maniera equivalente, il rango di una matrice può essere definito come il massimo numero di vettori riga linermente indipendenti. Il rango minimo di una matrice è 1, il che significa che vi è una colonna tale per cui le altre colonne sono dei multipli di questa. Per l'esempio precedente, il rango della matrice \(\boldsymbol{A}\) è 2.

Se la matrice è quadrata, \(\boldsymbol{A}_{n \times n}\), ed è costituita da vettori tutti indipendenti tra di loro, allora il suo rango è \(n\). Se, invece, la matrice è rettangolare, \(\boldsymbol{A}_{m \times n}\), allora il suo rango può essere al massimo il più piccolo tra i due valori \emph{m} ed \emph{n}, cioè:

\[r(\boldsymbol{A}_{m \times n}) \leq min(m,n)\]

\hypertarget{matrice-inversa}{%
\subsection{Matrice inversa}\label{matrice-inversa}}

L'inversa di una matrice quadrata è l'analogo del reciproco per gli scalari. Se \(b\) è uno scalare e \(b=0\), allora il reciproco di \(b\), \(1/b\) \emph{non esiste} -- non è definito. Allo stesso modo, vi sono delle matrici che ``si comportano come lo 0'' e per le quali l'inversa non è definita. Tali matrici si dicono \emph{singolari}.

Sia \(\boldsymbol{A}\) una matrice quadrata di dimensione \(n\). Si definisce \emph{matrice inversa} la matrice, denotata con \(\boldsymbol{A}^{-1}\), che premoltiplicata o postmoltiplicata per \(\boldsymbol{A}\) fornisce la matrice identità:

\[\boldsymbol{A}\boldsymbol{A}^{-1}=\boldsymbol{A}^{-1}\boldsymbol{A}=\boldsymbol{I}\]

La condizione per l'esistenza e l'unicità di \(\boldsymbol{A}^{-1}\) è che le colonne di \(\boldsymbol{A}\) siano linearmente indipendenti.

Nel caso di una matrice diagonale la determinazione della matrice inversa risulta immediata: \(\boldsymbol{D}^{-1}= diag(1/d_1, \dots, 1/d_n)\). Nel caso di una matrice non diagonale, la matrice inversa si trova usando il computer dove complicate formule per matrici di qualunque dimensione sono implementate in vari software. Solo per matrici di piccole dimensioni sono disponibili semplici espressioni analitiche per il calcolo della matrice inversa.

Per esempio, sia

\[\boldsymbol{A} =  \left[ \begin{array}{c c}
3 & 4 \\
2 & 6
\end{array}
 \right]\]

allora

\[\boldsymbol{A}^{-1} =  \left[ \begin{array}{c c}
.6 & -.4 \\
-.2 & .3
\end{array}
 \right]\]

e

\[\boldsymbol{A}\boldsymbol{A}^{-1} =\left[ \begin{array}{c c}
3 & 4 \\
2 & 6
\end{array}
 \right]
\left[ \begin{array}{c c}
.6 & -.4 \\
-.2 & .3
\end{array}
 \right] =
 \left[ \begin{array}{c c}
1 & 0 \\
0 & 1
\end{array}
 \right]\]

Se \(\boldsymbol{A}\) e \(\boldsymbol{B}\) sono due matrici non singolari aventi le stesse dimensioni, allora l'inversa del loro prodotto è uguale al prodotto delle loro inverse nella sequenza opposta:

\[(\boldsymbol{AB})^{-1}=\boldsymbol{B}^{-1}\boldsymbol{A}^{-1}\]

L'inversa della trasposta di una matrice non singolare è uguale alla trasposta dell'inversa:

\[(\boldsymbol{A}')^{-1}=(\boldsymbol{A}^{-1})'\]

\hypertarget{determinante-di-una-matrice}{%
\subsection{Determinante di una matrice}\label{determinante-di-una-matrice}}

Sia \(\boldsymbol{A}\) una matrice quadrata. Il determinante di \(\boldsymbol{A}\) è uno scalare, \(|\boldsymbol{A}|\), il cui valore assoluto misura il volume del parallelepipedo delimitato dalle colonne di \(\boldsymbol{A}\). Nel caso della matrice identità il volume è pari a 1, per cui \(|\boldsymbol{I}| =1\). Per una matrice diagonale \(\boldsymbol{D} = diag(d_1, \dots, d_n)\) si ha

\[|\boldsymbol{D}| =  d_1 \cdot d_2, \dots, d_n = \prod_{i=1}^{n}d_i\]

Per una matrice \(2 \times 2\)

\[\boldsymbol{A} =  \left[ \begin{array}{c c}
a_{11}& a_{12} \\
a_{21} & a_{22} \end{array} \right]\]

il determinante di \(\boldsymbol{A}\) vale:

\[|\boldsymbol{A}| =  a_{11}a_{22}-a_{12}a_{21}\]

Per esempio:

\[\boldsymbol{A} = \left[ \begin{array}{c c}
1 & -2 \\
3 & 9
\end{array}
 \right] \quad |\boldsymbol{A}| = 1\cdot 9 - (-2) \cdot  3 = 15\]

Il determinante è definito anche per matrici di dimensioni superiori anche se, in quel caso, i calcoli sono molto più complessi (una volta ancora, si usi il computer!).

\hypertarget{determinante-e-inversa}{%
\subsection{Determinante e inversa}\label{determinante-e-inversa}}

Vi è una relazione tra il determinante e l'inversa di una matrice. Se la matrice \(\boldsymbol{A}\) ha dimensioni \(2 \times 2\) l'inversa di \(\boldsymbol{A}\) si trova nel modo seguente

\[\boldsymbol{A}^{-1} = \frac{1}{|\boldsymbol{A}|} \left[
\begin{array}{c c}
a_{22} & -a_{12} \\
-a_{21} & a_{11}
\end{array}
 \right]\]

Anche per le matrici di dimensioni maggiori la matrice inversa è definita nei termini del determinante, ma le formule di calcolo sono molto più complesse.

Per esempio, sia

\[\boldsymbol{A} = \left[ \begin{array}{c c}
3 & 4 \\
2 & 6
\end{array}
\right]\]

allora

\[\boldsymbol{A}^{-1} = \frac{1}{10} \left[
\begin{array}{c c}
6 & -4 \\
-2 & 3
\end{array}
\right]= \left[ \begin{array}{c c}
.6 & -.4 \\
-.2 & .3
\end{array}
 \right]\]

In precedenza abbiamo detto che, in alcuni casi, una matrice ``si comporta come lo 0.'' Il \emph{determinante} di una matrice è ci dice quando una matrice ``si comporta come lo 0.'' \(|\boldsymbol{A}| = 0\), infatti, se una riga (o una colonna) è una combinazione lineare di due (o più) righe (o colonne) di \(\boldsymbol{A}\).

Per esempio, nel caso di una matrice (\(2 \times 2\))

\[\boldsymbol{A} =  \left( \begin{array}{c c}
a_{11}& a_{12} \\
a_{21} & a_{22} \end{array} \right)\]

supponiamo che

\[\left(%
\begin{array}{c}
  a_{11} \\
  a_{21} \\
\end{array}%
\right)=2
\left(%
\begin{array}{c}
  a_{12} \\
  a_{22} \\
\end{array}%
\right)\]

Allora

\[\boldsymbol{A} =  \left( \begin{array}{c c}
2a_{12}& a_{12} \\
2a_{22} & a_{22} \end{array} \right)\]

e

\[|\boldsymbol{A}| = 2a_{12}a_{22}-2a_{12}a_{22}=0\]

In conclusione, se il determinante è uguale a zero, allora la matrice inversa non esiste. Nel caso di una matrice (\(2 \times 2\)), infatti, la formula dell'inversa richiede la divisione per \(a_{11}a_{22}-a_{12}a_{21}\) che, nel caso di una matrice singolare, è uguale a zero.

\hypertarget{proprietuxe0-del-determinante}{%
\subsection{Proprietà del determinante}\label{proprietuxe0-del-determinante}}

\begin{itemize}
\item
  \(|\boldsymbol{A}'| = |\boldsymbol{A}|\).
\item
  Se \(\boldsymbol{A}\) contiene una colonna o una riga i cui elementi sono tutti 0, allora \(|\boldsymbol{A}|=0\).
\item
  Se \(\boldsymbol{A}\) contiene due colonne (o righe) identiche, allora \(|\boldsymbol{A}|=0\).
\item
  \(|\boldsymbol{A}| = 0\) se una riga (o una colonna) è combinazione lineare di due (o più) righe (o colonne) di \(\boldsymbol{A}\).
\item
  \(|\boldsymbol{A}| = 1/|\boldsymbol{A}^{-1}|\).
\item
  \(|\boldsymbol{I}| = 1\).
\item
  \(|\boldsymbol{A} \boldsymbol{B}| = |\boldsymbol{A}| |\boldsymbol{B}|\).
\end{itemize}

Per una matrice quadrata \(\boldsymbol{A}\), le seguenti affermazioni sono equivalenti: \(\boldsymbol{A}\) è non singolare, \(|\boldsymbol{A}|\neq 0\), \(\boldsymbol{A}^{-1}\) esiste.

\hypertarget{radici-e-vettori-latenti}{%
\subsection{Radici e vettori latenti}\label{radici-e-vettori-latenti}}

Dal determinante di una matrice si possono ricavare le \emph{radici latenti} o \emph{autovalori} (denotati da \(\lambda_i\)) e i \emph{vettori latenti} o \emph{autovettori} della matrice. Alle nozioni di autovalore e autovettore verrà qui fornita un'interpretazione geometrica.

Simuliamo di dati di due variabili associate tra loro:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(}\StringTok{"car"}\NormalTok{)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123456}\NormalTok{)}
\NormalTok{npoints }\OtherTok{\textless{}{-}} \DecValTok{20}
\NormalTok{x }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(}\FunctionTok{scale}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(npoints, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{)))}
\NormalTok{y }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(}\FunctionTok{scale}\NormalTok{(}\DecValTok{3} \SpecialCharTok{*}\NormalTok{ x }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(npoints, }\DecValTok{0}\NormalTok{, }\DecValTok{2}\NormalTok{)))}
\FunctionTok{mean}\NormalTok{(x)}
\CommentTok{\#\textgreater{} [1] 1.077e{-}17}
\FunctionTok{mean}\NormalTok{(y)}
\CommentTok{\#\textgreater{} [1] {-}1.873e{-}17}
\FunctionTok{cor}\NormalTok{(x, y)}
\CommentTok{\#\textgreater{} [1] 0.8291}
\end{Highlighting}
\end{Shaded}

Disegnamo il diagramma di dispersione con un ellisse che contiene la nube di punti:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Y }\OtherTok{\textless{}{-}} \FunctionTok{cbind}\NormalTok{(x, y)}
\NormalTok{car}\SpecialCharTok{::}\FunctionTok{dataEllipse}\NormalTok{(}
\NormalTok{  Y[, }\DecValTok{1}\NormalTok{], Y[, }\DecValTok{2}\NormalTok{],}
  \AttributeTok{levels =} \FloatTok{0.95}\NormalTok{,}
  \AttributeTok{lty =} \DecValTok{2}\NormalTok{,}
  \AttributeTok{ylim =} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{, }\DecValTok{3}\NormalTok{),}
  \AttributeTok{xlim =} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{, }\DecValTok{3}\NormalTok{)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{cfa_book_files/figure-latex/unnamed-chunk-337-1} \end{center}

Se racchiudiamo le osservazioni (\(v_1, v_2\)) con un'ellisse, allora la lunghezza dei semiassi maggiori e minori dell'ellisse sarà proporzionale a \(\sqrt{\lambda_1}\) e \(\sqrt{\lambda_2}\). L'asse maggiore è la linea passante per il punto (\(\bar{v_1}, \bar{v_2}\)) nella direzione determinata dal primo autovettore \(\boldsymbol{a}_1'\) con pendenza uguale a \(a_{12}/a_{11}\). L'asse minore è la linea passante per il punto (\(\bar{v_1}, \bar{v_2}\)) nella direzione determinata dal secondo autovettore \(\boldsymbol{a}_2\).

Calcoliamo ora gli autovettori e gli autovalori:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{s }\OtherTok{\textless{}{-}} \FunctionTok{cov}\NormalTok{(Y)}
\NormalTok{ee }\OtherTok{\textless{}{-}} \FunctionTok{eigen}\NormalTok{(s)}
\end{Highlighting}
\end{Shaded}

Disegniamo gli assi dell'ellisse:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{car}\SpecialCharTok{::}\FunctionTok{dataEllipse}\NormalTok{(}
\NormalTok{  Y[, }\DecValTok{1}\NormalTok{], Y[, }\DecValTok{2}\NormalTok{],}
  \AttributeTok{levels =} \FloatTok{0.95}\NormalTok{,}
  \AttributeTok{lty =} \DecValTok{2}\NormalTok{,}
  \AttributeTok{ylim =} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{, }\DecValTok{3}\NormalTok{),}
  \AttributeTok{xlim =} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{, }\DecValTok{3}\NormalTok{)}
\NormalTok{)}
\NormalTok{k }\OtherTok{\textless{}{-}} \FloatTok{2.65}
\FunctionTok{arrows}\NormalTok{(}
  \DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{,}
\NormalTok{  k }\SpecialCharTok{*} \FunctionTok{sqrt}\NormalTok{(ee}\SpecialCharTok{$}\NormalTok{values[}\DecValTok{1}\NormalTok{]) }\SpecialCharTok{*}\NormalTok{ ee}\SpecialCharTok{$}\NormalTok{vectors[}\DecValTok{1}\NormalTok{],}
\NormalTok{  k }\SpecialCharTok{*} \FunctionTok{sqrt}\NormalTok{(ee}\SpecialCharTok{$}\NormalTok{values[}\DecValTok{1}\NormalTok{]) }\SpecialCharTok{*}\NormalTok{ ee}\SpecialCharTok{$}\NormalTok{vectors[}\DecValTok{2}\NormalTok{],}
  \AttributeTok{code =} \DecValTok{2}\NormalTok{,}
  \AttributeTok{col =} \StringTok{"red"}\NormalTok{,}
  \AttributeTok{lwd =} \DecValTok{2}
\NormalTok{)}
\FunctionTok{arrows}\NormalTok{(}
  \DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{,}
\NormalTok{  k }\SpecialCharTok{*} \FunctionTok{sqrt}\NormalTok{(ee}\SpecialCharTok{$}\NormalTok{values[}\DecValTok{2}\NormalTok{]) }\SpecialCharTok{*}\NormalTok{ ee}\SpecialCharTok{$}\NormalTok{vectors[}\DecValTok{1}\NormalTok{],}
\NormalTok{  k }\SpecialCharTok{*} \FunctionTok{sqrt}\NormalTok{(ee}\SpecialCharTok{$}\NormalTok{values[}\DecValTok{2}\NormalTok{]) }\SpecialCharTok{*} \SpecialCharTok{{-}}\NormalTok{ee}\SpecialCharTok{$}\NormalTok{vectors[}\DecValTok{2}\NormalTok{],}
  \AttributeTok{code =} \DecValTok{2}\NormalTok{,}
  \AttributeTok{col =} \StringTok{"red"}\NormalTok{,}
  \AttributeTok{lwd =} \DecValTok{2}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{cfa_book_files/figure-latex/unnamed-chunk-339-1} \end{center}

Tale analisi si può estendere a qualunque numero di variabili. Per esempio, nel caso di tre variabili, possiamo pensare di disegnare un ellisoide attorno ad una nube di punti nello spazio tridimensionale. Anche in questo caso, gli autovalori e gli associati autovettori corrisponderanno agli assi dell'elissoide.

\hypertarget{scomposizione-spettrale-di-una-matrice}{%
\subsection{Scomposizione spettrale di una matrice}\label{scomposizione-spettrale-di-una-matrice}}

Data una matrice quadrata e simmetrica di dimensione \(n\), \(\boldsymbol{A}\), esistono una matrice diagonale \(\boldsymbol{\Lambda}\) e una matrice ortogonale \(\boldsymbol{V}\) tali che

\[\boldsymbol{A} =\boldsymbol{V} \boldsymbol{\Lambda} \boldsymbol{V}',\] dove

\begin{itemize}
\tightlist
\item
  \(\boldsymbol{\Lambda}\) è una matrice diagonale i cui elementi sono gli autovalori di \(\boldsymbol{A}\): \(\boldsymbol{\Lambda} = diag(\lambda_1, \lambda_2,  \dots, \lambda_n)\);
\item
  \(\boldsymbol{V}\) è una matrice ortogonale le cui colonne \((v_1, v_2, \dots, v_p)\) sono gli autovettori di \(\boldsymbol{A}\) associati ai rispettivi autovalori.
\end{itemize}

In maniera equivalente

\[\boldsymbol{A} \boldsymbol{V} =  \boldsymbol{\Lambda} \boldsymbol{V}'.\]

Premoltiplicando entrambi i membri per \(\boldsymbol{V}'\) si ottiene

\[\boldsymbol{V}'\boldsymbol{A} \boldsymbol{V} =
\boldsymbol{\Lambda},\]

da cui l'affermazione che la matrice degli autovettori diagonalizza \(\boldsymbol{A}\).

Per esempio,

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sigma }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}
  \AttributeTok{data =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\FloatTok{0.5}\NormalTok{, }\FloatTok{0.5}\NormalTok{, }\FloatTok{1.25}\NormalTok{),}
  \AttributeTok{nrow =} \DecValTok{2}\NormalTok{,}
  \AttributeTok{ncol =} \DecValTok{2}
\NormalTok{)}
\NormalTok{sigma}
\CommentTok{\#\textgreater{}      [,1] [,2]}
\CommentTok{\#\textgreater{} [1,]  1.0 0.50}
\CommentTok{\#\textgreater{} [2,]  0.5 1.25}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{out }\OtherTok{\textless{}{-}} \FunctionTok{eigen}\NormalTok{(sigma)}
\NormalTok{out}
\CommentTok{\#\textgreater{} eigen() decomposition}
\CommentTok{\#\textgreater{} $values}
\CommentTok{\#\textgreater{} [1] 1.6404 0.6096}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} $vectors}
\CommentTok{\#\textgreater{}        [,1]    [,2]}
\CommentTok{\#\textgreater{} [1,] 0.6154 {-}0.7882}
\CommentTok{\#\textgreater{} [2,] 0.7882  0.6154}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Lambda }\OtherTok{\textless{}{-}} \FunctionTok{diag}\NormalTok{(out}\SpecialCharTok{$}\NormalTok{values)}
\NormalTok{Lambda}
\CommentTok{\#\textgreater{}      [,1]   [,2]}
\CommentTok{\#\textgreater{} [1,] 1.64 0.0000}
\CommentTok{\#\textgreater{} [2,] 0.00 0.6096}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{U }\OtherTok{\textless{}{-}}\NormalTok{ out}\SpecialCharTok{$}\NormalTok{vectors}
\NormalTok{U}
\CommentTok{\#\textgreater{}        [,1]    [,2]}
\CommentTok{\#\textgreater{} [1,] 0.6154 {-}0.7882}
\CommentTok{\#\textgreater{} [2,] 0.7882  0.6154}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{U }\SpecialCharTok{\%*\%}\NormalTok{ Lambda }\SpecialCharTok{\%*\%} \FunctionTok{t}\NormalTok{(U)}
\CommentTok{\#\textgreater{}      [,1] [,2]}
\CommentTok{\#\textgreater{} [1,]  1.0 0.50}
\CommentTok{\#\textgreater{} [2,]  0.5 1.25}
\end{Highlighting}
\end{Shaded}

\hypertarget{autovalori-e-determinante}{%
\subsection{Autovalori e determinante}\label{autovalori-e-determinante}}

Il determinante di una matrice è il prodotto degli autovalori:

\[\begin{aligned}
    |\boldsymbol{A}| &= \prod_{i=1}^{p} \lambda_i. \notag
    \end{aligned}\]

La traccia di una matrice è uguale alla somma degli autovalori:

\[\begin{aligned}
    tr(\boldsymbol{A}) &= \sum_{i=1}^{p} \lambda_i. \notag
    \end{aligned}\]

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sigma }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\AttributeTok{data =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\FloatTok{0.5}\NormalTok{, }\FloatTok{0.5}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{nrow =} \DecValTok{2}\NormalTok{, }\AttributeTok{ncol =} \DecValTok{2}\NormalTok{)}
\NormalTok{sigma}
\CommentTok{\#\textgreater{}      [,1] [,2]}
\CommentTok{\#\textgreater{} [1,]  1.0  0.5}
\CommentTok{\#\textgreater{} [2,]  0.5  2.0}

\NormalTok{out }\OtherTok{\textless{}{-}} \FunctionTok{eigen}\NormalTok{(sigma)}
\NormalTok{out}
\CommentTok{\#\textgreater{} eigen() decomposition}
\CommentTok{\#\textgreater{} $values}
\CommentTok{\#\textgreater{} [1] 2.2071 0.7929}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} $vectors}
\CommentTok{\#\textgreater{}        [,1]    [,2]}
\CommentTok{\#\textgreater{} [1,] 0.3827 {-}0.9239}
\CommentTok{\#\textgreater{} [2,] 0.9239  0.3827}
\end{Highlighting}
\end{Shaded}

La traccia di una matrice è uguale alla somma degli autovalori:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sum}\NormalTok{(out}\SpecialCharTok{$}\NormalTok{values)}
\CommentTok{\#\textgreater{} [1] 3}
\end{Highlighting}
\end{Shaded}

Il determinante di una matrice è il prodotto degli autovalori:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{det}\NormalTok{(sigma)}
\CommentTok{\#\textgreater{} [1] 1.75}
\NormalTok{out}\SpecialCharTok{$}\NormalTok{values[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{*}\NormalTok{ out}\SpecialCharTok{$}\NormalTok{values[}\DecValTok{2}\NormalTok{]}
\CommentTok{\#\textgreater{} [1] 1.75}
\end{Highlighting}
\end{Shaded}

Gli autovalori di \(\boldsymbol{A}^{-1}\) sono i reciproci degli autovalori di \(\boldsymbol{A}\); gli autovettori sono coincidenti.

  \bibliography{refs.bib,book.bib,packages.bib}

\printindex

\end{document}
