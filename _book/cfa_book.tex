% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  11pt,
]{krantz}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
  \setmonofont[Scale=0.775]{MesloLGS NF}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Appunti di Costruzione e validazione di strumenti di misura dell'efficacia dell'intervento psicologico in neuropsicologia -- B020881 (B213)},
  pdfauthor={Corrado Caudek},
  colorlinks=true,
  linkcolor={Maroon},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.33,0.33,0.33}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.61,0.61,0.61}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.06,0.06,0.06}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.5,0.5,0.5}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0,0,0}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.27,0.27,0.27}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.27,0.27,0.27}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.06,0.06,0.06}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.14,0.14,0.14}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.06,0.06,0.06}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0,0,0}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.27,0.27,0.27}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.43,0.43,0.43}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0,0,0}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.5,0.5,0.5}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.5,0.5,0.5}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0,0,0}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.5,0.5,0.5}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}

\defaultfontfeatures{Scale=MatchLowercase}

\usepackage{booktabs}
\usepackage{longtable}
\usepackage[bf,singlelinecheck=off]{caption}

\usepackage{framed,color}
\definecolor{shadecolor}{RGB}{248,248,248}

\renewcommand{\textfraction}{0.05}
\renewcommand{\topfraction}{0.8}
\renewcommand{\bottomfraction}{0.8}
\renewcommand{\floatpagefraction}{0.75}

\renewenvironment{quote}{\begin{VF}}{\end{VF}}
\let\oldhref\href
\renewcommand{\href}[2]{#2\footnote{\url{#1}}}

\ifxetex
  \usepackage{letltxmacro}
  \setlength{\XeTeXLinkMargin}{1pt}
  \LetLtxMacro\SavedIncludeGraphics\includegraphics
  \def\includegraphics#1#{% #1 catches optional stuff (star/opt. arg.)
    \IncludeGraphicsAux{#1}%
  }%
  \newcommand*{\IncludeGraphicsAux}[2]{%
    \XeTeXLinkBox{%
      \SavedIncludeGraphics#1{#2}%
    }%
  }%
\fi

\makeatletter
\newenvironment{kframe}{%
\medskip{}
\setlength{\fboxsep}{.8em}
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\renewenvironment{Shaded}{\begin{kframe}}{\end{kframe}}

\usepackage{makeidx}
\makeindex

\urlstyle{tt}

\usepackage{amsthm}
\makeatletter
\def\thm@space@setup{%
  \thm@preskip=8pt plus 2pt minus 4pt
  \thm@postskip=\thm@preskip
}
\makeatother

\DeclareMathOperator{\V}{\mathbb{V}} % Define variance operator
\DeclareMathOperator{\Var}{\mathbb{V}} % Define variance operator
\DeclareMathOperator{\SD}{SD} % Define sd operator
\DeclareMathOperator{\Cov}{Cov} % Define covariance operator
\DeclareMathOperator{\Corr}{Corr} % Define correlation operator
\DeclareMathOperator{\Me}{Me} % Define mediane operator
\DeclareMathOperator{\Mo}{Mo} % Define mode operator

\DeclareMathOperator{\Bin}{Binomial} % Define binomial operator
\DeclareMathOperator{\Bernoulli}{Bernoulli} % Define Bernoulli operator
\DeclareMathOperator{\Ber}{\mathscr{B}} % Define Bernoulli operator
\DeclareMathOperator{\Poi}{Poisson} % Define Poisson operator
\DeclareMathOperator{\Uniform}{Uniform} % Define Uniform operator
\DeclareMathOperator{\Cauchy}{Cauchy} % Define Cauchy operator
\DeclareMathOperator{\B}{B} % beta function
% \mbox{B}(a, b) % beta function
% \mbox{Beta}(a, b) % beta distribution

\DeclareMathOperator{\elpd}{elpd} % Define elpd operator
\DeclareMathOperator{\lppd}{lppd} % Define lppd operator
\DeclareMathOperator{\LOO}{LOO} % Define LOO operator
\DeclareMathOperator{\argmin}{arg\,min} 
\DeclareMathOperator{\argmax}{arg\,max} 

\newcommand{\E}{\mathbb{E}} % Define expected value operator
\newcommand{\R}{\textsf{R}} % Define R programming language symbol
\newcommand{\Real}{\mathbb{R}} % Define real number operator
\newcommand{\Prob}{\mathscr{P}}
\newcommand{\indep}{\perp \!\!\! \perp}

\usepackage[
 labelfont=bf,
 font={small, it}
]{caption}
\usepackage{upquote} % print correct quotes in verbatim-environments
\usepackage{empheq}
\usepackage{xfrac}

\usepackage{polyglossia}
\setmainlanguage{italian}

\frontmatter
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{apalike}

\title{Appunti di Costruzione e validazione di strumenti di misura dell'efficacia dell'intervento psicologico in neuropsicologia -- B020881 (B213)}
\author{Corrado Caudek}
\date{2022-03-04}

\begin{document}
\maketitle

\cleardoublepage\newpage\thispagestyle{empty}\null
% \cleardoublepage\newpage\thispagestyle{empty}\null
%\cleardoublepage\newpage
\thispagestyle{empty}
\begin{center}
\Large{Appunti di Costruzione e validazione di strumenti di misura dell'efficacia dell'intervento psicologico in neuropsicologia -- AA 2021/2022}

\vskip20pt

\includegraphics{images/actually_2x.png}
\end{center}

\setlength{\abovedisplayskip}{-5pt}
\setlength{\abovedisplayshortskip}{-5pt}

{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}
\listoffigures
\listoftables
\hypertarget{prefazione}{%
\chapter*{Prefazione}\label{prefazione}}


La presente dispensa contiene il materiale delle lezioni dell'insegnamento di \emph{Costruzione e validazione di strumenti di misura dell'efficacia dell'intervento psicologico in neuropsicologia} B020881 (B213) rivolto agli studenti del secondo anno del Corso di Laurea Magistrale in Psicologia Clinica e della Salute e Neuropsicologia (curriculum: assessment e intervento psicologici in neuropsicologia - E21), A.A. 2021-2022. L'insegnamento si propone di fornire agli studenti un'introduzione all'assessment psicologico, ovvero un insieme di conoscenze/competenze che si pongono all'intersezione tra psicometria, statistica e informatica.

Nello specifico, l'insegnamento si focalizzerà sull'analisi fattoriale confermativa (\emph{confermatory factor analysis}, CFA) e sull'analisi fattoriale esplorativa, (\emph{explorative factor analysis}, EFA), cioè sugli strumenti che vengono usati durante il processo di sviluppo dei test psicometrici, ovvero che vengono usati per esaminare la struttura latente di una scala psicologica (ad esempio un questionario). In questo contesto, la CFA viene utilizzata per verificare il numero di dimensioni sottostanti gli indicatori (fattori) e l'intensità delle relazioni item-fattore (saturazioni fattoriali). La CFA consente anche di capire di come dovrebbe essere svolto lo scoring di un test. Quando la struttura latente è multifattoriale (cioè, a due o più fattori), il numero di fattori è indicativo del numero di sottoscale e di come esse dovrebbero essere codificate. La CFA è un importante strumento analitico anche per altri aspetti della valutazione psicometrica. Può essere utilizzata per stimare l'affidabilità di scala dei test psicometrici in modo da evitare i problemi della teoria classica dei test (ad es. alpha di Cronbach). Dati i recenti progressi nell'analisi dei dati categoriali, ora la CFA offre un quadro analitico comparabile a quello offerto dalla teoria di risposta agli item (IRT). In effetti, secondo \citet{brown2015confirmatory}, la CFA offre una maggiore flessibilità analitica rispetto al modello IRT tradizionale.

Un costrutto è un concetto teorico che può essere operazionalizzato nei termini di un fattore. In psicologia clinica, psichiatria e neuropsicologia, ad esempio, i disturbi mentali sono costrutti manifestati da vari insiemi di sintomi che sono riportati dal paziente o osservati da altri. La CFA è uno strumento analitico indispensabile per la validazione dei costrutti psicologici. I risultati della CFA possono fornire prove convincenti della validità convergente e discriminante dei costrutti teorici. La validità convergente è indicata dall'evidenza che diversi indicatori di costrutti teoricamente simili o sovrapposti sono fortemente correlati. La validità discriminante è indicata dai risultati che mostrano che gli indicatori di costrutti teoricamente distinti sono altamente incorrelati. Un punto di forza fondamentale degli approcci CFA per la costruzione e la validazione di uno strumento psicometrico è che le risultanti stime di validità convergente e discriminante sono corrette per l'errore di misurazione. Pertanto, la CFA fornisce un quadro analitico migliore rispetto ai metodi tradizionali che non tengono conto dell'errore di misurazione (ad esempio, gli approcci ordinari ai minimi quadrati come la correlazione/regressione multipla, i quali presuppongono che le variabili nell'analisi siano prive di errori di misurazione).

Spesso, parte della covariazione delle misure osservate è dovuta a fonti diverse dai fattori latenti di interesse. Questa covariazione aggiuntiva spesso riflette la varianza del metodo utilizzato per la misurazione. Gli effetti del metodo possono verificarsi anche all'interno di un'unica modalità di valutazione. Ad esempio, effetti del metodo sono solitamente presenti nei questionari che contengono una combinazione di elementi formulati positivamente e negativamente. Sfortunatamente, l'EFA non è in grado di stimare gli effetti del metodo. In effetti, l'uso di EFA quando esistono effetti del metodo può produrre risultati fuorvianti, ovvero suggerire la presenza di fattori aggiuntivi che corrispondono invece ad artefatti della misurazione. Nella CFA, invece, gli effetti del metodo possono essere specificati come parte della teoria dell'errore del modello di misurazione.

Un altro punto di forza della CFA è la sua capacità di affrontare il problema della generalizzabilità del modello di misurazione tra gruppi di individui o nel tempo. La valutazione dell'invarianza della misura è un aspetto importante dello sviluppo del test. Se un test è destinato a essere somministrato in una popolazione eterogenea, si dovrebbe stabilire che le sue proprietà di misurazione sono equivalenti in sottogruppi della popolazione (es. sesso, razza). Si dice che un test è distorto quando alcuni dei suoi elementi non misurano il costrutto sottostante in modo comparabile tra gruppi di rispondenti. Il test fornisce una stima distorta se, ad esempio, per un dato livello di vera intelligenza, gli uomini tendono a ottenere un punteggio di QI più alto rispetto alle donne. Il problema della generalizzabilità della validità del costrutto tra i gruppi può essere affrontato nella CFA esaminando gruppi multipli mediante modelli MIMIC (indicatori multipli, cause multiple). Inotre, è possibile chiedersi se il modello di misurazione sia equivalente tra i gruppi. Le soluzioni CFA a gruppi multipli vengono anche utilizzate per esaminare l'invarianza della misurazione longitudinale. Questo è un aspetto molto importante dell'analisi delle variabili latenti dei progetti di misure ripetute. In assenza di tale valutazione, non è possibile determinare se il cambiamento temporale in un costrutto sia dovuto a un vero cambiamento dei rispondenti o a cambiamenti nel modo di rispondere alla scala nel tempo. L'analisi a gruppi multipli può essere applicata a qualsiasi tipo di modello CFA. Ad esempio, queste procedure possono essere incorporate nell'analisi dei dati multitratto-multimetodo per esaminare la generalizzabilità della validità del costrutto tra gruppi.

In questo insegnamento la discussione delle teciche della CFA sarà preceduta da un'introduzione relativa alla EFA e la teoria classica dei test. La EFA, infatti, può essere concepita il metodo che viene utilizzato nei primi passi dello sviluppo di una scala psicometria, mentre la teoria classica dei test rappresenta la cornice teorica di partenza, di cui la CFA e i modelli di equazioni strutturali costituiscono uno sviluppo.

L'insegnamento pone una grande enfasi non solo sulla comprensione dei concetti teorici necessari per la costruzione e la validazione di uno strumento di misura in psicologia, ma anche sulla capacità di applicare tali concetti in situazioni concrete. Di conseguenza, la discussione dei concetti sarà sempre accompagnata da applicazioni pratiche. Tali applicazioni richiedono l'uso di un software. In questo insegnamento useremo \(\textsf{R}\) \citep{rmanual} quale linguaggio di programmazione probabilistica e, tra gli altri, il pacchetto \texttt{lavaan} che consente di svolgere le analisi statistiche della CFA e della EFA \citep{beaujean2014latent}. La teoria classica dei test verrà descritta con riferimento al classico testo di \citet{lord1968statistical}. Questa dispensa, inoltre, segue da vicino la trattazione della CFA fornita nei testi di \citet{mcdonald2013test} e di \citet{brown2015confirmatory}.

Trattando di argomenti avanzati, questo insegnamento presuppone la conoscenza di base dei concetti fondamentali della teoria delle probabilità; presuppone inoltre il possesso delle conoscenze di base necessarie per procedere all'utilizzo di \(\textsf{R}\). Informazioni su tali argomenti sono forniti nella dispensa di Psicometria (A.A. 2021-2022).

\begin{flushright}
Corrado Caudek\\
Marzo 2022 \end{flushright}

\mainmatter

\hypertarget{part-il-modello-lineare}{%
\part{Il modello lineare}\label{part-il-modello-lineare}}

\hypertarget{lanalisi-di-regressione}{%
\chapter{L'analisi di regressione}\label{lanalisi-di-regressione}}

Conoscere l'analisi di regressione aiuta a capire la teoria classica dei test, l'analisi fattoriale e i modelli di equazioni strutturali. Sebbene le tecniche dell'analisi di regressione analizzino solo le variabili osservate, i principi della regressione costituiscono la base delle tecniche più avanzate che includono anche le variabili latenti.

\hypertarget{regressione-bivariata}{%
\section{Regressione bivariata}\label{regressione-bivariata}}

Il modello di regressione bivariata descrive l'associazione tra il valore atteso di \(Y \mid x_i\) e \(x\) nei termini di una relazione lineare:

\[
\mathbb{E}(Y \mid x_i) = \alpha + \beta x_i,
\] dove i valori \(x_i\) sono considerati fissi per disegno. Nel modello ``classico'', si assume che le distribuzioni \(Y \mid x_i\) siano Normali con deviazione standard \(\sigma_\varepsilon\).

Il significato dei coefficienti di regressione è semplice:

\begin{itemize}
\tightlist
\item
  \(\alpha\) è il valore atteso di \(Y\) quando \(X = 0\);
\item
  \(\beta\) è l'incremento atteso nel valore atteso di \(Y\) quando \(X\) aumenta di un'unità.
\end{itemize}

Per fare un esempio, consideriamo i dati dell'antropologo Sahlins, il quale si è chiesto se esiste un'associazione tra l'ampiezza del clan (\texttt{consumers}) e l'area occupata da quel clan (\texttt{acres}) in una popolazione di cacciatori-raccoglitori. I dati sono i seguenti:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data}\NormalTok{(Sahlins)}
\FunctionTok{head}\NormalTok{(Sahlins)}
\CommentTok{\#\textgreater{}   consumers acres}
\CommentTok{\#\textgreater{} 1      1.00  1.71}
\CommentTok{\#\textgreater{} 2      1.08  1.52}
\CommentTok{\#\textgreater{} 3      1.15  1.29}
\CommentTok{\#\textgreater{} 4      1.15  3.09}
\CommentTok{\#\textgreater{} 5      1.20  2.21}
\CommentTok{\#\textgreater{} 6      1.30  2.26}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Sahlins }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ consumers, }\AttributeTok{y =}\NormalTok{ acres)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_smooth}\NormalTok{(}\AttributeTok{method =}\NormalTok{ lm, }\AttributeTok{se =} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{cfa_book_files/figure-latex/unnamed-chunk-4-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fm }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(acres }\SpecialCharTok{\textasciitilde{}}\NormalTok{ consumers, }\AttributeTok{data =}\NormalTok{ Sahlins)}
\NormalTok{fm}\SpecialCharTok{$}\NormalTok{coef}
\CommentTok{\#\textgreater{} (Intercept)   consumers }
\CommentTok{\#\textgreater{}      1.3756      0.5163}
\end{Highlighting}
\end{Shaded}

Dalla figura notiamo che, se \texttt{consumers} aumenta di un'unità (da 1.2 a 2.2), allora la retta di regressione (ovvero, il valore atteso di \(Y\)) aumenta di circa 0.5 punti -- esattamente, aumenta di 0.5163 punti, come indicato dalla stima del coefficiente \(\beta\). L'interpretazione del coefficiente \(\alpha\) è più problematica, perché non ha senso pensare ad un clan di ampiezza 0. Per affrontare questo problema, centriamo il predittore.

\hypertarget{regressori-centrati}{%
\subsection{Regressori centrati}\label{regressori-centrati}}

Esprimiamo la variabile \texttt{consumers} nei termini degli scarti dalla media:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Sahlins }\OtherTok{\textless{}{-}}\NormalTok{ Sahlins }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{xc =}\NormalTok{ consumers }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(consumers)}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

Svolgiamo nuovamente l'analisi di regressione con il nuovo predittore:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fm1 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(acres }\SpecialCharTok{\textasciitilde{}}\NormalTok{ xc, }\AttributeTok{data =}\NormalTok{ Sahlins)}
\NormalTok{fm1}\SpecialCharTok{$}\NormalTok{coef}
\CommentTok{\#\textgreater{} (Intercept)          xc }
\CommentTok{\#\textgreater{}      2.1620      0.5163}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Sahlins }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ xc, }\AttributeTok{y =}\NormalTok{ acres)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_smooth}\NormalTok{(}\AttributeTok{method =}\NormalTok{ lm, }\AttributeTok{se =} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{cfa_book_files/figure-latex/unnamed-chunk-8-1} \end{center}

La stima di \(\beta\) è rimasta invariata ma ora possiamo attribuire un significato alla stima di \(\alpha\): questo coefficiente indica il valore atteso della \(Y\) quando \(X\) assume il suo valore medio.

\hypertarget{minimi-quadrati}{%
\subsection{Minimi quadrati}\label{minimi-quadrati}}

La stima dei coefficienti del modello di regressione può essere effettuata in modi diversi: massima verosimiglianza o metodi bayesiani. Se ci limitiamo qui alla massima verosimiglianza possiamo semplificare il problema assumento che le distribuzioni condizionate \(Y \mid x\) siano Normali. In tali circostanze, la stima dei coefficienti del modello di regressione può essere trovata con il metodo dei minimi quadrati.

In pratica, questo significa trovare i coefficienti \(a\) e \(b\) che minimizzano

\[
SS_{\text{res}} = \sum(y_i - \hat{y}_i)^2,
\] con \(\hat{y}_i = a + b x_i\).

Per fornire un'idea di come questo viene fatto, usiamo una simulazione. Per semplicità, supponiamo di conoscere \(a = 1.3756445\) e di volere stimare \(b\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}}\NormalTok{ Sahlins}\SpecialCharTok{$}\NormalTok{consumers}
\NormalTok{y }\OtherTok{\textless{}{-}}\NormalTok{ Sahlins}\SpecialCharTok{$}\NormalTok{acres}
\NormalTok{a }\OtherTok{\textless{}{-}} \FloatTok{1.3756445}

\NormalTok{nrep }\OtherTok{\textless{}{-}} \FloatTok{1e3}
\NormalTok{b }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\AttributeTok{length.out =}\NormalTok{ nrep)}

\NormalTok{ssres }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\ConstantTok{NA}\NormalTok{, nrep)}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{nrep) \{}
\NormalTok{  yhat }\OtherTok{\textless{}{-}}\NormalTok{ a }\SpecialCharTok{+}\NormalTok{ b[i] }\SpecialCharTok{*}\NormalTok{ x}
\NormalTok{  ssres[i] }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{((y }\SpecialCharTok{{-}}\NormalTok{ yhat)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Un grafico di \(SS_{\text{res}}\) in funzione di \(b\) mostra che il valore \(b\) che minimizza \(SS_{\text{res}}\) corrisponde, appunto, a 0.5163.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{tibble}\NormalTok{(b, ssres) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ b, }\AttributeTok{y =}\NormalTok{ ssres)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{cfa_book_files/figure-latex/unnamed-chunk-10-1} \end{center}

\hypertarget{relazione-tra-b-e-r}{%
\subsection{\texorpdfstring{Relazione tra \(b\) e \(r\)}{Relazione tra b e r}}\label{relazione-tra-b-e-r}}

Un altro modo per interpretare \(b\) è quello di considerare la relazione tra la pendenza della retta di regressione e il coefficiente di correlazione:

\[
b_X = r_{XY} \frac{S_X}{S_Y}
\]

L'equazione precedente rende chiaro che, se i dati sono standardizzati, \(b = r\).

Verifichiamo:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Sahlins }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{select}\NormalTok{(acres, consumers) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{cor}\NormalTok{()}
\CommentTok{\#\textgreater{}            acres consumers}
\CommentTok{\#\textgreater{} acres     1.0000    0.3757}
\CommentTok{\#\textgreater{} consumers 0.3757    1.0000}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fm2 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(}\FunctionTok{scale}\NormalTok{(acres) }\SpecialCharTok{\textasciitilde{}} \FunctionTok{scale}\NormalTok{(consumers), }\AttributeTok{data =}\NormalTok{ Sahlins)}
\NormalTok{fm2}\SpecialCharTok{$}\NormalTok{coef}
\CommentTok{\#\textgreater{}      (Intercept) scale(consumers) }
\CommentTok{\#\textgreater{}        9.917e{-}17        3.757e{-}01}
\end{Highlighting}
\end{Shaded}

\hypertarget{attenuazione}{%
\subsection{Attenuazione}\label{attenuazione}}

Il fenomeno dell'attenuazione si verifica quando \(X\) viene misurato con una componente di errore. Esaminiamo la seguente simulazione.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1234}\NormalTok{)}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{100}
\NormalTok{x }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{10}\NormalTok{, }\FloatTok{1.5}\NormalTok{)}
\NormalTok{y }\OtherTok{\textless{}{-}} \FloatTok{1.5} \SpecialCharTok{*}\NormalTok{ x }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{0}\NormalTok{, }\DecValTok{2}\NormalTok{)}
\FunctionTok{tibble}\NormalTok{(x, y) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(x, y)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{cfa_book_files/figure-latex/unnamed-chunk-13-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sim\_dat }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(x, y)}
\NormalTok{fm }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x, sim\_dat)}
\NormalTok{fm}\SpecialCharTok{$}\NormalTok{coef}
\CommentTok{\#\textgreater{} (Intercept)           x }
\CommentTok{\#\textgreater{}      0.4221      1.4652}
\end{Highlighting}
\end{Shaded}

Questi sono i coefficienti di regressione quando \(X\) è misurata senza errori.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sim\_dat }\OtherTok{\textless{}{-}}\NormalTok{ sim\_dat }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{x1 =}\NormalTok{ x }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{0}\NormalTok{, }\DecValTok{2}\NormalTok{)}
\NormalTok{  )}

\NormalTok{fm1 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1, sim\_dat)}
\NormalTok{fm1}\SpecialCharTok{$}\NormalTok{coef}
\CommentTok{\#\textgreater{} (Intercept)          x1 }
\CommentTok{\#\textgreater{}      8.3872      0.6296}
\end{Highlighting}
\end{Shaded}

Aggiungendo una componente d'errore su \(X\), la grandezza del coefficiente \(b\) diminuisce.

\hypertarget{coefficiente-di-determinazione}{%
\subsection{Coefficiente di determinazione}\label{coefficiente-di-determinazione}}

Tecnicamente, il coefficiente di determinazione è dato da:

\[
R^2 = \frac{\sum(\hat{y} - \bar{y})^2}{\sum(y_i - \bar{y})^2}
\]

Al denominatore abbiamo la \emph{devianza totale}, ovvero una misura della dispersione di \(y_i\) rispetto alla media \(\bar{y}\). Al numeratore abbiamo una misura della dispersione del valore atteso della \(Y\) rispetto alla sua media. Il rapporto, dunque, ci dice qual è la quota della variabilità totale di \(Y\) che può essere predetta in base al modello lineare.

Per i dati di Sahlins abbiamo:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mod }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(acres }\SpecialCharTok{\textasciitilde{}}\NormalTok{ consumers, }\AttributeTok{data =}\NormalTok{ Sahlins)}
\NormalTok{a }\OtherTok{\textless{}{-}}\NormalTok{ mod}\SpecialCharTok{$}\NormalTok{coef[}\DecValTok{1}\NormalTok{]}
\NormalTok{b }\OtherTok{\textless{}{-}}\NormalTok{ mod}\SpecialCharTok{$}\NormalTok{coef[}\DecValTok{2}\NormalTok{]}
\NormalTok{yhat }\OtherTok{\textless{}{-}}\NormalTok{ a }\SpecialCharTok{+}\NormalTok{ b }\SpecialCharTok{*}\NormalTok{ Sahlins}\SpecialCharTok{$}\NormalTok{consumers}
\NormalTok{ss\_tot }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{((Sahlins}\SpecialCharTok{$}\NormalTok{acres }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(Sahlins}\SpecialCharTok{$}\NormalTok{acres))}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\NormalTok{ss\_reg }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{((yhat }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(Sahlins}\SpecialCharTok{$}\NormalTok{acres))}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\NormalTok{r2 }\OtherTok{\textless{}{-}}\NormalTok{ ss\_reg }\SpecialCharTok{/}\NormalTok{ ss\_tot}
\NormalTok{r2}
\CommentTok{\#\textgreater{} [1] 0.1411}
\end{Highlighting}
\end{Shaded}

Verifichiamo:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(mod)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Call:}
\CommentTok{\#\textgreater{} lm(formula = acres \textasciitilde{} consumers, data = Sahlins)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Residuals:}
\CommentTok{\#\textgreater{}     Min      1Q  Median      3Q     Max }
\CommentTok{\#\textgreater{} {-}0.8763 {-}0.1873 {-}0.0211  0.2135  1.1206 }
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Coefficients:}
\CommentTok{\#\textgreater{}             Estimate Std. Error t value Pr(\textgreater{}|t|)   }
\CommentTok{\#\textgreater{} (Intercept)    1.376      0.468    2.94   0.0088 **}
\CommentTok{\#\textgreater{} consumers      0.516      0.300    1.72   0.1026   }
\CommentTok{\#\textgreater{} {-}{-}{-}}
\CommentTok{\#\textgreater{} Signif. codes:  }
\CommentTok{\#\textgreater{} 0 \textquotesingle{}***\textquotesingle{} 0.001 \textquotesingle{}**\textquotesingle{} 0.01 \textquotesingle{}*\textquotesingle{} 0.05 \textquotesingle{}.\textquotesingle{} 0.1 \textquotesingle{} \textquotesingle{} 1}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Residual standard error: 0.454 on 18 degrees of freedom}
\CommentTok{\#\textgreater{} Multiple R{-}squared:  0.141,  Adjusted R{-}squared:  0.0934 }
\CommentTok{\#\textgreater{} F{-}statistic: 2.96 on 1 and 18 DF,  p{-}value: 0.103}
\end{Highlighting}
\end{Shaded}

Da cui deriva che \(R^2\) è uguale al quadrato del coefficiente di correlazione:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cor}\NormalTok{(Sahlins}\SpecialCharTok{$}\NormalTok{acres, Sahlins}\SpecialCharTok{$}\NormalTok{consumers)}\SpecialCharTok{\^{}}\DecValTok{2}
\CommentTok{\#\textgreater{} [1] 0.1411}
\end{Highlighting}
\end{Shaded}

\hypertarget{errore-standard-della-regressione}{%
\subsection{Errore standard della regressione}\label{errore-standard-della-regressione}}

L'errore standard della regressione è una stima della dispersione di \(y \mid x_i\) nella popolazione. Non è altro che la deviazione standard dei residui

\[
e = y_i - \hat{y}_i
\]

che, al denominatore, riporta \(n-2\). La ragione è che, per calcolare \(\hat{y}\), vengono ``perduti'' due gradi di libertà -- il calcolo di \(\hat{y}\) è basato sulla stima di due coefficienti: \(a\) e \(b\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{e }\OtherTok{\textless{}{-}}\NormalTok{ yhat }\SpecialCharTok{{-}}\NormalTok{ Sahlins}\SpecialCharTok{$}\NormalTok{acres}
\NormalTok{(}\FunctionTok{sum}\NormalTok{(e}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) }\SpecialCharTok{/}\NormalTok{ (}\FunctionTok{length}\NormalTok{(Sahlins}\SpecialCharTok{$}\NormalTok{acres) }\SpecialCharTok{{-}} \DecValTok{2}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{sqrt}\NormalTok{()}
\CommentTok{\#\textgreater{} [1] 0.4543}
\end{Highlighting}
\end{Shaded}

Il valore trovato corrisponde a quello riportato nell'output di \texttt{lm()}.

\hypertarget{regressione-multipla}{%
\section{Regressione multipla}\label{regressione-multipla}}

Nella regressione multipla vengono utilizzati \(k > 1\) predittori:

\[
y_i = \alpha + \sum_{j=1}^k \beta_j x_i + \varepsilon_i.
\] L'interpretazione geometrica è simile a quella del modello bivariato. Nel caso di due predittori, il valore atteso della \(y\) può essere rappresentato da un piano; nel caso di \(k > 2\) predittori, da un iper-piano. Nel caso di \(k=2\), tale piano è posto in uno spazio di dimensioni \(x_1\), \(x_2\) (che possiamo immaginare definire un piano orizzontale) e \(y\) (ortogonale a tale piano). La superficie piana che rappresenta \(\mathbb{E}(y)\) è inclinata in maniera tale che l'angolo tra il piano e l'asse \(x_1\) corrisponde a \(\beta_1\) e l'angolo tra il piano e l'asse \(x_2\) corrisponde a \(\beta_2\).

\hypertarget{significato-dei-coefficienti-parziali-di-regressione}{%
\subsection{Significato dei coefficienti parziali di regressione}\label{significato-dei-coefficienti-parziali-di-regressione}}

Ai coefficienti parziali del modello di regressione multipla possiamo assegnare la seguente interpretazione:

\emph{Il coefficiente parziale di regressione \(\beta_j\) rappresenta l'incremento atteso della \(y\) se \(x_j\) viene incrementata di un'unità, tenendo costante il valore delle altre variabili indipendenti.}

Un modo per interpretare la locuzione ``al netto dell'effetto delle altre variabili indipendenti'' è quello di esaminare la relazione tra la \(y\) parzializzata e la \(x_j\) parzializzata. In questo contesto, parzializzare significa decomporre una variabile di due componenti: una componente che è linearmente predicibile da una o più altre variabili e una componente che è linearmente incorrelata con tali varibili ``terze''.

Eseguiamo questa ``depurazione'' dell'effetto delle variabili ``terze'' sia sulla \(y\) sia su \(x_j\). A questo punto possiamo esaminare la relazione bivariata che intercorre tra la componente della \(y\) linearmente indipendente dalle variabili ``terze'' e la componente della \(x_j\) linearmente indipendente dalle variabili ``terze''. Il coefficiente di regressione bivariato così ottenuto è identico al coefficiente parziale di regressione nel modello di regressione multipla. Possiamo così ottenere un'interpretazione di \(\beta_j\).

Esaminiamo un caso concreto.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d }\OtherTok{\textless{}{-}}\NormalTok{ rio}\SpecialCharTok{::}\FunctionTok{import}\NormalTok{(}
\NormalTok{  here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{(}\StringTok{"data"}\NormalTok{, }\StringTok{"kidiq.dta"}\NormalTok{)}
\NormalTok{)}
\FunctionTok{glimpse}\NormalTok{(d)}
\CommentTok{\#\textgreater{} Rows: 434}
\CommentTok{\#\textgreater{} Columns: 5}
\CommentTok{\#\textgreater{} $ kid\_score \textless{}dbl\textgreater{} 65, 98, 85, 83, 115, 98, 69, 106, 1\textasciitilde{}}
\CommentTok{\#\textgreater{} $ mom\_hs    \textless{}dbl\textgreater{} 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\textasciitilde{}}
\CommentTok{\#\textgreater{} $ mom\_iq    \textless{}dbl\textgreater{} 121.12, 89.36, 115.44, 99.45, 92.75\textasciitilde{}}
\CommentTok{\#\textgreater{} $ mom\_work  \textless{}dbl\textgreater{} 4, 4, 4, 3, 4, 1, 4, 3, 1, 1, 1, 4,\textasciitilde{}}
\CommentTok{\#\textgreater{} $ mom\_age   \textless{}dbl\textgreater{} 27, 25, 27, 25, 27, 18, 20, 23, 24,\textasciitilde{}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fm }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(}
\NormalTok{  kid\_score }\SpecialCharTok{\textasciitilde{}}\NormalTok{ mom\_iq }\SpecialCharTok{+}\NormalTok{ mom\_work }\SpecialCharTok{+}\NormalTok{ mom\_age }\SpecialCharTok{+}\NormalTok{ mom\_hs,}
  \AttributeTok{data =}\NormalTok{ d}
\NormalTok{)}
\NormalTok{fm}\SpecialCharTok{$}\NormalTok{coef}
\CommentTok{\#\textgreater{} (Intercept)      mom\_iq    mom\_work     mom\_age }
\CommentTok{\#\textgreater{}     20.8226      0.5621      0.1337      0.2199 }
\CommentTok{\#\textgreater{}      mom\_hs }
\CommentTok{\#\textgreater{}      5.5612}
\end{Highlighting}
\end{Shaded}

Eseguiamo la parzializzazione di \(y\) in funzione delle variabili \texttt{mom\_work}, \texttt{mom\_age} e \texttt{mom\_hs}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fm\_y }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(kid\_score }\SpecialCharTok{\textasciitilde{}}\NormalTok{ mom\_work }\SpecialCharTok{+}\NormalTok{ mom\_age }\SpecialCharTok{+}\NormalTok{ mom\_hs, }\AttributeTok{data =}\NormalTok{ d)}
\end{Highlighting}
\end{Shaded}

Lo stesso per \texttt{mom\_iq}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fm\_x }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(mom\_iq }\SpecialCharTok{\textasciitilde{}}\NormalTok{ mom\_work }\SpecialCharTok{+}\NormalTok{ mom\_age }\SpecialCharTok{+}\NormalTok{ mom\_hs, }\AttributeTok{data =}\NormalTok{ d)}
\end{Highlighting}
\end{Shaded}

Esaminiamo ora la regressione bivariata tra le componenti parzializzate della \(y\) e di \(x_j\):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mod }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(fm\_y}\SpecialCharTok{$}\NormalTok{residuals }\SpecialCharTok{\textasciitilde{}}\NormalTok{ fm\_x}\SpecialCharTok{$}\NormalTok{residuals)}
\NormalTok{mod}\SpecialCharTok{$}\NormalTok{coef}
\CommentTok{\#\textgreater{}    (Intercept) fm\_x$residuals }
\CommentTok{\#\textgreater{}     {-}1.652e{-}15      5.621e{-}01}
\end{Highlighting}
\end{Shaded}

Si vede come il coefficiente di regressione bivariato risulta identico al corrispondente coefficiente parziale di regressione.

\hypertarget{relazioni-causali}{%
\subsection{Relazioni causali}\label{relazioni-causali}}

Un altro modo per interpretare i coefficienti parziali di regressione è nell'ambito dei quelli che vengono chiamati i \emph{path diagrams}. I diagrammi di percorso, che tratteremo in seguito e qui solo anticipiamo, descrivono le relazioni ``causali'' tra variabili: le variabili a monte del diagramma di percorso indicono le ``cause'' esogene e le variabili a valle indicano gli effetti, ovvero le variabili endogene. I coefficienti di percorso rappresentati graficamente come frecce orientate corrispondono all'effetto \emph{diretto} sulla variabile verso cui punta la freccia della variabile a monte della freccia. Tali coefficienti di percorso non sono altro che i coefficienti parziali di regressione del modello di regressione multipla. In questo contesto, indicano l'effetto atteso \emph{diretto} sulla variabile endogena dell'incremento di un'unità della variabile esogena, lasciano immutate tutte le altre relazioni strutturali del modello.

Usiamo la funzione \texttt{sem()} del pacchetto \texttt{lavaan} per definire il modello rappresentato nel successivo diagramma di percorso:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model }\OtherTok{\textless{}{-}} \StringTok{"}
\StringTok{  kid\_score \textasciitilde{} mom\_hs + mom\_iq + mom\_work + mom\_age}
\StringTok{"}
\end{Highlighting}
\end{Shaded}

Adattiamo il modello ai dati

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{sem}\NormalTok{(model, }\AttributeTok{data =}\NormalTok{ d)}
\end{Highlighting}
\end{Shaded}

Il diagramma di percorso si ottiene con le seguenti istruzioni:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{semPaths}\NormalTok{(}
\NormalTok{  fit, }\StringTok{"est"}\NormalTok{,}
  \AttributeTok{posCol =} \FunctionTok{c}\NormalTok{(}\StringTok{"black"}\NormalTok{),}
  \AttributeTok{edge.label.cex =} \FloatTok{0.9}\NormalTok{,}
  \AttributeTok{sizeMan =} \DecValTok{7}\NormalTok{,}
  \AttributeTok{what =} \StringTok{"path"}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{cfa_book_files/figure-latex/unnamed-chunk-27-1} \end{center}

Come indicato nel diagramma, l'effetto diretto di \texttt{mom\_iq} su \texttt{kid\_score} è identico al corrispondente coefficiente parziale di regressione.

\hypertarget{errore-di-specificazione}{%
\subsection{Errore di specificazione}\label{errore-di-specificazione}}

Spiritosamente chiamato ``heartbreak of L.O.V.E.'' (Left-Out Variable Error; \citet{mauro1990understanding}), l'errore di specificazione è una caratteristica fondamentale dei modelli di regressione che deve sempre essere tenuta a mente quando interpretiamo i risultati di questa analisi statistica. L'errore di specificazione si verifica quando escludiamo dal modello di regressione una variabile che

\begin{itemize}
\tightlist
\item
  è associata con altre variabili nel modello,
\item
  ha un effetto diretto sulla \(y\).
\end{itemize}

Come conseguenza dell'errore di specificazione, la direzione e il segno dei coefficienti parziali di regressione risultano sistematicamente distorti.

Consideriamo un esempio con dati simulati nei quali immaginiamo che la prestazione sia positivamente associata alla motivazione e negativamente associata all'ansia. Immaginiamo inoltre che vi sia una correlazione positiva tra ansia a motivazione. Ci chiediamo cosa succede al coefficiente parziale della variabile ``motivazione'' se la variabile ``ansia'' viene esclusa dal modello di regressione.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{400}
\NormalTok{anxiety }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{10}\NormalTok{, }\FloatTok{1.5}\NormalTok{)}
\NormalTok{motivation }\OtherTok{\textless{}{-}} \FloatTok{4.0} \SpecialCharTok{*}\NormalTok{ anxiety }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{0}\NormalTok{, }\FloatTok{3.5}\NormalTok{)}
\FunctionTok{cor}\NormalTok{(anxiety, motivation)}
\CommentTok{\#\textgreater{} [1] 0.8618}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{performance }\OtherTok{\textless{}{-}} \FloatTok{0.5} \SpecialCharTok{*}\NormalTok{ motivation }\SpecialCharTok{{-}} \FloatTok{5.0} \SpecialCharTok{*}\NormalTok{ anxiety }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(n, }\DecValTok{0}\NormalTok{, }\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sim\_dat2 }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(performance, motivation, anxiety)}
\NormalTok{fm1 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(performance }\SpecialCharTok{\textasciitilde{}}\NormalTok{ motivation }\SpecialCharTok{+}\NormalTok{ anxiety, sim\_dat2)}
\FunctionTok{coef}\NormalTok{(fm1)}
\CommentTok{\#\textgreater{} (Intercept)  motivation     anxiety }
\CommentTok{\#\textgreater{}      1.3712      0.4954     {-}5.1052}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fm2 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(performance }\SpecialCharTok{\textasciitilde{}}\NormalTok{ motivation, sim\_dat2)}
\FunctionTok{summary}\NormalTok{(fm2)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Call:}
\CommentTok{\#\textgreater{} lm(formula = performance \textasciitilde{} motivation, data = sim\_dat2)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Residuals:}
\CommentTok{\#\textgreater{}     Min      1Q  Median      3Q     Max }
\CommentTok{\#\textgreater{} {-}13.501  {-}3.409   0.005   3.311  12.616 }
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Coefficients:}
\CommentTok{\#\textgreater{}             Estimate Std. Error t value Pr(\textgreater{}|t|)    }
\CommentTok{\#\textgreater{} (Intercept) {-}12.3972     1.4459   {-}8.57  2.2e{-}16 ***}
\CommentTok{\#\textgreater{} motivation   {-}0.4372     0.0355  {-}12.31  \textless{} 2e{-}16 ***}
\CommentTok{\#\textgreater{} {-}{-}{-}}
\CommentTok{\#\textgreater{} Signif. codes:  }
\CommentTok{\#\textgreater{} 0 \textquotesingle{}***\textquotesingle{} 0.001 \textquotesingle{}**\textquotesingle{} 0.01 \textquotesingle{}*\textquotesingle{} 0.05 \textquotesingle{}.\textquotesingle{} 0.1 \textquotesingle{} \textquotesingle{} 1}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Residual standard error: 4.87 on 398 degrees of freedom}
\CommentTok{\#\textgreater{} Multiple R{-}squared:  0.276,  Adjusted R{-}squared:  0.274 }
\CommentTok{\#\textgreater{} F{-}statistic:  151 on 1 and 398 DF,  p{-}value: \textless{}2e{-}16}
\end{Highlighting}
\end{Shaded}

Il risultato prodotto dal modello di regressione è sbagliato: come conseguenza dell'errore di specificazione, il segno del coefficiente parziale di regressione della variabile ``motivazione'' è negativo, anche se nel vero modello di regressione tale coefficiente ha il segno opposto. Quindi, se noi interpretassimo il coefficiente parziale ottenuto in termini casuali, saremmo portati a concludere che la motivazione fa diminuire la prestazione anche se, in realtà (nel modello generatore dei dati), è vero l'opposto.

È facile vedere perché questo si verifica. Supponiamo che il vero modello sia

\[
y = \alpha + \beta_1 X_1 + \beta_2 X_2 + \varepsilon
\] che verrebbe stimato con

\[
y = a + b_1 X_1 + b_2 X_2 + e.
\] Supponiamo che il ricercatore creda invece che

\[
y = \alpha^\prime + \beta_1^\prime X_1 + \varepsilon^\prime
\]

e quindi stimi

\[
y = a^\prime + b_1^\prime X_1 + e^\prime
\]

omettendo \(X_2\) dal modello. Ci chiediamo che relazione ci sia tra \(b_1^\prime\) e \(b_1\).

La formula per \(b_1^\prime\) è

\begin{equation}
\begin{aligned}
b_1^\prime &= \frac{\mbox{Cov}(X_1, Y)}{\mbox{Var}(X_1)}\notag\\
&= \frac{\mbox{Cov}(X_1, a + b_1 X_1 + b_2 X_2 + e)}{\mbox{Var}(X_1)}\notag\\
&= \frac{\mbox{Cov}(X_1, a)+b_1 \mbox{Cov}(X_1, X_1) + b_2 \mbox{Cov}(X_1, X_2) + \mbox{Cov}(X_1, e)}{\mbox{Var}(X_1)}\notag\\
&= \frac{0 + b_1 \mbox{Var}(X_1) + b_2 \mbox{Cov}(X_1, X_2) + 0}{\mbox{Var}(X_1)}\notag\\
&= b_1 + b_2 \frac{\mbox{Cov}(X_1, X_2)}{\mbox{Var}(X_1)}.
\end{aligned}
\end{equation}

Quindi, se \(X_2\) viene erroneamente omesso dal modello, abbiamo che

\[
\mathbb{E}(b_1^\prime) = \beta_1 + \beta_2 \frac{\sigma_{12}}{\sigma_1^2}.
\] Verifichiamo per i dati dell'esempio che stiamo discutendo. Nel caso presente, \(X_1\) è \texttt{motivation} e \(X_2\) + \texttt{anxiety}. Dunque, applicando la formula precedente, otteniamo lo stesso valore per il coefficiente di regressione associato a \texttt{motivation} che era stato ottenuto adattando ai dati il modello \texttt{performance\ \textasciitilde{}\ motivation}, ovvero:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fm1}\SpecialCharTok{$}\NormalTok{coef[}\DecValTok{2}\NormalTok{] }\SpecialCharTok{+}\NormalTok{ fm1}\SpecialCharTok{$}\NormalTok{coef[}\DecValTok{3}\NormalTok{] }\SpecialCharTok{*}
  \FunctionTok{cov}\NormalTok{(sim\_dat2}\SpecialCharTok{$}\NormalTok{motivation, sim\_dat2}\SpecialCharTok{$}\NormalTok{anxiety) }\SpecialCharTok{/}
  \FunctionTok{var}\NormalTok{(sim\_dat2}\SpecialCharTok{$}\NormalTok{motivation)}
\CommentTok{\#\textgreater{} motivation }
\CommentTok{\#\textgreater{}    {-}0.4372}
\end{Highlighting}
\end{Shaded}

In conclusione, \(b_1^\prime\) è uno stimatore distorto di \(\beta_1\). Si noti che questa distorsione non scomparirà all'aumentare della numerosità campionaria, il che (in termini statistici) ci porta a concludere che un tale stimatore è \emph{inconsistente}. Quello che succede in pratica è che alla variabile \(X_1\) vengono attribuiti gli effetti delle variabili che sono state omesse dal modello. Si noti che una tale distorsione sistematica di \(b_1^\prime\) può essere evitata solo se si verificano due condizioni:

\begin{itemize}
\tightlist
\item
  \(\beta_2 = 0\). Questo è ovvio, dato che, se \(\beta_2 = 0\), ciò significa che il modello non è specificato in modo errato, cioè \(X_2\) non appartiene al modello perché non ha un effetto diretto sulla \(Y\).
\item
  \(\sigma_{12} = 0\). Cioè, se \(X_1\) e \(X_2\) sono incorrelate, allora l'omissione di una delle due variabili non comporta stime distorte dell'effetto dell'altra.
\end{itemize}

\hypertarget{soppressione}{%
\subsection{Soppressione}\label{soppressione}}

Le conseguenze dell'errore di specificazione sono chiamate ``soppressione'' (\emph{suppression}). In generale, si ha soppressione quando (1) il valore assoluto del peso beta di un predittore è maggiore di quello della sua correlazione bivariata con il criterio o (2) i due hanno segni opposti.

\begin{itemize}
\tightlist
\item
  L'esempio descritto sopra è un caso di \emph{soppressione negativa}, dove il predittore ha correlazioni bivariate positive con il criterio, ma si riceve un peso beta negativo nell'analisi di regressione multipla.
\item
  Un secondo tipo di soppressione è la \emph{soppressione classica}, in cui un predittore non è correlato al criterio ma riceve un peso beta diverso da zero se un altro predittore viene controllato.
\item
  C'è anche la \emph{soppressione reciproca} che può verificarsi quando due variabili sono correlate positivamente con il criterio ma negativamente tra loro.
\end{itemize}

\hypertarget{stepwise-regression}{%
\subsection{Stepwise regression}\label{stepwise-regression}}

Un'implicazione della soppressione è che i predittori non dovrebbero essere selezionati in base ai valori delle correlazioni bivariate con il criterio. Queste associazioni di ordine zero non controllano gli effetti degli altri predittori, quindi i loro valori possono essere fuorvianti rispetto ai coefficienti di regressione parziale per le stesse variabili. Per lo stesso motivo, il fatto che le correlazioni bivariate con il criterio siano statisticamente significative o meno è irrilevante per quanto riguarda la selezione dei predittori. Sebbene le procedure informatiche di regressione rendano facile tali processi di selezione dei predittori, i ricercatori dovrebbero evitare di usare tali metodi. Il rischio è che anche piccole, ma non rilevate, non-linearità o effetti indiretti tra i predittori possano seriamente distocere i coefficienti di regressione parziale. È meglio selezionare giudiziosamente il minor numero di predittori sulla base di ragioni teoriche o dei risultati di ricerche precedenti.

Una volta selezionati, ci sono due modi di base per inserire i predittori nell'equazione di regressione: uno consiste nell'inserire tutti i predittori contemporaneamente. L'altro è inserirli nel corso di una serie di passaggi, ovvero mediante usando una procedura sequenziale. L'ordine di ingresso può essere determinato in base a uno di due diversi standard: teorici (razionali) o empirici (statistici). Lo standard razionale corrisponde alla regressione gerarchica, in cui si comunica al computer un ordine fisso per inserire i predittori. Ad esempio, a volte le variabili demografiche vengono inserite nel primo passaggio, quindi nel secondo passaggio viene inserita una variabile psicologica di interesse. Questo ordine non solo controlla le variabili demografiche ma permette anche di valutare il potere predittivo della variabile psicologica, al di là di quello delle semplici variabili demografiche. Quest'ultimo può essere stimato come l'aumento della correlazione multipla al quadrato, o \(\Delta R^2\), da quella della fase 1 con solo predittori demografici a quella della fase 2 con tutti i predittori nell'equazione di regressione.

Un esempio di standard statistico è la regressione \emph{stepwise}, in cui il computer seleziona l'inserimento dei predittori in base esclusivamente alla significatività statistica; cioè, viene chiesto: quale predittore, se inserito nell'equazione, avrebbe il valore\_\(p\) più piccolo per il test del suo coefficiente di regressione parziale? Dopo la selezione, i predittori in una fase successiva possono essere rimossi dall'equazione di regressione in base ai loro valori-\(p\) (ad esempio, se \(p \geq\) .05). Il processo stepwise si interrompe quando, aggiungendo più predittori, \(\Delta R^2\) non migliora. Varianti della regressione stepwise includono \emph{forward inclusion}, in cui i predittori selezionati non vengono successivamente rimossi dal modello, e \emph{backward elimination}, che inizia con tutti i predittori nel modello per poi rimuoverne alcuni in passi successivi. I problemi relativi ai metodi stepwise sono così gravi da essere effettivamente banditi in alcuni giornali. Un problema è che fanno leva su risultati che si ottengono per caso, in dipendenza delle idiosincrasie del campione (quindi, non replicabili).

In secondo luogo, una volta che un insieme finale di predittori selezionati razionalmente è stato inserito nell'equazione di regressione, tali predittori non dovrebbero essere successivamente rimossi se i loro coefficienti di regressione non sono statisticamente significativi: il ricercatore non dovrebbe sentirsi in dovere di lasciar perdere ogni predittore che non risulta statisticamente significativo. In campioni piccoli, la potenza dei test di significatività è bassa e la rimozione di un predittore non significativo può alterare sostanzialmente la soluzione. Se c'è una buona ragione per includere un predittore, allora è meglio lasciarlo nel modello, fino a prova contraria.

\hypertarget{ch:factorial-invariance}{%
\chapter{Invarianza di misura}\label{ch:factorial-invariance}}

I precedenti esempi di CFA presentati in questa dispensa sono stati stimati all'interno di un singolo gruppo, hanno utilizzato come input un'unica matrice covarianza e hanno portato alla stima dei parametri del modello sui quali non è stata imposta alcuna restrizione. In questo capitolo, le analisi precedenti verranno estese considerano il problema dell'invarianza di misura. Quello che ci chiediamo è se sia sensato considerare la medesima struttura fattoriale in gruppi diversi. In altre parole, ci chiediamo se viene misurata la stessa variabile latente tra gruppi diversi. Questa proprietà è chiamata \emph{invarianza di misura} \citep{meredith1993measurement}. L'approccio che viene utilizzato per stabilire l'evidenze dell'invarianza di misura è attraverso l'analisi fattoriale confermativa a gruppi multipli (\emph{multiple-group confirmatory factor analysis}, MG-CFA). È solo nella misura in cui viene dimostrata l'equivalenza di misura che sono possibili i confronti tra gruppi. Nel presente capitolo, verrà affrontato il invarianza di misura considerando prima il caso di indicatori continui e poi il caso di indicatori categoriali.

\hypertarget{indicatori-continui}{%
\section{Indicatori continui}\label{indicatori-continui}}

\hypertarget{intercette-degli-item}{%
\subsection{Intercette degli item}\label{intercette-degli-item}}

In generale, i modelli di equazioni strutturali vengono utilizzati per modellare unicamente la matrice di covarianza delle variabili osservate in un set di dati. Ricordiamo che, quando abbiamo introdotto il modello dell'analisi fattoriale,

\[
y_i = \mu + \lambda_j \xi_k + \delta_i,
\]

per semplicità abbiamo ignorato la media \(\mu\) degli indicatori esprimendo i dati osservati nei termini degli scarti dalla media, \(y_i -\mu\), in quanto ciò lascia immutate le covarianze. Tuttavia, in alcune applicazioni (quali l'invarianza di misura, ad esempio), è utile considerare anche le medie delle variabili osservate. Per ottenere ciò è possibile fare esplicito riferimento alle intercette delle equazioni precedenti nella sintassi \texttt{lavaan} del modello. È possibile fare riferimento all'intercetta di una variabile manifesta nel modo seguente:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{variable }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}
\end{Highlighting}
\end{Shaded}

laddove la parte sinistra dell'espressione precedente contiene il nome della variabile osservata a cui si fa riferimento. Per esempio, nel caso di un modello a due fattori comuni, è possibile aggiungere le intercette delle variabili manifeste nel modo seguente:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mod }\OtherTok{\textless{}{-}} \StringTok{"}
\StringTok{  \# two{-}factor model}
\StringTok{  f1 =\textasciitilde{} x1 + x2 + x3}
\StringTok{  f2 =\textasciitilde{} x4 + x5 + x6}
\StringTok{  \# intercepts}
\StringTok{  x1 \textasciitilde{} 1}
\StringTok{  x2 \textasciitilde{} 1}
\StringTok{  x3 \textasciitilde{} 1}
\StringTok{  x4 \textasciitilde{} 1}
\StringTok{  x5 \textasciitilde{} 1}
\StringTok{  x6 \textasciitilde{} 1}
\StringTok{"}
\end{Highlighting}
\end{Shaded}

Tuttavia, è più conveniente omettere le intercette nella specificazione del modello e aggiungere l'argomento \texttt{meanstructure\ =\ TRUE} nella funzione \texttt{cfa()}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{cfa}\NormalTok{(}
\NormalTok{  mod,}
  \AttributeTok{data =}\NormalTok{ d,}
  \AttributeTok{meanstructure =} \ConstantTok{TRUE}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Si noti che la statistica chi-quadrato e il numero di gradi di libertà sono gli stessi in un modello con o senza \texttt{meanstructure}. Il motivo è che, nel caso di un modello con \texttt{meanstructure}, vengono introdotti nuovi dati (il valore della media per ciascuna delle \(p\) variabili osservate) ma vengono anche aggiunti \(p\) parametri da stimare (un'intercetta per ciascuna delle \(p\) variabili osservate). Il risultato finale è che la bontà dell'adattamento resta immutata. In pratica, l'unico motivo per aggiungere le interecette nella sintassi del modello è quello di stabilire dei vincoli nella stima di tali parametri.

\hypertarget{terminologia}{%
\subsection{Terminologia}\label{terminologia}}

La discussione dell'invarianza di misura nel contesto della CFA fa uso della seguente terminologia.

\begin{itemize}
\tightlist
\item
  L'invarianza configurale (\emph{configural invariance}) verifica se la struttura dei fattori è la stessa tra i gruppi, ovvero verifica la presenza dello stesso numero di fattori e di pattern di saturazioni fattoriali simili tra gruppi.
\item
  L'invarianza metrica (\emph{metric invariance}) o ``invarianza fattoriale debole'' (\emph{weak factorial invariance}) verifica se i carichi fattoriali degli elementi sono gli stessi tra i gruppi. Invarianza scalare (\emph{scalar invariance}) o ``invarianza fattoriale forte'' verifica se le intercette sono le stesse tra i gruppi.
\item
  L'invarianza fattoriale rigorosa (\emph{strict factorial invariance}), infine, verifica se i residui degli indicatori sono gli stessi tra i gruppi.
\end{itemize}

\hypertarget{un-esempio-concreto}{%
\subsection{Un esempio concreto}\label{un-esempio-concreto}}

Consideriamo qui un esempio discusso da \citet{brown2015confirmatory}. Il modello CFA riguarda un modello di misurazione per la depressione maggiore così come definita nel DSM-IV. Ci sono 9 indicatori:

\begin{itemize}
\tightlist
\item
  MDD1, depressed mood;
\item
  MDD2, loss of interest in usual activities;
\item
  MDD3, weight/appetite change;
\item
  MDD4, sleep disturbance;
\item
  MDD5, psychomotor agitation/retardation;
\item
  MDD6, fatigue/loss of energy;
\item
  MDD7, feelings of worthlessness/guilt;
\item
  MDD8, concentration difficulties;
\item
  MDD9, thoughts of death/suicidality.
\end{itemize}

Leggiamo i dati:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d }\OtherTok{\textless{}{-}} \FunctionTok{readRDS}\NormalTok{(}
\NormalTok{  here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{(}\StringTok{"data"}\NormalTok{, }\StringTok{"mdd\_sex.RDS"}\NormalTok{)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Il problema riguarda l'invarianza fattoriale in funzione del genere. Consideriamo il seguente modello:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model\_mdd }\OtherTok{\textless{}{-}} \StringTok{"}
\StringTok{  MDD =\textasciitilde{} mdd1 + mdd2 + mdd3 + mdd4 + mdd5 + mdd6 + mdd7 + mdd8 +}
\StringTok{         mdd9}
\StringTok{  mdd1 \textasciitilde{}\textasciitilde{} mdd2}
\StringTok{"}
\end{Highlighting}
\end{Shaded}

Si noti la presenza di una correlazione residua tra gli indicatori \texttt{mdd1} e \texttt{mdd2}.

Esaminiamo dunque le varie forme di invarianza fattoriale:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# configural invariance}
\NormalTok{fit\_ef }\OtherTok{\textless{}{-}} \FunctionTok{cfa}\NormalTok{(}
\NormalTok{  model\_mdd,}
  \AttributeTok{data =}\NormalTok{ d,}
  \AttributeTok{group =} \StringTok{"sex"}\NormalTok{,}
  \AttributeTok{meanstructure =} \ConstantTok{TRUE}
\NormalTok{)}
\CommentTok{\# equal factor laodings}
\NormalTok{fit\_efl }\OtherTok{\textless{}{-}} \FunctionTok{update}\NormalTok{(}
\NormalTok{  fit\_ef,}
  \AttributeTok{group.equal =} \FunctionTok{c}\NormalTok{(}\StringTok{"loadings"}\NormalTok{)}
\NormalTok{)}
\CommentTok{\# equal indicator intercepts}
\NormalTok{fit\_eii }\OtherTok{\textless{}{-}} \FunctionTok{update}\NormalTok{(}
\NormalTok{  fit\_efl,}
  \AttributeTok{group.equal =} \FunctionTok{c}\NormalTok{(}\StringTok{"loadings"}\NormalTok{, }\StringTok{"intercepts"}\NormalTok{)}
\NormalTok{)}
\CommentTok{\# equal indicator error variances}
\NormalTok{fit\_eir }\OtherTok{\textless{}{-}} \FunctionTok{update}\NormalTok{(}
\NormalTok{  fit\_eii,}
  \AttributeTok{group.equal =} \FunctionTok{c}\NormalTok{(}\StringTok{"loadings"}\NormalTok{, }\StringTok{"intercepts"}\NormalTok{, }\StringTok{"residuals"}\NormalTok{)}
\NormalTok{)}
\CommentTok{\# equal factor variances}
\NormalTok{fit\_fv }\OtherTok{\textless{}{-}} \FunctionTok{update}\NormalTok{(}
\NormalTok{  fit\_eir,}
  \AttributeTok{group.equal =} \FunctionTok{c}\NormalTok{(}
    \StringTok{"loadings"}\NormalTok{, }\StringTok{"intercepts"}\NormalTok{, }\StringTok{"residuals"}\NormalTok{,}
    \StringTok{"lv.variances"}
\NormalTok{  )}
\NormalTok{)}
\CommentTok{\# equal latent means}
\NormalTok{fit\_fm }\OtherTok{\textless{}{-}} \FunctionTok{update}\NormalTok{(}
\NormalTok{  fit\_fv,}
  \AttributeTok{group.equal =} \FunctionTok{c}\NormalTok{(}
    \StringTok{"loadings"}\NormalTok{, }\StringTok{"intercepts"}\NormalTok{, }\StringTok{"residuals"}\NormalTok{,}
    \StringTok{"lv.variances"}\NormalTok{, }\StringTok{"means"}
\NormalTok{  )}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Confrontiamo i modelli:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{lavTestLRT}\NormalTok{(fit\_ef, fit\_efl, fit\_eii, fit\_eir, fit\_fv, fit\_fm)}
\CommentTok{\#\textgreater{} Chi{-}Squared Difference Test}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}         Df   AIC   BIC Chisq Chisq diff Df diff}
\CommentTok{\#\textgreater{} fit\_ef  52 27526 27785  98.9                   }
\CommentTok{\#\textgreater{} fit\_efl 60 27514 27735 102.8       3.93       8}
\CommentTok{\#\textgreater{} fit\_eii 68 27510 27695 115.3      12.47       8}
\CommentTok{\#\textgreater{} fit\_eir 77 27502 27645 125.0       9.71       9}
\CommentTok{\#\textgreater{} fit\_fv  78 27501 27639 125.8       0.79       1}
\CommentTok{\#\textgreater{} fit\_fm  79 27501 27635 127.7       1.92       1}
\CommentTok{\#\textgreater{}         Pr(\textgreater{}Chisq)}
\CommentTok{\#\textgreater{} fit\_ef            }
\CommentTok{\#\textgreater{} fit\_efl       0.86}
\CommentTok{\#\textgreater{} fit\_eii       0.13}
\CommentTok{\#\textgreater{} fit\_eir       0.37}
\CommentTok{\#\textgreater{} fit\_fv        0.37}
\CommentTok{\#\textgreater{} fit\_fm        0.17}
\end{Highlighting}
\end{Shaded}

Il confronto tra i precedenti modelli nidificati che introducono vincoli sempre più tringenti sui parametri indica che non vi è una ``significativa'' perdita di bontà dell'adattamento passando dal modello congenerico al modello che assume l'uguaglianza delle saturazioni fattoriali, delle intercette, delle varianze residue, delle varianze delle variabili latenti e delle medie nei due gruppi. Questi dati, dunque, forniscono forti evidenze di invarianza fattoriale tra maschi e femmine in relazione al costrutto di depressione maggiore.

\hypertarget{variabili-a-livello-ordinale}{%
\section{Variabili a livello ordinale}\label{variabili-a-livello-ordinale}}

I test di invarianza per i dati ordinali sono diversi da quelli utilizzati con continuo variabili in termini dello stimatore che viene utilizzato e del tipo di analisi statistica che viene svolta. Le variabili ordinali hanno opzioni di risposta che hanno un ordine logico, come come la gamma da fortemente in disaccordo a fortemente d'accordo; o da mai, a volte, spesso, a sempre. Queste opzioni possono essere ordinate logicamente e per convenzione ad esse venono assegnati valori numerici interi. Tuttavia, poiché le risposte ordinali non corrispondono a veri valori quantitativi (come 0 volte a settimana, 5 volte a settimana e 10 volte a settimana), l'assegnazione di numeri alle risposte ordinali da utilizzare nelle analisi è arbitraria. Ad esempio, le stesse cinque opzioni di risposta ordinate potrebbero essere assegnati valori da 0 a 4, da 1 a 5 o da 5 a 1. Pertanto, i dati ordinali non possono essere analizzati come se fossero continui. ``Le medie, le varianze e le covarianze delle variabili ordinali non hanno significato'' ( Jöreskog, p.~1). Tuttavia, l'ordinamento delle risposte può essere analizzato tramite apposite procedure speficiche ai dati ordinali. Abbiamo visto in precedenza come lo stimatore attualmente consigliato per i dati ordinali è quello dei minimi quadrati ponderati. Consideriamo qui il problema dell'invarianza di misura.

Oltre alla stima WLS, nell'analisi di dati ordinali viene utilizzata una matrice di correlazione policorica invece della solita matrice di covarianza. Per ciascuna coppia di variabili ordinali viene calcolata una correlazione policorica sulla base dell'ipotesi che una variabile continua latente normalmente distribuita sia responsabile delle frequenze osservate delle risposte ordinali in ciascuna variabile. Secondo questa ipotesi, ogni valore di risposta ordinale osservato corrisponde a un intervallo di valori normalizzati tra soglie, o cutoff, sulla variabile continua latente sottostante. Tali soglie (\(\tau_1, \tau_2, \dots, \tau_k\)) sono dei margini verticali che suddividono l'area sottesa alla funzione di densità della distribuzione normale sottostante in \(k\) sezioni, ciascuna delle quali corrisponde alla frequenza del punteggio ordinale che è stato osservato in quella categoria di risposta. L'invarianza delle soglie (\emph{treshold invariance}) assume che tali soglie necessarie per definire le correlazioni policoriche siano invarianti tra gruppi.

\citet{wu2016identification} mostrano come la procedura per la valutazione dell'invarianza di misura che è stata descritta in precedenza debba essere modificata nel caso di indicatori categoriali. La procedura usuale consiste nel definire prima un modello di riferimento e successivamente di imporre restrizioni crescenti ai parametri. Secondo \citet{wu2016identification}, tale approccio non è ottimale nel caso di dati categoriali perché dipende fortemente dal modo in cui vengono definite le soglie rispetto alle scale delle risposte continue latenti nel modello di base. Dunque, secondo \citet{wu2016identification}, è prima necessario valutare l'equivalenza delle soglie tra gruppi (\emph{threshold model}) e poi valutare il modello che ipotizza l'equivalenza tra i gruppi delle saturazioni fattoriali.

Per illutrare tale procedura, replichiamo qui il tutorial messo a punto da \citet{svetina2020multiple}. Questi autori utilizzano quattro item dei una scala del bullismo per tre paesi (31 = Azerbaigian; 40 = Austria; 246 = Finlandia). Tutti gli item sono misurati su una scala di tipo Likert a 4 punti, che va da 0 (mai) a 3 (almeno una volta alla settimana). Gli item di questa scala chiedono agli studenti quante volte durante l'anno è successo loro a scuola uno degli episodi in questione; per esempio: ``mi prendevano in giro o mi insultavano''. Le dimensioni del campione per l'Azerbaigian, l'Austria e la Finlandia sono rispettivamente 3808, 4457 e 4520. Leggiamo in dati in \(\textsf{R}\):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dat }\OtherTok{\textless{}{-}} \FunctionTok{read.table}\NormalTok{(}\StringTok{"data/BULLY.dat"}\NormalTok{, }\AttributeTok{header =} \ConstantTok{FALSE}\NormalTok{)}
\FunctionTok{names}\NormalTok{(dat) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"IDCNTRY"}\NormalTok{, }\StringTok{"R09A"}\NormalTok{, }\StringTok{"R09B"}\NormalTok{, }\StringTok{"R09C"}\NormalTok{, }\StringTok{"R09D"}\NormalTok{)}
\FunctionTok{head}\NormalTok{(dat)}
\CommentTok{\#\textgreater{}   IDCNTRY R09A R09B R09C R09D}
\CommentTok{\#\textgreater{} 1      31    3    3    0    0}
\CommentTok{\#\textgreater{} 2      31    0    0    0    0}
\CommentTok{\#\textgreater{} 3      31    3    2    1    3}
\CommentTok{\#\textgreater{} 4      31    0    0    3    0}
\CommentTok{\#\textgreater{} 5      31    0    0    0    0}
\CommentTok{\#\textgreater{} 6      31    0    0    0    0}
\end{Highlighting}
\end{Shaded}

Viene creata la matrice \texttt{all.results} per immagazzinare i risultati dei diversi modelli che verranno confrontati, chiamati \emph{baseline} (nessun vincolo tra gruppi), \emph{proposition 4} (equivalenza delle soglie tra gruppi), e \emph{proposition 7} (equivalenza delle soglie e delle saturazioni fattoriali tra gruppi). Gli indici di bontà dell'adattamento che verranno considerati sono: chi-square, df, p, RMSEA, CFI, e TLI.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{all.results }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\ConstantTok{NA}\NormalTok{, }\AttributeTok{ncol =} \DecValTok{6}\NormalTok{, }\AttributeTok{nrow =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{baseline-model}{%
\subsection{Baseline model}\label{baseline-model}}

Nel \emph{baseline model} non viene posto alcun vincolo tra i gruppi o le misure ripetute:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mod.cat }\OtherTok{\textless{}{-}} \StringTok{"F1 =\textasciitilde{} R09A + R09B + R09C + R09D"}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{baseline }\OtherTok{\textless{}{-}} \FunctionTok{measEq.syntax}\NormalTok{(}
  \AttributeTok{configural.model =}\NormalTok{ mod.cat,}
  \AttributeTok{data =}\NormalTok{ dat,}
  \AttributeTok{ordered =} \FunctionTok{c}\NormalTok{(}\StringTok{"R09A"}\NormalTok{, }\StringTok{"R09B"}\NormalTok{, }\StringTok{"R09C"}\NormalTok{, }\StringTok{"R09D"}\NormalTok{),}
  \AttributeTok{parameterization =} \StringTok{"delta"}\NormalTok{,}
  \AttributeTok{ID.fac =} \StringTok{"std.lv"}\NormalTok{,}
  \AttributeTok{ID.cat =} \StringTok{"Wu.Estabrook.2016"}\NormalTok{,}
  \AttributeTok{group =} \StringTok{"IDCNTRY"}\NormalTok{,}
  \AttributeTok{group.equal =} \StringTok{"configural"}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Informazioni sul modello baseline si ottengono nel modo seguente:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(baseline)}
\end{Highlighting}
\end{Shaded}

Le proprietà del modello possono essere esplicitate con la seguente istruzione:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cat}\NormalTok{(}\FunctionTok{as.character}\NormalTok{(baseline))}
\end{Highlighting}
\end{Shaded}

Per potere essere passato a \texttt{lavaan}, l'oggetto \texttt{baseline} deve essere in formato \texttt{char}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model.baseline }\OtherTok{\textless{}{-}} \FunctionTok{as.character}\NormalTok{(baseline)}
\end{Highlighting}
\end{Shaded}

Adattiamo il modello ai dati:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit.baseline }\OtherTok{\textless{}{-}} \FunctionTok{cfa}\NormalTok{(}
\NormalTok{  model.baseline,}
  \AttributeTok{data =}\NormalTok{ dat,}
  \AttributeTok{group =} \StringTok{"IDCNTRY"}\NormalTok{,}
  \AttributeTok{ordered =} \FunctionTok{c}\NormalTok{(}\StringTok{"R09A"}\NormalTok{, }\StringTok{"R09B"}\NormalTok{, }\StringTok{"R09C"}\NormalTok{, }\StringTok{"R09D"}\NormalTok{)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Salviamo i risultati:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{all.results[}\DecValTok{1}\NormalTok{, ] }\OtherTok{\textless{}{-}}
  \FunctionTok{round}\NormalTok{(}\FunctionTok{data.matrix}\NormalTok{(}
    \FunctionTok{fitmeasures}\NormalTok{(fit.baseline, }\AttributeTok{fit.measures =} \FunctionTok{c}\NormalTok{(}
      \StringTok{"chisq.scaled"}\NormalTok{, }\StringTok{"df.scaled"}\NormalTok{, }\StringTok{"pvalue.scaled"}\NormalTok{,}
      \StringTok{"rmsea.scaled"}\NormalTok{, }\StringTok{"cfi.scaled"}\NormalTok{, }\StringTok{"tli.scaled"}
\NormalTok{    ))}
\NormalTok{  ),}
  \AttributeTok{digits =} \DecValTok{3}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\hypertarget{invarianza-delle-soglie}{%
\subsection{Invarianza delle soglie}\label{invarianza-delle-soglie}}

Consideriamo ora il modello \emph{threshold invariance} \citep[chiamata \emph{Proposition 4} da][]{wu2016identification}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{prop4 }\OtherTok{\textless{}{-}} \FunctionTok{measEq.syntax}\NormalTok{(}
  \AttributeTok{configural.model =}\NormalTok{ mod.cat,}
  \AttributeTok{data =}\NormalTok{ dat,}
  \AttributeTok{ordered =} \FunctionTok{c}\NormalTok{(}\StringTok{"R09A"}\NormalTok{, }\StringTok{"R09B"}\NormalTok{, }\StringTok{"R09C"}\NormalTok{, }\StringTok{"R09D"}\NormalTok{),}
  \AttributeTok{parameterization =} \StringTok{"delta"}\NormalTok{,}
  \AttributeTok{ID.fac =} \StringTok{"std.lv"}\NormalTok{,}
  \AttributeTok{ID.cat =} \StringTok{"Wu.Estabrook.2016"}\NormalTok{,}
  \AttributeTok{group =} \StringTok{"IDCNTRY"}\NormalTok{,}
  \AttributeTok{group.equal =} \FunctionTok{c}\NormalTok{(}\StringTok{"thresholds"}\NormalTok{)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Adattiamo il modello ai dati:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model.prop4 }\OtherTok{\textless{}{-}} \FunctionTok{as.character}\NormalTok{(prop4)}
\NormalTok{fit.prop4 }\OtherTok{\textless{}{-}} \FunctionTok{cfa}\NormalTok{(}
\NormalTok{  model.prop4,}
  \AttributeTok{data =}\NormalTok{ dat,}
  \AttributeTok{group =} \StringTok{"IDCNTRY"}\NormalTok{,}
  \AttributeTok{ordered =} \FunctionTok{c}\NormalTok{(}\StringTok{"R09A"}\NormalTok{, }\StringTok{"R09B"}\NormalTok{, }\StringTok{"R09C"}\NormalTok{, }\StringTok{"R09D"}\NormalTok{)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Salviamo i risulati

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# store model fit information for proposition 4}
\NormalTok{all.results[}\DecValTok{2}\NormalTok{, ] }\OtherTok{\textless{}{-}}
  \FunctionTok{round}\NormalTok{(}\FunctionTok{data.matrix}\NormalTok{(}
    \FunctionTok{fitmeasures}\NormalTok{(fit.prop4, }\AttributeTok{fit.measures =} \FunctionTok{c}\NormalTok{(}
      \StringTok{"chisq.scaled"}\NormalTok{, }\StringTok{"df.scaled"}\NormalTok{, }\StringTok{"pvalue.scaled"}\NormalTok{,}
      \StringTok{"rmsea.scaled"}\NormalTok{, }\StringTok{"cfi.scaled"}\NormalTok{, }\StringTok{"tli.scaled"}
\NormalTok{    ))}
\NormalTok{  ),}
  \AttributeTok{digits =} \DecValTok{3}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

Eseguiamo il confronto tra il modello di \emph{threshold invariance} e il modello di \emph{baseline}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{lavTestLRT}\NormalTok{(fit.baseline, fit.prop4)}
\CommentTok{\#\textgreater{} Scaled Chi{-}Squared Difference Test (method = "satorra.2000")}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} lavaan }\AlertTok{NOTE}\CommentTok{:}
\CommentTok{\#\textgreater{}     The "Chisq" column contains standard test statistics, not the}
\CommentTok{\#\textgreater{}     robust test that should be reported per model. A robust difference}
\CommentTok{\#\textgreater{}     test is a function of two standard (not robust) statistics.}
\CommentTok{\#\textgreater{}  }
\CommentTok{\#\textgreater{}              Df AIC BIC Chisq Chisq diff Df diff}
\CommentTok{\#\textgreater{} fit.baseline  6          26.9                   }
\CommentTok{\#\textgreater{} fit.prop4    14          42.2       46.1       8}
\CommentTok{\#\textgreater{}              Pr(\textgreater{}Chisq)    }
\CommentTok{\#\textgreater{} fit.baseline               }
\CommentTok{\#\textgreater{} fit.prop4       2.2e{-}07 ***}
\CommentTok{\#\textgreater{} {-}{-}{-}}
\CommentTok{\#\textgreater{} Signif. codes:  }
\CommentTok{\#\textgreater{} 0 \textquotesingle{}***\textquotesingle{} 0.001 \textquotesingle{}**\textquotesingle{} 0.01 \textquotesingle{}*\textquotesingle{} 0.05 \textquotesingle{}.\textquotesingle{} 0.1 \textquotesingle{} \textquotesingle{} 1}
\end{Highlighting}
\end{Shaded}

\hypertarget{threshold-and-loading-invariance}{%
\subsection{Threshold and loading invariance}\label{threshold-and-loading-invariance}}

Consideriamo ora il modello \emph{threshold and loading invariance} \citep[chiamato \emph{Proposition 7} da][]{wu2016identification}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{prop7 }\OtherTok{\textless{}{-}} \FunctionTok{measEq.syntax}\NormalTok{(}
  \AttributeTok{configural.model =}\NormalTok{ mod.cat,}
  \AttributeTok{data =}\NormalTok{ dat,}
  \AttributeTok{ordered =} \FunctionTok{c}\NormalTok{(}\StringTok{"R09A"}\NormalTok{, }\StringTok{"R09B"}\NormalTok{, }\StringTok{"R09C"}\NormalTok{, }\StringTok{"R09D"}\NormalTok{),}
  \AttributeTok{parameterization =} \StringTok{"delta"}\NormalTok{,}
  \AttributeTok{ID.fac =} \StringTok{"std.lv"}\NormalTok{,}
  \AttributeTok{ID.cat =} \StringTok{"Wu.Estabrook.2016"}\NormalTok{,}
  \AttributeTok{group =} \StringTok{"IDCNTRY"}\NormalTok{,}
  \AttributeTok{group.equal =} \FunctionTok{c}\NormalTok{(}\StringTok{"thresholds"}\NormalTok{, }\StringTok{"loadings"}\NormalTok{)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Adattiamo il modello ai dati:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model.prop7 }\OtherTok{\textless{}{-}} \FunctionTok{as.character}\NormalTok{(prop7)}
\NormalTok{fit.prop7 }\OtherTok{\textless{}{-}} \FunctionTok{cfa}\NormalTok{(}
\NormalTok{  model.prop7,}
  \AttributeTok{data =}\NormalTok{ dat, }\AttributeTok{group =} \StringTok{"IDCNTRY"}\NormalTok{,}
  \AttributeTok{ordered =} \FunctionTok{c}\NormalTok{(}\StringTok{"R09A"}\NormalTok{, }\StringTok{"R09B"}\NormalTok{, }\StringTok{"R09C"}\NormalTok{, }\StringTok{"R09D"}\NormalTok{)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Salviamo i risultati:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{all.results[}\DecValTok{3}\NormalTok{, ] }\OtherTok{\textless{}{-}}
  \FunctionTok{round}\NormalTok{(}\FunctionTok{data.matrix}\NormalTok{(}
    \FunctionTok{fitmeasures}\NormalTok{(fit.prop7, }\AttributeTok{fit.measures =} \FunctionTok{c}\NormalTok{(}
      \StringTok{"chisq.scaled"}\NormalTok{, }\StringTok{"df.scaled"}\NormalTok{, }\StringTok{"pvalue.scaled"}\NormalTok{,}
      \StringTok{"rmsea.scaled"}\NormalTok{, }\StringTok{"cfi.scaled"}\NormalTok{, }\StringTok{"tli.scaled"}
\NormalTok{    ))}
\NormalTok{  ), }\AttributeTok{digits =} \DecValTok{3}\NormalTok{)}

\NormalTok{column.names }\OtherTok{\textless{}{-}}
  \FunctionTok{c}\NormalTok{(}
    \StringTok{"chisq.scaled"}\NormalTok{, }\StringTok{"df.scaled"}\NormalTok{, }\StringTok{"pvalue.scaled"}\NormalTok{, }\StringTok{"rmsea.scaled"}\NormalTok{,}
    \StringTok{"cfi.scaled"}\NormalTok{, }\StringTok{"tli.scaled"}
\NormalTok{  )}

\NormalTok{row.names }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"baseline"}\NormalTok{, }\StringTok{"prop4"}\NormalTok{, }\StringTok{"prop7"}\NormalTok{)}

\FunctionTok{colnames}\NormalTok{(all.results) }\OtherTok{\textless{}{-}}\NormalTok{ column.names}
\FunctionTok{rownames}\NormalTok{(all.results) }\OtherTok{\textless{}{-}}\NormalTok{ row.names}
\end{Highlighting}
\end{Shaded}

Eseguiamo i confronti tra modelli:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{lavTestLRT}\NormalTok{(fit.prop4, fit.prop7)}
\CommentTok{\#\textgreater{} Scaled Chi{-}Squared Difference Test (method = "satorra.2000")}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} lavaan }\AlertTok{NOTE}\CommentTok{:}
\CommentTok{\#\textgreater{}     The "Chisq" column contains standard test statistics, not the}
\CommentTok{\#\textgreater{}     robust test that should be reported per model. A robust difference}
\CommentTok{\#\textgreater{}     test is a function of two standard (not robust) statistics.}
\CommentTok{\#\textgreater{}  }
\CommentTok{\#\textgreater{}           Df AIC BIC Chisq Chisq diff Df diff}
\CommentTok{\#\textgreater{} fit.prop4 14          42.2                   }
\CommentTok{\#\textgreater{} fit.prop7 20          93.1       54.7       6}
\CommentTok{\#\textgreater{}           Pr(\textgreater{}Chisq)    }
\CommentTok{\#\textgreater{} fit.prop4               }
\CommentTok{\#\textgreater{} fit.prop7    5.4e{-}10 ***}
\CommentTok{\#\textgreater{} {-}{-}{-}}
\CommentTok{\#\textgreater{} Signif. codes:  }
\CommentTok{\#\textgreater{} 0 \textquotesingle{}***\textquotesingle{} 0.001 \textquotesingle{}**\textquotesingle{} 0.01 \textquotesingle{}*\textquotesingle{} 0.05 \textquotesingle{}.\textquotesingle{} 0.1 \textquotesingle{} \textquotesingle{} 1}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{lavTestLRT}\NormalTok{(fit.prop7, fit.baseline)}
\CommentTok{\#\textgreater{} Scaled Chi{-}Squared Difference Test (method = "satorra.2000")}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} lavaan }\AlertTok{NOTE}\CommentTok{:}
\CommentTok{\#\textgreater{}     The "Chisq" column contains standard test statistics, not the}
\CommentTok{\#\textgreater{}     robust test that should be reported per model. A robust difference}
\CommentTok{\#\textgreater{}     test is a function of two standard (not robust) statistics.}
\CommentTok{\#\textgreater{}  }
\CommentTok{\#\textgreater{}              Df AIC BIC Chisq Chisq diff Df diff}
\CommentTok{\#\textgreater{} fit.baseline  6          26.9                   }
\CommentTok{\#\textgreater{} fit.prop7    20          93.1        102      14}
\CommentTok{\#\textgreater{}              Pr(\textgreater{}Chisq)    }
\CommentTok{\#\textgreater{} fit.baseline               }
\CommentTok{\#\textgreater{} fit.prop7       2.3e{-}15 ***}
\CommentTok{\#\textgreater{} {-}{-}{-}}
\CommentTok{\#\textgreater{} Signif. codes:  }
\CommentTok{\#\textgreater{} 0 \textquotesingle{}***\textquotesingle{} 0.001 \textquotesingle{}**\textquotesingle{} 0.01 \textquotesingle{}*\textquotesingle{} 0.05 \textquotesingle{}.\textquotesingle{} 0.1 \textquotesingle{} \textquotesingle{} 1}
\end{Highlighting}
\end{Shaded}

Un confronto tra gli indici di bontà di adattamento dei tre modelli è fornito di seguito:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{all.results}
\CommentTok{\#\textgreater{}          chisq.scaled df.scaled pvalue.scaled}
\CommentTok{\#\textgreater{} baseline        50.94         6             0}
\CommentTok{\#\textgreater{} prop4          111.98        14             0}
\CommentTok{\#\textgreater{} prop7          210.64        20             0}
\CommentTok{\#\textgreater{}          rmsea.scaled cfi.scaled tli.scaled}
\CommentTok{\#\textgreater{} baseline        0.042      0.997      0.991}
\CommentTok{\#\textgreater{} prop4           0.041      0.993      0.992}
\CommentTok{\#\textgreater{} prop7           0.047      0.987      0.989}
\end{Highlighting}
\end{Shaded}

In conclusione, nel caso presente, il test del rapporto di verosimiglianza indica che non viene rispettata neppure l'invarianza delle soglie tra gruppi. Gli altri confronti, dunque, sono superflui.

  \bibliography{refs.bib,book.bib,packages.bib}

\printindex

\end{document}
