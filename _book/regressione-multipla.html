<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>1.2 Regressione multipla | Appunti di Costruzione e validazione di strumenti di misura dell’efficacia dell’intervento psicologico in neuropsicologia – B020881 (B213)</title>
  <meta name="description" content="This document contains the materials of the lessons of Costruzione e validazione di strumenti di misura dell’efficacia dell’intervento psicologico in neuropsicologia – B020881 (B213) (2021/2022) aimed at students of the second year of the Degree Course Laurea Magistrale in Psicologia (LM-51) of the University of Florence, Italy." />
  <meta name="generator" content="bookdown 0.24.4 and GitBook 2.6.7" />

  <meta property="og:title" content="1.2 Regressione multipla | Appunti di Costruzione e validazione di strumenti di misura dell’efficacia dell’intervento psicologico in neuropsicologia – B020881 (B213)" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This document contains the materials of the lessons of Costruzione e validazione di strumenti di misura dell’efficacia dell’intervento psicologico in neuropsicologia – B020881 (B213) (2021/2022) aimed at students of the second year of the Degree Course Laurea Magistrale in Psicologia (LM-51) of the University of Florence, Italy." />
  <meta name="github-repo" content="ccaudek/cfa_book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="1.2 Regressione multipla | Appunti di Costruzione e validazione di strumenti di misura dell’efficacia dell’intervento psicologico in neuropsicologia – B020881 (B213)" />
  
  <meta name="twitter:description" content="This document contains the materials of the lessons of Costruzione e validazione di strumenti di misura dell’efficacia dell’intervento psicologico in neuropsicologia – B020881 (B213) (2021/2022) aimed at students of the second year of the Degree Course Laurea Magistrale in Psicologia (LM-51) of the University of Florence, Italy." />
  

<meta name="author" content="Corrado Caudek" />


<meta name="date" content="2022-03-03" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="regressione-bivariata.html"/>
<link rel="next" href="ch:teoria_classica.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Appunti di Costruzione e valutazione di test psicometrici</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prefazione</a></li>
<li class="part"><span><b>I Il modello lineare</b></span></li>
<li class="chapter" data-level="1" data-path="lanalisi-di-regressione.html"><a href="lanalisi-di-regressione.html"><i class="fa fa-check"></i><b>1</b> L’analisi di regressione</a>
<ul>
<li class="chapter" data-level="1.1" data-path="regressione-bivariata.html"><a href="regressione-bivariata.html"><i class="fa fa-check"></i><b>1.1</b> Regressione bivariata</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="regressione-bivariata.html"><a href="regressione-bivariata.html#regressori-centrati"><i class="fa fa-check"></i><b>1.1.1</b> Regressori centrati</a></li>
<li class="chapter" data-level="1.1.2" data-path="regressione-bivariata.html"><a href="regressione-bivariata.html#minimi-quadrati"><i class="fa fa-check"></i><b>1.1.2</b> Minimi quadrati</a></li>
<li class="chapter" data-level="1.1.3" data-path="regressione-bivariata.html"><a href="regressione-bivariata.html#relazione-tra-b-e-r"><i class="fa fa-check"></i><b>1.1.3</b> Relazione tra <span class="math inline">\(b\)</span> e <span class="math inline">\(r\)</span></a></li>
<li class="chapter" data-level="1.1.4" data-path="regressione-bivariata.html"><a href="regressione-bivariata.html#attenuazione"><i class="fa fa-check"></i><b>1.1.4</b> Attenuazione</a></li>
<li class="chapter" data-level="1.1.5" data-path="regressione-bivariata.html"><a href="regressione-bivariata.html#coefficiente-di-determinazione"><i class="fa fa-check"></i><b>1.1.5</b> Coefficiente di determinazione</a></li>
<li class="chapter" data-level="1.1.6" data-path="regressione-bivariata.html"><a href="regressione-bivariata.html#errore-standard-della-regressione"><i class="fa fa-check"></i><b>1.1.6</b> Errore standard della regressione</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="regressione-multipla.html"><a href="regressione-multipla.html"><i class="fa fa-check"></i><b>1.2</b> Regressione multipla</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="regressione-multipla.html"><a href="regressione-multipla.html#significato-coefficienti-parziali-di-regressione"><i class="fa fa-check"></i><b>1.2.1</b> Significato coefficienti parziali di regressione</a></li>
<li class="chapter" data-level="1.2.2" data-path="regressione-multipla.html"><a href="regressione-multipla.html#relazioni-causali"><i class="fa fa-check"></i><b>1.2.2</b> Relazioni causali</a></li>
<li class="chapter" data-level="1.2.3" data-path="regressione-multipla.html"><a href="regressione-multipla.html#errore-di-specificazione"><i class="fa fa-check"></i><b>1.2.3</b> Errore di specificazione</a></li>
<li class="chapter" data-level="1.2.4" data-path="regressione-multipla.html"><a href="regressione-multipla.html#soppressione"><i class="fa fa-check"></i><b>1.2.4</b> Soppressione</a></li>
<li class="chapter" data-level="1.2.5" data-path="regressione-multipla.html"><a href="regressione-multipla.html#stepwise-regression"><i class="fa fa-check"></i><b>1.2.5</b> Stepwise regression</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II La teoria classica dei test</b></span></li>
<li class="chapter" data-level="2" data-path="ch:teoria_classica.html"><a href="ch:teoria_classica.html"><i class="fa fa-check"></i><b>2</b> Fondamenti teorici</a>
<ul>
<li class="chapter" data-level="2.1" data-path="valutazione-psicometrica-come-ragionamento-inferenziale.html"><a href="valutazione-psicometrica-come-ragionamento-inferenziale.html"><i class="fa fa-check"></i><b>2.1</b> Valutazione psicometrica come ragionamento inferenziale</a></li>
<li class="chapter" data-level="2.2" data-path="la-teoria-classica.html"><a href="la-teoria-classica.html"><i class="fa fa-check"></i><b>2.2</b> La Teoria Classica</a></li>
<li class="chapter" data-level="2.3" data-path="le-due-componenti-del-punteggio-osservato.html"><a href="le-due-componenti-del-punteggio-osservato.html"><i class="fa fa-check"></i><b>2.3</b> Le due componenti del punteggio osservato</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="le-due-componenti-del-punteggio-osservato.html"><a href="le-due-componenti-del-punteggio-osservato.html#il-punteggio-vero"><i class="fa fa-check"></i><b>2.3.1</b> Il punteggio vero</a></li>
<li class="chapter" data-level="2.3.2" data-path="le-due-componenti-del-punteggio-osservato.html"><a href="le-due-componenti-del-punteggio-osservato.html#somministrazioni-ripetute"><i class="fa fa-check"></i><b>2.3.2</b> Somministrazioni ripetute</a></li>
<li class="chapter" data-level="2.3.3" data-path="le-due-componenti-del-punteggio-osservato.html"><a href="le-due-componenti-del-punteggio-osservato.html#le-assunzioni-sul-punteggio-ottenuto"><i class="fa fa-check"></i><b>2.3.3</b> Le assunzioni sul punteggio ottenuto</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="lerrore-standard-della-misurazione-sigma_e.html"><a href="lerrore-standard-della-misurazione-sigma_e.html"><i class="fa fa-check"></i><b>2.4</b> L’errore standard della misurazione <span class="math inline">\(\sigma_E\)</span></a></li>
<li class="chapter" data-level="2.5" data-path="assiomi-della-teoria-classica.html"><a href="assiomi-della-teoria-classica.html"><i class="fa fa-check"></i><b>2.5</b> Assiomi della Teoria Classica</a></li>
<li class="chapter" data-level="2.6" data-path="lattendibilità-del-test.html"><a href="lattendibilità-del-test.html"><i class="fa fa-check"></i><b>2.6</b> L’attendibilità del test</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="lattendibilità-del-test.html"><a href="lattendibilità-del-test.html#la-varianza-del-punteggio-osservato"><i class="fa fa-check"></i><b>2.6.1</b> La varianza del punteggio osservato</a></li>
<li class="chapter" data-level="2.6.2" data-path="lattendibilità-del-test.html"><a href="lattendibilità-del-test.html#la-covarianza-tra-punteggio-osservato-e-punteggio-vero"><i class="fa fa-check"></i><b>2.6.2</b> La covarianza tra punteggio osservato e punteggio vero</a></li>
<li class="chapter" data-level="2.6.3" data-path="lattendibilità-del-test.html"><a href="lattendibilità-del-test.html#definizione-e-significato-dellattendibilità"><i class="fa fa-check"></i><b>2.6.3</b> Definizione e significato dell’attendibilità</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="attendibilità-e-modello-di-regressione-lineare.html"><a href="attendibilità-e-modello-di-regressione-lineare.html"><i class="fa fa-check"></i><b>2.7</b> Attendibilità e modello di regressione lineare</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="attendibilità-e-modello-di-regressione-lineare.html"><a href="attendibilità-e-modello-di-regressione-lineare.html#simulazione"><i class="fa fa-check"></i><b>2.7.1</b> Simulazione</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="misurazioni-parallele-e-affidabilità.html"><a href="misurazioni-parallele-e-affidabilità.html"><i class="fa fa-check"></i><b>2.8</b> Misurazioni parallele e affidabilità</a>
<ul>
<li class="chapter" data-level="2.8.1" data-path="misurazioni-parallele-e-affidabilità.html"><a href="misurazioni-parallele-e-affidabilità.html#la-correlazione-tra-misurazioni-parallele"><i class="fa fa-check"></i><b>2.8.1</b> La correlazione tra misurazioni parallele</a></li>
<li class="chapter" data-level="2.8.2" data-path="misurazioni-parallele-e-affidabilità.html"><a href="misurazioni-parallele-e-affidabilità.html#la-correlazione-tra-due-forme-parallele-del-test"><i class="fa fa-check"></i><b>2.8.2</b> La correlazione tra due forme parallele del test</a></li>
<li class="chapter" data-level="2.8.3" data-path="misurazioni-parallele-e-affidabilità.html"><a href="misurazioni-parallele-e-affidabilità.html#la-correlazione-tra-punteggio-osservato-e-punteggio-vero"><i class="fa fa-check"></i><b>2.8.3</b> La correlazione tra punteggio osservato e punteggio vero</a></li>
<li class="chapter" data-level="2.8.4" data-path="misurazioni-parallele-e-affidabilità.html"><a href="misurazioni-parallele-e-affidabilità.html#i-fattori-che-influenzano-lattendibilità"><i class="fa fa-check"></i><b>2.8.4</b> I fattori che influenzano l’attendibilità</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="metodi-alternativi-per-la-stima-del-coefficiente-di-attendibilità.html"><a href="metodi-alternativi-per-la-stima-del-coefficiente-di-attendibilità.html"><i class="fa fa-check"></i><b>2.9</b> Metodi alternativi per la stima del coefficiente di attendibilità</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="ch:missing_data.html"><a href="ch:missing_data.html"><i class="fa fa-check"></i><b>3</b> Dati mancanti</a>
<ul>
<li class="chapter" data-level="3.1" data-path="tipologie-di-dati-mancanti.html"><a href="tipologie-di-dati-mancanti.html"><i class="fa fa-check"></i><b>3.1</b> Tipologie di dati mancanti</a></li>
<li class="chapter" data-level="3.2" data-path="la-gestione-dei-dati-mancanti.html"><a href="la-gestione-dei-dati-mancanti.html"><i class="fa fa-check"></i><b>3.2</b> La gestione dei dati mancanti</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="la-gestione-dei-dati-mancanti.html"><a href="la-gestione-dei-dati-mancanti.html#metodo-direct-ml"><i class="fa fa-check"></i><b>3.2.1</b> Metodo Direct ML</a></li>
<li class="chapter" data-level="3.2.2" data-path="la-gestione-dei-dati-mancanti.html"><a href="la-gestione-dei-dati-mancanti.html#un-esempio-concreto"><i class="fa fa-check"></i><b>3.2.2</b> Un esempio concreto</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="ch:cat_data.html"><a href="ch:cat_data.html"><i class="fa fa-check"></i><b>4</b> Dati non gaussiani e categoriali</a>
<ul>
<li class="chapter" data-level="4.1" data-path="dati-non-gaussiani.html"><a href="dati-non-gaussiani.html"><i class="fa fa-check"></i><b>4.1</b> Dati non gaussiani</a></li>
<li class="chapter" data-level="4.2" data-path="dati-categoriali.html"><a href="dati-categoriali.html"><i class="fa fa-check"></i><b>4.2</b> Dati categoriali</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="dati-categoriali.html"><a href="dati-categoriali.html#un-esempio-concreto-1"><i class="fa fa-check"></i><b>4.2.1</b> Un esempio concreto</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="_blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Appunti di Costruzione e validazione di strumenti di misura dell’efficacia dell’intervento psicologico in neuropsicologia – B020881 (B213)</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="regressione-multipla" class="section level2" number="1.2">
<h2><span class="header-section-number">1.2</span> Regressione multipla</h2>
<p>Nella regressione multipla vengono utilizzati <span class="math inline">\(k &gt; 1\)</span> predittori:</p>
<p><span class="math display">\[
y_i = \alpha + \sum_{j=1}^k \beta_j x_i + \varepsilon_i.
\]</span>
L’interpretazione geometrica è simile a quella del modello bivariato. Nel caso di due predittori, il valore atteso della <span class="math inline">\(y\)</span> può essere rappresentato da un piano; nel caso di <span class="math inline">\(k &gt; 2\)</span> predittori, da un iper-piano. Nel caso di <span class="math inline">\(k=2\)</span>, tale piano è posto in uno spazio di dimensioni <span class="math inline">\(x_1\)</span>, <span class="math inline">\(x_2\)</span> (che possiamo immaginare definire un piano orizzontale) e <span class="math inline">\(y\)</span> (ortogonale a tale piano). La superficie piana che rappresenta <span class="math inline">\(\mathbb{E}(y)\)</span> è inclinata in maniera tale che l’angolo tra il piano e l’asse <span class="math inline">\(x_1\)</span> corrisponde a <span class="math inline">\(\beta_1\)</span> e l’angolo tra il piano e l’asse <span class="math inline">\(x_2\)</span> corrisponde a <span class="math inline">\(\beta_2\)</span>.</p>
<div id="significato-coefficienti-parziali-di-regressione" class="section level3" number="1.2.1">
<h3><span class="header-section-number">1.2.1</span> Significato coefficienti parziali di regressione</h3>
<p>Ai coefficienti parziali del modello di regressione multipla possiamo assegnare la seguente interpretazione:</p>
<p><em>Il coefficiente parziale di regressione <span class="math inline">\(\beta_j\)</span> rappresenta l’incremento atteso della <span class="math inline">\(y\)</span> se <span class="math inline">\(x_j\)</span> viene incrementata di un’unità, tenendo costante il valore delle altre variabili indipendenti.</em></p>
<p>Un modo per interpretare la locuzione “al netto dell’effetto delle altre variabili indipendenti” è quello di esaminare la relazione tra la <span class="math inline">\(y\)</span> parzializzata e la <span class="math inline">\(x_j\)</span> parzializzata. In questo contesto, parzializzare significa decomporre una variabile di due componenti: una componente che è linearmente predicibile da una o più altre variabili e una componente che è linearmente incorrelata con tali varibili “terze”.</p>
<p>Eseguiamo questa “depurazione” dell’effetto delle variabili “terze” sia sulla <span class="math inline">\(y\)</span> sia su <span class="math inline">\(x_j\)</span>. A questo punto possiamo esaminare la relazione bivariata che intercorre tra la componente della <span class="math inline">\(y\)</span> linearmente indipendente dalle variabili “terze” e la componente della <span class="math inline">\(x_j\)</span> linearmente indipendente dalle variabili “terze”. Il coefficiente di regressione bivariato così ottenuto è identico al coefficiente parziale di regressione nel modello di regressione multipla. Possiamo così ottenere un’interpretazione di <span class="math inline">\(\beta_j\)</span>.</p>
<p>Esaminiamo un caso concreto.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="regressione-multipla.html#cb18-1" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> rio<span class="sc">::</span><span class="fu">import</span>(</span>
<span id="cb18-2"><a href="regressione-multipla.html#cb18-2" aria-hidden="true" tabindex="-1"></a>  here<span class="sc">::</span><span class="fu">here</span>(<span class="st">&quot;data&quot;</span>, <span class="st">&quot;kidiq.dta&quot;</span>)</span>
<span id="cb18-3"><a href="regressione-multipla.html#cb18-3" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb18-4"><a href="regressione-multipla.html#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(d)</span>
<span id="cb18-5"><a href="regressione-multipla.html#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Rows: 434</span></span>
<span id="cb18-6"><a href="regressione-multipla.html#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Columns: 5</span></span>
<span id="cb18-7"><a href="regressione-multipla.html#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $ kid_score &lt;dbl&gt; 65, 98, 85, 83, 115, 98, 69, 106, 102, 95, 91, 58, 84, 78, 1…</span></span>
<span id="cb18-8"><a href="regressione-multipla.html#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $ mom_hs    &lt;dbl&gt; 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, …</span></span>
<span id="cb18-9"><a href="regressione-multipla.html#cb18-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $ mom_iq    &lt;dbl&gt; 121.11753, 89.36188, 115.44316, 99.44964, 92.74571, 107.9018…</span></span>
<span id="cb18-10"><a href="regressione-multipla.html#cb18-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $ mom_work  &lt;dbl&gt; 4, 4, 4, 3, 4, 1, 4, 3, 1, 1, 1, 4, 4, 4, 2, 1, 3, 3, 4, 3, …</span></span>
<span id="cb18-11"><a href="regressione-multipla.html#cb18-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $ mom_age   &lt;dbl&gt; 27, 25, 27, 25, 27, 18, 20, 23, 24, 19, 23, 24, 27, 26, 24, …</span></span></code></pre></div>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="regressione-multipla.html#cb19-1" aria-hidden="true" tabindex="-1"></a>fm <span class="ot">&lt;-</span> <span class="fu">lm</span>(kid_score <span class="sc">~</span> mom_iq <span class="sc">+</span> mom_work <span class="sc">+</span> mom_age <span class="sc">+</span> mom_hs, <span class="at">data =</span> d)</span>
<span id="cb19-2"><a href="regressione-multipla.html#cb19-2" aria-hidden="true" tabindex="-1"></a>fm<span class="sc">$</span>coef</span>
<span id="cb19-3"><a href="regressione-multipla.html#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; (Intercept)      mom_iq    mom_work     mom_age      mom_hs </span></span>
<span id="cb19-4"><a href="regressione-multipla.html#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  20.8226117   0.5620814   0.1337287   0.2198599   5.5611781</span></span></code></pre></div>
<p>Eseguiamo la parzializzazione di <span class="math inline">\(y\)</span> in funzione delle variabili <code>mom_work</code>, <code>mom_age</code> e <code>mom_hs</code>:</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="regressione-multipla.html#cb20-1" aria-hidden="true" tabindex="-1"></a>fm_y <span class="ot">&lt;-</span> <span class="fu">lm</span>(kid_score <span class="sc">~</span> mom_work <span class="sc">+</span> mom_age <span class="sc">+</span> mom_hs, <span class="at">data =</span> d)</span></code></pre></div>
<p>Lo stesso per <code>mom_iq</code>:</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="regressione-multipla.html#cb21-1" aria-hidden="true" tabindex="-1"></a>fm_x <span class="ot">&lt;-</span> <span class="fu">lm</span>(mom_iq <span class="sc">~</span> mom_work <span class="sc">+</span> mom_age <span class="sc">+</span> mom_hs, <span class="at">data =</span> d)</span></code></pre></div>
<p>Esaminiamo ora la regressione bivariata tra le componenti parzializzate della <span class="math inline">\(y\)</span> e di <span class="math inline">\(x_j\)</span>:</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="regressione-multipla.html#cb22-1" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(fm_y<span class="sc">$</span>residuals <span class="sc">~</span> fm_x<span class="sc">$</span>residuals)</span>
<span id="cb22-2"><a href="regressione-multipla.html#cb22-2" aria-hidden="true" tabindex="-1"></a>mod<span class="sc">$</span>coef</span>
<span id="cb22-3"><a href="regressione-multipla.html#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    (Intercept) fm_x$residuals </span></span>
<span id="cb22-4"><a href="regressione-multipla.html#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  -1.651851e-15   5.620814e-01</span></span></code></pre></div>
<p>Si vede come il coefficiente di regressione bivariato risulta identico al corrispondente coefficiente parziale di regressione.</p>
</div>
<div id="relazioni-causali" class="section level3" number="1.2.2">
<h3><span class="header-section-number">1.2.2</span> Relazioni causali</h3>
<p>Un altro modo per interpretare i coefficienti parziali di regressione è nell’ambito dei quelli che vengono chiamati i <em>path diagrams</em>. I diagrammi di percorso, che tratteremo in seguito e qui solo anticipiamo, descrivono le relazioni “causali” tra variabili: le variabili a monte del diagramma di percorso indicono le “cause” esogene e le variabili a valle indicano gli effetti, ovvero le variabili endogene. I coefficienti di percorso rappresentati graficamente come frecce orientate corrispondono all’effetto <em>diretto</em> sulla variabile verso cui punta la freccia della variabile a monte della freccia. Tali coefficienti di percorso non sono altro che i coefficienti parziali di regressione del modello di regressione multipla. In questo contesto, indicano l’effetto atteso <em>diretto</em> sulla variabile endogena dell’incremento di un’unità della variabile esogena, lasciano immutate tutte le altre relazioni strutturali del modello.</p>
<p>Usiamo la funzione <code>sem()</code> del pacchetto <code>lavaan</code> per definire il modello rappresentato nel successivo diagramma di percorso:</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="regressione-multipla.html#cb23-1" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="st">&quot;</span></span>
<span id="cb23-2"><a href="regressione-multipla.html#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="st">  kid_score ~ mom_hs + mom_iq + mom_work + mom_age</span></span>
<span id="cb23-3"><a href="regressione-multipla.html#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="st">&quot;</span></span></code></pre></div>
<p>Adattiamo il modello ai dati</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="regressione-multipla.html#cb24-1" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">sem</span>(model, <span class="at">data =</span> d)</span></code></pre></div>
<p>Il diagramma di percorso si ottiene con le seguenti istruzioni:</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="regressione-multipla.html#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="fu">semPaths</span>(</span>
<span id="cb25-2"><a href="regressione-multipla.html#cb25-2" aria-hidden="true" tabindex="-1"></a>  fit, <span class="st">&quot;est&quot;</span>,</span>
<span id="cb25-3"><a href="regressione-multipla.html#cb25-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">posCol =</span> <span class="fu">c</span>(<span class="st">&quot;black&quot;</span>),</span>
<span id="cb25-4"><a href="regressione-multipla.html#cb25-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">edge.label.cex =</span> <span class="fl">0.9</span>,</span>
<span id="cb25-5"><a href="regressione-multipla.html#cb25-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">sizeMan =</span> <span class="dv">7</span>,</span>
<span id="cb25-6"><a href="regressione-multipla.html#cb25-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">what =</span> <span class="st">&quot;path&quot;</span></span>
<span id="cb25-7"><a href="regressione-multipla.html#cb25-7" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p><img src="cfa_book_files/figure-html/unnamed-chunk-26-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>Come indicato nel diagramma, l’effetto diretto di <code>mom_iq</code> su <code>kid_score</code> è identico al corrispondente coefficiente parziale di regressione.</p>
</div>
<div id="errore-di-specificazione" class="section level3" number="1.2.3">
<h3><span class="header-section-number">1.2.3</span> Errore di specificazione</h3>
<p>Spiritosamente chiamato “heartbreak of L.O.V.E.” (Left-Out Variable Error; <span class="citation">Mauro (<a href="#ref-mauro1990understanding" role="doc-biblioref">1990</a>)</span>), l’errore di specificazione è una caratteristica fondamentale dei modelli di regressione che deve sempre essere tenuta a mente quando interpretiamo i risultati di questa analisi statistica. L’errore di specificazione si verifica quando escludiamo dal modello di regressione una variabile che</p>
<ul>
<li>è associata con altre variabili nel modello,</li>
<li>ha un effetto diretto sulla <span class="math inline">\(y\)</span>.</li>
</ul>
<p>Come conseguenza dell’errore di specificazione, la direzione e il segno dei coefficienti parziali di regressione risultano sistematicamente distorti.</p>
<p>Consideriamo un esempio con dati simulati nei quali immaginiamo che la prestazione sia positivamente associata alla motivazione e negativamente associata all’ansia. Immaginiamo inoltre che vi sia una correlazione positiva tra ansia a motivazione. Ci chiediamo cosa succede al coefficiente parziale della variabile “motivazione” se la variabile “ansia” viene esclusa dal modello di regressione.</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="regressione-multipla.html#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb26-2"><a href="regressione-multipla.html#cb26-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">400</span></span>
<span id="cb26-3"><a href="regressione-multipla.html#cb26-3" aria-hidden="true" tabindex="-1"></a>anxiety <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="dv">10</span>, <span class="fl">1.5</span>)</span>
<span id="cb26-4"><a href="regressione-multipla.html#cb26-4" aria-hidden="true" tabindex="-1"></a>motivation <span class="ot">&lt;-</span> <span class="fl">4.0</span> <span class="sc">*</span> anxiety <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="dv">0</span>, <span class="fl">3.5</span>)</span>
<span id="cb26-5"><a href="regressione-multipla.html#cb26-5" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(anxiety, motivation)</span>
<span id="cb26-6"><a href="regressione-multipla.html#cb26-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.8617706</span></span></code></pre></div>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="regressione-multipla.html#cb27-1" aria-hidden="true" tabindex="-1"></a>performance <span class="ot">&lt;-</span> <span class="fl">0.5</span> <span class="sc">*</span> motivation <span class="sc">-</span> <span class="fl">5.0</span> <span class="sc">*</span> anxiety <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="dv">0</span>, <span class="dv">3</span>)</span></code></pre></div>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="regressione-multipla.html#cb28-1" aria-hidden="true" tabindex="-1"></a>sim_dat2 <span class="ot">&lt;-</span> <span class="fu">tibble</span>(performance, motivation, anxiety)</span>
<span id="cb28-2"><a href="regressione-multipla.html#cb28-2" aria-hidden="true" tabindex="-1"></a>fm1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(performance <span class="sc">~</span> motivation <span class="sc">+</span> anxiety, sim_dat2)</span>
<span id="cb28-3"><a href="regressione-multipla.html#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(fm1)</span>
<span id="cb28-4"><a href="regressione-multipla.html#cb28-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; (Intercept)  motivation     anxiety </span></span>
<span id="cb28-5"><a href="regressione-multipla.html#cb28-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   1.3711965   0.4953886  -5.1052176</span></span></code></pre></div>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="regressione-multipla.html#cb29-1" aria-hidden="true" tabindex="-1"></a>fm2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(performance <span class="sc">~</span> motivation, sim_dat2)</span>
<span id="cb29-2"><a href="regressione-multipla.html#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fm2)</span>
<span id="cb29-3"><a href="regressione-multipla.html#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb29-4"><a href="regressione-multipla.html#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Call:</span></span>
<span id="cb29-5"><a href="regressione-multipla.html#cb29-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; lm(formula = performance ~ motivation, data = sim_dat2)</span></span>
<span id="cb29-6"><a href="regressione-multipla.html#cb29-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb29-7"><a href="regressione-multipla.html#cb29-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Residuals:</span></span>
<span id="cb29-8"><a href="regressione-multipla.html#cb29-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     Min      1Q  Median      3Q     Max </span></span>
<span id="cb29-9"><a href="regressione-multipla.html#cb29-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; -13.501  -3.409   0.005   3.311  12.616 </span></span>
<span id="cb29-10"><a href="regressione-multipla.html#cb29-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb29-11"><a href="regressione-multipla.html#cb29-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Coefficients:</span></span>
<span id="cb29-12"><a href="regressione-multipla.html#cb29-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;              Estimate Std. Error t value Pr(&gt;|t|)    </span></span>
<span id="cb29-13"><a href="regressione-multipla.html#cb29-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; (Intercept) -12.39720    1.44591  -8.574 2.24e-16 ***</span></span>
<span id="cb29-14"><a href="regressione-multipla.html#cb29-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; motivation   -0.43717    0.03553 -12.305  &lt; 2e-16 ***</span></span>
<span id="cb29-15"><a href="regressione-multipla.html#cb29-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; ---</span></span>
<span id="cb29-16"><a href="regressione-multipla.html#cb29-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb29-17"><a href="regressione-multipla.html#cb29-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb29-18"><a href="regressione-multipla.html#cb29-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Residual standard error: 4.866 on 398 degrees of freedom</span></span>
<span id="cb29-19"><a href="regressione-multipla.html#cb29-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Multiple R-squared:  0.2756, Adjusted R-squared:  0.2738 </span></span>
<span id="cb29-20"><a href="regressione-multipla.html#cb29-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; F-statistic: 151.4 on 1 and 398 DF,  p-value: &lt; 2.2e-16</span></span></code></pre></div>
<p>Il risultato prodotto dal modello di regressione è sbagliato: come conseguenza dell’errore di specificazione, il segno del coefficiente parziale di regressione della variabile “motivazione” è negativo, anche se nel vero modello di regressione tale coefficiente ha il segno opposto. Quindi, se noi interpretassimo il coefficiente parziale ottenuto in termini casuali, saremmo portati a concludere che la motivazione fa diminuire la prestazione anche se, in realtà (nel modello generatore dei dati), è vero l’opposto.</p>
<p>È facile vedere perché questo si verifica. Supponiamo che il vero modello sia</p>
<p><span class="math display">\[
y = \alpha + \beta_1 X_1 + \beta_2 X_2 + \varepsilon
\]</span>
che verrebbe stimato con</p>
<p><span class="math display">\[
y = a + b_1 X_1 + b_2 X_2 + e.
\]</span>
Supponiamo che il ricercatore creda invece che</p>
<p><span class="math display">\[
y = \alpha^\prime + \beta_1^\prime X_1 + \varepsilon^\prime
\]</span></p>
<p>e quindi stimi</p>
<p><span class="math display">\[
y = a^\prime + b_1^\prime X_1 + e^\prime
\]</span></p>
<p>omettendo <span class="math inline">\(X_2\)</span> dal modello.</p>
<p>Ci chiediamo che relazione ci sia tra <span class="math inline">\(b_1^\prime\)</span> e <span class="math inline">\(b_1\)</span>.</p>
<p>La formula per <span class="math inline">\(b_1^\prime\)</span> è</p>
<p><span class="math display">\[
\begin{align}
b_1^\prime &amp;= \frac{\mbox{Cov}(X_1, Y)}{\mbox{Var}(X_1)}\notag\\
&amp;= \frac{\mbox{Cov}(X_1, a + b_1 X_1 + b_2 X_2 + e)}{\mbox{Var}(X_1)}\notag\\
&amp;= \frac{\mbox{Cov}(X_1, a)+b_1 \mbox{Cov}(X_1, X_1) + b_2 \mbox{Cov}(X_1, X_2) + \mbox{Cov}(X_1, e)}{\mbox{Var}(X_1)}\notag\\
&amp;= \frac{0 + b_1 \mbox{Var}(X_1) + b_2 \mbox{Cov}(X_1, X_2) + 0}{\mbox{Var}(X_1)}\notag\\
&amp;= b_1 + b_2 \frac{\mbox{Cov}(X_1, X_2)}{\mbox{Var}(X_1)}.
\end{align}
\]</span></p>
<p>Quindi, se <span class="math inline">\(X_2\)</span> viene erroneamente omesso dal modello,</p>
<p><span class="math display">\[
\mathbb{E}(b_1^\prime) = \beta_1 + \beta_2 \frac{\sigma_{12}}{\sigma_1^2}.
\]</span>
Verifichiamo per i dati dell’esempio che stiamo discutendo. Nel caso presente, <span class="math inline">\(X_1\)</span> è <code>motivation</code> e <span class="math inline">\(X_2\)</span> + <code>anxiety</code>. Dunque, applicando la formula precedente, otteniamo lo stesso valore per il coefficiente di regressione associato a <code>motivation</code> che era stato ottenuto adattando ai dati il modello <code>performance ~ motivation</code>, ovvero:</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="regressione-multipla.html#cb30-1" aria-hidden="true" tabindex="-1"></a>fm1<span class="sc">$</span>coef[<span class="dv">2</span>] <span class="sc">+</span> fm1<span class="sc">$</span>coef[<span class="dv">3</span>] <span class="sc">*</span> <span class="fu">cov</span>(sim_dat2<span class="sc">$</span>motivation, sim_dat2<span class="sc">$</span>anxiety) <span class="sc">/</span> <span class="fu">var</span>(sim_dat2<span class="sc">$</span>motivation)</span>
<span id="cb30-2"><a href="regressione-multipla.html#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; motivation </span></span>
<span id="cb30-3"><a href="regressione-multipla.html#cb30-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; -0.4371675</span></span></code></pre></div>
</div>
<div id="soppressione" class="section level3" number="1.2.4">
<h3><span class="header-section-number">1.2.4</span> Soppressione</h3>
<p>Le conseguenze dell’errore di specificazione sono chiamate “soppressione” (<em>suppression</em>). In generale, si ha soppressione quando (1) il valore assoluto del peso beta di un predittore è maggiore di quello della sua correlazione bivariata con il criterio o (2) i due hanno segni opposti.</p>
<ul>
<li>L’esempio descritto sopra è un caso di <em>soppressione negativa</em>, dove il predittore ha correlazioni bivariate positive con il criterio, ma si riceve un peso beta negativo nell’analisi di regressione multipla.</li>
<li>Un secondo tipo di soppressione è la <em>soppressione classica</em>, in cui un predittore non è correlato al criterio ma riceve un peso beta diverso da zero se un altro predittore viene controllato.</li>
<li>C’è anche la <em>soppressione reciproca</em> che può verificarsi quando due variabili sono correlate positivamente con il criterio ma negativamente tra loro.</li>
</ul>
</div>
<div id="stepwise-regression" class="section level3" number="1.2.5">
<h3><span class="header-section-number">1.2.5</span> Stepwise regression</h3>
<p>Un’implicazione della soppressione è che i predittori non dovrebbero essere selezionati in base ai valori delle correlazioni bivariate con il criterio. Queste associazioni di ordine zero non controllano gli effetti degli altri predittori, quindi i loro valori possono essere fuorvianti rispetto ai coefficienti di regressione parziale per le stesse variabili. Per lo stesso motivo, il fatto che le correlazioni bivariate con il criterio siano statisticamente significative o meno è irrilevante per quanto riguarda la selezione dei predittori. Sebbene le procedure informatiche di regressione rendano facile tali processi di selezione dei predittori, i ricercatori dovrebbero evitare di usare tali metodi. Il rischio è che anche piccole, ma non rilevate, non-linearità o effetti indiretti tra i predittori possano seriamente distocere i coefficienti di regressione parziale. È meglio selezionare giudiziosamente il minor numero di predittori sulla base di ragioni teoriche o dei risultati di ricerche precedenti.</p>
<p>Una volta selezionati, ci sono due modi di base per inserire i predittori nell’equazione di regressione: uno consiste nell’inserire tutti i predittori contemporaneamente. L’altro è inserirli nel corso di una serie di passaggi, ovvero mediante usando una procedura sequenziale. L’ordine di ingresso può essere determinato in base a uno di due diversi standard: teorici (razionali) o empirici (statistici). Lo standard razionale corrisponde alla regressione gerarchica, in cui si comunica al computer un ordine fisso per inserire i predittori. Ad esempio, a volte le variabili demografiche vengono inserite nel primo passaggio, quindi nel secondo passaggio viene inserita una variabile psicologica di interesse. Questo ordine non solo controlla le variabili demografiche ma permette anche di valutare il potere predittivo della variabile psicologica, al di là di quello delle semplici variabili demografiche. Quest’ultimo può essere stimato come l’aumento della correlazione multipla al quadrato, o <span class="math inline">\(\Delta R^2\)</span>, da quella della fase 1 con solo predittori demografici a quella della fase 2 con tutti i predittori nell’equazione di regressione.</p>
<p>Un esempio di standard statistico è la regressione <em>stepwise</em>, in cui il computer seleziona l’inserimento dei predittori in base esclusivamente alla significatività statistica; cioè, viene chiesto: quale predittore, se inserito nell’equazione, avrebbe il valore_<span class="math inline">\(p\)</span> più piccolo per il test del suo coefficiente di regressione parziale? Dopo la selezione, i predittori in una fase successiva possono essere rimossi dall’equazione di regressione in base ai loro valori-<span class="math inline">\(p\)</span> (ad esempio, se <span class="math inline">\(p \geq\)</span> .05). Il processo stepwise si interrompe quando, aggiungendo più predittori, <span class="math inline">\(\Delta R^2\)</span> non migliora. Varianti della regressione stepwise includono <em>forward inclusion</em>, in cui i predittori selezionati non vengono successivamente rimossi dal modello, e <em>backward elimination</em>, che inizia con tutti i predittori nel modello per poi rimuoverne alcuni in passi successivi.
I problemi relativi ai metodi stepwise sono così gravi da essere effettivamente banditi in alcuni giornali. Un problema è che fanno leva su risultati che si ottengono per caso, in dipendenza delle idiosincrasie del campione (quindi, non replicabili).</p>
<p>In secondo luogo, una volta che un insieme finale di predittori selezionati razionalmente è stato inserito nell’equazione di regressione, tali predittori non dovrebbero essere successivamente rimossi se i loro coefficienti di regressione non sono statisticamente significativi: il ricercatore non dovrebbe sentirsi in dovere di lasciar perdere ogni predittore che non risulta statisticamente significativo. In campioni piccoli, la potenza dei test di significatività è bassa e la rimozione di un predittore non significativo può alterare sostanzialmente la soluzione. Se c’è una buona ragione per includere un predittore, allora è meglio lasciarlo nel modello, fino a prova contraria.</p>

</div>
</div>
<!-- </div> -->



<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-mauro1990understanding" class="csl-entry">
Mauro, Robert. 1990. <span>“<span class="nocase">Understanding LOVE (left out variables error): A method for estimating the effects of omitted variables.</span>”</span> <em>Psychological Bulletin</em> 108 (2): 314–29.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="regressione-bivariata.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="ch:teoria_classica.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/ccaudek/ds4psy/edit/master/010_regression.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["cfa_book.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
