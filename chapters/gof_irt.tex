\chapter{Verifica delle assunzioni e proprietà}
\label{chapter:goodness_of_fit_irt} 

%% un esempio di analisi è fornito nella pagina
%% http://wiki.r-project.org/rwiki/doku.php?id=packages:cran:ltm
%% può essere usato come esempio conclusivo dei modelli irt

%--------------------------------------------------------------

I modelli IRT possono essere sottoposti a tre tipi di verifiche: la verifica delle assunzioni, la verifica delle proprietà e la verifica dell'adattamento del modello ai dati (o valutazione del fit).

\section{La verifica delle assunzioni}

L'assunzione di unidimensionalità non può mai essere completamente rispettata poiché le prestazioni del rispondente sono influenzate da
esistono molteplici fattori, quali ad esempio: la personalità, il livello di motivazione, l'ansia, le esperienze precedenti con i questionari, la tendenza a tirare ad indovinare quando in dubbio e l'uso di altre capacità cognitive oltre a quella che si suppone venga essere misurata in maniera predominante dal test. Sebbene questi fattori non siano direttamente misurabili, ciò che è richiesto è che esista tra essi un fattore ``dominante'' che sintetizzi l'abilità latente del rispondente.

\subsection{Unidimensionalità}

Per verificare l'assunzione di unidimensionalità del tratto latente si possono utilizzare diverse tecniche. Ad esempio, in \R\; viene implementata una procedura, chiamata {\it modified parallel analysis}, per stabilire quando le violazioni di questa assunzione siano troppo severe da consentire una stima soddisfacente dei parametri dei modelli IRT. Come indicato da Drasgow e Lissak  (1983), tale analisi inizia con la matrice dei punteggi di $N$ rispondenti su $p$ item. Viene poi calcolata la matrice $N \times p$ di correlazioni prodotto-momento tra i punteggi degli item. Il quadrato delle correlazioni multiple tra i punteggi a ciascun item e i rimanenti $p - 1$ punteggi viene utilizzato quale stima della comunalità e da tale matrice ridotta di correlazioni vengono stimati gli autovalori. Questa analisi viene ripetuta per una matrice di valori causali estratti da una normale standardizzata.  Il $j$-esimo fattore  estratto dai dati reali viene mantenuto se il suo autovalore ha valore maggiore dell'$j$-esimo autovalore estratto dai dati sintetici. Tale metodo è implementato nella funzione {\tt unidimTest()} disponibile nel pacchetto {\tt ltm}.

\begin{exmp}
Consideriamo il test prodotto dalla funzione {\tt unidimTest()} nel caso dei dati contenuti nel data frame {\tt LSAT}:
\begin{lstlisting}
library(ltm)
out1 <- unidimTest(ltm(LSAT ~ z1), B = 200)
out1
#> 
#> Unidimensionality Check using Modified Parallel Analysis
#> 
#> Alternative hypothesis: the second eigenvalue of the  
#> observed data is substantially larger than the second 
#> eigenvalue of data under the assumed IRT model
#> 
#> Second eigenvalue in the observed data: 0.2254
#> Average of second eigenvalues in Monte Carlo samples: 
#> 0.2557
#> Monte Carlo samples: 200
#> p-value: 0.6517
\end{lstlisting}
Il test eseguito suggerisce che, nel caso di questi dati, l'assunzione di unidimensionalità è rispettata. Consideriamo ora i dati contenuti nel data frame {\tt WIRST}.
\begin{lstlisting}
out2 <- unidimTest(ltm(WIRS ~ z1), B = 200)
out2
#> Second eigenvalue in the observed data: 1.1291
#> Average of second eigenvalues in Monte Carlo samples: 
#> 0.5557
#> Monte Carlo samples: 200
#> p-value: 0.005
\end{lstlisting}
In questo secondo esempio, invece, il test fornisce evidenze di violazione dell'assunzione di unidimensionalità.
\end{exmp}

%\begin{figure}
%  \begin{center}
%    \includegraphics[width=7cm]{Rplot_WIRST_DimTest.pdf}
%    \caption{{\it Autovalori per il test di dimensionalità.  I dati sono contenuti nel data frame {\tt WIRST}.}}
%    \label{fig:lsat_dimTest}
%  \end{center}
%\end{figure}

\subsection{La bontà dell'adattamento}

La bontà di adattamento si verifica valutando la congruenza tra i dati
e il modello. Se un modello non è appropriato, l'utilizzo dei parametri
stimati risulta compromesso. La bontà dell'adattamento viene verificata mediante vari tipi di indici.  Qui ne esamineremo i seguenti: (\emph{i}) indici basati sulle statistiche 
$\chi^2$ o $G^2$, (\emph{ii}) indici basati sui residui standardizzati,
(\emph{iii}) indici basati sulla funzione di verosimiglianza,
(\emph{iv}) il rapporto di verosimiglianze, (\emph{v}) indici derivati
dalla regressione logistica.


\subsubsection{Statistiche $\chi^2$ o $G^2$}

Un test per la bontà di adattamento può essere eseguito mediante la statistica $\chi^2$ 
\begin{equation}
\sum_{r=1}^{2^p}\frac{ [O(r) - E(r)]^2 }{E(r)},
\end{equation}
dove $r$ rappresenta un pattern di risposta, $O(r)$ e $E(r)$ rappresentano le frequenze osservate e le frequenze attese e $p$ indica il numero di item. I gradi di libertà sono uguali al numero di pattern di risposta meno il numero di parametri stimati dal modello. 

\begin{exmp}
Si condiderino i dati simulati contenuti nel data frame {\tt raschdat1} disponibili nel pacchetto {\tt eRm}.  Adattiamo il modello di Rasch con parametro di discriminazione uguale a 1:
\begin{lstlisting}
fitRasch.c <- rasch(raschdat1, constraint = cbind(ncol(X) + 1, 1))
\end{lstlisting}
\noindent Il pacchetto {\tt ltm} consente di calcolare una statistica $\chi^2$ mediante la funzione {\tt GoF.rasch()}.  La funzione esegue un test parametrico di tipo bootstrap basato sulla statistica chi-quadrato.  Tale procedura è preferibile alla tradizionale approssimazione chi-quadrato in quanto la procedura tradizionale non è valida nel caso di un grande numero di item (ovvero, nel caso di molte configurazioni di risposta aventi frequenze attese minori di 1).
\begin{lstlisting}
#> Bootstrap Goodness-of-Fit using Pearson chi-squared
#> 
#> Tobs: 98435.71 
#> data-sets: 101 
#> p-value: 0.178 
\end{lstlisting}
Con un $p$-valore di $0.178$ non ci sono evidenze di mancanza di adattamento del modello ai dati.
\end{exmp}

%---------------------------------------------------------------------------
\subsubsection{Item Fit}

Il calcolo della statistica  \emph{item fit} richiede (i) la stima dei parametri di abilità e difficoltà, (ii) la formazione di un piccolo numero di gruppi di osservazioni con livelli simili di abilità, (iii) il confronto, tramite una statistica chi-quadrato, tra la proporzione empirica di risposte corrette ad un item in un intervallo e la probabilità di una risposta corretta stimata dal modello. 
La statistica \emph{item fit} ha la seguente forma:
\begin{equation}
\sum_{j=1}^G  \frac{N_j(O_{ij}-E_{ij})^2}{E_{ij}(1-E_{ij})},
\end{equation}
\noindent dove $i$ è l'item e $j$ è l'intervallo creato i rispondenti sulla base delle delle abilità stimate, $G$ è il numero di intervalli in cui il continuum dell'abilità è stato suddiviso, $N_j$ è il numero di rispondenti che cadono nell'intervallo $j$-esimo, $O_{ij}$ è la proporzione osservata di risposte corrette (o positive) per l'item $i$-esimo nell'intervallo $j$-esimo,  $E_{ij}$ è la probabilità stimata dal modello per una risposta corretta (o positiva) per l'item $i$-esimo in corrispondenza del livello mediano di abilità dell'intervallo $j$-esimo. 
Questa statistica si distribuisce come $\chi^2$ con un numero di
gradi di libertà uguale a $G-m$, dove $m$ è il numero dei parametri
stimati dal modello.


% \section{Metodo dei residui standard}\label{item_person_fit}

% Nell'analisi dei dati IRT, vengono solitamente esclusi dall'analisi  rispondenti e item in base ai valori assunti dagli indici  {\it item-fit} e {\it person-fit}. Entrambi questi indici sono basati sui residui del modello. Per calcolare tali residui, la matrice $\boldsymbol{P}$ delle probabilità predette dal modello  viene sottratta dalla matrice $\boldsymbol{X}$ dei dati osservati ottendendo in questo modo la matrice $\boldsymbol{Y}_{I \times J}$ dei residui {\it score}. Dividendo la matrice $\boldsymbol{Y}$ per la varianza delle risposte, si ottiene la matrice $\boldsymbol{Z}$ dei residui standardizzati. La somma dei valori colonna innalzati al quadrato e divisa per il numero di item corrisponde all'indice {\it person-fit} e la somma dei valori riga innalzati al quadrato  e divisa per il numero di rispondenti corrisponde all'indice  {\it item-fit}. Entrambi sono distribuiti come $\chi^2$ con gradi di libertà $J-1$ e $I-1$, rispettivamente. Sulla base di questi indici, statistiche standardizzate  ponderate ({\it infit}) o non ponderate ({\it outfit}) possono essere calcolate per valutare l'adattamento agli item o ai rispondenti. 

% Il metodo dei residui standard per la verifica della bontà dell'adattamento si fonda sulla differenza tra la risposta $X_{ij}= 1, \;0$, attribuita dal rispondente $i$-esimo al  $j$-esimo item, e il valore atteso per quella risposta $P_{ij}=E(X_{ij})$, dove il valore atteso è la probabilità che quell'item riceva una risposta corretta secondo il modello IRT. Il residuo standard si calcola nel modo seguente:
% \begin{equation}
% Z_{ij}^2=\frac{X_{ij}-P_{ij}}{P_{ij}(1-P_{ij})}
% \end{equation}

% Nel caso del modello di Rasch, la statistica $Z^2$ si riduce a $\exp[-(\theta_i-\beta_j)]$ per una risposta corretta e a $\exp(\theta_i-\beta_j)$ per una risposta sbagliata.
% Considerimo il caso in cui il livello di abilità è molto maggiore della difficoltà dell'item, per esempio $\theta_i-\beta_j=4$. In tali circostanze, secondo il modello di Rasch, la probabilità di una risposta corretta è uguale a $P=\exp(4)/(1+\exp(4))=0.98$. Se il $j$-esimo item riceve una risposta corretta da parte dell'$i$-esimo rispondente,  
% % ovvero $\theta_i \gg \beta_j$.  In tali circostanze i modelli IRT predicono che la probabilità predetta di una risposta corretta sarà  grande. Per esempio, se $\theta_i-\beta_j=4$, allora il modello di Rasch predice che  una risposta corretta sarà osservata con probabilità pari a $P=\exp(4)/(1+\exp(4))=0.98$. Nel caso di una risposta corretta,
% la statistica $Z_{ij}^2$ assume  il valore di 
% \begin{equation*}
% Z^2_{ij}=\frac{(1-P_{ij})^2}{P_{ij}(1-P_{ij})}=\exp(-4)=0.02
% \end{equation*}
% \noindent Se la risposta al  $j$-esimo item è sbagliata, invece, la statistica $Z_{ij}^2$  è uguale a
% \begin{equation*}
% Z_{ij}^2=\frac{(0-P_{ij})^2}{P_{ij}(1-P_{ij})}=\exp(4)=54.60
% \end{equation*}

% \noindent Le statistiche $Z_{ij}^2$, sommate sugli $I$ rispondenti e divise per $I$, producono il  \emph{residuo standardizzato} per il $j$-esimo item:
% \begin{equation}
% \text{Item Fit} = \sum_{i=1}^I \frac{Z_{ij}^2}{I}
% \end{equation} 

% \noindent Tale residuo standardizzato segue la distribuzione $\chi^2$ con $I-1$ gradi di libertà (Wright, \& Panchapakesan, 1969) \citep{wright:1969}. 

% Allo stesso modo, sommando su tutti gli item
% \begin{equation}
% \text{Person Fit} = \sum_{j=1}^J \frac{Z_{ij}^2}{J}
% \end{equation}  

% \noindent si ottiene il residuo standardizzato per l'$i$-esimo rispondente. In questo caso, il residuo standardizzato segue la distribuzione  $\chi^2$ con $J-1$ gradi di libertà.

% \subsection{Sommario}

% In conclusione, nel caso di item dicotomici, gli indici di bontà dell'adattamento basati sui residui standardizzati possono essere calcolati usando le formule seguenti:\\

% \begin{tabular}{ll}
% $X_{ij}=0, \; 1$ & risposta osservata\\ 
% $P_{ij}$ & probabilità predetta dal modello\\ 
% $Q_{ij}=P_{ij}(1-P_{ij})$ & varianza della risposta\\ 
% $Y_{ij}=X_{ij}-P_{ij}$ & residui {\it score}\\
% $Z_{ij}=Y_{ij}/Q_{ij}^{1/2}$ & residui standardizzati \\
% \end{tabular}\\

% \bigskip
% Indici di Infit e Outfit:\\

% \begin{tabular}{ll}
% $U_i=\sum_{j=1}^J Z^2_{ij}/J$ & Person Outfit\\ 
% $U_j=\sum_{i=1}^I Z^2_{ij}/I$ & Item Outfit\\ 
% $V_i=\sum_{j=1}^J Z^2_{ij}/ \sum_{j=1}^JQ_{ij}$ & Person Infit\\ 
% $V_j=\sum_{i=1}^I Z^2_{ij}/ \sum_{i=1}^IQ_{ij}$ & Item Infit  \\ 
% \end{tabular}\\

% \bigskip
% Errori standard\\

% \begin{tabular}{ll}
% $SE_U= \left[\sum(1/Q-4)\right]^{1/2} / \sum J$ & Outfit\\ 
% $SE_V= \left(\sum Q - 4\sum Q^2\right)^{1/2} / \sum Q$ & Infit\\ 
% \end{tabular}\\

% \bigskip
% Standardizzazione degli indici della bontà di adattamento\\

% \begin{tabular}{ll}
% $T_U= (U^{1/3}-1)(3/SE_U)+(SE_U/3)$ & Outfit \\ 
% $T_V= (V^{1/3}-1)(3/SE_V)+(SE_V/3)$ & Infit \\ 
% \end{tabular}\\

%
%Si considerino i dati simulati contenuti nel data frame {\tt raschdat1} disponibili nel pacchetto {\tt eRm}.  Adattiamo il modello di Rasch usando la funzione {\tt RM()}:
%\medskip
%\begin{lstlisting}
%> res <- RM(raschdat1)
%\end{lstlisting}
%\medskip
%\noindent Le statistiche relative agli item si ottengono nel modo seguente.  Riportiamo quisolo le prime 10 delle 30 righe della matrice prodotta da {\tt itemfit()}:
%\medskip
%\begin{lstlisting}
%> p.res <- person.parameter(res)
%> itemfit(p.res)
%
%Itemfit Statistics: 
%      Chisq  df p-value Outfit MSQ Infit MSQ
%I1   81.960 100   0.906      0.820     0.956
%I2   99.754 100   0.488      0.998     1.068
%I3   99.031 100   0.509      0.990     0.950
%I4   84.222 100   0.871      0.842     0.888
%I5  108.892 100   0.255      1.089     1.118
%I6  121.981 100   0.067      1.220     1.172
%I7   88.410 100   0.790      0.884     0.968
%I8  106.900 100   0.300      1.069     0.947
%I9   87.800 100   0.803      0.878     0.941
%I10  86.028 100   0.839      0.860     0.903
%\end{lstlisting}


% \noindent Le statistiche relative ai rispondenti sono le seguente.  Nuovamente, riportiamo solo le prime 10 delle 100 righe della matrice prodotta da {\tt personfit()}:

% \medskip
% \begin{lstlisting}
% > personfit(p.res)

% Personfit Statistics: 
%       Chisq df p-value Outfit MSQ Infit MSQ
% P1   19.836 30   0.921      0.661     1.001
% P2   35.676 30   0.219      1.189     1.089
% P3   24.199 30   0.763      0.807     1.041
% P4   20.991 30   0.888      0.700     0.900
% P5   27.385 30   0.603      0.913     1.007
% P6   29.811 30   0.475      0.994     1.091
% P7   20.707 30   0.897      0.690     0.880
% P8   57.763 30   0.002      1.925     1.003
% P9   25.579 30   0.696      0.853     1.056
% P10  31.693 30   0.382      1.056     1.036
% \end{lstlisting}


%---------------------------------------------------------------------------
\subsubsection{Person Fit}

Per valutare l'adattamento delle configurazioni delle risposte agli item, sono stati proposti molti indici detti {\it person-fit} (Meijer, \& Sijtsma, 1995). Considereremo qui la statistica chiamata $\ell_z$ e proposta da Drasgow, Levine e Williams (1985).  La statistica  $\ell_z$ è basata sulla funzione di log-verosimiglianza:
\begin{equation}
\ell = \sum_{i=1}^p x_i P_i(\theta) + (1- x_i)\log[1-P_i(\theta)],
\end{equation}
dove $i$ sono gli item ($i=1,\dots, p$). 

Due problemi sorgono quando $\ell$ viene usata quale indice di bontà di adattamento.  In primo luogo, la statistica $\ell$ non è standardizzata, il che significa che la classificazione di una configurazione di risposte come aberrante o normale dipende da $\theta$. In secondo luogo, per potere classificare una configurazione di risposte come aberrante, è necessario conoscere la distribuzione della statistica sotto l'ipotesi nulla.  

Per superare i problemi della dipendenza dall'abilità $\theta$ e della distribuzione campionaria sconosciuta, Drasgow, Levine e Williams (1985) hanno proposto una versione standardizzata di $\ell$, denotata con $\ell_z$:
\begin{equation}
\ell_z = \frac{\ell - \mathscr{E}(\ell)}{\sqrt{\mathscr{V}(\ell)}},
\end{equation}
\noindent dove $\mathscr{E}(l)$ e $\mathscr{V}(l)$ denotano il valore atteso e la varianza di $\ell$, rispettivamente. Queste quantità sono date da
\begin{equation}
\mathscr{E}(\ell) = \sum_{i=1}^p \left\{P_i(\theta) \log [ P_i(\theta) ] + [1-P_i(\theta)] \log[1-P_i(\theta)]  \right\},
\end{equation}

\begin{equation}
\mathscr{V}(l) = \sum_{i=1}^p P_i(\theta)  [1-P_i(\theta)] \left\{ \log \left[ \frac{ P_i(\theta)  }{1 -P_i(\theta)  } \right] \right\}^2.
\end{equation}
La statistica $\ell_z$ ha un valore atteso pari a $0$ e una varianza unitaria quando i rispondenti rispondono in maniera coerente ai parametri stimati del modello IRT. Grandi valori negativi (minori di $-2$) indicano configurazioni di risposte aberranti.  Grandi valori positivi indicano un adattamento migliore di quello previsto dal modello. 

Uno dei limiti degli indici {\it person-fit} è che sono in grado di identificare configurazioni aberranti di risposte, ma non c'è modo di stabilire quali siano le cause di questa mancanza di adattamento.  Un secondo problema con questi indici riguarda il potere statistico.  In questo contesto, il potere statistico è definito come la capacità di identificare una configurazione di risposte aberrante quando essa è presente. I ricercatori hanno stabilito che, per aumentare il potere statistico di tali indici, è necessario che i questionari contengano molti item (più di 30), i parametri di difficoltà abbiano un'ampia gamma di valori e gli item siano dotati di un grande potere discriminante (Meijer, Molenaar, \& Sijtsma, 1994; Reise, \& Flannery, 1996).


%\subsection{Illustrazione}
%
%Si considerino i dati simulati contenuti nel data frame {\tt raschdat1} disponibili nel pacchetto {\tt eRm}. Adattiamo ai dati un modello di Rasch e utilizziamo la funzione {\tt person.fit()} contenute nel pacchetto {\tt ltm}. Vengono calcolate sono le statistiche $\ell_0$ di  Levine e Rubin (1979) e $\ell_z$ di Drasgow et al. (1985). Vengono riportati qui sotto i primi $10$ dei $100$ valori della statistica $\ell_z$:
%
%\begin{lstlisting}
%> fitRasch.c <- rasch(raschdat1, constraint = cbind(ncol(X) + 1, 1))
%> out$p.values
%             Lz
%1   0.763731974
%2   0.781673576
%3   0.899651606
%4   0.525534225
%5   0.653319644
%6   0.644084807
%7   0.151852544
%8   0.588188948
%9   0.270119333
%10  0.393444454
%\end{lstlisting}

\subsection{Confronto tra modelli}

Come nel caso di altri modelli basati sulle procedure di massima verosimiglianza,  il confronto tra modelli IRT nidificati può essere realizzato utilizzando la statistica del \emph{rapporto di verosimiglianze}.  Il modello 2PL è nidificato nel modello 3PL in quanto può essere derivato da esso ponendo il vincolo $\gamma=0$.  Il modello di Rasch è nidificato nel modello 2PL potendo essere derivato da esso imponendo il vincolo $\alpha=0$.  Il test del rapporto di verosimiglianze può dunque essere usato per stabilire se i parametri aggiuntivi $\alpha$ e $\gamma$ migliorano l'adattamento del modello ai dati.

\begin{exmp}
Si considerino i dati simulati contenuti nel data frame {\tt raschdat1} disponibili nel pacchetto {\tt eRm}.  Iniziamo ad adattare il modello di Rasch con parametro di discriminazione uguale a 1:
\begin{lstlisting}
fitRasch.c <- rasch(
  raschdat1, 
  constraint = cbind(ncol(X) + 1, 1)
  )
fitRasch.c
#> Log.Lik: -1752.944
\end{lstlisting}
Adattiamo ora il modello di Rasch senza porre vincoli sul parametro di discriminazione:
\begin{lstlisting}
fitRasch <- rasch(raschdat1)
fitRasch
#> Log.Lik: -1752.882
\end{lstlisting}
Nel secondo modello  viene stimato un parametro aggiuntivo rispetto al modello precedente.  Il test del rapporto di verosimiglianze, dunque, avrà un grado di libertà:
\begin{lstlisting}
anova(fitRasch.c, fitRasch)
#> 
#>  Likelihood Ratio Table
#>                AIC     BIC  log.Lik  LRT df p.value
#> fitRasch.c 3565.89 3644.04 -1752.94                
#> fitRasch   3567.76 3648.52 -1752.88 0.13  1   0.724
\end{lstlisting}
Il massimo della funzione di log-verosimiglianza si estrae dall'oggetto creato dalla funzione {\tt rasch()} nel modo seguente:
\begin{lstlisting}
fitRasch.c$log.Lik
#> [1] -1752.944
fitRasch$log.Lik
#> [1] -1752.882
\end{lstlisting}
Il test del rapporto di verosimiglianze è uguale a $$G^2=-2(\ell_v -\ell_g)$$ dove $\ell_v$ e $\ell_g$ sono, rispettivamente, i massimi delle funzioni di log-verosimiglianza del modello vincolato e del modello generale: 
\begin{lstlisting}
G2 <- -2 * (fitRasch.c$log.Lik - fitRasch$log.Lik)
G2
#> [1] 0.1250849
\end{lstlisting}
La statistica $G^2$ si distribuisce come $\chi^2$ con un grado di libertà. Il $p$-valore dunque sarà uguale a
\begin{lstlisting}
1 - pchisq(G2, 1)
#> [1] 0.7235836
\end{lstlisting}
La perdita di adattamento del modello con un parametro aggiuntivo non è dunque statisticamente significativa: viene dunque mantenuto il modello più semplice.
Adattiamo ora il modello 2PL:
\begin{lstlisting}
fit2PL <- ltm(X ~ z1)
fit2PL
#> Coefficients:
#>          Dffclt  Dscrmn
#> Item 1   -1.270   1.133
#> Item 2    0.168   0.797
#> Item 3   -0.564   1.078
#> Item 4    0.656   1.524
#> Item 5    2.397   0.561
#> Item 6    0.170   0.481
#> Item 7   -0.466   1.085
#> Item 8   -0.500   1.128
#> Item 9   -0.314   1.140
#> Item 10   1.112   1.281
#> Item 11   1.008   0.793
#> Item 12  -0.168   1.270
#> Item 13   1.645   1.061
#> Item 14   3.587   0.589
#> Item 15  -0.168   0.845
#> Item 16   0.820   0.957
#> Item 17  -0.257   0.507
#> Item 18   0.395   0.662
#> Item 19   0.931   1.041
#> Item 20  -0.767   0.572
#> Item 21  -0.643   1.264
#> Item 22  -0.629   1.475
#> Item 23  -0.623   0.734
#> Item 24   0.237   0.746
#> Item 25   0.763   1.601
#> Item 26  -0.899   1.212
#> Item 27   0.290   0.993
#> Item 28   0.367   1.606
#> Item 29   0.746   1.499
#> Item 30  -0.627   0.824
#> 
#> Log.Lik: -1737.207
\end{lstlisting}
Il modello 2PL stima 30 parametri aggiuntivi rispetto al modello di Rasch con parametro di discriminazione uguale a 1.  Il test del rapporto di verosimiglianze avrà dunque 30 gradi di libertà:
\begin{lstlisting}
anova(fitRasch.c, fit2PL)
#> 
#>  Likelihood Ratio Table
#>                AIC     BIC  log.Lik   LRT df p.value
#> fitRasch.c 3565.89 3644.04 -1752.94                 
#> fit2PL     3594.41 3750.72 -1737.21 31.47 30   0.392
\end{lstlisting}
Il fatto che ad ogni item venga attribuito un diverso potere discriminante non migliora in maniera significativa l'adattamento del modello ai dati. 
Adattiamo ora il modello 3PL:
\begin{lstlisting}
fit3PL <- tpm(X)
fit3PL
#> Coefficients:
#>          Gussng  Dffclt  Dscrmn
#> Item 1    0.420  -0.266   2.076
#> Item 2    0.000   0.153   0.781
#> Item 3    0.000  -0.566   1.095
#> Item 4    0.000   0.629   1.596
#> Item 5    0.000   1.994   0.682
#> Item 6    0.424   1.317  21.424
#> Item 7    0.441   0.673  92.702
#> Item 8    0.000  -0.495   1.168
#> Item 9    0.278   0.308   2.455
#> Item 10   0.090   1.077   2.569
#> Item 11   0.000   1.104   0.689
#> Item 12   0.000  -0.165   1.320
#> Item 13   0.000   1.530   1.138
#> Item 14   0.000   3.119   0.681
#> Item 15   0.310   0.563   2.634
#> Item 16   0.000   0.777   0.996
#> Item 17   0.000  -0.276   0.518
#> Item 18   0.365   1.323  60.341
#> Item 19   0.000   0.916   1.030
#> Item 20   0.541   1.042  27.472
#> Item 21   0.000  -0.672   1.195
#> Item 22   0.000  -0.606   1.574
#> Item 23   0.000  -0.567   0.855
#> Item 24   0.338   0.693  84.187
#> Item 25   0.000   0.696   1.872
#> Item 26   0.000  -0.951   1.132
#> Item 27   0.000   0.272   1.021
#> Item 28   0.000   0.368   1.566
#> Item 29   0.060   0.748   2.465
#> Item 30   0.000  -0.637   0.832
#> 
#> Log.Lik: -1723.819
\end{lstlisting}
Il test del rapporto di verosimiglianze tra il modello 3PL e il modello di Rasch con parametro di discriminazione uguale a 1 produce
\begin{lstlisting}
anova(fitRasch.c, fit3PL)
#> 
#>  Likelihood Ratio Table
#>                AIC     BIC  log.Lik   LRT df p.value
#> fitRasch.c 3565.89 3644.04 -1752.94                 
#> fit3PL     3627.64 3862.10 -1723.82 58.25 60    0.54
\end{lstlisting}
un risultato non significativo.  Per questi dati (simulati), dunque, l'introduzione dei parametri di discriminazione $\alpha_j$ e di guessing $\gamma_i$ non migliora l'adattamento ai dati.
\end{exmp}

\subsubsection{Indici derivati dalla regressione logistica}

La funzione {\tt gofIRT} del pacchetto {\tt eRm} fornisce una serie di
misure di bontà di adattamento derivate dalla regressione logistica
(Mair, Reise, \& Bentler, 2008). Tra quelle forite
dalla funzione {\tt gofIRT}, alcune sono state discusse in precedenza,
tra cui l'indice di Hosmer-Lemeshow, la statistica $R^2$, la matrice
di confusione con le frequenze relative dei valori osservati e
predetti, l'area sotto la curva ROC.  
Sono inoltre forniti i seguenti indici: Accuracy = $(VN+VP)/(VN+VP+FN+FP)$, 
Sensitivity = $VP/(VP+FN)$, Specificity = $VN/(FP+VN)$,
dove $VP$ = veri positivi, 
$FP$ = falsi positivi, 
$VN$ = veri negativi,
$FN$ = falsi negativi.

\begin{exmp}

Si considerino i dati simulati contenuti nel data frame {\tt raschdat1} disponibili nel pacchetto {\tt eRm}.  

\begin{lstlisting}
library(eRm)
data(raschdat1)
res <- RM(raschdat1)
pres <- person.parameter(res)
gof.res <- gofIRT(pres)
summary(gof.res)
#> 
#> Goodness-of-Fit Tests
#>                       value         df p-value
#> Collapsed Deviance  770.574        780   0.588
#> Hosmer-Lemeshow       6.793          8   0.559
#> Rost Deviance      2564.654 1073741794   1.000
#> Casewise Deviance  3221.328       2945   0.000
#> 
#> R-Squared Measures
#> Pearson R2: 0.275
#> Sum-of-Squares R2: 0.275
#> McFadden R2: 0.287
#> 
#> Classifier Results - Confusion Matrix (relative frequencies)
#>          observed
#> predicted     0     1
#>         0 0.404 0.135
#>         1 0.130 0.330
#> 
#> Accuracy: 0.735
#> Sensitivity: 0.709
#> Specificity: 0.757
#> Area under ROC: 0.803
#> Gini coefficient: 0.606
\end{lstlisting}
\end{exmp}





